import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
import json
import plotly.express as px
import plotly.graph_objects as go
import time

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), 'scraper'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'ml'))

try:
    import auto_scraper
    from feature_engineering import process_data
except ImportError as e:
    st.error(f"Import Error: {e}")

st.set_page_config(page_title="AI Keiba Predictor", layout="wide")

# --- Utils ---
@st.cache_resource
def load_model(mode="JRA"):
    model_path = os.path.join(os.path.dirname(__file__), f"ml/models/lgbm_model_nar.pkl" if mode == "NAR" else "ml/models/lgbm_model.pkl")
    if os.path.exists(model_path):
        with open(model_path, 'rb') as f:
            return pickle.load(f)
    return None

@st.cache_resource
def load_model_metadata(mode="JRA"):
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã‚€"""
    meta_path = os.path.join(os.path.dirname(__file__), f"ml/models/lgbm_model_nar_meta.json" if mode == "NAR" else "ml/models/lgbm_model_meta.json")
    if os.path.exists(meta_path):
        with open(meta_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

def get_data_freshness(mode="JRA"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—"""
    db_path = os.path.join(os.path.dirname(__file__), "database_nar.csv" if mode == "NAR" else "database.csv")
    if os.path.exists(db_path):
        import datetime
        mtime = os.path.getmtime(db_path)
        last_updated = datetime.datetime.fromtimestamp(mtime)
        days_ago = (datetime.datetime.now() - last_updated).days
        return last_updated.strftime("%Y-%m-%d %H:%M"), days_ago
    return None, None

def calculate_confidence_score(ai_prob, model_meta, jockey_compat=None, course_compat=None, distance_compat=None):
    """
    äºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰

    Args:
        ai_prob: AIäºˆæ¸¬ç¢ºç‡ï¼ˆ0-1ï¼‰
        model_meta: ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        jockey_compat: é¨æ‰‹ç›¸æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        course_compat: ã‚³ãƒ¼ã‚¹é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        distance_compat: è·é›¢é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰

    Returns:
        int: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
    """
    if not model_meta:
        return 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # ===== 1. ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦: ãƒ¢ãƒ‡ãƒ«ã®AUCã‹ã‚‰ç®—å‡º =====
    base_confidence = model_meta.get('performance', {}).get('auc', 0.75) * 100

    # ===== 2. ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹èª¿æ•´ =====
    data_size = model_meta.get('data_stats', {}).get('total_records', 0)
    if data_size < 1000:
        data_penalty = -20  # ãƒ‡ãƒ¼ã‚¿é‡å°‘ãªã„
    elif data_size < 3000:
        data_penalty = -8
    elif data_size < 5000:
        data_penalty = -3
    else:
        data_penalty = 0

    # ===== 3. äºˆæ¸¬ç¢ºç‡ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé€£ç¶šçš„ãªèª¿æ•´ï¼‰ =====
    # 0.5ã‹ã‚‰é›¢ã‚Œã‚‹ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒç¢ºä¿¡ã‚’æŒã£ã¦ã„ã‚‹ï¼‰
    # 0.5ã«è¿‘ã„ã»ã©ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒè¿·ã£ã¦ã„ã‚‹ï¼‰
    distance_from_uncertain = abs(ai_prob - 0.5)

    # è·é›¢ã«åŸºã¥ãä¿¡é ¼åº¦ãƒœãƒ¼ãƒŠã‚¹: 0.5é›¢ã‚Œã¦ã„ã‚‹ã¨æœ€å¤§+20ã€0.0ã ã¨-20
    # å¼ã‚’èª¿æ•´ã—ã¦ç¯„å›²ã‚’æ‹¡å¤§
    prob_bonus = (distance_from_uncertain * 2 - 0.25) * 40

    # ã•ã‚‰ã«æ¥µç«¯ãªäºˆæ¸¬ï¼ˆ<0.05 or >0.95ï¼‰ã«ã¯è¿½åŠ ãƒœãƒ¼ãƒŠã‚¹
    if ai_prob < 0.05 or ai_prob > 0.95:
        prob_bonus += 12

    # AIç¢ºç‡ãŒæ¥µç«¯ã«ä½ã„å ´åˆã¯ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§ï¼‰
    if ai_prob < 0.08:
        prob_bonus -= 10

    # ===== 4. é©æ€§ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆæ–°è¦è¿½åŠ ï¼‰ =====
    compat_bonus = 0

    # åˆ©ç”¨å¯èƒ½ãªé©æ€§ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ
    compat_scores = []
    if jockey_compat is not None and not pd.isna(jockey_compat):
        compat_scores.append(jockey_compat)
    if course_compat is not None and not pd.isna(course_compat):
        compat_scores.append(course_compat)
    if distance_compat is not None and not pd.isna(distance_compat):
        compat_scores.append(distance_compat)

    if compat_scores:
        avg_compat = sum(compat_scores) / len(compat_scores)
        min_compat = min(compat_scores)

        # å¹³å‡é©æ€§ã«ã‚ˆã‚‹èª¿æ•´
        if avg_compat >= 9:
            compat_bonus = +15  # å…¨ã¦é«˜é©æ€§
        elif avg_compat >= 7:
            compat_bonus = +8
        elif avg_compat >= 5:
            compat_bonus = 0
        elif avg_compat >= 3:
            compat_bonus = -12
        else:
            compat_bonus = -25  # ãƒ‡ãƒ¼ã‚¿å“è³ªãŒä½ã„

        # æœ€ä½ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹è¿½åŠ ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆã„ãšã‚Œã‹ã®é©æ€§ãŒæ¥µç«¯ã«ä½ã„å ´åˆï¼‰
        if min_compat < 3:
            compat_bonus -= 15  # è‡´å‘½çš„ãªä¸é©æ€§
        elif min_compat < 5:
            compat_bonus -= 8

    # ===== æœ€çµ‚è¨ˆç®— =====
    confidence = base_confidence + data_penalty + prob_bonus + compat_bonus

    # ç¯„å›²ã‚’æ‹¡å¤§: 20-95ï¼ˆã‚ˆã‚Šå·®åˆ¥åŒ–ï¼‰
    return int(max(20, min(95, confidence)))

def load_schedule_data(mode="JRA"):
    json_path = os.path.join(os.path.dirname(__file__), "todays_data_nar.json" if mode == "NAR" else "todays_data.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# --- UI ---
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Logic Explanation
with st.expander("â„¹ï¸ ã“ã®AIäºˆæƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ã¤ã„ã¦ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)"):
    st.markdown("""
    ### ğŸ§  AIäºˆæƒ³ã®ä»•çµ„ã¿
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**LightGBM**ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€éå»ã®è†¨å¤§ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ1ç€ï¼ˆå‹åˆ©ï¼‰ã®ç¢ºç‡ã€ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
    
    #### ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
    - **åŸºæœ¬æƒ…å ±**: æ ç•ªã€é¦¬ç•ªã€é¦¬é½¢ã€æ–¤é‡ã€é¨æ‰‹
    - **éå»5èµ°ã®æˆç¸¾**: ç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã€ä¸Šã‚Š3Fã€é€šéé †ï¼ˆè„šè³ªï¼‰ã€é¦¬ä½“é‡ã€é¦¬å ´çŠ¶æ…‹ã€**å¤©æ°—**ã€**æœ€çµ‚ã‚ªãƒƒã‚º**
    - **ç›´è¿‘é‡è¦–**: éå»ã®ãƒ¬ãƒ¼ã‚¹ã¯ç›´è¿‘ã®ã‚‚ã®ã»ã©é‡è¦è¦–ã™ã‚‹ã€Œæ™‚é–“æ¸›è¡°ã€å‡¦ç†ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
    
    #### æœŸå¾…å€¤ (EV) ã®è¨ˆç®—å¼
    å˜ã«å‹ã¤ç¢ºç‡ãŒé«˜ã„é¦¬ã‚’é¸ã¶ã®ã§ã¯ãªãã€ã€Œã‚ªãƒƒã‚ºã«å¯¾ã—ã¦æœŸå¾…å€¤ãŒé«˜ã„é¦¬ã€ã‚’è¦‹ã¤ã‘ã‚‹è¨­è¨ˆã§ã™ã€‚
    $$
    Expected Value = (AIå‹ç‡ \\times äºˆæƒ³å®¶ã®å°è£œæ­£ \\times ç¾åœ¨ã‚ªãƒƒã‚º) - 1.0
    $$
    - **ãƒ—ãƒ©ã‚¹ (ç·‘è‰²)**: é•·æœŸçš„ã«è²·ã£ã¦ãƒ—ãƒ©ã‚¹ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ã„é¦¬
    - **äºˆæƒ³å®¶ã®å°**: ã‚ãªãŸã®ç›´æ„Ÿï¼ˆå°ï¼‰ã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ã§ã€AIã®ç¢ºç‡ã‚’è£œæ­£ã§ãã¾ã™

    #### ğŸ‡ ä¸­å¤®ç«¶é¦¬ vs ğŸŒ™ åœ°æ–¹ç«¶é¦¬
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¼šå ´ã‹ã‚‰è‡ªå‹•çš„ã«ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã¨åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰ã‚’åˆ¤å®šã—ã€ãã‚Œãã‚Œã«æœ€é©åŒ–ã•ã‚ŒãŸæœŸå¾…å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    **ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.3å€, â—¯=1.15å€ï¼ˆæ§ãˆã‚ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚

    **åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.8å€, â—¯=1.4å€ï¼ˆç©æ¥µçš„ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„

    #### ğŸ“Š ä¿¡é ¼æ€§å‘ä¸Šã®å–ã‚Šçµ„ã¿
    - **ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: è¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ï¼ˆAUCï¼‰ã€ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¸¸æ™‚è¡¨ç¤º
    - **äºˆæ¸¬ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: å„äºˆæ¸¬ã«ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’0-100%ã§æ•°å€¤åŒ–
    - **ãƒ‡ãƒ¼ã‚¿æ–°é®®åº¦**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’è¡¨ç¤ºï¼ˆ3æ—¥ä»¥å†…ãŒç†æƒ³ï¼‰
    - **æ³¨æ„å–šèµ·**: ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³ã‚„äºˆæ¸¬ã®é™ç•Œã‚’æ˜ç¤º
    - **é€æ˜æ€§**: ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ»é™ç•Œã‚’éš ã•ãšé–‹ç¤º
    """)

# --- Admin Menu ---
st.markdown("### è¨­å®š")
mode = st.radio("é–‹å‚¬ãƒ¢ãƒ¼ãƒ‰ (Mode)", ["JRA (ä¸­å¤®ç«¶é¦¬)", "NAR (åœ°æ–¹ç«¶é¦¬)"], horizontal=True)
mode_val = "JRA" if "JRA" in mode else "NAR"

with st.expander("ğŸ› ï¸ ç®¡ç†ãƒ„ãƒ¼ãƒ« (ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°ãªã©)"):
    col_admin_1, col_admin_2 = st.columns([1, 1])
    with col_admin_1:
         if st.button("ğŸ“… ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’æ›´æ–° (ä»Šå¾Œ1é€±é–“)"):
            with st.spinner(f"{mode_val}ã®æœ€æ–°ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ä¸­..."):
                success, msg = auto_scraper.scrape_todays_schedule(mode=mode_val)
                if success:
                    st.success(msg)
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {msg}")
    
    with col_admin_2:
         if st.button("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿"):
             st.cache_resource.clear()
             st.success("ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ¬¡å›äºˆæ¸¬æ™‚ã«å†ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# --- Race Selection ---
st.subheader("ğŸ“ ãƒ¬ãƒ¼ã‚¹é¸æŠ")

schedule_data = load_schedule_data(mode=mode_val)
race_id = None

if schedule_data and "races" in schedule_data:
    races = schedule_data['races']
    
    # 1. Filter by Date
    dates = sorted(list(set([r.get('date', 'Unknown') for r in races])))
    
    # Layout columns for selection
    col_date, col_venue, col_race = st.columns(3)
    
    with col_date:
         selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
    
    # Filter races by date
    todays_races = [r for r in races if r.get('date') == selected_date]
    
    if todays_races:
        # 2. Filter by Venue (New)
        venues = sorted(list(set([r['venue'] for r in todays_races])))
        
        with col_venue:
            selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ", venues)
            
        # Filter races by venue
        venue_races = [r for r in todays_races if r['venue'] == selected_venue]
        
        # 3. Select Race
        # Sort by race number just in case
        venue_races.sort(key=lambda x: int(x['number']))
        
        race_options = {f"{r['number']}R: {r['name']}": r['id'] for r in venue_races}
        
        with col_race:
            selected_label = st.selectbox("3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list(race_options.keys()))
            if selected_label:
                race_id = race_options[selected_label]
    else:
        st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
else:
    st.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    race_id = st.text_input("ãƒ¬ãƒ¼ã‚¹IDç›´æ¥å…¥åŠ› (12æ¡)", value="202305021211")


# Main Analysis
if race_id:
    st.header(f"ãƒ¬ãƒ¼ã‚¹åˆ†æ: {race_id}")

    # Load Model and Metadata
    model = load_model(mode=mode_val)
    model_meta = load_model_metadata(mode=mode_val)
    last_updated, days_ago = get_data_freshness(mode=mode_val)

    # Display Model Information and Data Freshness
    with st.expander("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ª", expanded=False):
        if model_meta:
            col_info1, col_info2, col_info3 = st.columns(3)

            with col_info1:
                st.metric(
                    "ãƒ¢ãƒ‡ãƒ«AUCï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰",
                    f"{model_meta.get('performance', {}).get('auc', 0):.3f}",
                    help="0.5=ãƒ©ãƒ³ãƒ€ãƒ ã€1.0=å®Œå…¨äºˆæ¸¬ã€‚0.75ä»¥ä¸ŠãŒç›®å®‰"
                )
                st.caption(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é‡: {model_meta.get('data_stats', {}).get('total_records', 0):,}ä»¶")

            with col_info2:
                if last_updated:
                    freshness_color = "ğŸŸ¢" if days_ago <= 3 else "ğŸŸ¡" if days_ago <= 7 else "ğŸ”´"
                    st.metric(
                        "ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°",
                        f"{days_ago}æ—¥å‰",
                        delta=f"{freshness_color} {last_updated}"
                    )
                else:
                    st.metric("ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°", "ä¸æ˜")

            with col_info3:
                data_size = model_meta.get('data_stats', {}).get('total_records', 0)
                if data_size < 1000:
                    quality = "âš ï¸ å°è¦æ¨¡"
                    quality_help = "ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ãŸã‚ã€äºˆæ¸¬ç²¾åº¦ã¯é™å®šçš„ã§ã™"
                elif data_size < 3000:
                    quality = "ğŸŸ¡ ä¸­è¦æ¨¡"
                    quality_help = "ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™"
                else:
                    quality = "ğŸŸ¢ ååˆ†"
                    quality_help = "ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã§å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™"

                st.metric("ãƒ‡ãƒ¼ã‚¿å“è³ª", quality, help=quality_help)

            # Warnings
            if model_meta.get('warnings'):
                st.warning("**âš ï¸ æ³¨æ„äº‹é …:**\n" + "\n".join([f"- {w}" for w in model_meta['warnings']]))
        else:
            st.info("ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    button_analyze = st.button("ğŸš€ ã“ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã™ã‚‹ (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»AIäºˆæ¸¬)", type="primary", use_container_width=True)

    if button_analyze:
        if not race_id:
             st.error("ãƒ¬ãƒ¼ã‚¹IDãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        elif not model:
             st.error(f"ãƒ¢ãƒ‡ãƒ« ({mode_val}) ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ç®¡ç†ç”»é¢ã§å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            # === å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ– ===
            st.markdown("---")
            st.subheader("ğŸ”„ AIäºˆæ¸¬å‡¦ç†ãƒ•ãƒ­ãƒ¼")

            # ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()

            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å–å¾—
            status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 1/4:** å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            progress_bar.progress(25)
            df = auto_scraper.scrape_shutuba_data(race_id, mode=mode_val)

            if df is not None and not df.empty:
                status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 1/4: å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
                status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 2/4:** ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­ï¼ˆéå»5èµ°ã®æˆç¸¾ã€é©æ€§ã‚¹ã‚³ã‚¢ç­‰ï¼‰...")
                progress_bar.progress(50)
                X_df = process_data(df, use_venue_features=False)
                status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 2/4: ç‰¹å¾´é‡è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—3: AIäºˆæ¸¬
                status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 3/4:** AIãƒ¢ãƒ‡ãƒ«ã§å‹ç‡ã‚’äºˆæ¸¬ä¸­...")
                progress_bar.progress(75)

                if model:
                    try:
                        # Drop meta cols for prediction
                        # Meta cols are handled in process_data, but result has meta + features + rank
                        # We need to filter only numeric features matching model
                        # Model expects features used in training.
                        # Features: weighted_avg_... + age
                        # We should robustly select.
                        
                        # Identify feature cols from X_df
                        # Exclude non-numeric and 'rank'
                        meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
                        features = [c for c in X_df.columns if c not in meta_cols and c != 'target_win']
                        # Ensure numeric
                        X_pred = X_df[features].select_dtypes(include=['number']).fillna(0)
                        
                        probs = model.predict(X_pred)

                        df['AI_Prob'] = probs
                        df['AI_Score'] = (probs * 100).astype(int)

                        # Calculate confidence score for each prediction with compatibility data
                        # ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦èŠ/ãƒ€ãƒ¼ãƒˆé©æ€§ã‚’é¸æŠ
                        confidences = []
                        for idx, p in enumerate(probs):
                            # é©æ€§ã‚¹ã‚³ã‚¢ã‚’å–å¾—ï¼ˆX_dfã‹ã‚‰ï¼‰
                            jockey_c = X_df['jockey_compatibility'].iloc[idx] if 'jockey_compatibility' in X_df.columns else None
                            distance_c = X_df['distance_compatibility'].iloc[idx] if 'distance_compatibility' in X_df.columns else None

                            # ã‚³ãƒ¼ã‚¹é©æ€§: èŠã‹ãƒ€ãƒ¼ãƒˆã‹åˆ¤å®šï¼ˆã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚«ãƒ©ãƒ ã‹ã‚‰ï¼‰
                            course_c = None
                            if 'turf_compatibility' in X_df.columns and 'dirt_compatibility' in X_df.columns:
                                # ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šï¼ˆ'èŠ' or 'ãƒ€'ï¼‰
                                # df_displayã‹ã‚‰å–å¾—ã™ã‚‹ã‹ã€X_dfã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                                if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df.columns:
                                    course_type = df['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[idx]
                                    if course_type == 'èŠ':
                                        course_c = X_df['turf_compatibility'].iloc[idx]
                                    elif course_type == 'ãƒ€':
                                        course_c = X_df['dirt_compatibility'].iloc[idx]
                                else:
                                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯èŠã‚’ä½¿ç”¨
                                    course_c = X_df['turf_compatibility'].iloc[idx]

                            conf = calculate_confidence_score(p, model_meta, jockey_c, course_c, distance_c)
                            confidences.append(conf)

                        df['Confidence'] = confidences

                        status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 3/4: AIäºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸ")

                        # ã‚¹ãƒ†ãƒƒãƒ—4: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
                        status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 4/4:** äºˆæ¸¬ä¿¡é ¼åº¦ã‚’è¨ˆç®—ä¸­...")
                        progress_bar.progress(100)

                        # Merge features back to df for display
                        # We need: turf_compatibility, dirt_compatibility, jockey_compatibility, distance_compatibility, weighted_avg_speed, weighted_avg_rank
                        cols_to_merge = [
                            'turf_compatibility', 'dirt_compatibility', 
                            'jockey_compatibility', 'distance_compatibility', 
                            'weighted_avg_speed', 'weighted_avg_rank'
                        ]
                        for c in cols_to_merge:
                            if c in X_df.columns:
                                df[c] = X_df[c]


                        status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 4/4: ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        progress_bar.progress(100)

                    except Exception as e:
                        status_text.error(f"âŒ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                        df['AI_Prob'] = 0.0
                        df['AI_Score'] = 0.0
                else:
                    status_text.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                    df['AI_Prob'] = 0.0
                    df['AI_Score'] = 0.0

                # 4. Display
                # Store in session state to persist edits
                st.session_state[f'data_{race_id}'] = df

                # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                st.markdown("---")
                st.success("ğŸ‰ **AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼** ä¸‹è¨˜ã®çµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # Show Data if available
    if f'data_{race_id}' in st.session_state:
        df_display = st.session_state[f'data_{race_id}'].copy()

        # === ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã®è¡¨ç¤º ===
        st.markdown("---")
        st.subheader("ğŸ‡ ãƒ¬ãƒ¼ã‚¹æ¦‚è¦")

        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±
        col_r1, col_r2, col_r3, col_r4 = st.columns(4)
        with col_r1:
            venue = df_display['ä¼šå ´'].iloc[0] if 'ä¼šå ´' in df_display.columns else "ä¸æ˜"
            st.metric("é–‹å‚¬å ´", venue)
        with col_r2:
            race_name = df_display['ãƒ¬ãƒ¼ã‚¹å'].iloc[0] if 'ãƒ¬ãƒ¼ã‚¹å' in df_display.columns else "ä¸æ˜"
            st.metric("ãƒ¬ãƒ¼ã‚¹å", race_name if len(str(race_name)) < 20 else str(race_name)[:17] + "...")
        with col_r3:
            course_type = df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0] if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns else "ä¸æ˜"
            distance = df_display['è·é›¢'].iloc[0] if 'è·é›¢' in df_display.columns else "ä¸æ˜"
            st.metric("ã‚³ãƒ¼ã‚¹", f"{course_type} {distance}m")
        with col_r4:
            num_horses = len(df_display)
            st.metric("å‡ºèµ°é ­æ•°", f"{num_horses}é ­")

        # AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼
        if 'AI_Score' in df_display.columns and 'Confidence' in df_display.columns:
            avg_confidence = df_display['Confidence'].mean()
            max_ai_score = df_display['AI_Score'].max()
            st.info(f"ğŸ“Š **AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼**: æœ€é«˜AIå‹ç‡ {max_ai_score}% | å¹³å‡ä¿¡é ¼åº¦ {avg_confidence:.0f}%")

        # ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã®è©³ç´°è¡¨ç¤º
        venue = df_display['ä¼šå ´'].iloc[0] if 'ä¼šå ´' in df_display.columns else None
        if venue:
            try:
                from ml.venue_characteristics import get_venue_characteristics
                venue_char = get_venue_characteristics(venue)

                if venue_char:
                    st.markdown("#### ğŸŸï¸ ã‚³ãƒ¼ã‚¹ç‰¹æ€§")

                    col_c1, col_c2, col_c3, col_c4 = st.columns(4)

                    # ç›´ç·šè·é›¢
                    with col_c1:
                        straight = venue_char.get('turf_straight', 0)
                        if straight:
                            straight_label = "é•·ã„" if straight > 500 else "çŸ­ã„" if straight < 300 else "æ¨™æº–"
                            st.metric("ç›´ç·šè·é›¢", f"{straight}m", delta=straight_label)
                        else:
                            st.metric("ç›´ç·šè·é›¢", "ä¸æ˜")

                    # å‹¾é…ï¼ˆå‚¾æ–œï¼‰
                    with col_c2:
                        slope = venue_char.get('slope', 'normal')
                        slope_map = {
                            'steep': 'æ€¥å‚ã‚ã‚Š',
                            'moderate': 'ç·©ã‚„ã‹ãªå‚',
                            'flat': 'å¹³å¦',
                            'normal': 'æ¨™æº–'
                        }
                        slope_label = slope_map.get(slope, slope)
                        slope_icon = "â›°ï¸" if slope == 'steep' else "ğŸ”ï¸" if slope == 'moderate' else "â”"
                        st.metric("å‹¾é…ï¼ˆå‚¾æ–œï¼‰", slope_label, delta=slope_icon)

                    # ã‚³ãƒ¼ã‚¹å¹…
                    with col_c3:
                        track_width = venue_char.get('track_width', 'standard')
                        width_map = {
                            'narrow': 'å°å›ã‚Š',
                            'standard': 'æ¨™æº–',
                            'wide': 'åºƒã„ã‚³ãƒ¼ã‚¹'
                        }
                        width_label = width_map.get(track_width, track_width)
                        st.metric("ã‚³ãƒ¼ã‚¹å¹…", width_label)

                    # å¤–æ æœ‰åˆ©åº¦
                    with col_c4:
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        if outer_advantage > 1.05:
                            outer_label = "å¤–æ æœ‰åˆ©"
                            outer_delta = "â†‘"
                        elif outer_advantage < 0.95:
                            outer_label = "å†…æ æœ‰åˆ©"
                            outer_delta = "â†“"
                        else:
                            outer_label = "å…¬å¹³"
                            outer_delta = "="
                        st.metric("æ ç•ªå‚¾å‘", outer_label, delta=outer_delta)

                    # ç‰¹æ€§ã®å½±éŸ¿èª¬æ˜
                    with st.expander("ğŸ’¡ ã“ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ãŒEVè¨ˆç®—ã«ä¸ãˆã‚‹å½±éŸ¿", expanded=False):
                        st.markdown(f"""
                        #### ğŸŸï¸ {venue}ã®ç‰¹æ€§

                        **1. ç›´ç·šè·é›¢: {straight}m ({straight_label})**
                        - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: äººæ°—é¦¬ã‚„ã‚„ä¸åˆ© (-5%)ã€ç©´é¦¬ã‚„ã‚„æœ‰åˆ© (+5%)
                        - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: äººæ°—é¦¬æœ‰åˆ© (+5%)ã€ç©´é¦¬ä¸åˆ© (-5%)
                        - ç†ç”±: é•·ã„ç›´ç·šã¯å·®ã—é¦¬ã«æœ‰åˆ©ã€çŸ­ã„ç›´ç·šã¯é€ƒã’ãƒ»å…ˆè¡Œé¦¬ã«æœ‰åˆ©

                        **2. å‹¾é…ï¼ˆå‚¾æ–œï¼‰: {slope_label}**
                        - æ€¥å‚ã‚ã‚Š: äººæ°—é¦¬ï¼ˆãƒ‘ãƒ¯ãƒ¼ãŒã‚ã‚‹é¦¬ï¼‰ãŒæœ‰åˆ© (+2%)
                        - ç†ç”±: å‚ã‚’ç™»ã‚‹éš›ã«é¦¬åŠ›ãŒå¿…è¦ã§ã€å®Ÿç¸¾é¦¬ãŒå„ªä½
                        - è©²å½“ç«¶é¦¬å ´: ä¸­å±±ã€é˜ªç¥ãªã©

                        **3. ã‚³ãƒ¼ã‚¹å¹…: {width_label}**
                        - å°å›ã‚Š: äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ© (+3%)
                        - ç†ç”±: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãã€å™¨ç”¨ã•ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹

                        **4. æ ç•ªå‚¾å‘: {outer_label}**
                        - å¤–æ æœ‰åˆ©ãªå ´åˆ: 6-8æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´ (Ã—{outer_advantage:.2f})
                        - å†…æ æœ‰åˆ©ãªå ´åˆ: 1-3æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´

                        âš ï¸ ã“ã‚Œã‚‰ã®èª¿æ•´ã¯æœŸå¾…å€¤(EV)è¨ˆç®—æ™‚ã«è‡ªå‹•çš„ã«é©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
                        """)
            except Exception as e:
                pass  # venue_characteristics ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        # Prepare Editor DF
        # Columns: Horse, Prob, Odds, Mark
        if 'Odds' not in df_display.columns:
             # Try to get scraped odds if available
             if 'å˜å‹' in df_display.columns:
                 df_display['Odds'] = pd.to_numeric(df_display['å˜å‹'], errors='coerce').fillna(0.0)
             else:
                 df_display['Odds'] = 0.0
        
        rename_map = {
            'AI_Score': 'AIã‚¹ã‚³ã‚¢(%)',
            'Confidence': 'ä¿¡é ¼åº¦',
            'Odds': 'ç¾åœ¨ã‚ªãƒƒã‚º',
            'æ€§é½¢': 'å¹´é½¢',
            'é¦¬ ç•ª': 'é¦¬ç•ª',
            'jockey_compatibility': 'é¨æ‰‹ç›¸æ€§',
            'distance_compatibility': 'è·é›¢é©æ€§',
            'course_compatibility': 'ã‚³ãƒ¼ã‚¹é©æ€§',
            'weighted_avg_speed': 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'
        }
        
        # Select appropriate course compatibility
        # If 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' contains 'èŠ', use turf, else dirt
        # Default to turf if unknown
        is_turf_race = True
        if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
             # Check first row (all same race)
             c_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
             if 'ãƒ€' in c_type:
                 is_turf_race = False
        
        if is_turf_race:
             df_display['course_compatibility'] = df_display.get('turf_compatibility', 10.0)
        else:
             df_display['course_compatibility'] = df_display.get('dirt_compatibility', 10.0)
             
        # Ensure all display columns exist
        defaults = {
            'jockey_compatibility': 10.0,
            'distance_compatibility': 10.0,
            'weighted_avg_speed': 16.0,
            'Confidence': 50
        }
        for c, v in defaults.items():
            if c not in df_display.columns:
                df_display[c] = v


        display_cols = ['æ ', 'é¦¬ ç•ª', 'é¦¬å', 'æ€§é½¢', 'AI_Score', 'Confidence', 'Odds', 'jockey_compatibility', 'course_compatibility', 'distance_compatibility']

        
        edited_df = df_display[display_cols].copy()
        edited_df.rename(columns=rename_map, inplace=True)
        
        # Add Mark column
        edited_df['äºˆæƒ³å°'] = ""
        
        st.subheader("ğŸ“ äºˆæƒ³ãƒ»ã‚ªãƒƒã‚ºå…¥åŠ›")
        
        col_input_1, col_input_2 = st.columns([3, 1])
        with col_input_1:
             st.info("ã€Œäºˆæƒ³å°ã€ã‚„ã€Œç¾åœ¨ã‚ªãƒƒã‚ºã€ã‚’ç·¨é›†ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœŸå¾…å€¤(EV)ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
        with col_input_2:
             if st.button("ğŸ”„ æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—"):
                 with st.spinner("æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
                     try:
                         current_odds = auto_scraper.scrape_odds_for_race(race_id, mode=mode_val)
                         # Update session state df
                         if current_odds:
                             odds_map = {x['number']: x['odds'] for x in current_odds}
                             
                             target_df = st.session_state[f'data_{race_id}']
                             
                             # Update 'å˜å‹' and 'Odds'
                             def update_odds(row):
                                 try:
                                     num = int(row['é¦¬ ç•ª'])
                                     return odds_map.get(num, row.get('Odds', 0.0))
                                 except:
                                     return row.get('Odds', 0.0)
                                 
                             target_df['Odds'] = target_df.apply(update_odds, axis=1)
                             target_df['å˜å‹'] = target_df['Odds'] # Sync
                             
                             st.session_state[f'data_{race_id}'] = target_df
                             st.success("ã‚ªãƒƒã‚ºã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                             st.rerun()
                         else:
                             st.warning("ã‚ªãƒƒã‚ºã®å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                     except Exception as e:
                         st.error(f"ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        
        edited_df = st.data_editor(
            edited_df,
            column_config={
                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                    "AIæœŸå¾…åº¦",
                    help="1ç€ï¼ˆå‹åˆ©ï¼‰ã® AIäºˆæ¸¬ç¢ºç‡",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ä¿¡é ¼åº¦": st.column_config.ProgressColumn(
                    "äºˆæ¸¬ä¿¡é ¼åº¦",
                    help="ã“ã®äºˆæ¸¬ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ï¼ˆãƒ¢ãƒ‡ãƒ«AUCã€ãƒ‡ãƒ¼ã‚¿é‡ã€äºˆæ¸¬ç¢ºç‡ã‚’è€ƒæ…®ï¼‰",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç¾åœ¨ã‚ªãƒƒã‚º": st.column_config.NumberColumn(
                    "ç¾åœ¨ã‚ªãƒƒã‚º",
                    help="æœ€æ–°ã®å˜å‹ã‚ªãƒƒã‚ºã‚’å…¥åŠ›",
                    step=0.1,
                    format="%.1f"
                ),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(
                    "æ¨å¥¨åº¦(Kelly)",
                    help="ã‚±ãƒªãƒ¼åŸºæº–ã«ã‚ˆã‚‹æ¨å¥¨è³­ã‘ç‡ (ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨åº¦)",
                    format="%.1f%%",
                    min_value=0,
                    max_value=30, # Max display scale (usually >30% is rare)
                ),
                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                    "äºˆæƒ³å°",
                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                    required=False,
                ),
                "é¨æ‰‹ç›¸æ€§": st.column_config.NumberColumn(
                    "é¨æ‰‹ç›¸æ€§",
                    help="ã“ã®é¨æ‰‹ã§ã®å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                ),
                "ã‚³ãƒ¼ã‚¹é©æ€§": st.column_config.NumberColumn(
                    "ã‚³ãƒ¼ã‚¹é©æ€§",
                    help="èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                ),
                "è·é›¢é©æ€§": st.column_config.NumberColumn(
                    "è·é›¢é©æ€§",
                    help="åŒè·é›¢ã§ã®å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                )
            },
            hide_index=True,
            num_rows="fixed"  
        )
        
        # Calculate EV with JRA/NAR distinction
        # Determine race type from user's mode selection (as primary source)
        race_type = mode_val  # Use user's selected mode (JRA or NAR) as primary source of truth
        venue = ''  # Initialize venue

        # Get venue information if available
        if 'ä¼šå ´' in df_display.columns and len(df_display) > 0:
            venue = df_display['ä¼šå ´'].iloc[0]

            # If venue is available, use it to verify/override race_type for accuracy
            if venue:
                try:
                    import sys
                    import os
                    sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'ml'))
                    from race_classifier import classify_race_type
                    venue_based_type = classify_race_type(venue)
                    # Use venue-based classification (more accurate than mode selection)
                    race_type = venue_based_type
                except:
                    # Fallback: manual classification
                    jra_venues = ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']
                    race_type = 'JRA' if venue in jra_venues else 'NAR'

        # EV calculation with race type AND venue specific parameters
        # Import venue characteristics
        venue_char = None
        try:
            from ml.venue_characteristics import get_venue_characteristics, get_distance_category
            if venue:
                venue_char = get_venue_characteristics(venue)
        except Exception as e:
            # Silently fail if venue characteristics not available
            pass

        # Base parameters by race type
        if race_type == 'JRA':
            # === ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰è¨­å®š ===
            # ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚ã€‚AIäºˆæ¸¬ã®ä¿¡é ¼æ€§ãŒé«˜ã„
            mark_weights = {
                "â—": 1.3,   # æœ¬å‘½: æ§ãˆã‚ã«1.3å€
                "â—¯": 1.15,  # å¯¾æŠ—: 1.15å€
                "â–²": 1.08,  # å˜ç©´: 1.08å€
                "â–³": 1.03,  # é€£ä¸‹: 1.03å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.08  # AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–ï¼ˆä¿¡é ¼æ€§é‡è¦–ï¼‰
            venue_info = f"ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰" + (f" - {venue}" if venue else "")
        else:
            # === åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰è¨­å®š ===
            # ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„ã€‚å¤§ç©´ç‹™ã„ã‚‚æœ‰åŠ¹
            mark_weights = {
                "â—": 1.8,   # æœ¬å‘½: ç©æ¥µçš„ã«1.8å€
                "â—¯": 1.4,   # å¯¾æŠ—: 1.4å€
                "â–²": 1.2,   # å˜ç©´: 1.2å€
                "â–³": 1.1,   # é€£ä¸‹: 1.1å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.05  # AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–ï¼ˆä½ç¢ºç‡ã§ã‚‚ç‹™ã†ä¾¡å€¤ã‚ã‚Šï¼‰
            venue_info = f"ğŸŒ™ åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰" + (f" - {venue}" if venue else "")

        # Venue-specific adjustments
        venue_features = []
        if venue_char:
            # ç›´ç·šè·é›¢ã«ã‚ˆã‚‹èª¿æ•´
            straight = venue_char.get('turf_straight', 300)
            if straight and straight > 500:  # é•·ã„ç›´ç·šï¼ˆæ–°æ½Ÿãªã©ï¼‰
                mark_weights["â—"] *= 0.95  # äººæ°—é¦¬ã‚„ã‚„ä¸åˆ©
                mark_weights["â–³"] *= 1.05  # ç©´é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("é•·ç›´ç·š")
            elif straight and straight < 300:  # çŸ­ã„ç›´ç·šï¼ˆä¸­å±±ã€å‡½é¤¨ãªã©ï¼‰
                mark_weights["â—"] *= 1.05  # äººæ°—é¦¬æœ‰åˆ©
                mark_weights["â–³"] *= 0.95  # ç©´é¦¬ä¸åˆ©
                venue_features.append("çŸ­ç›´ç·š")

            # ã‚³ãƒ¼ã‚¹å¹…ã«ã‚ˆã‚‹èª¿æ•´
            track_width = venue_char.get('track_width')
            if track_width == 'narrow':  # ç‹­ã„ã‚³ãƒ¼ã‚¹
                mark_weights["â—"] *= 1.03  # å…ˆè¡Œæœ‰åˆ©ã€äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("å°å›ã‚Š")
            elif track_width == 'wide':  # åºƒã„ã‚³ãƒ¼ã‚¹
                # é¦¬ç¾¤ãŒåºƒãŒã‚Šã‚„ã™ãã€å±•é–‹æ¬¡ç¬¬
                pass

            # å‹¾é…ã«ã‚ˆã‚‹èª¿æ•´
            slope = venue_char.get('slope')
            if slope == 'steep':  # æ€¥å‚ã‚ã‚Šï¼ˆä¸­å±±ãªã©ï¼‰
                mark_weights["â—"] *= 1.02  # ãƒ‘ãƒ¯ãƒ¼ã‚ã‚‹äººæ°—é¦¬æœ‰åˆ©
                venue_features.append("å‚ã‚ã‚Š")

        if venue_features:
            venue_info += f" ({', '.join(venue_features)})"

        st.info(venue_info)

        probs = edited_df['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
        odds = edited_df['ç¾åœ¨ã‚ªãƒƒã‚º']
        marks = edited_df['äºˆæƒ³å°']

        # Get run style compatibility if available
        run_style_compatibility = None
        if 'venue_run_style_compatibility' in edited_df.columns:
            run_style_compatibility = edited_df['venue_run_style_compatibility']

        # Get frame (æ ) for venue-specific frame advantage
        frames = None
        if 'æ ' in edited_df.columns:
            frames = edited_df['æ ']

        evs = []
        kellys = []

        for idx, (p, o, m) in enumerate(zip(probs, odds, marks)):
            # Safety filter (race type specific)
            if p < safety_threshold:
                ev = -1.0
                kelly = 0.0
            else:
                w = mark_weights.get(m, 1.0)

                # Adjust probability for NAR (higher uncertainty)
                if race_type == 'NAR':
                    # === åœ°æ–¹ç«¶é¦¬ã®ç¢ºç‡èª¿æ•´ ===
                    # åœ°æ–¹ã¯äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ãŸã‚ã€ç¢ºç‡ã‚’ä¿å®ˆçš„ã«èª¿æ•´
                    # é«˜ç¢ºç‡é¦¬: ã‚„ã‚„ä¸‹ã’ã‚‹ï¼ˆéä¿¡ã‚’é˜²ãï¼‰
                    # ä½ç¢ºç‡é¦¬: ã‚„ã‚„ä¸Šã’ã‚‹ï¼ˆç©´é¦¬ãƒãƒ£ãƒ³ã‚¹ã‚’è€ƒæ…®ï¼‰
                    # ä¾‹: 10%â†’14%(+4pt), 30%â†’32%(+2pt), 50%â†’50%(Â±0), 70%â†’68%(-2pt)
                    adjusted_p = p * 0.9 + 0.05
                else:
                    # === ä¸­å¤®ç«¶é¦¬ã®ç¢ºç‡èª¿æ•´ ===
                    # JRAã¯AIäºˆæ¸¬ã®ä¿¡é ¼æ€§ãŒé«˜ã„ãŸã‚ã€èª¿æ•´ãªã—
                    adjusted_p = p

                # Apply run style compatibility if available
                if run_style_compatibility is not None:
                    run_compat = run_style_compatibility.iloc[idx]
                    if not pd.isna(run_compat):
                        # è„šè³ªç›¸æ€§ãŒè‰¯ã„é¦¬ã¯æœŸå¾…å€¤ã‚’ä¸Šã’ã‚‹
                        adjusted_p *= run_compat

                # Apply frame advantage if available
                if frames is not None and venue_char:
                    frame = frames.iloc[idx]
                    if not pd.isna(frame):
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        frame_num = int(frame)
                        if frame_num >= 6:  # å¤–æ 
                            adjusted_p *= outer_advantage
                        elif frame_num <= 3:  # å†…æ 
                            # å¤–æ æœ‰åˆ©ãªä¼šå ´ã§ã¯å†…æ ã¯ä¸åˆ©
                            adjusted_p *= (2.0 - outer_advantage)

                ev = (adjusted_p * w * o) - 1.0
                # Kelly criterion (placeholder for now)
                kelly = 0.0
            evs.append(ev)
            kellys.append(kelly)

        edited_df['æœŸå¾…å€¤(EV)'] = evs
        edited_df['æ¨å¥¨åº¦(Kelly)'] = kellys

        # === AIæœŸå¾…åº¦TOP5ã®ã‚°ãƒ©ãƒ•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡¨ç¤ºï¼‰ ===
        st.markdown("---")
        st.subheader("ğŸ“Š AIæœŸå¾…åº¦ TOP5 åˆ†æ")

        # TOP5ã‚’æœŸå¾…å€¤(EV)ã§ã‚½ãƒ¼ãƒˆ
        top5_df = edited_df.nlargest(5, 'æœŸå¾…å€¤(EV)')

        # 1. æ¨ªæ£’ã‚°ãƒ©ãƒ•: AIç¢ºç‡ vs æœŸå¾…å€¤(EV)
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots

        fig_top5 = make_subplots(
            rows=1, cols=2,
            subplot_titles=("AIå‹ç‡äºˆæ¸¬ TOP5", "æœŸå¾…å€¤(EV) TOP5"),
            specs=[[{"type": "bar"}, {"type": "bar"}]]
        )

        # å·¦: AIå‹ç‡
        fig_top5.add_trace(
            go.Bar(
                y=top5_df['é¦¬å'],
                x=top5_df['AIã‚¹ã‚³ã‚¢(%)'],
                orientation='h',
                name='AIå‹ç‡',
                marker=dict(color='lightblue'),
                text=top5_df['AIã‚¹ã‚³ã‚¢(%)'].apply(lambda x: f'{x}%'),
                textposition='auto'
            ),
            row=1, col=1
        )

        # å³: æœŸå¾…å€¤(EV)
        colors = ['green' if ev > 0 else 'red' for ev in top5_df['æœŸå¾…å€¤(EV)']]
        fig_top5.add_trace(
            go.Bar(
                y=top5_df['é¦¬å'],
                x=top5_df['æœŸå¾…å€¤(EV)'],
                orientation='h',
                name='æœŸå¾…å€¤',
                marker=dict(color=colors),
                text=top5_df['æœŸå¾…å€¤(EV)'].apply(lambda x: f'{x:.2f}'),
                textposition='auto'
            ),
            row=1, col=2
        )

        fig_top5.update_xaxes(title_text="AIå‹ç‡ (%)", row=1, col=1)
        fig_top5.update_xaxes(title_text="æœŸå¾…å€¤ (EV)", row=1, col=2)
        fig_top5.update_yaxes(autorange="reversed", row=1, col=1)
        fig_top5.update_yaxes(autorange="reversed", row=1, col=2)
        fig_top5.update_layout(height=400, showlegend=False)

        st.plotly_chart(fig_top5, use_container_width=True)

        # 2. é©æ€§ã‚¹ã‚³ã‚¢æ¯”è¼ƒï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰
        st.markdown("#### ğŸ¯ TOP5 é©æ€§ã‚¹ã‚³ã‚¢æ¯”è¼ƒ")

        compatibility_cols = ['é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§']
        compat_data = []
        for idx, row in top5_df.iterrows():
            compat_data.append({
                'é¦¬å': row['é¦¬å'],
                'é¨æ‰‹ç›¸æ€§': row.get('é¨æ‰‹ç›¸æ€§', 10.0),
                'ã‚³ãƒ¼ã‚¹é©æ€§': row.get('ã‚³ãƒ¼ã‚¹é©æ€§', 10.0),
                'è·é›¢é©æ€§': row.get('è·é›¢é©æ€§', 10.0)
            })

        compat_df = pd.DataFrame(compat_data)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã«å€¤ã‚’åè»¢ï¼ˆ10 - å€¤ã§ã€å°ã•ã„æ–¹ãŒè‰¯ã„â†’å¤§ãã„æ–¹ãŒè‰¯ã„ ã«å¤‰æ›ï¼‰
        heatmap_data = []
        for col in compatibility_cols:
            heatmap_data.append([10 - val if val <= 10 else 0 for val in compat_df[col]])

        fig_heatmap = go.Figure(data=go.Heatmap(
            z=heatmap_data,
            x=compat_df['é¦¬å'],
            y=compatibility_cols,
            colorscale='RdYlGn',
            text=[[f'{val:.1f}' for val in compat_df[col]] for col in compatibility_cols],
            texttemplate='%{text}',
            textfont={"size": 12},
            colorbar=dict(title="é©æ€§åº¦<br>(é«˜ã„æ–¹ãŒè‰¯ã„)")
        ))

        fig_heatmap.update_layout(
            title="é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆæ•°å€¤ãŒå°ã•ã„æ–¹ãŒè‰¯ã„æˆç¸¾ï¼‰",
            xaxis_title="é¦¬å",
            height=300
        )

        st.plotly_chart(fig_heatmap, use_container_width=True)

        # 3. äºˆæ¸¬çµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰
        with st.expander("ğŸ’¡ äºˆæ¸¬çµæœã®è¦‹æ–¹ãƒ»è§£é‡ˆã‚¬ã‚¤ãƒ‰", expanded=False):
            st.markdown("""
            ### ğŸ“ˆ å„æŒ‡æ¨™ã®æ„å‘³

            **1. AIã‚¹ã‚³ã‚¢ï¼ˆAIå‹ç‡äºˆæ¸¬ï¼‰**
            - AIãŒäºˆæ¸¬ã—ãŸ1ç€ã«ãªã‚‹ç¢ºç‡ï¼ˆ%ï¼‰
            - **ç›®å®‰**: 10%ä»¥ä¸Šãªã‚‰æœ‰åŠ›å€™è£œã€15%ä»¥ä¸Šãªã‚‰æœ¬å‘½å€™è£œ
            - âš ï¸ æ³¨æ„: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆç®¡ç†ãƒšãƒ¼ã‚¸ã§å†å­¦ç¿’æ¨å¥¨ï¼‰

            **2. ä¿¡é ¼åº¦ï¼ˆäºˆæ¸¬ä¿¡é ¼åº¦ï¼‰**
            - ã“ã®äºˆæ¸¬ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ï¼ˆ20-95%ï¼‰
            - ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®:
              - ãƒ¢ãƒ‡ãƒ«AUCï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰
              - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é‡
              - AIäºˆæ¸¬ç¢ºç‡ï¼ˆæ¥µç«¯ãªå€¤ã»ã©ä¿¡é ¼åº¦é«˜ï¼‰
              - é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ãƒ»è·é›¢ï¼‰
            - **ç›®å®‰**: 70%ä»¥ä¸Šãªã‚‰é«˜ä¿¡é ¼ã€50%ä»¥ä¸‹ãªã‚‰è¦æ³¨æ„

            **3. æœŸå¾…å€¤ï¼ˆEV: Expected Valueï¼‰**
            - è³­ã‘ã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ1.0 = æç›Šåˆ†å²ç‚¹ï¼‰
            - **è¨ˆç®—å¼**: `(èª¿æ•´å¾ŒAIç¢ºç‡ Ã— ã‚ªãƒƒã‚º Ã— å°è£œæ­£) - 1.0`
            - **ç›®å®‰**:
              - EV > 0.2 â†’ å¼·ã„è²·ã„æ¨å¥¨
              - EV > 0.0 â†’ è²·ã„æ¨å¥¨
              - EV < 0.0 â†’ è¦‹é€ã‚Šæ¨å¥¨

            **4. é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ãƒ»è·é›¢ï¼‰**
            - éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ã—ãŸå¹³å‡ç€é †
            - **æ•°å€¤ãŒå°ã•ã„ã»ã©è‰¯ã„** (1.0=å¸¸ã«1ç€ã€10.0=å¹³å‡10ç€)
            - 3.0ä»¥ä¸‹: æŠœç¾¤ã®ç›¸æ€§
            - 5.0ä»¥ä¸‹: è‰¯å¥½
            - 7.0ä»¥ä¸Š: ã‚„ã‚„ä¸å®‰
            - 10.0: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰

            **5. ã‚³ãƒ¼ã‚¹ç‰¹æ€§ï¼ˆå‚¾æ–œãƒ»ç›´ç·šè·é›¢ãƒ»ã‚³ãƒ¼ã‚¹å¹…ãƒ»æ ç•ªï¼‰**
            - **å‹¾é…ï¼ˆå‚¾æ–œï¼‰**: æ€¥å‚ã‚ã‚Šã®ç«¶é¦¬å ´ã§ã¯äººæ°—é¦¬ãŒæœ‰åˆ©ï¼ˆ+2%ï¼‰
              - ä¸­å±±ã€é˜ªç¥ãªã©: å‚ã§ãƒ‘ãƒ¯ãƒ¼ãŒå¿…è¦ãªãŸã‚å®Ÿç¸¾é¦¬ãŒå„ªä½
            - **ç›´ç·šè·é›¢**:
              - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: å·®ã—é¦¬æœ‰åˆ©ã€ç©´é¦¬ãƒãƒ£ãƒ³ã‚¹ï¼ˆäººæ°—é¦¬-5%ã€ç©´é¦¬+5%ï¼‰
              - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: é€ƒã’ãƒ»å…ˆè¡Œé¦¬æœ‰åˆ©ã€äººæ°—é¦¬å …ã„ï¼ˆäººæ°—é¦¬+5%ï¼‰
            - **ã‚³ãƒ¼ã‚¹å¹…**:
              - å°å›ã‚Šã‚³ãƒ¼ã‚¹: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãå™¨ç”¨ãªé¦¬ãŒæœ‰åˆ©ï¼ˆäººæ°—é¦¬+3%ï¼‰
            - **æ ç•ªå‚¾å‘**:
              - å¤–æ æœ‰åˆ©ãªç«¶é¦¬å ´: 6-8æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´
              - å†…æ æœ‰åˆ©ãªç«¶é¦¬å ´: 1-3æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´

            âš ï¸ **ã“ã‚Œã‚‰ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã¯ã€ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™**

            ### ğŸ¯ æ¨å¥¨ã•ã‚Œã‚‹ä½¿ã„æ–¹

            1. **TOP5ã‚°ãƒ©ãƒ•**ã§AIæœŸå¾…åº¦ã®é«˜ã„é¦¬ã‚’ç¢ºèª
            2. **æœŸå¾…å€¤(EV)ãŒãƒ—ãƒ©ã‚¹**ã®é¦¬ã«æ³¨ç›®
            3. **ä¿¡é ¼åº¦ãŒ70%ä»¥ä¸Š**ã®äºˆæ¸¬ã‚’å„ªå…ˆ
            4. **é©æ€§ã‚¹ã‚³ã‚¢**ã§ç›¸æ€§ã‚’ç¢ºèªï¼ˆç‰¹ã«é¨æ‰‹ç›¸æ€§ã¯é‡è¦ï¼‰
            5. **ç¾åœ¨ã‚ªãƒƒã‚º**ã¨**äºˆæƒ³å°**ã‚’å…¥åŠ›ã—ã¦EVã‚’æœ€çµ‚èª¿æ•´

            ### âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

            - **ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå¿…è¦**: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€Œ3ç€ä»¥å†…ã€ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
            - ç®¡ç†ãƒšãƒ¼ã‚¸ã§ä¸¡ãƒ¢ãƒ‡ãƒ«ï¼ˆJRA/NARï¼‰ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„
            - å†å­¦ç¿’å¾Œã€AIç¢ºç‡ã¯5-15%ã®ç¯„å›²ï¼ˆ1ç€ç¢ºç‡ã¨ã—ã¦å¦¥å½“ï¼‰ã«ãªã‚Šã¾ã™
            """)

        st.markdown("---")
        st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")

        # Highlight high EV and Kelly
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]

        st.dataframe(
            edited_df.style
            .format({'æ¨å¥¨åº¦(Kelly)': lambda x: '-' if x <= 0 else f'{x:.1f}%', 'æœŸå¾…å€¤(EV)': '{:.2f}'})
            .applymap(lambda x: 'background-color: #d4edda' if x > 0 else '', subset=['æœŸå¾…å€¤(EV)', 'æ¨å¥¨åº¦(Kelly)'])
        )



        # Visualization
        st.markdown("---")
        st.subheader("ğŸ” å€‹åˆ¥é¦¬ã®è©³ç´°åˆ†æ")

        try:
            # 1. Select a horse for detailed analysis
            st.info("ğŸ’¡ ä¸‹è¨˜ã‹ã‚‰é¦¬ã‚’é¸æŠã™ã‚‹ã¨ã€èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆã¨éå»5èµ°ã®æ¨ç§»ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
            horse_options = df_display['é¦¬å'].tolist()
            selected_horse_name = st.selectbox("ğŸ´ è©³ç´°ã‚’è¦‹ã‚‹é¦¬ã‚’é¸æŠ", horse_options, key="horse_select")
            
            # Find row
            row = df_display[df_display['é¦¬å'] == selected_horse_name].iloc[0]
            
            # 2. Radar Chart (5 Axes)
            # Speed (Real), Stamina/Form (Rank), Jockey, Course, Distance
            
            # --- Scoring Logic (Lower rank is better, so Invert) ---
            # Rank 1 -> Score 10, Rank 10 -> Score 1, Rank 18 -> 0
            def rank_to_score(r):
                if pd.isna(r) or r > 18: return 0
                return max(0, min(10, (14 - r) * (10/13))) # Approx 1->10, 14->0

            # Speed: 16.0 is baseline. >17 is fast? <15 slow?
            # 1000m/60s = 16.6. 
            sp_val = row.get('weighted_avg_speed', 16.0)
            score_speed = max(0, min(10, (sp_val - 15.0) * 5)) # 17.0->10, 15.0->0

            j_val = row.get('jockey_compatibility', 10.0)
            score_jockey = rank_to_score(j_val)
            
            c_val = row.get('course_compatibility', 10.0) # Calculated above but only in display_df... wait, we are accessing df_display row.
            # We added 'course_compatibility' to df_display in UI section.
            # Re-calculate here if needed OR ensure row comes from df_display.
            # row comes from df_display!
            score_course = rank_to_score(c_val)
            
            d_val = row.get('distance_compatibility', 10.0)
            score_dist = rank_to_score(d_val)
            
            rank_val = row.get('weighted_avg_rank', 10.0)
            score_form = rank_to_score(rank_val)

            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=[score_speed, score_form, score_jockey, score_course, score_dist, score_speed],
                theta=['ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å®Ÿç¸¾(ç€é †)', 'é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§'],
                fill='toself',
                name=selected_horse_name
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 10])), 
                title=f"èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ: {selected_horse_name}"
            )
            
            # 3. Multi-Axis Line Chart (Past 5 Runs)
            history_data = []
            for i in range(5, 0, -1): # Chronological 5->1 (Oldest to Newest)
                if f"past_{i}_rank" in row and pd.notna(row[f"past_{i}_rank"]):
                     history_data.append({
                         "Run": f"{i}èµ°å‰",
                         "ç€é †": row[f"past_{i}_rank"],
                         "3Fã‚¿ã‚¤ãƒ ": row[f"past_{i}_last_3f"],
                         "é¦¬ä½“é‡": row[f"past_{i}_horse_weight"]
                     })
            
            if history_data:
                hist_df = pd.DataFrame(history_data)
                
                # Plotly with Secondary Y
                from plotly.subplots import make_subplots
                fig_line = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Rank (Left Y, Inverted)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['ç€é †'], name="ç€é †", mode='lines+markers'), secondary_y=False)
                
                # 3F (Right Y)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['3Fã‚¿ã‚¤ãƒ '], name="ä¸Šã‚Š3F", mode='lines+markers', line=dict(dash='dot')), secondary_y=True)
                
                fig_line.update_layout(title="éå»5èµ°ã®æ¨ç§» (ç€é † vs 3Fã‚¿ã‚¤ãƒ )")
                fig_line.update_yaxes(title_text="ç€é † (ä½ã„æ–¹ãŒè‰¯ã„)", autorange="reversed", secondary_y=False)
                fig_line.update_yaxes(title_text="ä¸Šã‚Š3Fã‚¿ã‚¤ãƒ  (ç§’)", secondary_y=True)
                
            else:
                fig_line = go.Figure()
                fig_line.add_annotation(text="è©³ç´°ãªéå»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            col_viz1, col_viz2 = st.columns(2)
            with col_viz1:
                st.markdown("##### èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ")
                st.plotly_chart(fig_radar, use_container_width=True)
            with col_viz2:
                st.markdown("##### éå»5èµ°ã®æ¨ç§»")
                st.plotly_chart(fig_line, use_container_width=True)

            # é¦¬ã®åŸºæœ¬æƒ…å ±ã¨AIäºˆæ¸¬çµæœã®ã‚µãƒãƒªãƒ¼
            st.markdown("---")
            st.markdown("##### ğŸ“ äºˆæ¸¬ã‚µãƒãƒªãƒ¼")
            selected_row = edited_df[edited_df['é¦¬å'] == selected_horse_name].iloc[0]

            col_s1, col_s2, col_s3, col_s4 = st.columns(4)
            with col_s1:
                st.metric("AIå‹ç‡", f"{selected_row['AIã‚¹ã‚³ã‚¢(%)']}%")
            with col_s2:
                st.metric("ä¿¡é ¼åº¦", f"{selected_row['ä¿¡é ¼åº¦']}%")
            with col_s3:
                ev_val = selected_row['æœŸå¾…å€¤(EV)']
                ev_delta = "è²·ã„æ¨å¥¨" if ev_val > 0 else "è¦‹é€ã‚Š"
                st.metric("æœŸå¾…å€¤(EV)", f"{ev_val:.2f}", delta=ev_delta)
            with col_s4:
                odds_val = selected_row.get('ç¾åœ¨ã‚ªãƒƒã‚º', 0.0)
                st.metric("ç¾åœ¨ã‚ªãƒƒã‚º", f"{odds_val:.1f}å€")

        except Exception as e:
            st.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.text(traceback.format_exc())
