import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
import json
import plotly.express as px
import plotly.graph_objects as go

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), 'scraper'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'ml'))

try:
    import auto_scraper
    from feature_engineering import process_data
except ImportError as e:
    st.error(f"Import Error: {e}")

st.set_page_config(page_title="AI Keiba Predictor", layout="wide")

# --- Utils ---
@st.cache_resource
def load_model():
    model_path = os.path.join(os.path.dirname(__file__), 'ml/models/lgbm_model.pkl')
    if os.path.exists(model_path):
        with open(model_path, 'rb') as f:
            return pickle.load(f)
    return None

def load_schedule_data():
    path = os.path.join(os.path.dirname(__file__), 'todays_data.json')
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# --- UI ---
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Logic Explanation
with st.expander("â„¹ï¸ ã“ã®AIäºˆæƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ã¤ã„ã¦ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)"):
    st.markdown("""
    ### ğŸ§  AIäºˆæƒ³ã®ä»•çµ„ã¿
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**LightGBM**ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€éå»ã®è†¨å¤§ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ3ç€ä»¥å†…ã«å…¥ã‚‹ç¢ºç‡ã€ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
    
    #### ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
    - **åŸºæœ¬æƒ…å ±**: æ ç•ªã€é¦¬ç•ªã€é¦¬é½¢ã€æ–¤é‡ã€é¨æ‰‹
    - **éå»5èµ°ã®æˆç¸¾**: ç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã€ä¸Šã‚Š3Fã€é€šéé †ï¼ˆè„šè³ªï¼‰ã€é¦¬ä½“é‡ã€é¦¬å ´çŠ¶æ…‹ã€**å¤©æ°—**ã€**æœ€çµ‚ã‚ªãƒƒã‚º**
    - **ç›´è¿‘é‡è¦–**: éå»ã®ãƒ¬ãƒ¼ã‚¹ã¯ç›´è¿‘ã®ã‚‚ã®ã»ã©é‡è¦è¦–ã™ã‚‹ã€Œæ™‚é–“æ¸›è¡°ã€å‡¦ç†ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
    
    #### æœŸå¾…å€¤ (EV) ã®è¨ˆç®—å¼
    å˜ã«å‹ã¤ç¢ºç‡ãŒé«˜ã„é¦¬ã‚’é¸ã¶ã®ã§ã¯ãªãã€ã€Œã‚ªãƒƒã‚ºã«å¯¾ã—ã¦æœŸå¾…å€¤ãŒé«˜ã„é¦¬ã€ã‚’è¦‹ã¤ã‘ã‚‹è¨­è¨ˆã§ã™ã€‚
    $$
    Expected Value = (AIå‹ç‡ \\times äºˆæƒ³å®¶ã®å°è£œæ­£ \\times ç¾åœ¨ã‚ªãƒƒã‚º) - 1.0
    $$
    - **ãƒ—ãƒ©ã‚¹ (ç·‘è‰²)**: é•·æœŸçš„ã«è²·ã£ã¦ãƒ—ãƒ©ã‚¹ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ã„é¦¬
    - **äºˆæƒ³å®¶ã®å°**: ã‚ãªãŸã®ç›´æ„Ÿï¼ˆå°ï¼‰ã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ã§ã€AIã®ç¢ºç‡ã‚’è£œæ­£ã§ãã¾ã™ (â—=1.5å€ãªã©)ã€‚
    """)

# --- Admin Menu ---
with st.expander("ğŸ›  ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ (ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»ãƒ¢ãƒ‡ãƒ«å†èª­ã¿è¾¼ã¿)"):
    col_admin1, col_admin2 = st.columns(2)
    
    with col_admin1:
        if st.button("ğŸ“… ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’æ›´æ–° (ä»Šå¾Œ1é€±é–“)"):
            with st.spinner("æœ€æ–°ã®ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ä¸­ (ç´„1åˆ†)..."):
                success, msg = auto_scraper.scrape_todays_schedule()
                if success:
                    st.success(msg)
                    st.rerun()
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {msg}")

    with col_admin2:
        if st.button("ğŸ§  æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿"):
            load_model.clear()
            st.cache_resource.clear()
            st.success("ãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸï¼")

# --- Race Selection ---
st.subheader("ğŸ“ ãƒ¬ãƒ¼ã‚¹é¸æŠ")

schedule_data = load_schedule_data()
race_id = None

if schedule_data and "races" in schedule_data:
    races = schedule_data['races']
    
    # 1. Filter by Date
    dates = sorted(list(set([r.get('date', 'Unknown') for r in races])))
    
    # Layout columns for selection
    col_date, col_venue, col_race = st.columns(3)
    
    with col_date:
         selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
    
    # Filter races by date
    todays_races = [r for r in races if r.get('date') == selected_date]
    
    if todays_races:
        # 2. Filter by Venue (New)
        venues = sorted(list(set([r['venue'] for r in todays_races])))
        
        with col_venue:
            selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ", venues)
            
        # Filter races by venue
        venue_races = [r for r in todays_races if r['venue'] == selected_venue]
        
        # 3. Select Race
        # Sort by race number just in case
        venue_races.sort(key=lambda x: int(x['number']))
        
        race_options = {f"{r['number']}R: {r['name']}": r['id'] for r in venue_races}
        
        with col_race:
            selected_label = st.selectbox("3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list(race_options.keys()))
            if selected_label:
                race_id = race_options[selected_label]
    else:
        st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
else:
    st.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    race_id = st.text_input("ãƒ¬ãƒ¼ã‚¹IDç›´æ¥å…¥åŠ› (12æ¡)", value="202305021211")


# Main Analysis
if race_id:
    st.header(f"ãƒ¬ãƒ¼ã‚¹åˆ†æ: {race_id}")
    
    if st.button("ğŸš€ ã“ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã™ã‚‹ (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»AIäºˆæ¸¬)"):
        with st.spinner("å‡ºé¦¬è¡¨ã¨éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­ (20ã€œ30ç§’ã‹ã‹ã‚Šã¾ã™)..."):
            # 1. Scrape
            df = auto_scraper.scrape_shutuba_data(race_id)
            
            if df is not None and not df.empty:
                # 2. FE
                X_df = process_data(df)
                
                # 3. Predict
                model = load_model()
                if model:
                    try:
                        # Drop meta cols for prediction
                        # Meta cols are handled in process_data, but result has meta + features + rank
                        # We need to filter only numeric features matching model
                        # Model expects features used in training.
                        # Features: weighted_avg_... + age
                        # We should robustly select.
                        
                        # Identify feature cols from X_df
                        # Exclude non-numeric and 'rank'
                        meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
                        features = [c for c in X_df.columns if c not in meta_cols and c != 'target_top3']
                        # Ensure numeric
                        X_pred = X_df[features].select_dtypes(include=['number']).fillna(0)
                        
                        probs = model.predict(X_pred)
                        
                        df['AI_Prob'] = probs
                        df['AI_Score'] = (probs * 100).astype(int)
                        
                        # Merge features back to df for display
                        # We need: turf_compatibility, dirt_compatibility, jockey_compatibility, distance_compatibility, weighted_avg_speed, weighted_avg_rank
                        cols_to_merge = [
                            'turf_compatibility', 'dirt_compatibility', 
                            'jockey_compatibility', 'distance_compatibility', 
                            'weighted_avg_speed', 'weighted_avg_rank'
                        ]
                        for c in cols_to_merge:
                            if c in X_df.columns:
                                df[c] = X_df[c]

                        
                    except Exception as e:
                        st.error(f"Prediction Error: {e}")
                        df['AI_Prob'] = 0.0
                        df['AI_Score'] = 0.0
                else:
                    st.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                    df['AI_Prob'] = 0.0
                    df['AI_Score'] = 0.0

                # 4. Display
                # Store in session state to persist edits
                st.session_state[f'data_{race_id}'] = df
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # Show Data if available
    if f'data_{race_id}' in st.session_state:
        df_display = st.session_state[f'data_{race_id}'].copy()
        
        # Prepare Editor DF
        # Columns: Horse, Prob, Odds, Mark
        if 'Odds' not in df_display.columns:
             # Try to get scraped odds if available
             if 'å˜å‹' in df_display.columns:
                 df_display['Odds'] = pd.to_numeric(df_display['å˜å‹'], errors='coerce').fillna(0.0)
             else:
                 df_display['Odds'] = 0.0
        
        rename_map = {
            'AI_Score': 'AIã‚¹ã‚³ã‚¢(%)',
            'Odds': 'ç¾åœ¨ã‚ªãƒƒã‚º',
            'æ€§é½¢': 'å¹´é½¢',
            'é¦¬ ç•ª': 'é¦¬ç•ª',
            'jockey_compatibility': 'é¨æ‰‹ç›¸æ€§',
            'distance_compatibility': 'è·é›¢é©æ€§',
            'course_compatibility': 'ã‚³ãƒ¼ã‚¹é©æ€§',
            'weighted_avg_speed': 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'
        }
        
        # Select appropriate course compatibility
        # If 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' contains 'èŠ', use turf, else dirt
        # Default to turf if unknown
        is_turf_race = True
        if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
             # Check first row (all same race)
             c_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
             if 'ãƒ€' in c_type:
                 is_turf_race = False
        
        if is_turf_race:
             df_display['course_compatibility'] = df_display.get('turf_compatibility', 10.0)
        else:
             df_display['course_compatibility'] = df_display.get('dirt_compatibility', 10.0)
             
        # Ensure all display columns exist
        defaults = {
            'jockey_compatibility': 10.0,
            'distance_compatibility': 10.0,
            'weighted_avg_speed': 16.0
        }
        for c, v in defaults.items():
            if c not in df_display.columns:
                df_display[c] = v


        display_cols = ['æ ', 'é¦¬ ç•ª', 'é¦¬å', 'æ€§é½¢', 'AI_Score', 'Odds', 'jockey_compatibility', 'course_compatibility', 'distance_compatibility']

        
        edited_df = df_display[display_cols].copy()
        edited_df.rename(columns=rename_map, inplace=True)
        
        # Add Mark column
        edited_df['äºˆæƒ³å°'] = ""
        
        st.subheader("ğŸ“ äºˆæƒ³ãƒ»ã‚ªãƒƒã‚ºå…¥åŠ›")
        
        col_input_1, col_input_2 = st.columns([3, 1])
        with col_input_1:
             st.info("ã€Œäºˆæƒ³å°ã€ã‚„ã€Œç¾åœ¨ã‚ªãƒƒã‚ºã€ã‚’ç·¨é›†ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœŸå¾…å€¤(EV)ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
        with col_input_2:
             if st.button("ğŸ”„ ç¾åœ¨ã‚ªãƒƒã‚ºã®ã¿æ›´æ–°"):
                 with st.spinner("æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
                     new_odds = auto_scraper.scrape_odds_for_race(race_id)
                     if new_odds:
                         # Update Session State
                         # new_odds is list of {number, odds}
                         odds_map = {x['number']: x['odds'] for x in new_odds}
                         
                         target_df = st.session_state[f'data_{race_id}']
                         
                         # Update 'å˜å‹' and 'Odds'
                         # Map using 'é¦¬ ç•ª' (ensure int type matching)
                         def update_odds(row):
                             try:
                                 num = int(row['é¦¬ ç•ª'])
                                 return odds_map.get(num, row.get('Odds', 0.0))
                             except:
                                 return row.get('Odds', 0.0)
                                 
                         target_df['Odds'] = target_df.apply(update_odds, axis=1)
                         target_df['å˜å‹'] = target_df['Odds'] # Sync
                         
                         st.session_state[f'data_{race_id}'] = target_df
                         st.success("ã‚ªãƒƒã‚ºã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                         st.rerun()
                     else:
                         st.warning("ã‚ªãƒƒã‚ºã®å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        
        edited_df = st.data_editor(
            edited_df,
            column_config={
                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                    "AIæœŸå¾…åº¦",
                    help="3ç€ä»¥å†…ã«å…¥ã‚‹AIäºˆæ¸¬ç¢ºç‡",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç¾åœ¨ã‚ªãƒƒã‚º": st.column_config.NumberColumn(
                    "ç¾åœ¨ã‚ªãƒƒã‚º",
                    help="æœ€æ–°ã®å˜å‹ã‚ªãƒƒã‚ºã‚’å…¥åŠ›",
                    step=0.1,
                    format="%.1f"
                ),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(
                    "æ¨å¥¨åº¦(Kelly)",
                    help="ã‚±ãƒªãƒ¼åŸºæº–ã«ã‚ˆã‚‹æ¨å¥¨è³­ã‘ç‡ (ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨åº¦)",
                    format="%.1f%%",
                    min_value=0,
                    max_value=30, # Max display scale (usually >30% is rare)
                ),
                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                    "äºˆæƒ³å°",
                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                    required=False,
                ),
                "é¨æ‰‹ç›¸æ€§": st.column_config.NumberColumn(
                    "é¨æ‰‹ç›¸æ€§",
                    help="ã“ã®é¨æ‰‹ã§ã®å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                ),
                "ã‚³ãƒ¼ã‚¹é©æ€§": st.column_config.NumberColumn(
                    "ã‚³ãƒ¼ã‚¹é©æ€§",
                    help="èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                ),
                "è·é›¢é©æ€§": st.column_config.NumberColumn(
                    "è·é›¢é©æ€§",
                    help="åŒè·é›¢ã§ã®å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                )
            },
            hide_index=True,
            num_rows="fixed"  
        )
        
        # Calculate EV
        mark_weights = {"â—": 1.5, "â—¯": 1.2, "â–²": 1.1, "â–³": 1.05, "âœ•": 0.0, "": 1.0}
        
        probs = edited_df['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
        odds = edited_df['ç¾åœ¨ã‚ªãƒƒã‚º']
        marks = edited_df['äºˆæƒ³å°']
        
        evs = []
        kellys = []
        
        for p, o, m in zip(probs, odds, marks):
            # Penalize low probability (Safety filter)
            if p < 0.08: # Ignore if AI chance is less than 8%
                ev = -1.0
                kelly = 0.0
            else:
                w = mark_weights.get(m, 1.0)
                p_weighted = p * w
                
                # EV
                ev = (p_weighted * o) - 1.0
                
                # Kelly: (p*o - 1) / (o - 1)
                if o > 1.0:
                    k = ((p_weighted * o) - 1.0) / (o - 1.0)
                    kelly = max(0.0, k * 100) # Convert to %
                else:
                    kelly = 0.0
                    
            evs.append(ev)
            kellys.append(kelly)
            
        edited_df['æœŸå¾…å€¤(EV)'] = evs
        edited_df['æ¨å¥¨åº¦(Kelly)'] = kellys

        
        # Highlight high EV
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]
        
        # Highlight high EV and Kelly
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]
        
        st.dataframe(
            edited_df.style
            .format({'æ¨å¥¨åº¦(Kelly)': lambda x: '-' if x <= 0 else f'{x:.1f}%', 'æœŸå¾…å€¤(EV)': '{:.2f}'})
            .applymap(lambda x: 'background-color: #d4edda' if x > 0 else '', subset=['æœŸå¾…å€¤(EV)', 'æ¨å¥¨åº¦(Kelly)'])
        )

        
        # Visualization
        st.subheader("ğŸ“Š è©³ç´°åˆ†æ")
        
        try:
            # 1. Select a horse for detailed analysis
            horse_options = df_display['é¦¬å'].tolist()
            selected_horse_name = st.selectbox("è©³ç´°ã‚’è¦‹ã‚‹é¦¬ã‚’é¸æŠ", horse_options)
            
            # Find row
            row = df_display[df_display['é¦¬å'] == selected_horse_name].iloc[0]
            
            # 2. Radar Chart (5 Axes)
            # Speed (Real), Stamina/Form (Rank), Jockey, Course, Distance
            
            # --- Scoring Logic (Lower rank is better, so Invert) ---
            # Rank 1 -> Score 10, Rank 10 -> Score 1, Rank 18 -> 0
            def rank_to_score(r):
                if pd.isna(r) or r > 18: return 0
                return max(0, min(10, (14 - r) * (10/13))) # Approx 1->10, 14->0

            # Speed: 16.0 is baseline. >17 is fast? <15 slow?
            # 1000m/60s = 16.6. 
            sp_val = row.get('weighted_avg_speed', 16.0)
            score_speed = max(0, min(10, (sp_val - 15.0) * 5)) # 17.0->10, 15.0->0

            j_val = row.get('jockey_compatibility', 10.0)
            score_jockey = rank_to_score(j_val)
            
            c_val = row.get('course_compatibility', 10.0) # Calculated above but only in display_df... wait, we are accessing df_display row.
            # We added 'course_compatibility' to df_display in UI section.
            # Re-calculate here if needed OR ensure row comes from df_display.
            # row comes from df_display!
            score_course = rank_to_score(c_val)
            
            d_val = row.get('distance_compatibility', 10.0)
            score_dist = rank_to_score(d_val)
            
            rank_val = row.get('weighted_avg_rank', 10.0)
            score_form = rank_to_score(rank_val)

            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=[score_speed, score_form, score_jockey, score_course, score_dist, score_speed],
                theta=['ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å®Ÿç¸¾(ç€é †)', 'é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§'],
                fill='toself',
                name=selected_horse_name
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 10])), 
                title=f"èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ: {selected_horse_name}"
            )
            
            # 3. Multi-Axis Line Chart (Past 5 Runs)
            history_data = []
            for i in range(5, 0, -1): # Chronological 5->1 (Oldest to Newest)
                if f"past_{i}_rank" in row and pd.notna(row[f"past_{i}_rank"]):
                     history_data.append({
                         "Run": f"{i}èµ°å‰",
                         "ç€é †": row[f"past_{i}_rank"],
                         "3Fã‚¿ã‚¤ãƒ ": row[f"past_{i}_last_3f"],
                         "é¦¬ä½“é‡": row[f"past_{i}_horse_weight"]
                     })
            
            if history_data:
                hist_df = pd.DataFrame(history_data)
                
                # Plotly with Secondary Y
                from plotly.subplots import make_subplots
                fig_line = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Rank (Left Y, Inverted)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['ç€é †'], name="ç€é †", mode='lines+markers'), secondary_y=False)
                
                # 3F (Right Y)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['3Fã‚¿ã‚¤ãƒ '], name="ä¸Šã‚Š3F", mode='lines+markers', line=dict(dash='dot')), secondary_y=True)
                
                fig_line.update_layout(title="éå»5èµ°ã®æ¨ç§» (ç€é † vs 3Fã‚¿ã‚¤ãƒ )")
                fig_line.update_yaxes(title_text="ç€é † (ä½ã„æ–¹ãŒè‰¯ã„)", autorange="reversed", secondary_y=False)
                fig_line.update_yaxes(title_text="ä¸Šã‚Š3Fã‚¿ã‚¤ãƒ  (ç§’)", secondary_y=True)
                
            else:
                fig_line = go.Figure()
                fig_line.add_annotation(text="è©³ç´°ãªéå»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            col_viz1, col_viz2 = st.columns(2)
            col_viz1.plotly_chart(fig_radar, use_container_width=True)
            col_viz2.plotly_chart(fig_line, use_container_width=True)
            
        except Exception as e:
            st.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.text(traceback.format_exc())
