import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
import json
import plotly.express as px
import plotly.graph_objects as go
import time

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), 'scraper'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'ml'))

try:
    import auto_scraper
    from feature_engineering import process_data
except ImportError as e:
    st.error(f"Import Error: {e}")

st.set_page_config(page_title="AI Keiba Predictor", layout="wide")

# --- Utils ---
@st.cache_resource
def load_model(mode="JRA"):
    model_path = os.path.join(os.path.dirname(__file__), f"ml/models/lgbm_model_nar.pkl" if mode == "NAR" else "ml/models/lgbm_model.pkl")
    if os.path.exists(model_path):
        with open(model_path, 'rb') as f:
            return pickle.load(f)
    return None

def load_schedule_data(mode="JRA"):
    json_path = os.path.join(os.path.dirname(__file__), "todays_data_nar.json" if mode == "NAR" else "todays_data.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# --- UI ---
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Logic Explanation
with st.expander("â„¹ï¸ ã“ã®AIäºˆæƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ã¤ã„ã¦ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)"):
    st.markdown("""
    ### ğŸ§  AIäºˆæƒ³ã®ä»•çµ„ã¿
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**LightGBM**ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€éå»ã®è†¨å¤§ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ3ç€ä»¥å†…ã«å…¥ã‚‹ç¢ºç‡ã€ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
    
    #### ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
    - **åŸºæœ¬æƒ…å ±**: æ ç•ªã€é¦¬ç•ªã€é¦¬é½¢ã€æ–¤é‡ã€é¨æ‰‹
    - **éå»5èµ°ã®æˆç¸¾**: ç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã€ä¸Šã‚Š3Fã€é€šéé †ï¼ˆè„šè³ªï¼‰ã€é¦¬ä½“é‡ã€é¦¬å ´çŠ¶æ…‹ã€**å¤©æ°—**ã€**æœ€çµ‚ã‚ªãƒƒã‚º**
    - **ç›´è¿‘é‡è¦–**: éå»ã®ãƒ¬ãƒ¼ã‚¹ã¯ç›´è¿‘ã®ã‚‚ã®ã»ã©é‡è¦è¦–ã™ã‚‹ã€Œæ™‚é–“æ¸›è¡°ã€å‡¦ç†ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
    
    #### æœŸå¾…å€¤ (EV) ã®è¨ˆç®—å¼
    å˜ã«å‹ã¤ç¢ºç‡ãŒé«˜ã„é¦¬ã‚’é¸ã¶ã®ã§ã¯ãªãã€ã€Œã‚ªãƒƒã‚ºã«å¯¾ã—ã¦æœŸå¾…å€¤ãŒé«˜ã„é¦¬ã€ã‚’è¦‹ã¤ã‘ã‚‹è¨­è¨ˆã§ã™ã€‚
    $$
    Expected Value = (AIå‹ç‡ \\times äºˆæƒ³å®¶ã®å°è£œæ­£ \\times ç¾åœ¨ã‚ªãƒƒã‚º) - 1.0
    $$
    - **ãƒ—ãƒ©ã‚¹ (ç·‘è‰²)**: é•·æœŸçš„ã«è²·ã£ã¦ãƒ—ãƒ©ã‚¹ã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ã„é¦¬
    - **äºˆæƒ³å®¶ã®å°**: ã‚ãªãŸã®ç›´æ„Ÿï¼ˆå°ï¼‰ã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ã§ã€AIã®ç¢ºç‡ã‚’è£œæ­£ã§ãã¾ã™

    #### ğŸ‡ ä¸­å¤®ç«¶é¦¬ vs ğŸŒ™ åœ°æ–¹ç«¶é¦¬
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¼šå ´ã‹ã‚‰è‡ªå‹•çš„ã«ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã¨åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰ã‚’åˆ¤å®šã—ã€ãã‚Œãã‚Œã«æœ€é©åŒ–ã•ã‚ŒãŸæœŸå¾…å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    **ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.3å€, â—¯=1.15å€ï¼ˆæ§ãˆã‚ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚

    **åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.8å€, â—¯=1.4å€ï¼ˆç©æ¥µçš„ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„
    """)

# --- Admin Menu ---
st.markdown("### è¨­å®š")
mode = st.radio("é–‹å‚¬ãƒ¢ãƒ¼ãƒ‰ (Mode)", ["JRA (ä¸­å¤®ç«¶é¦¬)", "NAR (åœ°æ–¹ç«¶é¦¬)"], horizontal=True)
mode_val = "JRA" if "JRA" in mode else "NAR"

with st.expander("ğŸ› ï¸ ç®¡ç†ãƒ„ãƒ¼ãƒ« (ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°ãªã©)"):
    col_admin_1, col_admin_2 = st.columns([1, 1])
    with col_admin_1:
         if st.button("ğŸ“… ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’æ›´æ–° (ä»Šå¾Œ1é€±é–“)"):
            with st.spinner(f"{mode_val}ã®æœ€æ–°ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ä¸­..."):
                success, msg = auto_scraper.scrape_todays_schedule(mode=mode_val)
                if success:
                    st.success(msg)
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {msg}")
    
    with col_admin_2:
         if st.button("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿"):
             st.cache_resource.clear()
             st.success("ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ¬¡å›äºˆæ¸¬æ™‚ã«å†ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# --- Race Selection ---
st.subheader("ğŸ“ ãƒ¬ãƒ¼ã‚¹é¸æŠ")

schedule_data = load_schedule_data(mode=mode_val)
race_id = None

if schedule_data and "races" in schedule_data:
    races = schedule_data['races']
    
    # 1. Filter by Date
    dates = sorted(list(set([r.get('date', 'Unknown') for r in races])))
    
    # Layout columns for selection
    col_date, col_venue, col_race = st.columns(3)
    
    with col_date:
         selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
    
    # Filter races by date
    todays_races = [r for r in races if r.get('date') == selected_date]
    
    if todays_races:
        # 2. Filter by Venue (New)
        venues = sorted(list(set([r['venue'] for r in todays_races])))
        
        with col_venue:
            selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ", venues)
            
        # Filter races by venue
        venue_races = [r for r in todays_races if r['venue'] == selected_venue]
        
        # 3. Select Race
        # Sort by race number just in case
        venue_races.sort(key=lambda x: int(x['number']))
        
        race_options = {f"{r['number']}R: {r['name']}": r['id'] for r in venue_races}
        
        with col_race:
            selected_label = st.selectbox("3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list(race_options.keys()))
            if selected_label:
                race_id = race_options[selected_label]
    else:
        st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
else:
    st.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    race_id = st.text_input("ãƒ¬ãƒ¼ã‚¹IDç›´æ¥å…¥åŠ› (12æ¡)", value="202305021211")


# Main Analysis
if race_id:
    st.header(f"ãƒ¬ãƒ¼ã‚¹åˆ†æ: {race_id}")
    
    # Load Model
    model = load_model(mode=mode_val)

    button_analyze = st.button("ğŸš€ ã“ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã™ã‚‹ (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»AIäºˆæ¸¬)")
    
    if button_analyze:
        if not race_id:
             st.error("ãƒ¬ãƒ¼ã‚¹IDãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        elif not model:
             st.error(f"ãƒ¢ãƒ‡ãƒ« ({mode_val}) ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ç®¡ç†ç”»é¢ã§å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("å‡ºé¦¬è¡¨ã‚’å–å¾—ã—ã€AIäºˆæ¸¬ã‚’å®Ÿè¡Œä¸­..."):
                # Scrape Shutuba
                df = auto_scraper.scrape_shutuba_data(race_id, mode=mode_val)
            
            if df is not None and not df.empty:
                # 2. FE (use_venue_features=False to match existing model trained with 27 features)
                X_df = process_data(df, use_venue_features=False)
                
                # 3. Predict
                if model:
                    try:
                        # Drop meta cols for prediction
                        # Meta cols are handled in process_data, but result has meta + features + rank
                        # We need to filter only numeric features matching model
                        # Model expects features used in training.
                        # Features: weighted_avg_... + age
                        # We should robustly select.
                        
                        # Identify feature cols from X_df
                        # Robustly select features matching the model
                        try:
                            model_features = model.feature_name()
                            # Ensure all model features exist in X_df
                            for f in model_features:
                                if f not in X_df.columns:
                                    X_df[f] = 0.0
                            
                            X_pred = X_df[model_features].fillna(0.0)
                            
                            probs = model.predict(X_pred)
                            
                            df['AI_Prob'] = probs
                            df['AI_Score'] = (probs * 100).astype(int)
                        except Exception as e:
                            st.error(f"Prediction Error (Feature Mismatch): {e}")
                            st.write(f"Model expects: {model.feature_name()}")
                            st.write(f"Data has: {list(X_df.columns)}")
                            raise e
                        
                        # Merge features back to df for display
                        # We need: turf_compatibility, dirt_compatibility, jockey_compatibility, distance_compatibility, weighted_avg_speed, weighted_avg_rank
                        cols_to_merge = [
                            'turf_compatibility', 'dirt_compatibility', 
                            'jockey_compatibility', 'distance_compatibility', 
                            'weighted_avg_speed', 'weighted_avg_rank'
                        ]
                        for c in cols_to_merge:
                            if c in X_df.columns:
                                df[c] = X_df[c]

                        
                    except Exception as e:
                        st.error(f"Prediction Error: {e}")
                        df['AI_Prob'] = 0.0
                        df['AI_Score'] = 0.0
                else:
                    st.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                    df['AI_Prob'] = 0.0
                    df['AI_Score'] = 0.0

                # 4. Display
                # Store in session state to persist edits
                st.session_state[f'data_{race_id}'] = df
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # Show Data if available
    if f'data_{race_id}' in st.session_state:
        df_display = st.session_state[f'data_{race_id}'].copy()
        
        # Prepare Editor DF
        # Columns: Horse, Prob, Odds, Mark
        if 'Odds' not in df_display.columns:
             # Try to get scraped odds if available
             if 'å˜å‹' in df_display.columns:
                 df_display['Odds'] = pd.to_numeric(df_display['å˜å‹'], errors='coerce').fillna(0.0)
             else:
                 df_display['Odds'] = 0.0
        
        rename_map = {
            'AI_Score': 'AIã‚¹ã‚³ã‚¢(%)',
            'Odds': 'ç¾åœ¨ã‚ªãƒƒã‚º',
            'æ€§é½¢': 'å¹´é½¢',
            'é¦¬ ç•ª': 'é¦¬ç•ª',
            'jockey_compatibility': 'é¨æ‰‹ç›¸æ€§',
            'distance_compatibility': 'è·é›¢é©æ€§',
            'course_compatibility': 'ã‚³ãƒ¼ã‚¹é©æ€§',
            'weighted_avg_speed': 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'
        }
        
        # Select appropriate course compatibility
        # If 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' contains 'èŠ', use turf, else dirt
        # Default to turf if unknown
        is_turf_race = True
        if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
             # Check first row (all same race)
             c_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
             if 'ãƒ€' in c_type:
                 is_turf_race = False
        
        if is_turf_race:
             df_display['course_compatibility'] = df_display.get('turf_compatibility', 10.0)
        else:
             df_display['course_compatibility'] = df_display.get('dirt_compatibility', 10.0)
             
        # Ensure all display columns exist
        defaults = {
            'jockey_compatibility': 10.0,
            'distance_compatibility': 10.0,
            'weighted_avg_speed': 16.0
        }
        for c, v in defaults.items():
            if c not in df_display.columns:
                df_display[c] = v


        display_cols = ['æ ', 'é¦¬ ç•ª', 'é¦¬å', 'æ€§é½¢', 'AI_Score', 'Odds', 'jockey_compatibility', 'course_compatibility', 'distance_compatibility']

        
        edited_df = df_display[display_cols].copy()
        edited_df.rename(columns=rename_map, inplace=True)
        
        # Add Mark column
        edited_df['äºˆæƒ³å°'] = ""
        
        st.subheader("ğŸ“ äºˆæƒ³ãƒ»ã‚ªãƒƒã‚ºå…¥åŠ›")
        
        col_input_1, col_input_2 = st.columns([3, 1])
        with col_input_1:
             st.info("ã€Œäºˆæƒ³å°ã€ã‚„ã€Œç¾åœ¨ã‚ªãƒƒã‚ºã€ã‚’ç·¨é›†ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœŸå¾…å€¤(EV)ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
        with col_input_2:
             if st.button("ğŸ”„ æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—"):
                 with st.spinner("æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
                     try:
                         current_odds = auto_scraper.scrape_odds_for_race(race_id, mode=mode_val)
                         # Update session state df
                         if current_odds:
                             odds_map = {x['number']: x['odds'] for x in current_odds}
                             
                             target_df = st.session_state[f'data_{race_id}']
                             
                             # Update 'å˜å‹' and 'Odds'
                             def update_odds(row):
                                 try:
                                     num = int(row['é¦¬ ç•ª'])
                                     return odds_map.get(num, row.get('Odds', 0.0))
                                 except:
                                     return row.get('Odds', 0.0)
                                 
                             target_df['Odds'] = target_df.apply(update_odds, axis=1)
                             target_df['å˜å‹'] = target_df['Odds'] # Sync
                             
                             st.session_state[f'data_{race_id}'] = target_df
                             st.success("ã‚ªãƒƒã‚ºã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                             st.rerun()
                         else:
                             st.warning("ã‚ªãƒƒã‚ºã®å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                     except Exception as e:
                         st.error(f"ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        
        edited_df = st.data_editor(
            edited_df,
            column_config={
                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                    "AIæœŸå¾…åº¦",
                    help="3ç€ä»¥å†…ã«å…¥ã‚‹AIäºˆæ¸¬ç¢ºç‡",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç¾åœ¨ã‚ªãƒƒã‚º": st.column_config.NumberColumn(
                    "ç¾åœ¨ã‚ªãƒƒã‚º",
                    help="æœ€æ–°ã®å˜å‹ã‚ªãƒƒã‚ºã‚’å…¥åŠ›",
                    step=0.1,
                    format="%.1f"
                ),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(
                    "æ¨å¥¨åº¦(Kelly)",
                    help="ã‚±ãƒªãƒ¼åŸºæº–ã«ã‚ˆã‚‹æ¨å¥¨è³­ã‘ç‡ (ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨åº¦)",
                    format="%.1f%%",
                    min_value=0,
                    max_value=30, # Max display scale (usually >30% is rare)
                ),
                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                    "äºˆæƒ³å°",
                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                    required=False,
                ),
                "é¨æ‰‹ç›¸æ€§": st.column_config.NumberColumn(
                    "é¨æ‰‹ç›¸æ€§",
                    help="ã“ã®é¨æ‰‹ã§ã®å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                ),
                "ã‚³ãƒ¼ã‚¹é©æ€§": st.column_config.NumberColumn(
                    "ã‚³ãƒ¼ã‚¹é©æ€§",
                    help="èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                ),
                "è·é›¢é©æ€§": st.column_config.NumberColumn(
                    "è·é›¢é©æ€§",
                    help="åŒè·é›¢ã§ã®å¹³å‡ç€é † (å°ã•ã„ã»ã©è‰¯ã„)",
                    format="%.1f"
                )
            },
            hide_index=True,
            num_rows="fixed"  
        )
        
        # Calculate EV with JRA/NAR distinction
        # Determine race type from venue
        race_type = 'JRA'  # Default
        venue = ''  # Initialize venue

        if 'ä¼šå ´' in df_display.columns and len(df_display) > 0:
            venue = df_display['ä¼šå ´'].iloc[0]

            # Import race classifier
            try:
                import sys
                import os
                sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'ml'))
                from race_classifier import classify_race_type
                race_type = classify_race_type(venue)
            except:
                # Fallback
                jra_venues = ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']
                race_type = 'JRA' if venue in jra_venues else 'NAR'

        # EV calculation with race type AND venue specific parameters
        # Import venue characteristics
        venue_char = None
        try:
            from ml.venue_characteristics import get_venue_characteristics, get_distance_category
            if venue:
                venue_char = get_venue_characteristics(venue)
        except Exception as e:
            # Silently fail if venue characteristics not available
            pass

        # Base parameters by race type
        if race_type == 'JRA':
            # ä¸­å¤®ç«¶é¦¬: ä¿¡é ¼æ€§ãŒé«˜ã„ã®ã§å°ã®å½±éŸ¿ã‚’æŠ‘ãˆã‚‹
            mark_weights = {"â—": 1.3, "â—¯": 1.15, "â–²": 1.08, "â–³": 1.03, "âœ•": 0.0, "": 1.0}
            safety_threshold = 0.08  # 8%
            venue_info = f"ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰" + (f" - {venue}" if venue else "")
        else:
            # åœ°æ–¹ç«¶é¦¬: æ³¢ä¹±ãŒå¤šã„ã®ã§å°ã®é‡ã¿ã‚’å¤§ãã
            mark_weights = {"â—": 1.8, "â—¯": 1.4, "â–²": 1.2, "â–³": 1.1, "âœ•": 0.0, "": 1.0}
            safety_threshold = 0.05  # 5%ï¼ˆåœ°æ–¹ã¯ä½ç¢ºç‡ã§ã‚‚ç‹™ã†ä¾¡å€¤ã‚ã‚Šï¼‰
            venue_info = f"ğŸŒ™ åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰" + (f" - {venue}" if venue else "")

        # Venue-specific adjustments
        venue_features = []
        if venue_char:
            # ç›´ç·šè·é›¢ã«ã‚ˆã‚‹èª¿æ•´
            straight = venue_char.get('turf_straight', 300)
            if straight and straight > 500:  # é•·ã„ç›´ç·šï¼ˆæ–°æ½Ÿãªã©ï¼‰
                mark_weights["â—"] *= 0.95  # äººæ°—é¦¬ã‚„ã‚„ä¸åˆ©
                mark_weights["â–³"] *= 1.05  # ç©´é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("é•·ç›´ç·š")
            elif straight and straight < 300:  # çŸ­ã„ç›´ç·šï¼ˆä¸­å±±ã€å‡½é¤¨ãªã©ï¼‰
                mark_weights["â—"] *= 1.05  # äººæ°—é¦¬æœ‰åˆ©
                mark_weights["â–³"] *= 0.95  # ç©´é¦¬ä¸åˆ©
                venue_features.append("çŸ­ç›´ç·š")

            # ã‚³ãƒ¼ã‚¹å¹…ã«ã‚ˆã‚‹èª¿æ•´
            track_width = venue_char.get('track_width')
            if track_width == 'narrow':  # ç‹­ã„ã‚³ãƒ¼ã‚¹
                mark_weights["â—"] *= 1.03  # å…ˆè¡Œæœ‰åˆ©ã€äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("å°å›ã‚Š")
            elif track_width == 'wide':  # åºƒã„ã‚³ãƒ¼ã‚¹
                # é¦¬ç¾¤ãŒåºƒãŒã‚Šã‚„ã™ãã€å±•é–‹æ¬¡ç¬¬
                pass

            # å‹¾é…ã«ã‚ˆã‚‹èª¿æ•´
            slope = venue_char.get('slope')
            if slope == 'steep':  # æ€¥å‚ã‚ã‚Šï¼ˆä¸­å±±ãªã©ï¼‰
                mark_weights["â—"] *= 1.02  # ãƒ‘ãƒ¯ãƒ¼ã‚ã‚‹äººæ°—é¦¬æœ‰åˆ©
                venue_features.append("å‚ã‚ã‚Š")

        if venue_features:
            venue_info += f" ({', '.join(venue_features)})"

        st.info(venue_info)

        probs = edited_df['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
        odds = edited_df['ç¾åœ¨ã‚ªãƒƒã‚º']
        marks = edited_df['äºˆæƒ³å°']

        # Get run style compatibility if available
        run_style_compatibility = None
        if 'venue_run_style_compatibility' in edited_df.columns:
            run_style_compatibility = edited_df['venue_run_style_compatibility']

        # Get frame (æ ) for venue-specific frame advantage
        frames = None
        if 'æ ' in edited_df.columns:
            frames = edited_df['æ ']

        evs = []
        kellys = []

        for idx, (p, o, m) in enumerate(zip(probs, odds, marks)):
            # Safety filter (race type specific)
            if p < safety_threshold:
                ev = -1.0
                kelly = 0.0
            else:
                w = mark_weights.get(m, 1.0)

                # Adjust probability for NAR (higher uncertainty)
                if race_type == 'NAR':
                    # åœ°æ–¹ã¯äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®
                    # é«˜ã„ç¢ºç‡ã¯å°‘ã—ä¸‹ã’ã€ä½ã„ç¢ºç‡ã¯å°‘ã—ä¸Šã’ã‚‹
                    adjusted_p = p * 0.9 + 0.05
                else:
                    adjusted_p = p

                # Apply run style compatibility if available
                if run_style_compatibility is not None:
                    run_compat = run_style_compatibility.iloc[idx]
                    if not pd.isna(run_compat):
                        # è„šè³ªç›¸æ€§ãŒè‰¯ã„é¦¬ã¯æœŸå¾…å€¤ã‚’ä¸Šã’ã‚‹
                        adjusted_p *= run_compat

                # Apply frame advantage if available
                if frames is not None:
                    try:
                        frame = int(frames.iloc[idx])
                         
                        # Default Venue Char adjustments
                        if venue_char:
                            outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                            if frame >= 6:  # å¤–æ 
                                adjusted_p *= outer_advantage
                            elif frame <= 3:  # å†…æ 
                                adjusted_p *= (2.0 - outer_advantage)
                        
                        # Tipster Logic: Mizusawa Specific
                        # æ°´æ²¢ã¯ã€Œå°å›ã‚Šã€ã€Œå…ˆè¡Œæœ‰åˆ©ã€ã€Œå†…æ æœ‰åˆ©ï¼ˆç‰¹ã«1300/1400mï¼‰ã€
                        if 'æ°´æ²¢' in venue_info:
                             # å†…æ  (1-3) æœ‰åˆ©
                             if frame <= 3:
                                 adjusted_p *= 1.15 # å†…æ ãƒœãƒ¼ãƒŠã‚¹
                             # å¤–æ  (7-8) å‰²å¼•
                             elif frame >= 7:
                                 adjusted_p *= 0.95
                        
                        # Tipster Logic: Kanazawa Specific
                        # é‡‘æ²¢ã¯ã€Œ1500mã¯å¤–æ ã‚‚è‡ªåœ¨ã€ã€Œ1400mã¯å†…æ å…ˆè¡Œæœ‰åˆ©ã€
                        if 'é‡‘æ²¢' in venue_info:
                            # è·é›¢åˆ¤å®š
                            is_1400 = False
                            if 'è·é›¢' in edited_df.columns:
                                try:
                                    d_val = int(str(edited_df['è·é›¢'].iloc[idx]).replace('m',''))
                                    if d_val == 1400: is_1400 = True
                                except: pass
                            
                            if is_1400:
                                # 1400m: å†…æ ï¼ˆ1-3æ ï¼‰å…ˆè¡Œæœ‰åˆ©ï¼ˆåŸºæœ¬ã‚»ã‚ªãƒªãƒ¼ï¼‰
                                if frame <= 3:
                                    adjusted_p *= 1.10
                                elif frame >= 7:
                                    adjusted_p *= 0.95
                                    
                                # è·é›¢é©æ€§ä¸€è‡´ï¼ˆ1400må¾—æ„ï¼‰ã®é¦¬ï¼ˆAIã‚¹ã‚³ã‚¢é«˜è©•ä¾¡é¦¬ï¼‰ã¸ã®ãƒœãƒ¼ãƒŠã‚¹
                                if p > 0.25:
                                    adjusted_p *= 1.05
                            else:
                                # 1500mä»–: å¤–æ (5-8)ã‚‚å‰²å¼•ã›ãšã€ã‚€ã—ã‚è‡ªåœ¨æ€§ã§ãƒ—ãƒ©ã‚¹è©•ä¾¡ï¼ˆç‰¹ã«äººæ°—é¦¬ï¼‰
                                if frame >= 5:
                                    adjusted_p *= 1.05 # å¤–æ ã®è‡ªåœ¨æ€§ã‚’è©•ä¾¡
                            
                            # 1. é€ƒã’ãƒ»å…ˆè¡Œï¼ˆè„šè³ª1-2ï¼‰ã‚’å¤§å¹…ãƒ—ãƒ©ã‚¹ï¼ˆå…¨è·é›¢å…±é€šï¼‰
                            pass

                        # Tipster Logic: Kawasaki Specific
                        # å·å´1500mã¯ã€Œã‚³ãƒ¼ãƒŠãƒ¼4å›ã®ç‹¬ç‰¹ãªã‚³ãƒ¼ã‚¹ã€ã€Œå†…æ ï¼ˆç‰¹ã«1-2æ ï¼‰ãŒåœ§å€’çš„æœ‰åˆ©ã€ã€Œå¤–æ ã¯è·é›¢ãƒ­ã‚¹å¤§ã€
                        if 'å·å´' in venue_info:
                            # 1. å†…æ ï¼ˆ1-2æ ï¼‰ã¯ã€Œè–åŸŸã€ç´šã®æœ‰åˆ©
                            if frame <= 2:
                                adjusted_p *= 1.20 # å¼·åŠ›ãªå†…æ ãƒœãƒ¼ãƒŠã‚¹
                            
                            # 2. å¤–æ ï¼ˆ7-8æ ï¼‰ã¯ã‚³ãƒ¼ãƒŠãƒ¼ãã¤ãè·é›¢ãƒ­ã‚¹å¤§
                            elif frame >= 7:
                                adjusted_p *= 0.90 # å³ã—ã‚ã®å‰²å¼•
                            
                            # 3. é¨æ‰‹ã®è…•ï¼ˆã‚³ãƒ¼ãƒŠãƒ¼å·§è€…ï¼‰
                            # jockey_compatibilityãŒé«˜ã„å ´åˆã€å°‘ã—ãƒœãƒ¼ãƒŠã‚¹
                            if 'jockey_compatibility' in edited_df.columns:
                                j_compat = edited_df['jockey_compatibility'].iloc[idx]
                                if j_compat <= 5.0 and j_compat > 0: # 1ã«è¿‘ã„ã»ã©å¥½æˆç¸¾ï¼ˆå¹³å‡ç€é †ï¼‰
                                     adjusted_p *= 1.05

                        # Tipster Logic: Sonoda Specific
                        # åœ’ç”°ã¯ã€Œ1230mã¯å¤–æ æœ‰åˆ©ï¼ˆã‚¹ãƒ ãƒ¼ã‚ºã«å…ˆè¡Œï¼‰ã€
                        if 'åœ’ç”°' in venue_info:
                             # 1230mæˆ¦ã‹ã©ã†ã‹ã®åˆ¤å®šï¼ˆè·é›¢åˆ—ãŒã‚ã‚Œã°ï¼‰
                             is_1230 = False
                             if 'è·é›¢' in edited_df.columns:
                                 try:
                                     d_val = int(str(edited_df['è·é›¢'].iloc[idx]).replace('m',''))
                                     if d_val == 1230: is_1230 = True
                                 except: pass
                             
                             if is_1230:
                                 # å¤–æ ï¼ˆ6-8æ ï¼‰æœ‰åˆ©
                                 if frame >= 6:
                                     adjusted_p *= 1.10
                             else:
                                 # åœ’ç”°1400mä»–: ã€Œå†…æ ã®å…ˆè¡Œé¦¬ã¯è¢«ã›ã‚‰ã‚Œã‚‹ãƒªã‚¹ã‚¯ã‚ã‚Šã€ã€Œå¤–æ ï¼ˆç‰¹ã«8æ ï¼‰ãŒå¥½æˆç¸¾ã€
                                 if frame >= 7:
                                     adjusted_p *= 1.05 # å¤–æ ãƒœãƒ¼ãƒŠã‚¹
                                 elif frame <= 2:
                                     adjusted_p *= 0.95 # å†…æ ã®è¢«ã•ã‚Œãƒªã‚¹ã‚¯å‰²å¼•
                                 
                                 # ã‚¹ãƒ”ãƒ¼ãƒ‰çµ¶å¯¾ä¸»ç¾©ï¼ˆæŒã¡æ™‚è¨ˆï¼‰
                                 if p > 0.3: # AIãŒé«˜è©•ä¾¡ã—ã¦ã„ã‚‹å ´åˆï¼ˆï¼èƒ½åŠ›ä¸Šä½ï¼‰
                                     adjusted_p *= 1.05 # ã•ã‚‰ã«å¾ŒæŠ¼ã—
                        
                        # Tipster Logic: Kasamatsu Specific
                        # ç¬ æ¾1400m/1600mã¯ã€Œé€ƒã’ãƒ»å…ˆè¡Œåœ§å€’çš„æœ‰åˆ©ã€ã€Œå†…æ ã®é€ƒã’æ®‹ã‚ŠãŒå¼·ã„ã€
                        if 'ç¬ æ¾' in venue_info:
                             # 1600mã‚‚1ã‚³ãƒ¼ãƒŠãƒ¼ã¾ã§200mã¨çŸ­ãã€å†…æ å…ˆè¡ŒãŒçµ¶å¯¾æœ‰åˆ©
                             
                             # 2. å†…æ ï¼ˆ1-3æ ï¼‰æœ‰åˆ©ï¼ˆç‰¹ã«é€ƒã’é¦¬ï¼‰
                             if frame <= 3:
                                 adjusted_p *= 1.15
                             # å¤–æ ã¯å‰²å¼•ï¼ˆè¢«ã•ã‚Œã‚‹ãƒªã‚¹ã‚¯å¤§ï¼‰
                             elif frame >= 7:
                                 adjusted_p *= 0.95
                                 
                             # 3. å…ˆè¡ŒåŠ›ï¼ˆæŒã¡æ™‚è¨ˆæ›ç®—ï¼‰
                             # 1600mæ›ç®—ãªã©ã§ãƒˆãƒƒãƒ—ã®é¦¬ï¼ˆAIé«˜è©•ä¾¡é¦¬ï¼‰ã‚’ã•ã‚‰ã«å¾ŒæŠ¼ã—
                             if p > 0.25:
                                 adjusted_p *= 1.05

                    except: pass

                # Market Confidence Fallback (Missing Data Safeguard)
                # ã‚ªãƒƒã‚º1.0~2.0å€ã®åœ§å€’çš„äººæ°—é¦¬ã«å¯¾ã—ã€AIãŒæ¥µç«¯ã«ä½ã„è©•ä¾¡ï¼ˆ20%æœªæº€ï¼‰ã‚’ä¸‹ã—ã¦ã„ã‚‹å ´åˆã€
                # ãƒ‡ãƒ¼ã‚¿æ¬ è½ã®å¯èƒ½æ€§ãŒé«˜ã„ãŸã‚ã€å¸‚å ´è©•ä¾¡ï¼ˆã‚ªãƒƒã‚ºï¼‰ã‚’ä¸€éƒ¨ä¿¡é ¼ã—ã¦è£œæ­£ã™ã‚‹ã€‚
                if o > 1.0 and o <= 2.5:
                     implied_prob = 0.8 / o # æ§é™¤ç‡è€ƒæ…®
                     if adjusted_p < (implied_prob * 0.4): # AIãŒå¸‚å ´ã®4å‰²ä»¥ä¸‹ã—ã‹è©•ä¾¡ã—ã¦ã„ãªã„å ´åˆ
                         adjusted_p = max(adjusted_p, implied_prob * 0.4) # æœ€ä½ã§ã‚‚å¸‚å ´è©•ä¾¡ã®4å‰²ã¯æŒãŸã›ã‚‹

                ev = (adjusted_p * m * o) - 1.0
                
                # Kelly Criterion
                # f = (p(b+1) - 1) / b  => (p*o - 1) / (o - 1)
                # p = adjusted_p * mark_bias
                p_final = adjusted_p * m
                
                if o > 1.0 and p_final > 0:
                    k = ((p_final * o) - 1.0) / (o - 1.0)
                    kelly = max(0.0, k * 100) # Convert to %
                    
                    # Cap Kelly at reasonable amounts (e.g. 50%) to prevent reckless betting
                    kelly = min(kelly, 50.0)
                else:
                    kelly = 0.0
            
            evs.append(ev)
            kellys.append(kelly)

        edited_df['æœŸå¾…å€¤(EV)'] = evs
        edited_df['æ¨å¥¨åº¦(Kelly)'] = kellys

        
        # Highlight high EV
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]
        
        # Highlight high EV and Kelly
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]
        
        st.dataframe(
            edited_df.style
            .format({'æ¨å¥¨åº¦(Kelly)': lambda x: '-' if x <= 0 else f'{x:.1f}%', 'æœŸå¾…å€¤(EV)': '{:.2f}'})
            .applymap(lambda x: 'background-color: #d4edda' if x > 0 else '', subset=['æœŸå¾…å€¤(EV)', 'æ¨å¥¨åº¦(Kelly)'])
        )

        
        # Visualization
        st.subheader("ğŸ“Š è©³ç´°åˆ†æ")
        
        try:
            # 1. Select a horse for detailed analysis
            horse_options = df_display['é¦¬å'].tolist()
            selected_horse_name = st.selectbox("è©³ç´°ã‚’è¦‹ã‚‹é¦¬ã‚’é¸æŠ", horse_options)
            
            # Find row
            row = df_display[df_display['é¦¬å'] == selected_horse_name].iloc[0]
            
            # 2. Radar Chart (5 Axes)
            # Speed (Real), Stamina/Form (Rank), Jockey, Course, Distance
            
            # --- Scoring Logic (Lower rank is better, so Invert) ---
            # Rank 1 -> Score 10, Rank 10 -> Score 1, Rank 18 -> 0
            def rank_to_score(r):
                if pd.isna(r) or r > 18: return 0
                return max(0, min(10, (14 - r) * (10/13))) # Approx 1->10, 14->0

            # Speed: 16.0 is baseline. >17 is fast? <15 slow?
            # 1000m/60s = 16.6. 
            sp_val = row.get('weighted_avg_speed', 16.0)
            score_speed = max(0, min(10, (sp_val - 15.0) * 5)) # 17.0->10, 15.0->0

            j_val = row.get('jockey_compatibility', 10.0)
            score_jockey = rank_to_score(j_val)
            
            c_val = row.get('course_compatibility', 10.0) # Calculated above but only in display_df... wait, we are accessing df_display row.
            # We added 'course_compatibility' to df_display in UI section.
            # Re-calculate here if needed OR ensure row comes from df_display.
            # row comes from df_display!
            score_course = rank_to_score(c_val)
            
            d_val = row.get('distance_compatibility', 10.0)
            score_dist = rank_to_score(d_val)
            
            rank_val = row.get('weighted_avg_rank', 10.0)
            score_form = rank_to_score(rank_val)

            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=[score_speed, score_form, score_jockey, score_course, score_dist, score_speed],
                theta=['ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å®Ÿç¸¾(ç€é †)', 'é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§'],
                fill='toself',
                name=selected_horse_name
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 10])), 
                title=f"èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ: {selected_horse_name}"
            )
            
            # 3. Multi-Axis Line Chart (Past 5 Runs)
            history_data = []
            for i in range(5, 0, -1): # Chronological 5->1 (Oldest to Newest)
                if f"past_{i}_rank" in row and pd.notna(row[f"past_{i}_rank"]):
                     history_data.append({
                         "Run": f"{i}èµ°å‰",
                         "ç€é †": row[f"past_{i}_rank"],
                         "3Fã‚¿ã‚¤ãƒ ": row[f"past_{i}_last_3f"],
                         "é¦¬ä½“é‡": row[f"past_{i}_horse_weight"]
                     })
            
            if history_data:
                hist_df = pd.DataFrame(history_data)
                
                # Plotly with Secondary Y
                from plotly.subplots import make_subplots
                fig_line = make_subplots(specs=[[{"secondary_y": True}]])
                
                # Rank (Left Y, Inverted)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['ç€é †'], name="ç€é †", mode='lines+markers'), secondary_y=False)
                
                # 3F (Right Y)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['3Fã‚¿ã‚¤ãƒ '], name="ä¸Šã‚Š3F", mode='lines+markers', line=dict(dash='dot')), secondary_y=True)
                
                fig_line.update_layout(title="éå»5èµ°ã®æ¨ç§» (ç€é † vs 3Fã‚¿ã‚¤ãƒ )")
                fig_line.update_yaxes(title_text="ç€é † (ä½ã„æ–¹ãŒè‰¯ã„)", autorange="reversed", secondary_y=False)
                fig_line.update_yaxes(title_text="ä¸Šã‚Š3Fã‚¿ã‚¤ãƒ  (ç§’)", secondary_y=True)
                
            else:
                fig_line = go.Figure()
                fig_line.add_annotation(text="è©³ç´°ãªéå»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            col_viz1, col_viz2 = st.columns(2)
            col_viz1.plotly_chart(fig_radar, use_container_width=True)
            col_viz2.plotly_chart(fig_line, use_container_width=True)
            
        except Exception as e:
            st.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.text(traceback.format_exc())
