#!/usr/bin/env python3
"""
æœ¬ç•ªé‹ç”¨ç‰ˆã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ”¹å–„ç‚¹:
1. TimeSeriesSplitã«ã‚ˆã‚‹æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆãƒ«ãƒƒã‚¯ã‚¢ãƒ˜ãƒƒãƒ‰ãƒã‚¤ã‚¢ã‚¹è§£æ¶ˆï¼‰
2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’1ç€ã®ã¿ã«å¤‰æ›´ï¼ˆtarget_winï¼‰
3. Brier Scoreã«ã‚ˆã‚‹ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
4. è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›
5. ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

ä½¿ç”¨æ–¹æ³•:
    python ml/train_model_production.py
"""

import pandas as pd
import lightgbm as lgb
import pickle
import os
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    brier_score_loss,
    log_loss,
    precision_score,
    recall_score,
    f1_score
)
from sklearn.calibration import calibration_curve
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


def validate_data(df):
    """
    ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’æ¤œè¨¼

    Args:
        df: DataFrame

    Returns:
        bool: æ¤œè¨¼çµæœ
    """
    print("\n" + "=" * 60)
    print("ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼")
    print("=" * 60)

    issues = []

    # 1. ãƒ‡ãƒ¼ã‚¿é‡ãƒã‚§ãƒƒã‚¯
    if len(df) < 500:
        issues.append(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³: {len(df)}è¡Œï¼ˆæ¨å¥¨: 500è¡Œä»¥ä¸Šï¼‰")
    else:
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿é‡: {len(df):,}è¡Œ")

    # 2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if 'target_win' in df.columns:
        win_rate = df['target_win'].mean()
        print(f"âœ… 1ç€ç‡: {win_rate:.2%}")

        if win_rate < 0.03 or win_rate > 0.20:
            issues.append(f"âš ï¸ 1ç€ç‡ãŒç•°å¸¸: {win_rate:.2%}ï¼ˆé€šå¸¸: 5-10%ï¼‰")
    else:
        issues.append("âŒ target_winåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # 3. æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
    missing = df.isnull().sum()
    missing_cols = missing[missing > 0]

    if len(missing_cols) > 0:
        print(f"\nâš ï¸ æ¬ æå€¤ãŒå­˜åœ¨ã™ã‚‹åˆ—: {len(missing_cols)}å€‹")
        for col, count in missing_cols.head(5).items():
            print(f"  - {col}: {count}ä»¶ ({count/len(df):.1%})")
    else:
        print("âœ… æ¬ æå€¤ãªã—")

    # 4. æ—¥ä»˜ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ç”¨ï¼‰
    if 'date' not in df.columns:
        issues.append("âŒ dateåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ã«å¿…é ˆï¼‰")
    else:
        print("âœ… dateåˆ—ã‚ã‚Š")

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "-" * 60)
    if len(issues) == 0:
        print("âœ… ã™ã¹ã¦ã®æ¤œè¨¼ã«åˆæ ¼")
        return True
    else:
        print(f"âš ï¸ {len(issues)}å€‹ã®å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
        for issue in issues:
            print(f"  {issue}")
        return False


def train_with_timeseries_split(data_path, model_path, params=None, n_splits=5):
    """
    TimeSeriesSplitã«ã‚ˆã‚‹æ™‚ç³»åˆ—åˆ†å‰²å­¦ç¿’

    Args:
        data_path (str): å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
        model_path (str): ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ
        params (dict): LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        n_splits (int): åˆ†å‰²æ•°

    Returns:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    print("\n" + "=" * 60)
    print("æœ¬ç•ªé‹ç”¨ç‰ˆãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("=" * 60)

    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not os.path.exists(data_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
        return None

    df = pd.read_csv(data_path)
    print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df):,}è¡Œ")

    # 2. ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
    if not validate_data(df):
        print("\nâš ï¸ ãƒ‡ãƒ¼ã‚¿å“è³ªã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å­¦ç¿’ã‚’ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ")
        print("   ç¶šè¡Œã™ã‚‹å ´åˆã¯Enterã‚’æŠ¼ã—ã¦ãã ã•ã„...")
        # input()  # æœ¬ç•ªã§ã¯æœ‰åŠ¹åŒ–

    # 3. ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æº–å‚™
    target_col = 'target_win'  # 1ç€ã®ã¿

    if target_col not in df.columns:
        print(f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_col}")
        print("   target_top3ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆéæ¨å¥¨ï¼‰")
        target_col = 'target_top3'

    # ãƒ¡ã‚¿ã‚«ãƒ©ãƒ ã‚’é™¤å¤–
    meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †',
                 'target_win', 'target_top3', 'run_style']

    # ç‰¹å¾´é‡ã‚’é¸æŠï¼ˆæ•°å€¤å‹ã®ã¿ï¼‰
    feature_cols = [c for c in df.columns if c not in meta_cols]
    X = df[feature_cols].select_dtypes(include=['number'])
    y = df[target_col]

    print(f"\nğŸ“ˆ ç‰¹å¾´é‡æ•°: {len(X.columns)}")
    print(f"   ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {target_col}")
    print(f"   æ­£ä¾‹ç‡: {y.mean():.2%}")

    # 4. æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ã®ãŸã‚ï¼‰
    if 'date' in df.columns:
        df_sorted = df.sort_values('date').reset_index(drop=True)
        X = df_sorted[feature_cols].select_dtypes(include=['number'])
        y = df_sorted[target_col]
        print("âœ… æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿")
    else:
        print("âš ï¸ dateåˆ—ãŒãªã„ãŸã‚ã€ç¾åœ¨ã®é †åºã§åˆ†å‰²ã—ã¾ã™")

    # 5. TimeSeriesSplitã§å­¦ç¿’
    tscv = TimeSeriesSplit(n_splits=n_splits)

    print(f"\nğŸ”„ TimeSeriesSplit ({n_splits}åˆ†å‰²) ã§å­¦ç¿’...")
    print("   ãƒ«ãƒƒã‚¯ã‚¢ãƒ˜ãƒƒãƒ‰ãƒã‚¤ã‚¢ã‚¹ã‚’é˜²ããŸã‚ã€æ™‚ç³»åˆ—é †ã«åˆ†å‰²\n")

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    lgb_params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'random_state': 42,
        'is_unbalance': True,  # ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
    }

    if params:
        lgb_params.update(params)

    # è©•ä¾¡æŒ‡æ¨™ã‚’æ ¼ç´
    metrics = {
        'auc': [],
        'brier': [],
        'logloss': [],
        'accuracy': [],
        'precision': [],
        'recall': [],
        'f1': []
    }

    fold = 1
    best_model = None
    best_auc = 0

    for train_idx, test_idx in tscv.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        print(f"\nã€Fold {fold}/{n_splits}ã€‘")
        print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(X_train):,}è¡Œ ({train_idx[0]} - {train_idx[-1]})")
        print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test):,}è¡Œ ({test_idx[0]} - {test_idx[-1]})")
        print(f"  å­¦ç¿’æœŸé–“ 1ç€ç‡: {y_train.mean():.2%}")
        print(f"  ãƒ†ã‚¹ãƒˆæœŸé–“ 1ç€ç‡: {y_test.mean():.2%}")

        # LightGBMå­¦ç¿’
        train_data = lgb.Dataset(X_train, label=y_train)
        test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

        model = lgb.train(
            lgb_params,
            train_data,
            num_boost_round=200,
            valid_sets=[test_data],
            valid_names=['valid'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=20, verbose=False),
                lgb.log_evaluation(period=50)
            ]
        )

        # äºˆæ¸¬
        y_pred_proba = model.predict(X_test)
        y_pred = (y_pred_proba > 0.5).astype(int)

        # è©•ä¾¡
        auc = roc_auc_score(y_test, y_pred_proba)
        brier = brier_score_loss(y_test, y_pred_proba)
        logloss = log_loss(y_test, y_pred_proba)
        accuracy = accuracy_score(y_test, y_pred)

        # Precision, Recall, F1ï¼ˆã‚¼ãƒ­é™¤ç®—å¯¾ç­–ï¼‰
        try:
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
        except:
            precision = recall = f1 = 0.0

        metrics['auc'].append(auc)
        metrics['brier'].append(brier)
        metrics['logloss'].append(logloss)
        metrics['accuracy'].append(accuracy)
        metrics['precision'].append(precision)
        metrics['recall'].append(recall)
        metrics['f1'].append(f1)

        print(f"  ğŸ“Š AUC: {auc:.4f}")
        print(f"  ğŸ“Š Brier Score: {brier:.4f}")
        print(f"  ğŸ“Š Log Loss: {logloss:.4f}")
        print(f"  ğŸ“Š Accuracy: {accuracy:.4f}")
        print(f"  ğŸ“Š Precision: {precision:.4f}")
        print(f"  ğŸ“Š Recall: {recall:.4f}")
        print(f"  ğŸ“Š F1: {f1:.4f}")

        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        if auc > best_auc:
            best_auc = auc
            best_model = model

        fold += 1

    # 6. è©•ä¾¡çµæœã®ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("å­¦ç¿’çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    for metric_name, values in metrics.items():
        mean_val = np.mean(values)
        std_val = np.std(values)
        print(f"{metric_name.upper():12s}: {mean_val:.4f} Â± {std_val:.4f}")

    # 7. æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã§å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’
    print("\nğŸ”„ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’...")

    train_data = lgb.Dataset(X, label=y)
    final_model = lgb.train(
        lgb_params,
        train_data,
        num_boost_round=200,
        callbacks=[lgb.log_evaluation(period=50)]
    )

    # 8. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    os.makedirs(os.path.dirname(model_path), exist_ok=True)

    with open(model_path, 'wb') as f:
        pickle.dump(final_model, f)

    print(f"\nâœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {model_path}")

    # 9. ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤º
    print("\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆTop 20ï¼‰:")
    importance = final_model.feature_importance(importance_type='gain')
    feature_imp = pd.DataFrame({
        'Feature': X.columns,
        'Importance': importance
    }).sort_values(by='Importance', ascending=False)

    for idx, row in feature_imp.head(20).iterrows():
        print(f"  {row['Feature']:40s}: {row['Importance']:,.0f}")

    return final_model


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    print("\n" + "=" * 60)
    print("ğŸ‡ ç«¶é¦¬äºˆæ¸¬ æœ¬ç•ªé‹ç”¨ç‰ˆãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("=" * 60)

    # ãƒ‘ã‚¹è¨­å®š
    data_path = "ml/processed_data.csv"
    model_path = "ml/models/lgbm_model_production.pkl"

    # ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(data_path):
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {data_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("\næ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã§ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:")
        print("  python ml/feature_engineering.py")
        return

    # å­¦ç¿’å®Ÿè¡Œ
    model = train_with_timeseries_split(
        data_path=data_path,
        model_path=model_path,
        n_splits=5
    )

    if model:
        print("\n" + "=" * 60)
        print("âœ… å­¦ç¿’å®Œäº†")
        print("=" * 60)
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. public_app.py ã‚’ç·¨é›†:")
        print("   MODEL_PATH = 'ml/models/lgbm_model_production.pkl'")
        print("\n2. ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•:")
        print("   streamlit run public_app.py")
    else:
        print("\nâŒ å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
