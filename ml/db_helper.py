"""
SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

Colabç’°å¢ƒã§ç”Ÿæˆã—ãŸSQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿æ›¸ãã™ã‚‹ãŸã‚ã®é–¢æ•°ç¾¤
"""

import sqlite3
import pandas as pd
import os
from typing import Optional, List, Dict, Any


class KeibaDatabase:
    """ç«¶é¦¬ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, db_path: str = "keiba_data.db"):
        """
        Args:
            db_path: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¹
        """
        self.db_path = db_path

        if not os.path.exists(db_path):
            raise FileNotFoundError(
                f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}\n"
                "Google Colabã§ colab_data_pipeline.ipynb ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            )

    def get_connection(self) -> sqlite3.Connection:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—"""
        return sqlite3.connect(self.db_path)

    def get_processed_data(self, mode: str = "JRA", limit: Optional[int] = None) -> pd.DataFrame:
        """
        å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            mode: "JRA" ã¾ãŸã¯ "NAR"
            limit: å–å¾—ã™ã‚‹æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶ï¼‰

        Returns:
            å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        """
        table_name = f"processed_data_{mode.lower()}"

        query = f"SELECT * FROM {table_name}"
        if limit:
            query += f" LIMIT {limit}"

        conn = self.get_connection()
        df = pd.read_sql_query(query, conn)
        conn.close()

        return df

    def get_race_data(self, race_id: str, mode: str = "JRA") -> pd.DataFrame:
        """
        ç‰¹å®šã®ãƒ¬ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            race_id: ãƒ¬ãƒ¼ã‚¹ID
            mode: "JRA" ã¾ãŸã¯ "NAR"

        Returns:
            ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        """
        table_name = f"processed_data_{mode.lower()}"

        query = f"SELECT * FROM {table_name} WHERE race_id = ?"

        conn = self.get_connection()
        df = pd.read_sql_query(query, conn, params=(race_id,))
        conn.close()

        return df

    def get_horse_history(self, horse_id: str, mode: str = "JRA", limit: int = 10) -> pd.DataFrame:
        """
        ç‰¹å®šã®é¦¬ã®éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            horse_id: é¦¬ID
            mode: "JRA" ã¾ãŸã¯ "NAR"
            limit: å–å¾—ã™ã‚‹æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°

        Returns:
            é¦¬ã®éå»ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        """
        table_name = f"processed_data_{mode.lower()}"

        query = f"""
            SELECT * FROM {table_name}
            WHERE horse_id = ?
            ORDER BY date DESC
            LIMIT ?
        """

        conn = self.get_connection()
        df = pd.read_sql_query(query, conn, params=(horse_id, limit))
        conn.close()

        return df

    def get_statistics(self, mode: str = "JRA") -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—

        Args:
            mode: "JRA" ã¾ãŸã¯ "NAR"

        Returns:
            çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        table_name = f"processed_data_{mode.lower()}"

        query = f"""
            SELECT
                COUNT(*) as total_records,
                COUNT(DISTINCT race_id) as unique_races,
                COUNT(DISTINCT horse_id) as unique_horses,
                MIN(date) as earliest_date,
                MAX(date) as latest_date,
                AVG(target_win) as win_rate
            FROM {table_name}
        """

        conn = self.get_connection()
        result = pd.read_sql_query(query, conn)
        conn.close()

        return result.iloc[0].to_dict()

    def get_feature_names(self, mode: str = "JRA") -> List[str]:
        """
        ç‰¹å¾´é‡ã®åˆ—åãƒªã‚¹ãƒˆã‚’å–å¾—

        Args:
            mode: "JRA" ã¾ãŸã¯ "NAR"

        Returns:
            åˆ—åã®ãƒªã‚¹ãƒˆ
        """
        table_name = f"processed_data_{mode.lower()}"

        conn = self.get_connection()
        cursor = conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [row[1] for row in cursor.fetchall()]
        conn.close()

        return columns

    def get_latest_update(self, mode: str = "JRA") -> Optional[str]:
        """
        æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã‚’å–å¾—

        Args:
            mode: "JRA" ã¾ãŸã¯ "NAR"

        Returns:
            æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        """
        table_name = f"processed_data_{mode.lower()}"

        query = f"SELECT MAX(date) as latest_date FROM {table_name}"

        conn = self.get_connection()
        result = pd.read_sql_query(query, conn)
        conn.close()

        latest = result['latest_date'].iloc[0]
        return latest if pd.notna(latest) else None

    def get_data_freshness(self, mode: str = "JRA") -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ã®é®®åº¦æƒ…å ±ã‚’å–å¾—ï¼ˆè¡¨ç¤ºç”¨ï¼‰

        Args:
            mode: "JRA" ã¾ãŸã¯ "NAR"

        Returns:
            é®®åº¦æƒ…å ±ã®æ–‡å­—åˆ—
        """
        from datetime import datetime

        latest = self.get_latest_update(mode)
        if not latest:
            return "ãƒ‡ãƒ¼ã‚¿ãªã—"

        # æ—¥ä»˜ã®è§£æ
        try:
            latest_date = pd.to_datetime(latest)
            today = pd.Timestamp.now()
            days_old = (today - latest_date).days

            if days_old == 0:
                return f"æœ€æ–°ï¼ˆä»Šæ—¥ï¼‰"
            elif days_old == 1:
                return f"1æ—¥å‰"
            elif days_old <= 7:
                return f"{days_old}æ—¥å‰"
            elif days_old <= 30:
                weeks = days_old // 7
                return f"{weeks}é€±é–“å‰"
            else:
                months = days_old // 30
                return f"{months}ãƒ¶æœˆå‰"
        except:
            return latest

    def execute_query(self, query: str, params: tuple = ()) -> pd.DataFrame:
        """
        ã‚«ã‚¹ã‚¿ãƒ ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
        
        Args:
            query: SQLã‚¯ã‚¨ãƒª
            params: ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns:
            ã‚¯ã‚¨ãƒªçµæœã®DataFrame
        """
        conn = self.get_connection()
        df = pd.read_sql_query(query, conn, params=params)
        conn.close()
        
        return df

    def save_processed_data(self, df: pd.DataFrame, mode: str = "JRA"):
        """
        å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        
        Args:
            df: ä¿å­˜ã™ã‚‹DataFrame
            mode: "JRA" ã¾ãŸã¯ "NAR"
        """
        table_name = f"processed_data_{mode.lower()}"
        conn = self.get_connection()
        
        # Save to SQL
        df.to_sql(table_name, conn, if_exists='replace', index=False, chunksize=1000)
        
        # Create indices for speed
        cursor = conn.cursor()
        indices = ['race_id', 'horse_id', 'date']
        for idx in indices:
            try:
                cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_{idx} ON {table_name}({idx})")
            except Exception as e:
                print(f"Index creation failed for {idx}: {e}")
        
        conn.commit()
        conn.close()


# ä¾¿åˆ©é–¢æ•°
def get_training_data(mode: str = "JRA", db_path: str = "keiba_data.db") -> pd.DataFrame:
    """
    å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Args:
        mode: "JRA" ã¾ãŸã¯ "NAR"
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹

    Returns:
        å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®DataFrame
    """
    db = KeibaDatabase(db_path)
    return db.get_processed_data(mode)


def get_data_stats(mode: str = "JRA", db_path: str = "keiba_data.db") -> Dict[str, Any]:
    """
    ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Args:
        mode: "JRA" ã¾ãŸã¯ "NAR"
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹

    Returns:
        çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
    """
    db = KeibaDatabase(db_path)
    return db.get_statistics(mode)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    import sys

    db_path = sys.argv[1] if len(sys.argv) > 1 else "keiba_data.db"

    if not os.path.exists(db_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        print("Google Colabã§ colab_data_pipeline.ipynb ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    db = KeibaDatabase(db_path)

    print("=" * 60)
    print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±")
    print("=" * 60)

    for mode in ["JRA", "NAR"]:
        try:
            print(f"\nğŸ“Š {mode}:")
            stats = db.get_statistics(mode)
            print(f"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['total_records']:,}")
            print(f"   ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°: {stats['unique_races']:,}")
            print(f"   ãƒ¦ãƒ‹ãƒ¼ã‚¯é¦¬æ•°: {stats['unique_horses']:,}")
            print(f"   ãƒ‡ãƒ¼ã‚¿æœŸé–“: {stats['earliest_date']} ï½ {stats['latest_date']}")
            print(f"   å‹ç‡: {stats['win_rate']:.2%}")
            print(f"   é®®åº¦: {db.get_data_freshness(mode)}")
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
