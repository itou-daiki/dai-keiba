{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‡ ç«¶é¦¬AI ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆGoogle Colabç‰ˆï¼‰\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š\n",
    "1. **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: netkeiba.comã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†\n",
    "2. **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: æ¬ æå€¤å‡¦ç†ã€å‹å¤‰æ›ã€å¤–ã‚Œå€¤é™¤å»\n",
    "3. **ç‰¹å¾´é‡ç”Ÿæˆ**: éå»èµ°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬ç”¨ç‰¹å¾´é‡ã‚’è¨ˆç®—\n",
    "4. **SQLiteä¿å­˜**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¦ã‚¢ãƒ—ãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ã«\n",
    "\n",
    "## ğŸ“‹ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Google Colabç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\nprint(\"ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\ntry:\n    !pip install beautifulsoup4 requests pandas numpy scikit-learn lightgbm tqdm -q\n    print(\"âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\nexcept Exception as e:\n    print(f\"âŒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„\")\n    raise\n\ntry:\n    import os\n    import sys\n    import sqlite3\n    import pandas as pd\n    import numpy as np\n    from datetime import datetime, timedelta\n    from tqdm import tqdm\n    import pickle\n    import json\n    print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\nexcept ImportError as e:\n    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ ä¸Šè¨˜ã®pipã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒæ­£ã—ãå®Ÿè¡Œã•ã‚ŒãŸã‹ç¢ºèªã—ã¦ãã ã•ã„\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Google Driveãƒã‚¦ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’Google Driveã«ä¿å­˜ã™ã‚‹å ´åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"âœ… Google Driveãƒã‚¦ãƒ³ãƒˆæˆåŠŸ\")\nexcept Exception as e:\n    print(f\"âŒ Google Driveãƒã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ ãƒ–ãƒ©ã‚¦ã‚¶ã§Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„\")\n    raise\n\n# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\nWORK_DIR = '/content/drive/MyDrive/keiba-ai'\n\ntry:\n    os.makedirs(WORK_DIR, exist_ok=True)\n    os.chdir(WORK_DIR)\n    print(f\"âœ… ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {WORK_DIR}\")\nexcept Exception as e:\n    print(f\"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã‚¨ãƒ©ãƒ¼: {e}\")\n    print(f\"ğŸ’¡ Google Driveã®å®¹é‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨\n    WORK_DIR = '/content'\n    os.chdir(WORK_DIR)\n    print(f\"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {WORK_DIR} ã‚’ä½¿ç”¨\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ GitHubã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’ã‚¯ãƒ­ãƒ¼ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GitHubãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆåˆå›ã®ã¿ï¼‰\nREPO_URL = \"https://github.com/YOUR_USERNAME/dai-keiba.git\"  # âš ï¸ å®Ÿéš›ã®URLã«å¤‰æ›´ã—ã¦ãã ã•ã„\n\nprint(\"ğŸ“¥ GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­...\")\n\ntry:\n    if not os.path.exists('dai-keiba'):\n        !git clone {REPO_URL}\n        if not os.path.exists('dai-keiba'):\n            raise Exception(\"ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n        print(\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã—ãŸ\")\n    else:\n        print(\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™\")\n        # æœ€æ–°ç‰ˆã‚’å–å¾—\n        try:\n            !cd dai-keiba && git pull\n            print(\"âœ… æœ€æ–°ç‰ˆã‚’å–å¾—ã—ã¾ã—ãŸ\")\n        except Exception as e:\n            print(f\"âš ï¸ git pullã«å¤±æ•—: {e}\")\n            print(\"ğŸ’¡ æ—¢å­˜ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½¿ç”¨ã—ã¾ã™\")\nexcept Exception as e:\n    print(f\"âŒ Gitã‚¯ãƒ­ãƒ¼ãƒ³ã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ REPO_URLã‚’æ­£ã—ã„URLã«å¤‰æ›´ã—ã¦ãã ã•ã„\")\n    print(\"ğŸ’¡ ã¾ãŸã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰‹å‹•ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n    raise\n\n# ãƒ‘ã‚¹ã®è¿½åŠ \ntry:\n    sys.path.append('dai-keiba')\n    sys.path.append('dai-keiba/scraper')\n    sys.path.append('dai-keiba/ml')\n    print(\"âœ… Pythonãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\nexcept Exception as e:\n    print(f\"âŒ ãƒ‘ã‚¹è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ•·ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n",
    "\n",
    "### JRAãƒ‡ãƒ¼ã‚¿ã®åé›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from scraper import auto_scraper\n    print(\"âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ\")\nexcept ImportError as e:\n    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ dai-keiba/scraper/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„\")\n    raise\n\n# è¨­å®š\nSTART_DATE = \"2023-01-01\"  # é–‹å§‹æ—¥\nEND_DATE = datetime.now().strftime(\"%Y-%m-%d\")  # ä»Šæ—¥ã¾ã§\nMODE = \"JRA\"  # JRA ã¾ãŸã¯ NAR\n\nprint(f\"ğŸ“… åé›†æœŸé–“: {START_DATE} ï½ {END_DATE}\")\nprint(f\"ğŸ‡ ãƒ¢ãƒ¼ãƒ‰: {MODE}\")\n\ncsv_path = f\"database_{MODE.lower()}.csv\"\ndb_path = \"keiba_data.db\"  # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹\n\ntry:\n    # ====================================\n    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨æ¬ è½åˆ†æ\n    # ====================================\n    print(\"\\nğŸ” æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªä¸­...\")\n\n    # æ—¢å­˜race_idã‚’å–å¾—ï¼ˆSQLiteã¾ãŸã¯CSVã‹ã‚‰ï¼‰\n    existing_race_ids = auto_scraper.get_existing_race_ids(\n        mode=MODE,\n        db_path=db_path if os.path.exists(db_path) else None,\n        csv_path=csv_path if os.path.exists(csv_path) else None\n    )\n\n    if existing_race_ids:\n        print(f\"âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {len(existing_race_ids)}ãƒ¬ãƒ¼ã‚¹\")\n\n        # æ¬ è½ãƒ¬ãƒ¼ã‚¹ã®åˆ†æ\n        from datetime import datetime\n        start_dt = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n        end_dt = datetime.strptime(END_DATE, \"%Y-%m-%d\")\n\n        missing_info = auto_scraper.find_missing_races(\n            start_dt,\n            end_dt,\n            existing_race_ids,\n            mode=MODE\n        )\n\n        print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ:\")\n        print(f\"   å¯¾è±¡æœŸé–“: {missing_info['total_days']}æ—¥é–“\")\n        print(f\"   é€±æœ«æ—¥æ•°: {missing_info['weekend_days']}æ—¥\")\n        print(f\"   æ—¢å­˜ãƒ¬ãƒ¼ã‚¹æ—¥: {missing_info['existing_race_dates']}æ—¥\")\n        print(f\"   ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡: {missing_info['coverage_rate']:.1%}\")\n\n        if missing_info['missing_weekend_dates']:\n            print(f\"\\nâš ï¸ æ¬ è½ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹é€±æœ«: {len(missing_info['missing_weekend_dates'])}æ—¥\")\n            print(\"   æœ€åˆã®10æ—¥:\")\n            for d in missing_info['missing_weekend_dates'][:10]:\n                print(f\"     - {d.strftime('%Y-%m-%d (%a)')}\")\n            if len(missing_info['missing_weekend_dates']) > 10:\n                print(f\"     ... ä»– {len(missing_info['missing_weekend_dates']) - 10}æ—¥\")\n\n            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª\n            print(f\"\\nğŸ’¡ ã“ã‚Œã‚‰ã®æ—¥ä»˜ã‚’å«ã‚€æœŸé–“ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™\")\n            print(f\"ğŸ’¡ æ—¢å­˜ã®race_idã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™\")\n        else:\n            print(f\"\\nâœ… æ¬ è½ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ã™ã¹ã¦ã®é€±æœ«ãŒã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã¾ã™\")\n    else:\n        print(\"â„¹ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆåˆå›ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰\")\n        print(f\"ğŸ’¡ å…¨æœŸé–“ {START_DATE} ï½ {END_DATE} ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¾ã™\")\n\n    # ====================================\n    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ\n    # ====================================\n    print(f\"\\nâ³ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...ï¼ˆæ•°æ™‚é–“ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰\")\n    print(\"ğŸ’¡ æ—¢å­˜ã®race_idã¯è‡ªå‹•çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™\")\n    print(\"ğŸ’¡ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯è‡ªå‹•çš„ã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™\\n\")\n\n    # auto_scraper.main()ã‚’å‘¼ã³å‡ºã—ï¼ˆå†…éƒ¨ã§existing_race_idsã‚’ä½¿ç”¨ï¼‰\n    auto_scraper.main(\n        start_date_arg=START_DATE,\n        end_date_arg=END_DATE,\n        mode_arg=MODE,\n        source_arg=\"jra\" if MODE == \"JRA\" else None\n    )\n\n    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã®ç¢ºèª\n    if os.path.exists(csv_path):\n        print(f\"\\nâœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†: {csv_path}\")\n        df = pd.read_csv(csv_path)\n        print(f\"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}\")\n        print(f\"   ãƒ¦ãƒ‹ãƒ¼ã‚¯race_id: {df['race_id'].nunique():,}\")\n\n        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n        if len(df) < 100:\n            print(\"âš ï¸ ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ã§ã™ï¼ˆ100ä»¶æœªæº€ï¼‰\")\n            print(\"ğŸ’¡ ã‚ˆã‚Šé•·ã„æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™\")\n\n        # å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒã‚§ãƒƒã‚¯\n        required_cols = ['race_id', 'horse_id', 'date']\n        missing_cols = [col for col in required_cols if col not in df.columns]\n        if missing_cols:\n            raise ValueError(f\"å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_cols}\")\n\n        # æ–°è¦è¿½åŠ ã•ã‚ŒãŸrace_idã®æ•°\n        new_race_ids = set(df['race_id'].astype(str)) - existing_race_ids\n        if new_race_ids:\n            print(f\"\\nğŸ†• æ–°è¦è¿½åŠ ã•ã‚ŒãŸãƒ¬ãƒ¼ã‚¹: {len(new_race_ids)}ä»¶\")\n        else:\n            print(f\"\\nğŸ’¡ æ–°è¦ãƒ¬ãƒ¼ã‚¹ã¯è¿½åŠ ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆã™ã¹ã¦æ—¢å­˜ï¼‰\")\n\n        print(\"âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯å®Œäº†\")\n    else:\n        raise FileNotFoundError(\n            f\"{csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\\n\"\n            \"ğŸ’¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒæ­£å¸¸ã«å®Œäº†ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\"\n        )\n\nexcept FileNotFoundError as e:\n    print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept ValueError as e:\n    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept Exception as e:\n    print(f\"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n    print(\"ğŸ’¡ ã¾ãŸã¯ã€æ‰‹å‹•ã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n    import traceback\n    print(\"\\nè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\")\n    traceback.print_exc()\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´é‡ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from ml.feature_engineering import calculate_features\n    print(\"âœ… ç‰¹å¾´é‡ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ\")\nexcept ImportError as e:\n    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ dai-keiba/ml/feature_engineering.py ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„\")\n    raise\n\n# è¨­å®š\nUSE_VENUE_FEATURES = True  # ä¼šå ´ç‰¹æ€§ç‰¹å¾´é‡ã‚’ä½¿ç”¨\n\ninput_csv = f\"database_{MODE.lower()}.csv\"\noutput_csv = f\"processed_data_{MODE.lower()}.csv\"\n\nprint(f\"âš™ï¸ ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹...\")\nprint(f\"   å…¥åŠ›: {input_csv}\")\nprint(f\"   å‡ºåŠ›: {output_csv}\")\nprint(f\"   ä¼šå ´ç‰¹æ€§: {USE_VENUE_FEATURES}\")\n\ntry:\n    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n    if not os.path.exists(input_csv):\n        raise FileNotFoundError(\n            f\"å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_csv}\\n\"\n            \"ğŸ’¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\"\n        )\n    \n    # ãƒ‡ãƒ¼ã‚¿ã®å‰ãƒã‚§ãƒƒã‚¯\n    df_input = pd.read_csv(input_csv)\n    print(f\"   å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {len(df_input):,}ä»¶\")\n    \n    if len(df_input) == 0:\n        raise ValueError(\"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™\")\n    \n    # ç‰¹å¾´é‡ç”Ÿæˆ\n    print(\"â³ ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...ï¼ˆæ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰\")\n    calculate_features(\n        input_csv,\n        output_csv,\n        lambda_decay=0.2,\n        use_venue_features=USE_VENUE_FEATURES\n    )\n    \n    # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼\n    if not os.path.exists(output_csv):\n        raise FileNotFoundError(f\"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {output_csv}\")\n    \n    df_output = pd.read_csv(output_csv)\n    print(f\"\\nâœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {output_csv}\")\n    print(f\"   å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿: {len(df_output):,}ä»¶\")\n    print(f\"   ç‰¹å¾´é‡æ•°: {len(df_output.columns)}å€‹\")\n    \n    # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª\n    required_output_cols = ['race_id', 'horse_id', 'date', 'target_win']\n    missing_cols = [col for col in required_output_cols if col not in df_output.columns]\n    if missing_cols:\n        raise ValueError(f\"å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã«å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_cols}\")\n    \n    # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯\n    null_counts = df_output.isnull().sum()\n    high_null_cols = null_counts[null_counts > len(df_output) * 0.5]\n    if len(high_null_cols) > 0:\n        print(f\"âš ï¸ æ¬ æå€¤ãŒ50%ä»¥ä¸Šã®ã‚«ãƒ©ãƒ : {len(high_null_cols)}å€‹\")\n        for col, count in high_null_cols.head(5).items():\n            print(f\"   - {col}: {count}/{len(df_output)} ({count/len(df_output)*100:.1f}%)\")\n    \n    print(\"âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯å®Œäº†\")\n    \nexcept FileNotFoundError as e:\n    print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept ValueError as e:\n    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept Exception as e:\n    print(f\"âŒ ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n    import traceback\n    print(\"\\nè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\")\n    traceback.print_exc()\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—3: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ\nDB_PATH = \"keiba_data.db\"\n\nprint(f\"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ: {DB_PATH}\")\n\ntry:\n    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n    if not os.path.exists(output_csv):\n        raise FileNotFoundError(\n            f\"ç‰¹å¾´é‡CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {output_csv}\\n\"\n            \"ğŸ’¡ ç‰¹å¾´é‡ç”Ÿæˆã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\"\n        )\n    \n    print(f\"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\")\n    df_processed = pd.read_csv(output_csv)\n    \n    print(f\"   ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df_processed):,}\")\n    print(f\"   ç‰¹å¾´é‡æ•°: {len(df_processed.columns)}\")\n    \n    if len(df_processed) == 0:\n        raise ValueError(\"å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™\")\n    \n    # SQLiteæ¥ç¶š\n    print(f\"ğŸ”— SQLiteã«æ¥ç¶šä¸­...\")\n    conn = sqlite3.connect(DB_PATH)\n    \n    # ãƒ†ãƒ¼ãƒ–ãƒ«åã®æ±ºå®š\n    table_name = f\"processed_data_{MODE.lower()}\"\n    \n    print(f\"ğŸ’¾ ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ä¸­: {table_name}\")\n    \n    # DataFrameã‚’SQLiteã«ä¿å­˜\n    df_processed.to_sql(\n        table_name,\n        conn,\n        if_exists='replace',  # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç½®ãæ›ãˆ\n        index=False,\n        chunksize=1000  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–\n    )\n    \n    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆï¼ˆé«˜é€ŸåŒ–ï¼‰\n    print(\"ğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­...\")\n    cursor = conn.cursor()\n    \n    # race_idã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n    try:\n        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_race_id ON {table_name}(race_id)\")\n        print(\"   âœ… race_id ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\")\n    except Exception as e:\n        print(f\"   âš ï¸ race_id ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—: {e}\")\n    \n    # horse_idã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n    try:\n        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_horse_id ON {table_name}(horse_id)\")\n        print(\"   âœ… horse_id ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\")\n    except Exception as e:\n        print(f\"   âš ï¸ horse_id ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—: {e}\")\n    \n    # dateã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n    try:\n        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_date ON {table_name}(date)\")\n        print(\"   âœ… date ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\")\n    except Exception as e:\n        print(f\"   âš ï¸ date ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—: {e}\")\n    \n    conn.commit()\n    \n    print(f\"\\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {table_name}\")\n    \n    # ç¢ºèªã‚¯ã‚¨ãƒª\n    print(\"ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¤œè¨¼ä¸­...\")\n    result = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM {table_name}\", conn)\n    saved_count = result['count'].iloc[0]\n    print(f\"   ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {saved_count:,}\")\n    \n    if saved_count != len(df_processed):\n        print(f\"âš ï¸ è­¦å‘Š: ä¿å­˜æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ï¼ˆæœŸå¾…: {len(df_processed):,}, å®Ÿéš›: {saved_count:,}ï¼‰\")\n    else:\n        print(\"   âœ… ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãŒä¸€è‡´ã—ã¾ã—ãŸ\")\n    \n    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºã®ç¢ºèª\n    db_size = os.path.getsize(DB_PATH)\n    print(f\"   ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {db_size / 1024 / 1024:.2f} MB\")\n    \n    conn.close()\n    print(\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸ\")\n    \nexcept FileNotFoundError as e:\n    print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept ValueError as e:\n    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept sqlite3.Error as e:\n    print(f\"âŒ SQLiteã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n    if 'conn' in locals():\n        conn.close()\n    raise\nexcept Exception as e:\n    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n    import traceback\n    print(\"\\nè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\")\n    traceback.print_exc()\n    if 'conn' in locals():\n        conn.close()\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç¢ºèª\nprint(\"ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¤œè¨¼ä¸­...\")\n\ntry:\n    if not os.path.exists(DB_PATH):\n        raise FileNotFoundError(\n            f\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DB_PATH}\\n\"\n            \"ğŸ’¡ SQLiteä¿å­˜ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\"\n        )\n    \n    conn = sqlite3.connect(DB_PATH)\n    \n    # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§\n    print(\"\\nğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§:\")\n    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n    if len(tables) == 0:\n        print(\"âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“\")\n    else:\n        for table_name in tables['name']:\n            print(f\"   â€¢ {table_name}\")\n    \n    # ç¾åœ¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n    table_name = f\"processed_data_{MODE.lower()}\"\n    if table_name not in tables['name'].values:\n        raise ValueError(\n            f\"ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\\n\"\n            \"ğŸ’¡ SQLiteä¿å­˜ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\"\n        )\n    \n    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n    print(f\"\\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5ä»¶ï¼‰:\")\n    sample = pd.read_sql_query(f\"SELECT * FROM {table_name} LIMIT 5\", conn)\n    print(sample)\n    \n    # çµ±è¨ˆæƒ…å ±\n    print(f\"\\nğŸ“ˆ çµ±è¨ˆæƒ…å ±:\")\n    stats_query = f\"\"\"\n        SELECT \n            COUNT(*) as total_records,\n            COUNT(DISTINCT race_id) as unique_races,\n            COUNT(DISTINCT horse_id) as unique_horses,\n            MIN(date) as earliest_date,\n            MAX(date) as latest_date,\n            AVG(target_win) as win_rate\n        FROM {table_name}\n    \"\"\"\n    \n    try:\n        stats = pd.read_sql_query(stats_query, conn)\n        print(stats)\n        \n        # çµ±è¨ˆæƒ…å ±ã®æ¤œè¨¼\n        total_records = stats['total_records'].iloc[0]\n        win_rate = stats['win_rate'].iloc[0]\n        \n        if total_records < 1000:\n            print(f\"\\nâš ï¸ ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ã§ã™ï¼ˆ{total_records:,}ä»¶ï¼‰\")\n            print(\"ğŸ’¡ æ¨å¥¨: 5000ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™\")\n        \n        if win_rate < 0.03 or win_rate > 0.20:\n            print(f\"\\nâš ï¸ å‹ç‡ãŒç•°å¸¸ã§ã™: {win_rate:.2%}\")\n            print(\"ğŸ’¡ é€šå¸¸ã€å‹ç‡ã¯5-10%ç¨‹åº¦ã§ã™\")\n        else:\n            print(f\"\\nâœ… å‹ç‡ã¯æ­£å¸¸ç¯„å›²å†…ã§ã™: {win_rate:.2%}\")\n        \n    except Exception as e:\n        print(f\"âš ï¸ çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}\")\n    \n    # ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆ\n    print(f\"\\nğŸ“ ã‚«ãƒ©ãƒ ä¸€è¦§ï¼ˆæœ€åˆã®10å€‹ï¼‰:\")\n    pragma_query = f\"PRAGMA table_info({table_name})\"\n    columns_info = pd.read_sql_query(pragma_query, conn)\n    for idx, row in columns_info.head(10).iterrows():\n        print(f\"   {idx+1}. {row['name']} ({row['type']})\")\n    \n    if len(columns_info) > 10:\n        print(f\"   ... ä»– {len(columns_info) - 10}å€‹\")\n    \n    print(f\"\\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼å®Œäº†\")\n    print(f\"   ç·ã‚«ãƒ©ãƒ æ•°: {len(columns_info)}\")\n    \n    conn.close()\n    \nexcept FileNotFoundError as e:\n    print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept ValueError as e:\n    print(f\"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept sqlite3.Error as e:\n    print(f\"âŒ SQLiteã‚¨ãƒ©ãƒ¼: {e}\")\n    if 'conn' in locals():\n        conn.close()\n    raise\nexcept Exception as e:\n    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}\")\n    import traceback\n    print(\"\\nè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\")\n    traceback.print_exc()\n    if 'conn' in locals():\n        conn.close()\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¤ ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import files\n\n# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\nprint(\"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n\ntry:\n    if not os.path.exists(DB_PATH):\n        raise FileNotFoundError(\n            f\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DB_PATH}\\n\"\n            \"ğŸ’¡ SQLiteä¿å­˜ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\"\n        )\n    \n    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª\n    file_size = os.path.getsize(DB_PATH)\n    print(f\"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.2f} MB\")\n    \n    if file_size > 100 * 1024 * 1024:  # 100MBä»¥ä¸Š\n        print(\"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™\")\n        print(\"ğŸ’¡ Google Driveã«ä¿å­˜ã™ã‚‹ã“ã¨ã‚‚æ¤œè¨ã—ã¦ãã ã•ã„\")\n    \n    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n    files.download(DB_PATH)\n    \n    print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {DB_PATH}\")\n    print(\"\\nğŸ“Œ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n    print(\"1. ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®\")\n    print(\"2. ç®¡ç†ãƒšãƒ¼ã‚¸ï¼ˆadmin_app_simple.pyï¼‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\")\n    print(\"3. å…¬é–‹ãƒšãƒ¼ã‚¸ï¼ˆpublic_app.pyï¼‰ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ\")\n    \nexcept FileNotFoundError as e:\n    print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}\")\n    raise\nexcept Exception as e:\n    print(f\"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n    print(\"ğŸ’¡ Google Driveã«ä¿å­˜ã—ã¦ã‹ã‚‰æ‰‹å‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™\")\n    print(f\"   ã‚³ãƒãƒ³ãƒ‰: !cp {DB_PATH} /content/drive/MyDrive/\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ NARï¼ˆåœ°æ–¹ç«¶é¦¬ï¼‰ã®å‡¦ç†\n",
    "\n",
    "NARãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã«å‡¦ç†ã™ã‚‹å ´åˆã¯ã€MODEã‚’å¤‰æ›´ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NARå‡¦ç†ã®ä¾‹\n",
    "MODE_NAR = \"NAR\"\n",
    "\n",
    "# ä¸Šè¨˜ã®ã‚»ãƒ«ã‚’MODE=\"NAR\"ã§å†å®Ÿè¡Œã™ã‚‹ã‹ã€\n",
    "# ã¾ãŸã¯é–¢æ•°åŒ–ã—ã¦å‘¼ã³å‡ºã™\n",
    "\n",
    "def process_race_data(mode=\"JRA\", use_venue_features=True):\n",
    "    \"\"\"ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ãƒ¢ãƒ¼ãƒ‰: {mode}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆçœç•¥ï¼‰\n",
    "    \n",
    "    # 2. ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "    input_csv = f\"database_{mode.lower()}.csv\"\n",
    "    output_csv = f\"processed_data_{mode.lower()}.csv\"\n",
    "    \n",
    "    calculate_features(\n",
    "        input_csv,\n",
    "        output_csv,\n",
    "        lambda_decay=0.2,\n",
    "        use_venue_features=use_venue_features\n",
    "    )\n",
    "    \n",
    "    # 3. SQLä¿å­˜\n",
    "    df = pd.read_csv(output_csv)\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    table_name = f\"processed_data_{mode.lower()}\"\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"âœ… {mode}ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†å®Œäº†\")\n",
    "\n",
    "# JRAã¨NARã®ä¸¡æ–¹ã‚’å‡¦ç†\n",
    "# process_race_data(\"JRA\", use_venue_features=True)\n",
    "# process_race_data(\"NAR\", use_venue_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… å®Œäº†\n",
    "\n",
    "ã“ã‚Œã§ä»¥ä¸‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼š\n",
    "1. âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n",
    "2. âœ… ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "3. âœ… SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ\n",
    "4. âœ… ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼\n",
    "\n",
    "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š\n",
    "1. `keiba_data.db`ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®\n",
    "3. ç®¡ç†ç”»é¢ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n",
    "4. å…¬é–‹ãƒšãƒ¼ã‚¸ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}