{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‡ ç«¶é¦¬AI ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆGoogle Colabç‰ˆï¼‰\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š\n",
    "1. **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: netkeiba.comã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†\n",
    "2. **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: æ¬ æå€¤å‡¦ç†ã€å‹å¤‰æ›ã€å¤–ã‚Œå€¤é™¤å»\n",
    "3. **ç‰¹å¾´é‡ç”Ÿæˆ**: éå»èµ°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬ç”¨ç‰¹å¾´é‡ã‚’è¨ˆç®—\n",
    "4. **SQLiteä¿å­˜**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¦ã‚¢ãƒ—ãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ã«\n",
    "\n",
    "## ğŸ“‹ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "!pip install beautifulsoup4 requests pandas numpy scikit-learn lightgbm tqdm -q\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Google Driveãƒã‚¦ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’Google Driveã«ä¿å­˜ã™ã‚‹å ´åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
    "WORK_DIR = '/content/drive/MyDrive/keiba-ai'\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "print(f\"âœ… ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ GitHubã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’ã‚¯ãƒ­ãƒ¼ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHubãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "REPO_URL = \"https://github.com/YOUR_USERNAME/dai-keiba.git\"  # å®Ÿéš›ã®URLã«å¤‰æ›´\n",
    "\n",
    "if not os.path.exists('dai-keiba'):\n",
    "    !git clone {REPO_URL}\n",
    "    print(\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã—ãŸ\")\n",
    "else:\n",
    "    print(\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™\")\n",
    "    # æœ€æ–°ç‰ˆã‚’å–å¾—\n",
    "    !cd dai-keiba && git pull\n",
    "\n",
    "# ãƒ‘ã‚¹ã®è¿½åŠ \n",
    "sys.path.append('dai-keiba')\n",
    "sys.path.append('dai-keiba/scraper')\n",
    "sys.path.append('dai-keiba/ml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ•·ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n",
    "\n",
    "### JRAãƒ‡ãƒ¼ã‚¿ã®åé›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import auto_scraper\n",
    "\n",
    "# è¨­å®š\n",
    "START_DATE = \"2023-01-01\"  # é–‹å§‹æ—¥\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")  # ä»Šæ—¥ã¾ã§\n",
    "MODE = \"JRA\"  # JRA ã¾ãŸã¯ NAR\n",
    "\n",
    "print(f\"ğŸ“… åé›†æœŸé–“: {START_DATE} ï½ {END_DATE}\")\n",
    "print(f\"ğŸ‡ ãƒ¢ãƒ¼ãƒ‰: {MODE}\")\n",
    "print(\"\\nâ³ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...ï¼ˆæ•°æ™‚é–“ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰\")\n",
    "\n",
    "# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ\n",
    "# æ³¨: auto_scraperã®scrape_historical_dataé–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
    "# è©³ç´°ã¯ dai-keiba/ml/scrape_historical_data.py ã‚’å‚ç…§\n",
    "\n",
    "# æš«å®šçš„ã«CSVã¨ã—ã¦ä¿å­˜\n",
    "csv_path = f\"database_{MODE.lower()}.csv\"\n",
    "\n",
    "# ã“ã“ã«å®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã‚’å®Ÿè£…\n",
    "# ä¾‹: df = auto_scraper.scrape_range(START_DATE, END_DATE, MODE)\n",
    "# df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´é‡ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.feature_engineering import calculate_features\n",
    "\n",
    "# è¨­å®š\n",
    "USE_VENUE_FEATURES = True  # ä¼šå ´ç‰¹æ€§ç‰¹å¾´é‡ã‚’ä½¿ç”¨\n",
    "\n",
    "input_csv = f\"database_{MODE.lower()}.csv\"\n",
    "output_csv = f\"processed_data_{MODE.lower()}.csv\"\n",
    "\n",
    "print(f\"âš™ï¸ ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹...\")\n",
    "print(f\"   å…¥åŠ›: {input_csv}\")\n",
    "print(f\"   å‡ºåŠ›: {output_csv}\")\n",
    "print(f\"   ä¼šå ´ç‰¹æ€§: {USE_VENUE_FEATURES}\")\n",
    "\n",
    "# ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "calculate_features(\n",
    "    input_csv,\n",
    "    output_csv,\n",
    "    lambda_decay=0.2,\n",
    "    use_venue_features=USE_VENUE_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—3: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ\n",
    "DB_PATH = \"keiba_data.db\"\n",
    "\n",
    "print(f\"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ: {DB_PATH}\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "df_processed = pd.read_csv(output_csv)\n",
    "\n",
    "print(f\"   ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df_processed)}\")\n",
    "print(f\"   ç‰¹å¾´é‡æ•°: {len(df_processed.columns)}\")\n",
    "\n",
    "# SQLiteæ¥ç¶š\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# ãƒ†ãƒ¼ãƒ–ãƒ«åã®æ±ºå®š\n",
    "table_name = f\"processed_data_{MODE.lower()}\"\n",
    "\n",
    "# DataFrameã‚’SQLiteã«ä¿å­˜\n",
    "df_processed.to_sql(\n",
    "    table_name,\n",
    "    conn,\n",
    "    if_exists='replace',  # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç½®ãæ›ãˆ\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆï¼ˆé«˜é€ŸåŒ–ï¼‰\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_race_id ON {table_name}(race_id)\")\n",
    "cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_horse_id ON {table_name}(horse_id)\")\n",
    "cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_date ON {table_name}(date)\")\n",
    "conn.commit()\n",
    "\n",
    "print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {table_name}\")\n",
    "\n",
    "# ç¢ºèªã‚¯ã‚¨ãƒª\n",
    "result = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM {table_name}\", conn)\n",
    "print(f\"   ä¿å­˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {result['count'].iloc[0]}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ç¢ºèª\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "print(\"ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§:\")\n",
    "print(tables)\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n",
    "print(\"\\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­5ä»¶ï¼‰:\")\n",
    "sample = pd.read_sql_query(f\"SELECT * FROM {table_name} LIMIT 5\", conn)\n",
    "print(sample)\n",
    "\n",
    "# çµ±è¨ˆæƒ…å ±\n",
    "print(\"\\nğŸ“ˆ çµ±è¨ˆæƒ…å ±:\")\n",
    "stats = pd.read_sql_query(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(DISTINCT race_id) as unique_races,\n",
    "        COUNT(DISTINCT horse_id) as unique_horses,\n",
    "        MIN(date) as earliest_date,\n",
    "        MAX(date) as latest_date,\n",
    "        AVG(target_win) as win_rate\n",
    "    FROM {table_name}\n",
    "\"\"\", conn)\n",
    "print(stats)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¤ ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "files.download(DB_PATH)\n",
    "print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {DB_PATH}\")\n",
    "print(\"\\nğŸ‘‰ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ NARï¼ˆåœ°æ–¹ç«¶é¦¬ï¼‰ã®å‡¦ç†\n",
    "\n",
    "NARãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã«å‡¦ç†ã™ã‚‹å ´åˆã¯ã€MODEã‚’å¤‰æ›´ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NARå‡¦ç†ã®ä¾‹\n",
    "MODE_NAR = \"NAR\"\n",
    "\n",
    "# ä¸Šè¨˜ã®ã‚»ãƒ«ã‚’MODE=\"NAR\"ã§å†å®Ÿè¡Œã™ã‚‹ã‹ã€\n",
    "# ã¾ãŸã¯é–¢æ•°åŒ–ã—ã¦å‘¼ã³å‡ºã™\n",
    "\n",
    "def process_race_data(mode=\"JRA\", use_venue_features=True):\n",
    "    \"\"\"ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ãƒ¢ãƒ¼ãƒ‰: {mode}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆçœç•¥ï¼‰\n",
    "    \n",
    "    # 2. ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "    input_csv = f\"database_{mode.lower()}.csv\"\n",
    "    output_csv = f\"processed_data_{mode.lower()}.csv\"\n",
    "    \n",
    "    calculate_features(\n",
    "        input_csv,\n",
    "        output_csv,\n",
    "        lambda_decay=0.2,\n",
    "        use_venue_features=use_venue_features\n",
    "    )\n",
    "    \n",
    "    # 3. SQLä¿å­˜\n",
    "    df = pd.read_csv(output_csv)\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    table_name = f\"processed_data_{mode.lower()}\"\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"âœ… {mode}ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†å®Œäº†\")\n",
    "\n",
    "# JRAã¨NARã®ä¸¡æ–¹ã‚’å‡¦ç†\n",
    "# process_race_data(\"JRA\", use_venue_features=True)\n",
    "# process_race_data(\"NAR\", use_venue_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… å®Œäº†\n",
    "\n",
    "ã“ã‚Œã§ä»¥ä¸‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼š\n",
    "1. âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n",
    "2. âœ… ç‰¹å¾´é‡ç”Ÿæˆ\n",
    "3. âœ… SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ\n",
    "4. âœ… ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼\n",
    "\n",
    "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š\n",
    "1. `keiba_data.db`ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®\n",
    "3. ç®¡ç†ç”»é¢ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n",
    "4. å…¬é–‹ãƒšãƒ¼ã‚¸ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
