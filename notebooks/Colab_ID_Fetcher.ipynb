{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ†” ãƒã‚¹ã‚¿ãƒ¼IDãƒªã‚¹ãƒˆå–å¾—ãƒ„ãƒ¼ãƒ« (Seleniumç‰ˆ)\n",
                "Netkeibaã®é–‹å‚¬ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’å·¡å›ã—ã€æŒ‡å®šæœŸé–“å†…ã®**å…¨ã¦ã®ãƒ¬ãƒ¼ã‚¹ID**ã‚’å–å¾—ã—ã¦ `race_ids.csv` (JRA) / `race_ids_nar.csv` (NAR) ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
                "\n",
                "**é‡è¦**: ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯Seleniumã‚’ä½¿ç”¨ã—ã¦JavaScriptã§å‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¾ã™ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Seleniumã¨chromedriver-binaryã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
                "!pip install -q selenium\n",
                "!apt-get update > /dev/null 2>&1\n",
                "!apt-get install -y chromium-chromedriver > /dev/null 2>&1\n",
                "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
                "print(\"âœ… Selenium setup complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# è¨­å®š\n",
                "DATA_DIR = '/content/drive/MyDrive/dai-keiba/data/raw'\n",
                "JRA_ID_CSV = 'race_ids.csv'\n",
                "NAR_ID_CSV = 'race_ids_nar.csv'\n",
                "\n",
                "START_YEAR = 2025\n",
                "END_YEAR = 2026"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "import pandas as pd\n",
                "import re\n",
                "import time\n",
                "import os\n",
                "from tqdm.auto import tqdm\n",
                "from selenium import webdriver\n",
                "from selenium.webdriver.chrome.options import Options\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.support.ui import WebDriverWait\n",
                "from selenium.webdriver.support import expected_conditions as EC\n",
                "\n",
                "def get_kaisai_dates(year, month, mode='JRA'):\n",
                "    \"\"\"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã‹ã‚‰é–‹å‚¬æ—¥ã‚’å–å¾—(requestsä½¿ç”¨)\"\"\"\n",
                "    base_domain = \"race.netkeiba.com\" if mode == 'JRA' else \"nar.netkeiba.com\"\n",
                "    cal_url = f\"https://{base_domain}/top/calendar.html?year={year}&month={month}\"\n",
                "    \n",
                "    session = requests.Session()\n",
                "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
                "    \n",
                "    try:\n",
                "        resp = session.get(cal_url, headers=headers, timeout=10)\n",
                "        resp.encoding = 'EUC-JP'\n",
                "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
                "        \n",
                "        day_links = soup.select('a[href*=\"race_list.html?kaisai_date=\"]')\n",
                "        \n",
                "        dates = set()\n",
                "        for link in day_links:\n",
                "            href = link.get('href')\n",
                "            m = re.search(r'kaisai_date=(\\d{8})', href)\n",
                "            if m:\n",
                "                dates.add(m.group(1))\n",
                "        \n",
                "        return sorted(list(dates))\n",
                "    except Exception as e:\n",
                "        print(f\"  Error fetching calendar {year}/{month}: {e}\")\n",
                "        return []\n",
                "\n",
                "def get_race_ids_from_date_selenium(driver, date_str, mode='JRA'):\n",
                "    \"\"\"Seleniumã‚’ä½¿ã£ã¦ç‰¹å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—\"\"\"\n",
                "    base_domain = \"race.netkeiba.com\" if mode == 'JRA' else \"nar.netkeiba.com\"\n",
                "    list_url = f\"https://{base_domain}/top/race_list.html?kaisai_date={date_str}\"\n",
                "    \n",
                "    try:\n",
                "        driver.get(list_url)\n",
                "        \n",
                "        # JavaScriptã®èª­ã¿è¾¼ã¿ã‚’å¾…ã¤\n",
                "        time.sleep(2)\n",
                "        \n",
                "        # ãƒšãƒ¼ã‚¸ã®HTMLã‚½ãƒ¼ã‚¹ã‚’å–å¾—\n",
                "        page_source = driver.page_source\n",
                "        \n",
                "        # race_idã‚’å«ã‚€ãƒªãƒ³ã‚¯ã‚’æ¢ã™\n",
                "        race_ids = set()\n",
                "        \n",
                "        # æ–¹æ³•1: aã‚¿ã‚°ã®hrefå±æ€§ã‹ã‚‰\n",
                "        soup = BeautifulSoup(page_source, 'html.parser')\n",
                "        race_links = soup.find_all('a', href=re.compile(r'race_id=\\d+'))\n",
                "        \n",
                "        for link in race_links:\n",
                "            href = link.get('href')\n",
                "            m = re.search(r'race_id=(\\d+)', href)\n",
                "            if m:\n",
                "                rid = m.group(1)\n",
                "                if len(rid) == 12:\n",
                "                    race_ids.add(rid)\n",
                "        \n",
                "        # æ–¹æ³•2: ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹å…¨ä½“ã‹ã‚‰12æ¡ã®race_idãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™\n",
                "        if not race_ids:\n",
                "            year = date_str[:4]\n",
                "            pattern = rf'\\b({year}\\d{{8}})\\b'\n",
                "            matches = re.findall(pattern, page_source)\n",
                "            \n",
                "            for match in matches:\n",
                "                if len(match) == 12:\n",
                "                    # å ´æ‰€ã‚³ãƒ¼ãƒ‰ã§çµã‚Šè¾¼ã¿\n",
                "                    place_code = match[4:6]\n",
                "                    if mode == 'JRA':\n",
                "                        if place_code in [f\"{i:02d}\" for i in range(1, 11)]:\n",
                "                            race_ids.add(match)\n",
                "                    else:\n",
                "                        if int(place_code) >= 30:\n",
                "                            race_ids.add(match)\n",
                "        \n",
                "        return sorted(list(race_ids))\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"    Error fetching {date_str}: {e}\")\n",
                "        return []\n",
                "\n",
                "def fetch_race_ids(mode='JRA', start_year=2025, end_year=2026):\n",
                "    print(f\"\\nğŸš€ {mode} Race ID Fetching ({start_year}-{end_year})...\")\n",
                "    \n",
                "    base_domain = \"race.netkeiba.com\" if mode == 'JRA' else \"nar.netkeiba.com\"\n",
                "    save_csv = JRA_ID_CSV if mode == 'JRA' else NAR_ID_CSV\n",
                "    save_path = os.path.join(DATA_DIR, save_csv)\n",
                "    \n",
                "    all_ids = set()\n",
                "    \n",
                "    # æ—¢å­˜ã®IDã‚’èª­ã¿è¾¼ã¿\n",
                "    if os.path.exists(save_path):\n",
                "        try:\n",
                "            existing_df = pd.read_csv(save_path, dtype=str)\n",
                "            if 'race_id' in existing_df.columns:\n",
                "                all_ids = set(existing_df['race_id'].dropna().unique())\n",
                "                print(f\"  ğŸ“‚ Loaded {len(all_ids)} existing IDs from {save_csv}\")\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    # Seleniumãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’è¨­å®š\n",
                "    chrome_options = Options()\n",
                "    chrome_options.add_argument('--headless')\n",
                "    chrome_options.add_argument('--no-sandbox')\n",
                "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
                "    chrome_options.add_argument('--disable-gpu')\n",
                "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
                "    \n",
                "    driver = webdriver.Chrome(options=chrome_options)\n",
                "    \n",
                "    try:\n",
                "        for year in range(start_year, end_year + 1):\n",
                "            print(f\"  ğŸ“… Processing {year}...\")\n",
                "            \n",
                "            for month in range(1, 13):\n",
                "                # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰é–‹å‚¬æ—¥ã‚’å–å¾—\n",
                "                dates = get_kaisai_dates(year, month, mode)\n",
                "                \n",
                "                if not dates:\n",
                "                    continue\n",
                "                \n",
                "                # å„é–‹å‚¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—\n",
                "                for date_str in tqdm(dates, desc=f\"{year}/{month:02}\", leave=False):\n",
                "                    day_ids = get_race_ids_from_date_selenium(driver, date_str, mode)\n",
                "                    all_ids.update(day_ids)\n",
                "                    \n",
                "                    # å®šæœŸçš„ã«ä¿å­˜\n",
                "                    if len(all_ids) % 100 == 0:\n",
                "                        df_temp = pd.DataFrame({'race_id': sorted(list(all_ids))})\n",
                "                        df_temp.to_csv(save_path, index=False)\n",
                "    \n",
                "    finally:\n",
                "        driver.quit()\n",
                "    \n",
                "    # æœ€çµ‚ä¿å­˜\n",
                "    print(f\"\\nğŸ’¾ Saving {len(all_ids)} IDs to {save_path}...\")\n",
                "    df_out = pd.DataFrame({'race_id': sorted(list(all_ids))})\n",
                "    df_out.to_csv(save_path, index=False)\n",
                "    print(\"âœ… Done.\")\n",
                "    \n",
                "    return len(all_ids)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®Ÿè¡Œ\n",
                "if os.path.exists(DATA_DIR):\n",
                "    try:\n",
                "        jra_count = fetch_race_ids(mode='JRA', start_year=START_YEAR, end_year=END_YEAR)\n",
                "        print(f\"\\nâœ… JRA: {jra_count} IDs collected\")\n",
                "    except Exception as e:\n",
                "        print(f\"âŒ JRA Error: {e}\")\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "    \n",
                "    try:\n",
                "        nar_count = fetch_race_ids(mode='NAR', start_year=START_YEAR, end_year=END_YEAR)\n",
                "        print(f\"\\nâœ… NAR: {nar_count} IDs collected\")\n",
                "    except Exception as e:\n",
                "        print(f\"âŒ NAR Error: {e}\")\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "else:\n",
                "    print(f\"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DATA_DIR}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}