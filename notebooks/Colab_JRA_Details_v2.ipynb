{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‡ JRA è©³ç´°æƒ…å ±ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° (Stage 2/2) v2\n",
    "\n",
    "## ğŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿\n",
    "- **68ã‚«ãƒ©ãƒ **: past_1~5ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿(65ã‚«ãƒ©ãƒ ) + è¡€çµ±ãƒ‡ãƒ¼ã‚¿(3ã‚«ãƒ©ãƒ )\n",
    "\n",
    "## ğŸ“ å‰ææ¡ä»¶\n",
    "- Stage 1ã§ `database_basic.csv` ãŒä½œæˆæ¸ˆã¿\n",
    "- horse_idãŒå«ã¾ã‚Œã¦ã„ã‚‹\n",
    "\n",
    "## âœ… ç‰¹å¾´\n",
    "- è©²å½“ãƒ¬ãƒ¼ã‚¹æ™‚ç‚¹ã§ã®éå»èµ°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "- race_dateä»¥å‰ã®ãƒ¬ãƒ¼ã‚¹ã®ã¿\n",
    "- ã‚«ãƒ©ãƒ ã‚ºãƒ¬ã‚’å®Œå…¨ã«é˜²æ­¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive Mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "SAVE_DIR = '/content/drive/MyDrive/dai-keiba/data/raw'\n",
    "BASIC_CSV = 'database_basic.csv'\n",
    "DETAILS_CSV = 'database_details.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"âœ… Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¦¬å±¥æ­´ãƒ»è¡€çµ±å–å¾—é–¢æ•°\n",
    "\n",
    "def get_horse_details(horse_id, race_date):\n",
    "    \"\"\"\n",
    "    é¦¬ã®å±¥æ­´ãƒ»è¡€çµ±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—(68ã‚«ãƒ©ãƒ )\n",
    "    race_dateä»¥å‰ã®éå»5èµ°ã®ã¿å–å¾—\n",
    "    \"\"\"\n",
    "    details = {\n",
    "        'race_id': '',\n",
    "        'horse_id': horse_id\n",
    "    }\n",
    "    \n",
    "    # éå»5èµ°ã®åˆæœŸåŒ–\n",
    "    for i in range(1, 6):\n",
    "        prefix = f'past_{i}'\n",
    "        for field in ['date', 'rank', 'time', 'run_style', 'race_name', 'last_3f', \n",
    "                      'horse_weight', 'jockey', 'condition', 'odds', 'weather', 'distance', 'course_type']:\n",
    "            details[f'{prefix}_{field}'] = ''\n",
    "    \n",
    "    # è¡€çµ±ã®åˆæœŸåŒ–\n",
    "    details['father'] = ''\n",
    "    details['mother'] = ''\n",
    "    details['bms'] = ''\n",
    "    \n",
    "    try:\n",
    "        time.sleep(0.5)\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        \n",
    "        # é¦¬ãƒšãƒ¼ã‚¸å–å¾—\n",
    "        url = f\"https://db.netkeiba.com/horse/result/{horse_id}/\"\n",
    "        resp = requests.get(url, headers=headers, timeout=15)\n",
    "        resp.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        \n",
    "        # è¡€çµ±æƒ…å ±(ç°¡æ˜“ç‰ˆ - ãƒšãƒ¼ã‚¸å†…ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰)\n",
    "        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯è¡€çµ±ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "        \n",
    "        # ãƒ¬ãƒ¼ã‚¹å±¥æ­´å–å¾—\n",
    "        table = soup.select_one(\"table.db_h_race_results\")\n",
    "        if not table:\n",
    "            tables = soup.find_all(\"table\")\n",
    "            for t in tables:\n",
    "                if \"ç€é †\" in t.text:\n",
    "                    table = t\n",
    "                    break\n",
    "        \n",
    "        if table:\n",
    "            df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "            df = df.dropna(how='all')\n",
    "            df.columns = df.columns.astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "            \n",
    "            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "            if 'æ—¥ä»˜' in df.columns:\n",
    "                df['date_obj'] = pd.to_datetime(df['æ—¥ä»˜'].astype(str).str.replace('.', '/'), errors='coerce')\n",
    "                df = df.dropna(subset=['date_obj'])\n",
    "                \n",
    "                # race_dateä»¥å‰ã®ãƒ¬ãƒ¼ã‚¹ã®ã¿\n",
    "                current_date = pd.to_datetime(race_date)\n",
    "                df = df[df['date_obj'] < current_date]\n",
    "                df = df.sort_values('date_obj', ascending=False)\n",
    "                df = df.head(5)\n",
    "                \n",
    "                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º\n",
    "                for i, row in enumerate(df.itertuples(), 1):\n",
    "                    prefix = f'past_{i}'\n",
    "                    \n",
    "                    details[f'{prefix}_date'] = getattr(row, 'æ—¥ä»˜', '')\n",
    "                    details[f'{prefix}_rank'] = str(getattr(row, 'ç€é †', ''))\n",
    "                    details[f'{prefix}_time'] = str(getattr(row, 'ã‚¿ã‚¤ãƒ ', ''))\n",
    "                    details[f'{prefix}_race_name'] = str(getattr(row, 'ãƒ¬ãƒ¼ã‚¹å', ''))\n",
    "                    details[f'{prefix}_last_3f'] = str(getattr(row, 'ä¸Šã‚Š', ''))\n",
    "                    details[f'{prefix}_horse_weight'] = str(getattr(row, 'é¦¬ä½“é‡', ''))\n",
    "                    details[f'{prefix}_jockey'] = str(getattr(row, 'é¨æ‰‹', ''))\n",
    "                    details[f'{prefix}_condition'] = str(getattr(row, 'é¦¬å ´', ''))\n",
    "                    details[f'{prefix}_odds'] = str(getattr(row, 'å˜å‹', '') or getattr(row, 'ã‚ªãƒƒã‚º', ''))\n",
    "                    details[f'{prefix}_weather'] = str(getattr(row, 'å¤©æ°—', ''))\n",
    "                    \n",
    "                    # è·é›¢ãƒ»ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—\n",
    "                    dist_text = str(getattr(row, 'è·é›¢', ''))\n",
    "                    dist_match = re.search(r'(èŠ|ãƒ€|éšœ)(\\d+)', dist_text)\n",
    "                    if dist_match:\n",
    "                        course_type = dist_match.group(1)\n",
    "                        details[f'{prefix}_course_type'] = 'èŠ' if course_type == 'èŠ' else 'ãƒ€ãƒ¼ãƒˆ' if course_type == 'ãƒ€' else 'éšœå®³'\n",
    "                        details[f'{prefix}_distance'] = dist_match.group(2)\n",
    "                    \n",
    "                    # è„šè³ª(ç°¡æ˜“ç‰ˆ)\n",
    "                    details[f'{prefix}_run_style'] = '3'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ã‚¨ãƒ©ãƒ¼({horse_id}): {e}\")\n",
    "        return details\n",
    "\n",
    "print(\"âœ… Horse details function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ\n",
    "\n",
    "def run_details_scraping():\n",
    "    \"\"\"\n",
    "    Stage 1ã®CSVã‹ã‚‰horse_idã‚’èª­ã¿è¾¼ã¿ã€è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "    \"\"\"\n",
    "    basic_path = os.path.join(SAVE_DIR, BASIC_CSV)\n",
    "    details_path = os.path.join(SAVE_DIR, DETAILS_CSV)\n",
    "    \n",
    "    # Stage 1ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "    if not os.path.exists(basic_path):\n",
    "        print(f\"âŒ Stage 1ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {basic_path}\")\n",
    "        return\n",
    "    \n",
    "    df_basic = pd.read_csv(basic_path, dtype=str, on_bad_lines='skip', usecols=['race_id', 'horse_id', 'æ—¥ä»˜'])\n",
    "    print(f\"ğŸ“‹ Stage 1ãƒ‡ãƒ¼ã‚¿: {len(df_basic)}è¡Œ\")\n",
    "    \n",
    "    # æ—¢å­˜ã®detailsãƒ‡ãƒ¼ã‚¿\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(details_path):\n",
    "        df_existing = pd.read_csv(details_path, dtype=str, on_bad_lines='skip')\n",
    "        if 'race_id' in df_existing.columns and 'horse_id' in df_existing.columns:\n",
    "            existing_ids = set(df_existing['race_id'] + '_' + df_existing['horse_id'])\n",
    "        print(f\"ğŸ’¾ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {len(existing_ids)}ä»¶\")\n",
    "    \n",
    "    # å·®åˆ†è¨ˆç®—\n",
    "    df_basic['key'] = df_basic['race_id'] + '_' + df_basic['horse_id']\n",
    "    df_target = df_basic[~df_basic['key'].isin(existing_ids)]\n",
    "    print(f\"ğŸš€ ä»Šå›å–å¾—: {len(df_target)}ä»¶\\n\")\n",
    "    \n",
    "    if df_target.empty:\n",
    "        print(\"âœ… å…¨ã¦å–å¾—æ¸ˆã¿ã§ã™\")\n",
    "        return\n",
    "    \n",
    "    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n",
    "    buffer = []\n",
    "    chunk_size = 50\n",
    "    \n",
    "    for i, row in enumerate(tqdm(df_target.itertuples(), total=len(df_target))):\n",
    "        horse_id = row.horse_id\n",
    "        race_date = row.æ—¥ä»˜\n",
    "        race_id = row.race_id\n",
    "        \n",
    "        if not horse_id or not race_date:\n",
    "            continue\n",
    "        \n",
    "        details = get_horse_details(horse_id, race_date)\n",
    "        details['race_id'] = race_id\n",
    "        buffer.append(details)\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯ä¿å­˜\n",
    "        if len(buffer) >= chunk_size or (i == len(df_target) - 1 and buffer):\n",
    "            df_chunk = pd.DataFrame(buffer)\n",
    "            \n",
    "            # ã‚«ãƒ©ãƒ é †åºã‚’æ˜ç¤º\n",
    "            ordered_columns = ['race_id', 'horse_id']\n",
    "            for i in range(1, 6):\n",
    "                prefix = f'past_{i}'\n",
    "                for field in ['date', 'rank', 'time', 'run_style', 'race_name', 'last_3f', \n",
    "                              'horse_weight', 'jockey', 'condition', 'odds', 'weather', 'distance', 'course_type']:\n",
    "                    ordered_columns.append(f'{prefix}_{field}')\n",
    "            ordered_columns.extend(['father', 'mother', 'bms'])\n",
    "            \n",
    "            df_chunk = df_chunk[ordered_columns]\n",
    "            \n",
    "            if not os.path.exists(details_path):\n",
    "                df_chunk.to_csv(details_path, index=False)\n",
    "            else:\n",
    "                df_chunk.to_csv(details_path, mode='a', header=False, index=False)\n",
    "            \n",
    "            print(f\"  ğŸ’¾ Saved {len(buffer)} records\")\n",
    "            buffer = []\n",
    "    \n",
    "    print(\"\\nâœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†\")\n",
    "\n",
    "print(\"âœ… Main function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Ÿè¡Œ\n",
    "run_details_scraping()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}