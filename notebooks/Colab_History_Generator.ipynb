{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Past Race History Generator (Cross-Domain)\n\n- **ÁõÆÁöÑ**: ÈÅéÂéªËµ∞„Éá„Éº„Çø„ÇíËá™Â∑±ÁµêÂêà„ÅßÁîüÊàêÔºàJRA/NAR‰∏°Êñπ„ÇíÂèÇÁÖßÔºâ\n- **ÁâπÂæ¥**:\n  - ‰∫§ÊµÅÁ´∂Ëµ∞„ÉªËª¢Á±çÈ¶¨„Å´ÂØæÂøú\n  - JRAÈ¶¨„ÅÆNARÂá∫Ëµ∞Â±•Ê≠¥„ÄÅNARÈ¶¨„ÅÆJRAÂá∫Ëµ∞Â±•Ê≠¥„ÇÇÂèñÂæó\n  - HTTP„É™„ÇØ„Ç®„Çπ„Éà‰∏çË¶Å\n- **Âá∫Âäõ**: `database_xxx_with_history.csv`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Google Drive Mount\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ========================================\n",
                "# ‚öôÔ∏è „É¢„Éº„ÉâË®≠ÂÆö - „Åì„Åì„ÇíÂ§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
                "# ========================================\n",
                "\n",
                "MODE = 'JRA'  # 'JRA' „Åæ„Åü„ÅØ 'NAR' „ÇíÈÅ∏Êäû\n",
                "\n",
                "# ========================================"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Settings\n",
                "SAVE_DIR = '/content/drive/MyDrive/dai-keiba/data/raw'\n",
                "\n",
                "# ‰∏°Êñπ„ÅÆ„Éï„Ç°„Ç§„É´„ÇíË™≠„ÅøËæº„ÇÄÔºàÈÅéÂéªËµ∞Ê§úÁ¥¢Áî®Ôºâ\n",
                "JRA_BASIC = 'database_jra_basic.csv'\n",
                "NAR_BASIC = 'database_nar_basic.csv'\n",
                "\n",
                "# Âá∫Âäõ„Éï„Ç°„Ç§„É´Ôºà„É¢„Éº„Éâ„Å´Âü∫„Å•„ÅèÔºâ\n",
                "if MODE == 'JRA':\n",
                "    TARGET_FILE = JRA_BASIC\n",
                "    OUTPUT_FILE = 'database_jra_with_history.csv'\n",
                "elif MODE == 'NAR':\n",
                "    TARGET_FILE = NAR_BASIC\n",
                "    OUTPUT_FILE = 'database_nar_with_history.csv'\n",
                "else:\n",
                "    raise ValueError(f\"Invalid MODE: {MODE}\")\n",
                "\n",
                "print(f\"üìã Mode: {MODE}\")\n",
                "print(f\"   Target races: {TARGET_FILE}\")\n",
                "print(f\"   History source: {JRA_BASIC} + {NAR_BASIC} (cross-domain)\")\n",
                "print(f\"   Output: {OUTPUT_FILE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "print(\"‚úÖ Libraries loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Column mappings: Basic column -> past_N field name\n",
                "COLUMN_MAPPING = {\n",
                "    'Êó•‰ªò': 'date',\n",
                "    'ÁùÄÈ†Ü': 'rank',\n",
                "    '„Çø„Ç§„É†': 'time',\n",
                "    'È®éÊâã': 'jockey',\n",
                "    'È¶¨‰ΩìÈáç': 'horse_weight',\n",
                "    'Â¢óÊ∏õ': 'weight_change',\n",
                "    'Â§©ÂÄô': 'weather',\n",
                "    'È¶¨Â†¥Áä∂ÊÖã': 'condition',\n",
                "    'Ë∑ùÈõ¢': 'distance',\n",
                "    '„Ç≥„Éº„Çπ„Çø„Ç§„Éó': 'course_type',\n",
                "    'Âæå3F': 'last_3f',\n",
                "    'ÂçòÂãù„Ç™„ÉÉ„Ç∫': 'odds',\n",
                "    '„É¨„Éº„ÇπÂêç': 'race_name',\n",
                "    '‰ºöÂ†¥': 'venue',  # ËøΩÂä†: „Å©„ÅÆÁ´∂È¶¨Â†¥„ÅßËµ∞„Å£„Åü„Åã\n",
                "}\n",
                "\n",
                "print(f\"‚úÖ Mapping {len(COLUMN_MAPPING)} fields per past race\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main Processing Function\n",
                "\n",
                "def generate_cross_domain_history():\n",
                "    jra_path = os.path.join(SAVE_DIR, JRA_BASIC)\n",
                "    nar_path = os.path.join(SAVE_DIR, NAR_BASIC)\n",
                "    target_path = os.path.join(SAVE_DIR, TARGET_FILE)\n",
                "    output_path = os.path.join(SAVE_DIR, OUTPUT_FILE)\n",
                "    \n",
                "    # ========================================\n",
                "    # Step 1: Load and combine history source\n",
                "    # ========================================\n",
                "    print(\"üìÇ Loading data sources...\")\n",
                "    \n",
                "    df_history_parts = []\n",
                "    \n",
                "    # Load JRA\n",
                "    if os.path.exists(jra_path):\n",
                "        df_jra = pd.read_csv(jra_path, dtype=str)\n",
                "        df_jra['source'] = 'JRA'\n",
                "        df_history_parts.append(df_jra)\n",
                "        print(f\"   JRA: {len(df_jra)} rows\")\n",
                "    else:\n",
                "        print(f\"   ‚ö†Ô∏è JRA file not found: {jra_path}\")\n",
                "    \n",
                "    # Load NAR\n",
                "    if os.path.exists(nar_path):\n",
                "        df_nar = pd.read_csv(nar_path, dtype=str)\n",
                "        df_nar['source'] = 'NAR'\n",
                "        df_history_parts.append(df_nar)\n",
                "        print(f\"   NAR: {len(df_nar)} rows\")\n",
                "    else:\n",
                "        print(f\"   ‚ö†Ô∏è NAR file not found: {nar_path}\")\n",
                "    \n",
                "    if not df_history_parts:\n",
                "        print(\"‚ùå No data files found!\")\n",
                "        return None\n",
                "    \n",
                "    # Combine for history lookup\n",
                "    df_all_history = pd.concat(df_history_parts, ignore_index=True)\n",
                "    print(f\"   Combined history source: {len(df_all_history)} rows\")\n",
                "    \n",
                "    # ========================================\n",
                "    # Step 2: Load target data\n",
                "    # ========================================\n",
                "    print(f\"\\nüìã Loading target ({MODE})...\")\n",
                "    if not os.path.exists(target_path):\n",
                "        print(f\"‚ùå Target file not found: {target_path}\")\n",
                "        return None\n",
                "    \n",
                "    df_target = pd.read_csv(target_path, dtype=str)\n",
                "    print(f\"   Target rows: {len(df_target)}\")\n",
                "    \n",
                "    # ========================================\n",
                "    # Step 3: Prepare data\n",
                "    # ========================================\n",
                "    # Convert dates\n",
                "    df_all_history['date_obj'] = pd.to_datetime(df_all_history['Êó•‰ªò'], errors='coerce')\n",
                "    df_target['date_obj'] = pd.to_datetime(df_target['Êó•‰ªò'], errors='coerce')\n",
                "    \n",
                "    # Sort history by horse and date\n",
                "    df_all_history = df_all_history.sort_values(['horse_id', 'date_obj'])\n",
                "    \n",
                "    # Initialize past columns in target\n",
                "    past_fields = list(COLUMN_MAPPING.values())\n",
                "    for i in range(1, 6):\n",
                "        for field in past_fields:\n",
                "            df_target[f'past_{i}_{field}'] = ''\n",
                "    \n",
                "    # ========================================\n",
                "    # Step 4: Generate cross-domain history\n",
                "    # ========================================\n",
                "    print(f\"\\nüîÑ Generating cross-domain history for {MODE}...\")\n",
                "    \n",
                "    # Group combined history by horse_id\n",
                "    grouped = df_all_history.groupby('horse_id')\n",
                "    \n",
                "    cross_domain_count = 0\n",
                "    \n",
                "    for idx in tqdm(range(len(df_target)), desc=\"Processing\"):\n",
                "        row = df_target.iloc[idx]\n",
                "        horse_id = row['horse_id']\n",
                "        current_date = row['date_obj']\n",
                "        \n",
                "        if pd.isna(current_date) or pd.isna(horse_id):\n",
                "            continue\n",
                "        \n",
                "        # Get all races for this horse (from BOTH JRA and NAR)\n",
                "        try:\n",
                "            horse_races = grouped.get_group(horse_id)\n",
                "        except KeyError:\n",
                "            continue\n",
                "        \n",
                "        # Filter to races before current date\n",
                "        past_races = horse_races[horse_races['date_obj'] < current_date]\n",
                "        \n",
                "        if past_races.empty:\n",
                "            continue\n",
                "        \n",
                "        # Sort by date descending and take top 5\n",
                "        past_races = past_races.sort_values('date_obj', ascending=False).head(5)\n",
                "        \n",
                "        # Check if any past race is from the other domain\n",
                "        current_source = 'JRA' if MODE == 'JRA' else 'NAR'\n",
                "        if (past_races['source'] != current_source).any():\n",
                "            cross_domain_count += 1\n",
                "        \n",
                "        # Fill past columns\n",
                "        for i, (_, past_row) in enumerate(past_races.iterrows(), 1):\n",
                "            for basic_col, field_name in COLUMN_MAPPING.items():\n",
                "                if basic_col in past_row.index:\n",
                "                    val = past_row[basic_col]\n",
                "                    df_target.at[idx, f'past_{i}_{field_name}'] = str(val) if pd.notna(val) else ''\n",
                "    \n",
                "    # ========================================\n",
                "    # Step 5: Save result\n",
                "    # ========================================\n",
                "    # Drop temporary columns\n",
                "    df_target = df_target.drop(columns=['date_obj'])\n",
                "    \n",
                "    print(f\"\\nüíæ Saving to {OUTPUT_FILE}...\")\n",
                "    df_target.to_csv(output_path, index=False)\n",
                "    \n",
                "    # Stats\n",
                "    has_past1 = (df_target['past_1_date'] != '').sum()\n",
                "    print(f\"\\n‚úÖ Complete! ({MODE})\")\n",
                "    print(f\"   Total rows: {len(df_target)}\")\n",
                "    print(f\"   Rows with past_1 data: {has_past1} ({has_past1/len(df_target)*100:.1f}%)\")\n",
                "    print(f\"   üîÑ Cross-domain history: {cross_domain_count} rows have JRA‚ÜîNAR past races\")\n",
                "    \n",
                "    return df_target\n",
                "\n",
                "print(\"‚úÖ Function ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ÂÆüË°å\n",
                "df_result = generate_cross_domain_history()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ÁµêÊûúÁ¢∫Ë™çÔºà„ÇØ„É≠„Çπ„Éâ„É°„Ç§„É≥Â±•Ê≠¥„ÅÆ„Çµ„É≥„Éó„É´Ôºâ\n",
                "if df_result is not None:\n",
                "    # ÈÅéÂéªËµ∞„Å´Âà•„Éâ„É°„Ç§„É≥„ÅÆ‰ºöÂ†¥„ÅåÂê´„Åæ„Çå„Çã„Ç±„Éº„Çπ„ÇíÊé¢„Åô\n",
                "    jra_venues = {'Êú≠Âπå', 'ÂáΩÈ§®', 'Á¶èÂ≥∂', 'Êñ∞ÊΩü', 'Êù±‰∫¨', '‰∏≠Â±±', '‰∏≠‰∫¨', '‰∫¨ÈÉΩ', 'Èò™Á•û', 'Â∞èÂÄâ'}\n",
                "    \n",
                "    print(\"\\nüìä Cross-domain history examples:\")\n",
                "    count = 0\n",
                "    for _, row in df_result.iterrows():\n",
                "        past_venue = row.get('past_1_venue', '')\n",
                "        if past_venue:\n",
                "            is_jra_venue = past_venue in jra_venues\n",
                "            is_current_jra = MODE == 'JRA'\n",
                "            \n",
                "            # Cross-domain if venue doesn't match mode\n",
                "            if (is_current_jra and not is_jra_venue) or (not is_current_jra and is_jra_venue):\n",
                "                print(f\"\\n  Horse: {row.get('È¶¨Âêç', 'N/A')} ({row['horse_id']})\")\n",
                "                print(f\"    Current ({MODE}): {row['Êó•‰ªò']} @ {row.get('‰ºöÂ†¥', 'N/A')}\")\n",
                "                print(f\"    Past 1: {row['past_1_date']} @ {past_venue} (cross-domain!)\")\n",
                "                count += 1\n",
                "                if count >= 3:\n",
                "                    break\n",
                "    \n",
                "    if count == 0:\n",
                "        print(\"  (No cross-domain examples found in sample)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}