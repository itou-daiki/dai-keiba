{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# JRA Scraping Notebook\n",
    "\n",
    "ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã€Google Driveä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«è¿½åŠ ã—ã¾ã™ã€‚"
   ],
   "metadata": {
    "id": "intro_md"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Google Driveã®ãƒã‚¦ãƒ³ãƒˆ\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# â˜…â˜…â˜… è¨­å®šé …ç›® â˜…â˜…â˜…\n",
    "# scraperãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹ãƒ‘ã‚¹ (Google Driveä¸Šã®ãƒ‘ã‚¹)\n",
    "# ä¾‹: '/content/drive/MyDrive/dai-keiba'\n",
    "PROJECT_PATH = '/content/drive/MyDrive/dai-keiba'\n",
    "\n",
    "if not os.path.exists(PROJECT_PATH):\n",
    "    print(f\"Error: Path {PROJECT_PATH} does not exist. Please check your Drive structure.\")\n",
    "else:\n",
    "    print(f\"Project path found: {PROJECT_PATH}\")\n",
    "    os.chdir(PROJECT_PATH)\n",
    "    sys.path.append(PROJECT_PATH)\n"
   ],
   "metadata": {
    "id": "mount_drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import bs4\n",
    "except ImportError:\n",
    "    !pip install pandas requests beautifulsoup4\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import bs4\n",
    "\n",
    "from datetime import datetime, date\n",
    "from scraper.jra_scraper import scrape_jra_year, JRA_MONTH_PARAMS\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# ğŸš¨ 2023å¹´/2022å¹´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¶³ã®ä¿®æ­£ãƒ‘ãƒƒãƒ\n",
    "# ==========================================\n",
    "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ—ã‚’ä¸Šæ›¸ãæ›´æ–°\n",
    "try:\n",
    "    JRA_MONTH_PARAMS.update({\n",
    "        \"2023\": { \"01\": \"27\", \"02\": \"F5\", \"03\": \"C3\", \"04\": \"91\", \"05\": \"5F\", \"06\": \"2D\", \"07\": \"FB\", \"08\": \"C9\", \"09\": \"97\", \"10\": \"06\", \"11\": \"D4\", \"12\": \"A2\" },\n",
    "        \"2022\": { \"01\": \"9B\", \"02\": \"69\", \"03\": \"37\", \"04\": \"05\", \"05\": \"D3\", \"06\": \"A1\", \"07\": \"6F\", \"08\": \"3D\", \"09\": \"0B\", \"10\": \"7A\", \"11\": \"48\", \"12\": \"16\" }\n",
    "    })\n",
    "    print(\"âœ… JRA 2023/2022 Parameters have been patched successfully.\")\n",
    "except NameError:\n",
    "    print(\"âš ï¸ JRA_MONTH_PARAMS not found in scope. Ensure imports are correct.\")\n"
   ],
   "metadata": {
    "id": "imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œé–¢æ•°ã®å®šç¾©\n",
    "\n",
    "def jra_scrape_execution(year_str, start_date=None, end_date=None):\n",
    "    CSV_FILE_PATH = os.path.join(PROJECT_PATH, \"database.csv\")\n",
    "    print(f\"Using CSV Path: {CSV_FILE_PATH}\")\n",
    "\n",
    "    def save_chunk(df_chunk):\n",
    "        if os.path.exists(CSV_FILE_PATH):\n",
    "            try:\n",
    "                # Read types as string to prevent auto-float for IDs\n",
    "                existing_df = pd.read_csv(CSV_FILE_PATH, dtype={'race_id': str, 'horse_id': str})\n",
    "                combined_df = pd.concat([existing_df, df_chunk], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Read Error: {e}, creating new.\")\n",
    "                combined_df = df_chunk\n",
    "        else:\n",
    "            combined_df = df_chunk\n",
    "\n",
    "        # Deduplicate\n",
    "        subset_cols = ['race_id', 'é¦¬å']\n",
    "        subset_cols = [c for c in subset_cols if c in combined_df.columns]\n",
    "        if subset_cols:\n",
    "            combined_df.drop_duplicates(subset=subset_cols, keep='last', inplace=True)\n",
    "\n",
    "        combined_df.to_csv(CSV_FILE_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"  [Saved] Total rows: {len(combined_df)} (+{len(df_chunk)} new)\")\n",
    "\n",
    "    print(f\"Starting Scraping for {year_str} ({start_date} ~ {end_date})\")\n",
    "\n",
    "    # Load existing IDs to skip\n",
    "    existing_ids = set()\n",
    "    if os.path.exists(CSV_FILE_PATH):\n",
    "        try:\n",
    "             df_e = pd.read_csv(CSV_FILE_PATH, usecols=['race_id'], dtype={'race_id': str})\n",
    "             existing_ids = set(df_e['race_id'].astype(str))\n",
    "             print(f\"  Loaded {len(existing_ids)} existing race IDs to skip.\")\n",
    "        except:\n",
    "             pass\n",
    "\n",
    "    scrape_jra_year(year_str, start_date=start_date, end_date=end_date, save_callback=save_chunk, existing_race_ids=existing_ids)\n"
   ],
   "metadata": {
    "id": "def_exec"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã¨é–‹å§‹\n",
    "# -----------------------------\n",
    "TARGET_YEAR = \"2024\"\n",
    "TARGET_MONTH = 1  # â˜…ä½•æœˆã‚’å–å¾—ã™ã‚‹ã‹æŒ‡å®š (Noneã®å ´åˆã¯å…¨æœŸé–“ã€1ã€œ12ã‚’æŒ‡å®š)\n",
    "\n",
    "import calendar\n",
    "from datetime import date\n",
    "\n",
    "START_DATE = None\n",
    "END_DATE = None\n",
    "\n",
    "if TARGET_MONTH:\n",
    "    # æŒ‡å®šã—ãŸæœˆã®1æ—¥ã€œæœ«æ—¥ã‚’è¨­å®š\n",
    "    _, last_day = calendar.monthrange(int(TARGET_YEAR), int(TARGET_MONTH))\n",
    "    START_DATE = date(int(TARGET_YEAR), int(TARGET_MONTH), 1)\n",
    "    END_DATE = date(int(TARGET_YEAR), int(TARGET_MONTH), last_day)\n",
    "    print(f\"Targeting specific month: {START_DATE} to {END_DATE}\")\n",
    "else:\n",
    "    # è‡ªå‹•åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ (æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¿Œæ—¥ã‹ã‚‰)\n",
    "    CSV_FILE_PATH = os.path.join(PROJECT_PATH, \"database.csv\")\n",
    "    if os.path.exists(CSV_FILE_PATH):\n",
    "        try:\n",
    "             df_exist = pd.read_csv(CSV_FILE_PATH)\n",
    "             if 'æ—¥ä»˜' in df_exist.columns and not df_exist.empty:\n",
    "                 df_exist['date_obj'] = pd.to_datetime(df_exist['æ—¥ä»˜'], format='%Yå¹´%mæœˆ%dæ—¥', errors='coerce')\n",
    "                 last_date = df_exist['date_obj'].max()\n",
    "                 if pd.notna(last_date):\n",
    "                     # START_DATE = last_date.date() # æ—§: ç¶šãã‹ã‚‰\n",
    "                     # æ–°: æ¬ è½è£œå®Œã®ãŸã‚ã«ã€å¼·åˆ¶çš„ã«ãã®å¹´ã®1æœˆ1æ—¥ã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹ (existing_idsã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹)\n",
    "                     START_DATE = date(int(TARGET_YEAR), 1, 1)\n",
    "                     print(f\"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥æ™‚: {last_date.date()} (æ¬ è½ç¢ºèªã®ãŸã‚ {START_DATE} ã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³ã—ã¾ã™)\")\n",
    "        except Exception as e:\n",
    "            print(f\"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "print(f\"Scraping Target: {TARGET_YEAR}, Start: {START_DATE}, End: {END_DATE}\")\n",
    "jra_scrape_execution(TARGET_YEAR, start_date=START_DATE, end_date=END_DATE)\n"
   ],
   "metadata": {
    "id": "run_cell"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. ãƒ‡ãƒ¼ã‚¿åŠ å·¥ (Feature Engineering) ã®å®Ÿè¡Œ\n",
    "# ----------------------------------------\n",
    "# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸ database.csv ã‹ã‚‰å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™\n",
    "from ml.feature_engineering import calculate_features\n",
    "\n",
    "INPUT_CSV = os.path.join(PROJECT_PATH, \"database.csv\")\n",
    "OUTPUT_CSV = os.path.join(PROJECT_PATH, \"processed_data.csv\")\n",
    "\n",
    "if os.path.exists(INPUT_CSV):\n",
    "    print(\"Starting Feature Engineering...\")\n",
    "    calculate_features(INPUT_CSV, OUTPUT_CSV)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(\"Error: database.csv not found.\")\n"
   ],
   "metadata": {
    "id": "feature_eng"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}