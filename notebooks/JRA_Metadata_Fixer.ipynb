{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "intro_md"
            },
            "source": [
                "# JRA Metadata Fixer (Robust Version)\n",
                "\n",
                "JRAデータのメタデータ（天気、馬場、コース、回りなど）の欠損を補完するための専用ノートブックです。\n",
                "**特徴:**\n",
                "- 50件ごとの自動保存機能（Colabが落ちても安心）\n",
                "- 強力なスクレイピングロジック（回り情報の取得など）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mount_drive"
            },
            "outputs": [],
            "source": [
                "# 1. Google Driveのマウントと設定\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# プロジェクトパスの設定\n",
                "PROJECT_PATH = '/content/drive/MyDrive/dai-keiba'\n",
                "\n",
                "if not os.path.exists(PROJECT_PATH):\n",
                "    print(f\"Error: Path {PROJECT_PATH} does not exist.\")\n",
                "else:\n",
                "    print(f\"Project path found: {PROJECT_PATH}\")\n",
                "    os.chdir(PROJECT_PATH)\n",
                "    sys.path.append(PROJECT_PATH)\n",
                "    sys.path.append(os.path.join(PROJECT_PATH, 'scraper'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "# 2. ライブラリのインポート\n",
                "import pandas as pd\n",
                "import re\n",
                "import time\n",
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
                "\n",
                "# TQDM (プログレスバー)\n",
                "try:\n",
                "    from tqdm.auto import tqdm\n",
                "except ImportError:\n",
                "    !pip install tqdm\n",
                "    from tqdm.auto import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "logic_def"
            },
            "outputs": [],
            "source": [
                "# 3. ロジック定義\n",
                "\n",
                "def local_get_race_metadata(rid):\n",
                "    \"\"\"\n",
                "    Fetches Turn, Weather, Course, Condition from Netkeiba Race Page.\n",
                "    Designed to be robust and self-contained.\n",
                "    \"\"\"\n",
                "    url = f\"https://race.netkeiba.com/race/result.html?race_id={rid}\"\n",
                "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
                "    try:\n",
                "        resp = requests.get(url, headers=headers, timeout=10)\n",
                "        resp.encoding = 'EUC-JP' # Netkeiba Race usually EUC-JP\n",
                "        if resp.status_code != 200: return None\n",
                "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
                "        \n",
                "        data = {'race_id': rid}\n",
                "        \n",
                "        rd1 = soup.select_one(\".RaceData01\")\n",
                "        if rd1:\n",
                "            txt = rd1.text.strip()\n",
                "            \n",
                "            # Weather\n",
                "            if \"天候:晴\" in txt: data[\"weather\"] = \"晴\"\n",
                "            elif \"天候:曇\" in txt: data[\"weather\"] = \"曇\"\n",
                "            elif \"天候:小雨\" in txt: data[\"weather\"] = \"小雨\"\n",
                "            elif \"天候:雨\" in txt: data[\"weather\"] = \"雨\"\n",
                "            elif \"天候:雪\" in txt: data[\"weather\"] = \"雪\"\n",
                "            \n",
                "            # Condition\n",
                "            if \"馬場:良\" in txt: data[\"condition\"] = \"良\"\n",
                "            elif \"馬場:稍\" in txt: data[\"condition\"] = \"稍重\"\n",
                "            elif \"馬場:重\" in txt: data[\"condition\"] = \"重\"\n",
                "            elif \"馬場:不良\" in txt: data[\"condition\"] = \"不良\"\n",
                "            \n",
                "            # Course\n",
                "            match = re.search(r'(芝|ダ|障)(\\d+)m', txt)\n",
                "            if match:\n",
                "                ctype_raw = match.group(1)\n",
                "                if ctype_raw == \"芝\": data[\"course_type\"] = \"芝\"\n",
                "                elif ctype_raw == \"ダ\": data[\"course_type\"] = \"ダート\"\n",
                "                elif ctype_raw == \"障\": data[\"course_type\"] = \"障害\"\n",
                "                data[\"distance\"] = match.group(2)\n",
                "            \n",
                "            # Turn\n",
                "            if \"右\" in txt: data[\"turn\"] = \"右\"\n",
                "            elif \"左\" in txt: data[\"turn\"] = \"左\"\n",
                "            elif \"直線\" in txt: data[\"turn\"] = \"直\"\n",
                "            \n",
                "        return data\n",
                "    except Exception as e:\n",
                "        return None\n",
                "\n",
                "def fill_missing_past_data_robust():\n",
                "    csv_path = os.path.join(PROJECT_PATH, 'database.csv')\n",
                "    if not os.path.exists(csv_path):\n",
                "        print(f'Error: {csv_path} not found.')\n",
                "        return\n",
                "\n",
                "    print(f'Reading {csv_path}...')\n",
                "    df = pd.read_csv(csv_path, low_memory=False, dtype={'race_id': str})\n",
                "    \n",
                "    # Ensure columns exist\n",
                "    print('Checking Metadata (Course, Distance, Weather, Turn)...')\n",
                "    meta_cols = ['コースタイプ', '距離', '天候', '馬場状態', '回り']\n",
                "    for c in meta_cols:\n",
                "        if c not in df.columns: df[c] = None\n",
                "\n",
                "    # Identify missing rows\n",
                "    missing_meta_mask = (df['コースタイプ'].isna()) | (df['コースタイプ'] == '') | (df['回り'].isna())\n",
                "    if 'race_id' in df.columns:\n",
                "         rids_missing = df.loc[missing_meta_mask, 'race_id'].astype(str).unique()\n",
                "    else:\n",
                "         rids_missing = []\n",
                "\n",
                "    print(f'Found {len(rids_missing)} races with missing metadata.')\n",
                "\n",
                "    if len(rids_missing) > 0:\n",
                "        BATCH_SIZE = 50 \n",
                "        batch_buffer = {}\n",
                "        processed_count = 0\n",
                "        \n",
                "        print(\"Starting batch processing... (Saving every 50 races)\")\n",
                "        \n",
                "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
                "            futures = {executor.submit(local_get_race_metadata, rid): rid for rid in rids_missing}\n",
                "            \n",
                "            for future in tqdm(as_completed(futures), total=len(rids_missing), desc=\"Fetching Metadata\"):\n",
                "                try:\n",
                "                    data = future.result()\n",
                "                    if data and data.get('course_type'):\n",
                "                        batch_buffer[str(data['race_id'])] = data\n",
                "                except: pass\n",
                "                \n",
                "                processed_count += 1\n",
                "                \n",
                "                # BATCH SAVE\n",
                "                if len(batch_buffer) >= BATCH_SIZE:\n",
                "                    print(f'  Saving batch... ({processed_count}/{len(rids_missing)})')\n",
                "                    \n",
                "                    df['race_id_str'] = df['race_id'].astype(str)\n",
                "                    mask = df['race_id_str'].isin(batch_buffer.keys())\n",
                "                    \n",
                "                    # Create maps\n",
                "                    c_map = {rid: d.get('course_type') for rid, d in batch_buffer.items()}\n",
                "                    d_map = {rid: d.get('distance') for rid, d in batch_buffer.items()}\n",
                "                    w_map = {rid: d.get('weather') for rid, d in batch_buffer.items()}\n",
                "                    cond_map = {rid: d.get('condition') for rid, d in batch_buffer.items()}\n",
                "                    t_map = {rid: d.get('turn') for rid, d in batch_buffer.items()}\n",
                "\n",
                "                    # Update DataFrame\n",
                "                    df.loc[mask, 'コースタイプ'] = df.loc[mask, 'race_id_str'].map(c_map).fillna(df.loc[mask, 'コースタイプ'])\n",
                "                    df.loc[mask, '距離'] = df.loc[mask, 'race_id_str'].map(d_map).fillna(df.loc[mask, '距離'])\n",
                "                    df.loc[mask, '天候'] = df.loc[mask, 'race_id_str'].map(w_map).fillna(df.loc[mask, '天候'])\n",
                "                    df.loc[mask, '馬場状態'] = df.loc[mask, 'race_id_str'].map(cond_map).fillna(df.loc[mask, '馬場状態'])\n",
                "                    df.loc[mask, '回り'] = df.loc[mask, 'race_id_str'].map(t_map).fillna(df.loc[mask, '回り'])\n",
                "                    \n",
                "                    # Save to CSV\n",
                "                    temp_df = df.drop(columns=['race_id_str'], errors='ignore')\n",
                "                    temp_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
                "                    \n",
                "                    # Clear buffer\n",
                "                    batch_buffer = {}\n",
                "            \n",
                "            # FINAL SAVE\n",
                "            if batch_buffer:\n",
                "                print('  Saving final batch...')\n",
                "                df['race_id_str'] = df['race_id'].astype(str)\n",
                "                mask = df['race_id_str'].isin(batch_buffer.keys())\n",
                "                \n",
                "                c_map = {rid: d.get('course_type') for rid, d in batch_buffer.items()}\n",
                "                d_map = {rid: d.get('distance') for rid, d in batch_buffer.items()}\n",
                "                w_map = {rid: d.get('weather') for rid, d in batch_buffer.items()}\n",
                "                cond_map = {rid: d.get('condition') for rid, d in batch_buffer.items()}\n",
                "                t_map = {rid: d.get('turn') for rid, d in batch_buffer.items()}\n",
                "\n",
                "                df.loc[mask, 'コースタイプ'] = df.loc[mask, 'race_id_str'].map(c_map).fillna(df.loc[mask, 'コースタイプ'])\n",
                "                df.loc[mask, '距離'] = df.loc[mask, 'race_id_str'].map(d_map).fillna(df.loc[mask, '距離'])\n",
                "                df.loc[mask, '天候'] = df.loc[mask, 'race_id_str'].map(w_map).fillna(df.loc[mask, '天候'])\n",
                "                df.loc[mask, '馬場状態'] = df.loc[mask, 'race_id_str'].map(cond_map).fillna(df.loc[mask, '馬場状態'])\n",
                "                df.loc[mask, '回り'] = df.loc[mask, 'race_id_str'].map(t_map).fillna(df.loc[mask, '回り'])\n",
                "                \n",
                "                df.drop(columns=['race_id_str'], inplace=True, errors='ignore')\n",
                "                df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
                "\n",
                "        print('Done filling metadata.')\n",
                "    else:\n",
                "        print('All metadata present.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_fixer"
            },
            "outputs": [],
            "source": [
                "# 4. 実行\n",
                "fill_missing_past_data_robust()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}