{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ›¡ï¸ JRA (Safe Mode) Scraper Fix Notebook\n",
        "\n",
        "**é‡è¦:** ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒé€”ä¸­ã§åœæ­¢ã™ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œãªã„ï¼‰ç¾è±¡ã¯ã€ã‚¢ã‚¯ã‚»ã‚¹é »åº¦éå¤šã«ã‚ˆã‚‹**IPåˆ¶é™ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ï¼‰**ãŒåŸå› ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä»¥ä¸‹ã®å¯¾ç­–ã‚’è¡Œã£ãŸã€Œã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ã€ã§å®Ÿè¡Œã—ã¾ã™ã€‚\n",
        "\n",
        "1. **ä¸¦åˆ—å‡¦ç†ã®å»ƒæ­¢**: `ThreadPoolExecutor` ã‚’ä½¿ã‚ãšã€1ä»¶ãšã¤é †ç•ªã«å‡¦ç†ã—ã¾ã™ã€‚\n",
        "2. **å¾…æ©Ÿæ™‚é–“ã®å¢—åŠ **: å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã« `time.sleep(3)` ã‚’å…¥ã‚Œã¾ã™ã€‚\n",
        "3. **ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤º**: 429 Error (Too Many Requests) ãªã©ã®è©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
        "\n",
        "â€» å‡¦ç†é€Ÿåº¦ã¯é…ããªã‚Šã¾ã™ãŒã€ç¢ºå®Ÿã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®æªç½®ã§ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¨­å®š (ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„)\n",
        "PROJECT_PATH = '/content/drive/MyDrive/dai-keiba'\n",
        "sys.path.append(PROJECT_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. RaceScraper Class (Debug Enhanced)\n",
        "\n",
        "ã‚¨ãƒ©ãƒ¼åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã« `_get_soup` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import io\n",
        "\n",
        "class SafeRaceScraper:\n",
        "    def __init__(self):\n",
        "        self.headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "        }\n",
        "\n",
        "    def _get_soup(self, url):\n",
        "        try:\n",
        "            time.sleep(3) # Heavy delay for safety\n",
        "            response = requests.get(url, headers=self.headers, timeout=10)\n",
        "            \n",
        "            if response.status_code != 200:\n",
        "                print(f\"âš ï¸ HTTP Error {response.status_code} for {url}\")\n",
        "                return None\n",
        "                \n",
        "            response.encoding = response.apparent_encoding\n",
        "            return BeautifulSoup(response.text, 'html.parser')\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # ... Include minimal methods needed ...\n",
        "    # Simplified get_past_races logic\n",
        "    def get_past_races(self, horse_id, n_samples=5):\n",
        "        url = f\"https://db.netkeiba.com/horse/result/{horse_id}/\"\n",
        "        soup = self._get_soup(url)\n",
        "        if not soup:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        table = soup.select_one(\"table.db_h_race_results\")\n",
        "        if not table:\n",
        "            # Fallback\n",
        "            tables = soup.find_all(\"table\")\n",
        "            for t in tables:\n",
        "                if \"ç€é †\" in t.text:\n",
        "                    table = t\n",
        "                    break\n",
        "        \n",
        "        if not table:\n",
        "             return pd.DataFrame()\n",
        "\n",
        "        try:\n",
        "            df = pd.read_html(io.StringIO(str(table)))[0]\n",
        "            df = df.dropna(how='all')\n",
        "            \n",
        "            # Clean Columns\n",
        "            df.columns = df.columns.astype(str).str.replace(r'\\s+', '', regex=True)\n",
        "\n",
        "            if 'æ—¥ä»˜' in df.columns:\n",
        "                df['date_obj'] = pd.to_datetime(df['æ—¥ä»˜'], format='%Y/%m/%d', errors='coerce')\n",
        "                df = df.dropna(subset=['date_obj'])\n",
        "                df = df.sort_values('date_obj', ascending=False)\n",
        "                \n",
        "            if n_samples:\n",
        "                df = df.head(n_samples)\n",
        "            \n",
        "            # Simplified Run Style\n",
        "            if 'é€šé' in df.columns:\n",
        "                 # Simple heuristic\n",
        "                 df['run_style_val'] = 3 \n",
        "\n",
        "            # Map\n",
        "            column_map = {\n",
        "                'æ—¥ä»˜': 'date', 'é–‹å‚¬': 'venue', 'å¤©æ°—': 'weather', 'ãƒ¬ãƒ¼ã‚¹å': 'race_name',\n",
        "                'ç€é †': 'rank', 'æ ç•ª': 'waku', 'é¦¬ç•ª': 'umaban', 'é¨æ‰‹': 'jockey',\n",
        "                'æ–¤é‡': 'weight_carried', 'é¦¬å ´': 'condition', 'ã‚¿ã‚¤ãƒ ': 'time',\n",
        "                'ç€å·®': 'margin', 'ä¸Šã‚Š': 'last_3f', 'é€šé': 'passing',\n",
        "                'é¦¬ä½“é‡': 'horse_weight', 'run_style_val': 'run_style',\n",
        "                'å˜å‹': 'odds', 'ã‚ªãƒƒã‚º': 'odds', 'è·é›¢': 'raw_distance'\n",
        "            }\n",
        "            df.rename(columns=column_map, inplace=True)\n",
        "            \n",
        "            # Parse Distance\n",
        "            if 'raw_distance' in df.columns:\n",
        "                def parse_dist(x):\n",
        "                    if not isinstance(x, str): return None, None\n",
        "                    surf = 'èŠ' if 'èŠ' in x else 'ãƒ€' if 'ãƒ€' in x else 'éšœ' if 'éšœ' in x else None\n",
        "                    match = re.search(r'(\\d+)', x)\n",
        "                    dist = int(match.group(1)) if match else None\n",
        "                    return surf, dist\n",
        "                \n",
        "                parsed = df['raw_distance'].apply(parse_dist)\n",
        "                df['course_type'] = parsed.apply(lambda x: x[0])\n",
        "                df['distance'] = parsed.apply(lambda x: x[1])\n",
        "            else:\n",
        "                df['course_type'] = None\n",
        "                df['distance'] = None\n",
        "\n",
        "            # Coerce\n",
        "            if 'rank' in df.columns: df['rank'] = pd.to_numeric(df['rank'], errors='coerce')\n",
        "            if 'odds' in df.columns: df['odds'] = pd.to_numeric(df['odds'], errors='coerce')\n",
        "            \n",
        "            # Fill missing\n",
        "            for col in list(column_map.values()) + ['course_type', 'distance']:\n",
        "                if col not in df.columns: df[col] = None\n",
        "                \n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error parse: {e}\")\n",
        "            return pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_horse_history_safe(horse_id):\n",
        "    scraper = SafeRaceScraper()\n",
        "    df = scraper.get_past_races(horse_id, n_samples=5)\n",
        "    return horse_id, df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. JRA Data Fix Script (Safe Mode)\n",
        "\n",
        "ç›´åˆ—å‡¦ç†ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JRAã‚³ãƒ¼ãƒ‰ (Safe Single-Threaded)\n",
        "try:\n",
        "    from tqdm.auto import tqdm\n",
        "except ImportError:\n",
        "    !pip install tqdm\n",
        "    from tqdm.auto import tqdm\n",
        "\n",
        "def fill_missing_past_data_jra_safe():\n",
        "    csv_path = os.path.join(PROJECT_PATH, 'data', 'raw', 'database.csv')\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f'Error: {csv_path} not found.')\n",
        "        return\n",
        "\n",
        "    print(f'Reading {csv_path}...')\n",
        "    df = pd.read_csv(csv_path, low_memory=False, dtype={'race_id': str, 'horse_id': str})\n",
        "    \n",
        "    if 'horse_id' in df.columns:\n",
        "        df['horse_id'] = df['horse_id'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
        "\n",
        "    if 'æ—¥ä»˜' in df.columns:\n",
        "        df['date_dt'] = pd.to_datetime(df['æ—¥ä»˜'], format='%Yå¹´%mæœˆ%dæ—¥', errors='coerce')\n",
        "    else:\n",
        "        print('Error: æ—¥ä»˜ column not found.')\n",
        "        return\n",
        "\n",
        "    def save_df_safe(dataframe, msg=\"\"):\n",
        "        try:\n",
        "             out_df = dataframe.drop(columns=['date_dt', 'date_obj'], errors='ignore')\n",
        "             out_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "             print(f\"  [Saved] {msg}\")\n",
        "        except Exception as e:\n",
        "             print(f\"  [Save Failed] {e}\")\n",
        "\n",
        "    # === Fill Past History ===\n",
        "    unique_horses = df['horse_id'].dropna().unique()\n",
        "    \n",
        "    # Resume Logic\n",
        "    if 'past_1_date' in df.columns:\n",
        "        done_horses = df.loc[df['past_1_date'].notna(), 'horse_id'].unique()\n",
        "        unique_horses = [h for h in unique_horses if h not in done_horses]\n",
        "        \n",
        "    print(f'Processing {len(unique_horses)} horses (Safe Mode: Single Threaded)...')\n",
        "\n",
        "    # Smaller batch for save frequency\n",
        "    horse_batch_size = 20 \n",
        "    fields_map = {\n",
        "        'date': 'date', 'rank': 'rank', 'time': 'time', 'race_name': 'race_name', \n",
        "        'last_3f': 'last_3f', 'horse_weight': 'horse_weight', 'jockey': 'jockey', \n",
        "        'condition': 'condition', 'odds': 'odds', 'weather': 'weather', \n",
        "        'distance': 'distance', 'course_type': 'course_type'\n",
        "    }\n",
        "    \n",
        "    for k in fields_map.keys():\n",
        "        for i in range(1, 6):\n",
        "            col = f'past_{i}_{k}'\n",
        "            if col not in df.columns: df[col] = None\n",
        "\n",
        "    history_store = {}\n",
        "    \n",
        "    # Loop one by one\n",
        "    for i, hid in enumerate(tqdm(unique_horses)):\n",
        "        \n",
        "        # Fetch\n",
        "        _, hist_df = fetch_horse_history_safe(str(hid))\n",
        "        \n",
        "        if not hist_df.empty:\n",
        "            if 'date' in hist_df.columns:\n",
        "                hist_df['date_obj'] = pd.to_datetime(hist_df['date'], errors='coerce')\n",
        "                history_store[str(hid)] = hist_df\n",
        "        \n",
        "        # Batch Save Logic\n",
        "        if (i + 1) % horse_batch_size == 0 or (i + 1) == len(unique_horses):\n",
        "            \n",
        "            modified_batch = False\n",
        "            updates_count = 0\n",
        "            \n",
        "            if history_store:\n",
        "                mask_batch = df['horse_id'].isin(history_store.keys()) # Only current batch keys\n",
        "                target_indices = df[mask_batch].index\n",
        "                \n",
        "                for idx in target_indices:\n",
        "                    h_id = str(df.at[idx, 'horse_id'])\n",
        "                    current_date = df.at[idx, 'date_dt']\n",
        "                    \n",
        "                    if h_id in history_store:\n",
        "                        hist_df = history_store[h_id]\n",
        "                        if 'date_obj' not in hist_df.columns: continue\n",
        "                        \n",
        "                        past_races = hist_df[hist_df['date_obj'] < current_date].sort_values('date_obj', ascending=False).head(5)\n",
        "                        \n",
        "                        if not past_races.empty:\n",
        "                            for j, (p_idx, p_row) in enumerate(past_races.iterrows()):\n",
        "                                n = j + 1\n",
        "                                for k, v in fields_map.items():\n",
        "                                    df.at[idx, f'past_{n}_{k}'] = p_row.get(v)\n",
        "                                    modified_batch = True\n",
        "                            updates_count += 1\n",
        "            \n",
        "            if modified_batch:\n",
        "                batch_num = (i // horse_batch_size) + 1\n",
        "                save_df_safe(df, f\"Batch {batch_num} (Updates: {updates_count})\")\n",
        "                import gc\n",
        "                gc.collect()\n",
        "            \n",
        "            # Clear store\n",
        "            history_store = {}\n",
        "\n",
        "    if 'date_dt' in df.columns: df.drop(columns=['date_dt'], inplace=True, errors='ignore')\n",
        "    print('Done filling past data for JRA.')\n",
        "\n",
        "fill_missing_past_data_jra_safe()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}