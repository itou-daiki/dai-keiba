#!/usr/bin/env python3
"""
JRA Basic v2ã®scrape_race_basicé–¢æ•°ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
"""

import json
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰é–¢æ•°ã‚’æŠ½å‡º
notebook_path = "/Users/itoudaiki/Program/dai-keiba/notebooks/Colab_JRA_Basic_v2.ipynb"

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–¢æ•°ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å–å¾—
for cell in nb['cells']:
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        if 'def extract_metadata(' in source:
            exec(source)
            print("âœ… Metadata extraction function loaded")
        if 'def scrape_race_basic(' in source:
            exec(source)
            print("âœ… Scraping function loaded")

# ãƒ†ã‚¹ãƒˆ
race_id = "202001010201"
print(f"\nğŸ§ª Testing race_id: {race_id}\n")

try:
    df = scrape_race_basic(race_id)
    
    if df is not None:
        print(f"âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸ")
        print(f"   å–å¾—è¡Œæ•°: {len(df)}")
        print(f"   ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}")
        print(f"\nğŸ“Š æœ€åˆã®é¦¬:")
        print(df[['é¦¬å', 'ç€é †', 'corner_1', 'corner_2', 'corner_3', 'corner_4']].head(1))
    else:
        print(f"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—: NoneãŒè¿”ã•ã‚ŒãŸ")
        
except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()
