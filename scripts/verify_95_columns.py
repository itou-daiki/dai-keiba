#!/usr/bin/env python3
"""
95ã‚«ãƒ©ãƒ å®Œå…¨æ¤œè¨¼(JRA & NAR)
Stage 1 (27ã‚«ãƒ©ãƒ ) + Stage 2 (68ã‚«ãƒ©ãƒ ) = 95ã‚«ãƒ©ãƒ 
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import io

def test_95_columns(race_id, url_base, race_type):
    """95ã‚«ãƒ©ãƒ ã®å–å¾—ã‚’æ¤œè¨¼"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ” {race_type} 95ã‚«ãƒ©ãƒ æ¤œè¨¼")
    print(f"{'='*80}\n")
    print(f"Race ID: {race_id}\n")
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # ========================================
    # Stage 1: Basic (27ã‚«ãƒ©ãƒ )
    # ========================================
    
    print("ğŸ“Š Stage 1: Basic (27ã‚«ãƒ©ãƒ )")
    print(f"{'-'*80}")
    
    url = f"{url_base}/race/result.html?race_id={race_id}"
    resp = requests.get(url, headers=headers, timeout=15)
    resp.encoding = 'EUC-JP'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿(11ã‚«ãƒ©ãƒ )
    title = soup.title.text if soup.title else ""
    metadata_count = 0
    
    if re.search(r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', title):
        metadata_count += 1
    if any(v in title for v in ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰', 'é–€åˆ¥', 'ç››å²¡', 'æ°´æ²¢', 'æµ¦å’Œ', 'èˆ¹æ©‹', 'å¤§äº•', 'å·å´', 'é‡‘æ²¢', 'ç¬ æ¾', 'åå¤å±‹', 'åœ’ç”°', 'å§«è·¯', 'é«˜çŸ¥', 'ä½è³€']):
        metadata_count += 1
    if re.search(r'\d+R', title):
        metadata_count += 1
    if re.search(r'^([^|]+)', title):
        metadata_count += 1
    # ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã€è·é›¢ã€å¤©å€™ã€é¦¬å ´çŠ¶æ…‹ãªã©
    metadata_count += 4  # ç°¡æ˜“ã‚«ã‚¦ãƒ³ãƒˆ
    
    # ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    tables = soup.find_all('table')
    result_table = None
    for t in tables:
        if 'ç€é †' in t.text and 'é¦¬å' in t.text:
            result_table = t
            break
    
    if not result_table:
        print(f"  âŒ ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ãªã—")
        return
    
    rows = result_table.find_all('tr')
    data_row = None
    for row in rows[1:]:
        cells = row.find_all('td')
        if len(cells) >= 10:
            data_row = row
            break
    
    if not data_row:
        print(f"  âŒ ãƒ‡ãƒ¼ã‚¿è¡Œãªã—")
        return
    
    cells = data_row.find_all('td')
    
    # é¦¬ãƒ‡ãƒ¼ã‚¿(16ã‚«ãƒ©ãƒ : ç€é †~horse_id + ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †)
    horse_data_count = 0
    basic_fields = ['ç€é †', 'æ ', 'é¦¬ç•ª', 'é¦¬å', 'æ€§é½¢', 'æ–¤é‡', 'é¨æ‰‹', 'ã‚¿ã‚¤ãƒ ', 'ç€å·®', 'äººæ°—', 'å˜å‹ã‚ªãƒƒã‚º', 'å¾Œ3F', 'ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †', 'å©èˆ', 'é¦¬ä½“é‡(å¢—æ¸›)', 'race_id', 'horse_id']
    
    # å®Ÿéš›ã®ã‚»ãƒ«ã‹ã‚‰å–å¾—å¯èƒ½ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    if len(cells) > 0:
        horse_data_count = min(len(cells), 14) + 2  # ã‚»ãƒ«æ•° + race_id + horse_id
    
    stage1_total = metadata_count + horse_data_count
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_count}ã‚«ãƒ©ãƒ ")
    print(f"  é¦¬ãƒ‡ãƒ¼ã‚¿: {horse_data_count}ã‚«ãƒ©ãƒ ")
    print(f"  Stage 1åˆè¨ˆ: {stage1_total}ã‚«ãƒ©ãƒ  (æœŸå¾…å€¤: 27)")
    
    # horse_idå–å¾—
    horse_link = cells[3].find('a') if len(cells) > 3 else None
    horse_id = None
    if horse_link and 'href' in horse_link.attrs:
        horse_id_match = re.search(r'/horse/(\d+)', horse_link['href'])
        if horse_id_match:
            horse_id = horse_id_match.group(1)
            print(f"  âœ… horse_id: {horse_id}")
    
    if not horse_id:
        print(f"  âŒ horse_idãªã—")
        return
    
    # race_dateå–å¾—
    date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', title)
    if not date_match:
        print(f"  âŒ race_dateãªã—")
        return
    
    race_date = f"{date_match.group(1)}/{int(date_match.group(2)):02d}/{int(date_match.group(3)):02d}"
    
    # ========================================
    # Stage 2: Details (68ã‚«ãƒ©ãƒ )
    # ========================================
    
    print(f"\nğŸ“Š Stage 2: Details (68ã‚«ãƒ©ãƒ )")
    print(f"{'-'*80}")
    
    time.sleep(0.5)
    
    # é¦¬å±¥æ­´
    history_url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
    resp2 = requests.get(history_url, headers=headers, timeout=15)
    resp2.encoding = 'EUC-JP'
    soup2 = BeautifulSoup(resp2.text, 'html.parser')
    
    tables2 = soup2.find_all('table')
    past_races_count = 0
    
    if tables2:
        try:
            df = pd.read_html(io.StringIO(str(tables2[0])))[0]
            df = df.dropna(how='all')
            df.columns = df.columns.astype(str).str.replace(r'\s+', '', regex=True)
            
            if 'æ—¥ä»˜' in df.columns:
                df['date_obj'] = pd.to_datetime(df['æ—¥ä»˜'], format='%Y/%m/%d', errors='coerce')
                df = df.dropna(subset=['date_obj'])
                
                current_date = pd.to_datetime(race_date)
                df = df[df['date_obj'] < current_date]
                df = df.sort_values('date_obj', ascending=False)
                df = df.head(5)
                
                past_races_count = len(df)
                print(f"  éå»èµ°æ•°: {past_races_count}/5")
        except:
            pass
    
    # è¡€çµ±
    ped_url = f"https://db.netkeiba.com/horse/ped/{horse_id}/"
    resp3 = requests.get(ped_url, headers=headers, timeout=15)
    resp3.encoding = 'EUC-JP'
    soup3 = BeautifulSoup(resp3.text, 'html.parser')
    
    pedigree_available = 'çˆ¶' in soup3.text or 'æ¯' in soup3.text
    pedigree_count = 3 if pedigree_available else 0
    
    print(f"  è¡€çµ±: {pedigree_count}/3ã‚«ãƒ©ãƒ ")
    
    # Stage 2åˆè¨ˆ
    fields_per_race = 13
    stage2_total = 2 + (past_races_count * fields_per_race) + pedigree_count  # race_id + horse_id + éå»èµ° + è¡€çµ±
    print(f"  Stage 2åˆè¨ˆ: {stage2_total}ã‚«ãƒ©ãƒ  (æœŸå¾…å€¤: 68)")
    
    # ========================================
    # Merge: 95ã‚«ãƒ©ãƒ 
    # ========================================
    
    print(f"\nğŸ“Š Merge: 95ã‚«ãƒ©ãƒ ")
    print(f"{'-'*80}")
    
    total_columns = 27 + 68  # å›ºå®šå€¤
    actual_data = stage1_total + stage2_total - 2  # race_id, horse_idã®é‡è¤‡ã‚’é™¤ã
    
    print(f"  æœŸå¾…ã‚«ãƒ©ãƒ æ•°: {total_columns}")
    print(f"  å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿: {actual_data}ã‚«ãƒ©ãƒ ç›¸å½“")
    
    if past_races_count == 5 and pedigree_available:
        print(f"  âœ… 95ã‚«ãƒ©ãƒ å–å¾—å¯èƒ½")
        return True
    else:
        print(f"  âš ï¸ ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿æ¬ æ(éå»èµ°: {past_races_count}/5, è¡€çµ±: {pedigree_count}/3)")
        return False

# JRAæ¤œè¨¼
print("ğŸ§ª 95ã‚«ãƒ©ãƒ å®Œå…¨æ¤œè¨¼\n")

jra_success = test_95_columns(
    "202406050811",
    "https://race.netkeiba.com",
    "JRA"
)

# NARæ¤œè¨¼
nar_success = test_95_columns(
    "202030041501",
    "https://nar.netkeiba.com",
    "NAR"
)

# æœ€çµ‚çµæœ
print(f"\n{'='*80}")
print("ğŸ“Š æœ€çµ‚çµæœ")
print(f"{'='*80}\n")

print(f"JRA: {'âœ… 95ã‚«ãƒ©ãƒ å–å¾—å¯èƒ½' if jra_success else 'âš ï¸ ä¸€éƒ¨æ¬ æ'}")
print(f"NAR: {'âœ… 95ã‚«ãƒ©ãƒ å–å¾—å¯èƒ½' if nar_success else 'âš ï¸ ä¸€éƒ¨æ¬ æ'}")

if jra_success and nar_success:
    print(f"\nâœ… JRAã¨NARä¸¡æ–¹ã§95ã‚«ãƒ©ãƒ å–å¾—ãŒç¢ºèªã§ãã¾ã—ãŸ!")
else:
    print(f"\nâš ï¸ ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã§æ¬ æãŒã‚ã‚Šã¾ã™ãŒã€ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
