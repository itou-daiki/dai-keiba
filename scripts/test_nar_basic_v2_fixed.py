#!/usr/bin/env python3
"""
ä¿®æ­£ã•ã‚ŒãŸNAR Basic v2ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰é–¢æ•°ã‚’æŠ½å‡º
import json

notebook_path = "/Users/itoudaiki/Program/dai-keiba/notebooks/Colab_NAR_Basic_v2.ipynb"

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–¢æ•°ã‚’å–å¾—
for cell in nb['cells']:
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        if 'def extract_metadata(' in source:
            exec(source)
            break

# ãƒ†ã‚¹ãƒˆç”¨NAR race_id
test_race_ids = [
    ("202030041501", "2020å¹´ é–€åˆ¥1R"),
    ("202130041501", "2021å¹´ é–€åˆ¥1R"),
]

print("ğŸ§ª NAR Basic v2 ä¿®æ­£ç‰ˆãƒ†ã‚¹ãƒˆ\n")
print(f"{'='*80}\n")

for race_id, description in test_race_ids:
    url = f"https://nar.netkeiba.com/race/result.html?race_id={race_id}"
    
    print(f"ğŸ‡ {description} (ID: {race_id})")
    print(f"{'-'*80}")
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=15)
        resp.encoding = 'EUC-JP'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        metadata = extract_metadata(soup, url)
        
        print(f"ğŸ“Š æŠ½å‡ºçµæœ:")
        for key, value in metadata.items():
            status = "âœ…" if value else "âŒ"
            print(f"  {status} {key}: {value}")
        
        filled = sum(1 for v in metadata.values() if v)
        rate = filled / 11 * 100
        print(f"\næˆåŠŸç‡: {rate:.0f}% ({filled}/11)")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print()
