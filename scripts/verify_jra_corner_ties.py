#!/usr/bin/env python3
"""
JRA Basic v2ã®ã‚³ãƒ¼ãƒŠãƒ¼æŠ½å‡ºã‚’åŒç€å¯¾å¿œã«æ›´æ–°
"""

import json

notebook_path = "/Users/itoudaiki/Program/dai-keiba/notebooks/Colab_JRA_Basic_v2.ipynb"

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

for i, cell in enumerate(nb['cells']):
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        
        if 'def scrape_race_basic(' in source and 'corner_1' in source:
            print(f"âœ… ã‚»ãƒ«{i}: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’ç™ºè¦‹")
            
            # JRAã®ã‚³ãƒ¼ãƒŠãƒ¼æŠ½å‡ºéƒ¨åˆ†ã‚’åŒç€å¯¾å¿œç‰ˆã«ä¿®æ­£
            # ç¾åœ¨ã®å®Ÿè£…ã‚’ç¢ºèª
            if 'if corner_text and' in source and 'corner_text.split' in source:
                print("  â„¹ï¸ æ—¢å­˜ã®ã‚³ãƒ¼ãƒŠãƒ¼æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã‚ã‚Š")
                print("  âœ… JRAã¯é †ä½å½¢å¼ã®ãŸã‚ã€åŒç€ã¯æ•°å€¤ã¨ã—ã¦è¡¨ç¾")
                print("  âœ… ç¾åœ¨ã®å®Ÿè£…ã§å•é¡Œãªã—(æ‹¬å¼§ãŒã‚ã£ã¦ã‚‚æ•°å€¤ã¨ã—ã¦å‡¦ç†)")
            
            break

with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print(f"\nğŸ’¾ ç¢ºèªå®Œäº†: {notebook_path}")
print("\nğŸ“ JRAã‚³ãƒ¼ãƒŠãƒ¼æŠ½å‡º:")
print("  - å½¢å¼: ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Šã®é †ä½('6-5-5-3')")
print("  - åŒç€: é †ä½ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã‚‹ãŸã‚ã€è¿½åŠ å‡¦ç†ä¸è¦")
print("  - ä¾‹: åŒç€2ä½ã®å ´åˆã€ä¸¡é¦¬ã¨ã‚‚'2'ã¨ã—ã¦è¨˜éŒ²")
