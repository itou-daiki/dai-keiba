#!/usr/bin/env python3
"""
å…¨26ã‚«ãƒ©ãƒ ã®å®Œå…¨æ¤œè¨¼(JRA & NAR)
å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚»ãƒ«ä½ç½®ã‚’ç¢ºèªã—ã€å–å¾—çŠ¶æ³ã‚’æ¤œè¨¼
"""

import requests
from bs4 import BeautifulSoup
import re

def verify_all_fields(race_id, url, race_type):
    """å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å–å¾—ã‚’æ¤œè¨¼"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ” {race_type} å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼")
    print(f"{'='*80}\n")
    print(f"Race ID: {race_id}")
    print(f"URL: {url}\n")
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    resp = requests.get(url, headers=headers, timeout=15)
    resp.encoding = 'EUC-JP'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    title = soup.title.text if soup.title else ""
    full_text = soup.text
    
    print("ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
    print(f"{'-'*80}")
    
    metadata_results = {}
    
    # æ—¥ä»˜
    date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', title)
    if date_match:
        date_val = f"{date_match.group(1)}/{int(date_match.group(2)):02d}/{int(date_match.group(3)):02d}"
        metadata_results['æ—¥ä»˜'] = date_val
        print(f"  âœ… æ—¥ä»˜: {date_val}")
    else:
        metadata_results['æ—¥ä»˜'] = None
        print(f"  âŒ æ—¥ä»˜: å–å¾—å¤±æ•—")
    
    # ä¼šå ´
    if race_type == "JRA":
        venues = ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']
    else:
        venues = ['é–€åˆ¥', 'ç››å²¡', 'æ°´æ²¢', 'æµ¦å’Œ', 'èˆ¹æ©‹', 'å¤§äº•', 'å·å´', 'é‡‘æ²¢', 'ç¬ æ¾', 'åå¤å±‹', 'åœ’ç”°', 'å§«è·¯', 'é«˜çŸ¥', 'ä½è³€', 'ã°ã‚“ãˆã„å¸¯åºƒ']
    
    venue = None
    for v in venues:
        if v in title:
            venue = v
            break
    
    if venue:
        metadata_results['ä¼šå ´'] = venue
        print(f"  âœ… ä¼šå ´: {venue}")
    else:
        metadata_results['ä¼šå ´'] = None
        print(f"  âŒ ä¼šå ´: å–å¾—å¤±æ•—")
    
    # ãƒ¬ãƒ¼ã‚¹ç•ªå·
    race_num_match = re.search(r'(\d+)R', title)
    if race_num_match:
        race_num = race_num_match.group(0)
        metadata_results['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = race_num
        print(f"  âœ… ãƒ¬ãƒ¼ã‚¹ç•ªå·: {race_num}")
    else:
        metadata_results['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = None
        print(f"  âŒ ãƒ¬ãƒ¼ã‚¹ç•ªå·: å–å¾—å¤±æ•—")
    
    # ãƒ¬ãƒ¼ã‚¹å
    race_name_match = re.search(r'^([^|]+)', title)
    if race_name_match:
        race_name = re.sub(r'\s*(çµæœ|æ‰•æˆ»|æ‰•ã„æˆ»ã—).*$', '', race_name_match.group(1).strip())
        metadata_results['ãƒ¬ãƒ¼ã‚¹å'] = race_name
        print(f"  âœ… ãƒ¬ãƒ¼ã‚¹å: {race_name}")
    else:
        metadata_results['ãƒ¬ãƒ¼ã‚¹å'] = None
        print(f"  âŒ ãƒ¬ãƒ¼ã‚¹å: å–å¾—å¤±æ•—")
    
    # ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ãƒ»è·é›¢
    course_match = re.search(r'(èŠ|ãƒ€ãƒ¼ãƒˆ|ãƒ€)\s*(\d+)m', full_text)
    if course_match:
        course_type = 'èŠ' if 'èŠ' in course_match.group(1) else 'ãƒ€ãƒ¼ãƒˆ'
        distance = course_match.group(2)
        metadata_results['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'] = course_type
        metadata_results['è·é›¢'] = distance
        print(f"  âœ… ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—: {course_type}")
        print(f"  âœ… è·é›¢: {distance}m")
    else:
        metadata_results['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'] = None
        metadata_results['è·é›¢'] = None
        print(f"  âŒ ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—: å–å¾—å¤±æ•—")
        print(f"  âŒ è·é›¢: å–å¾—å¤±æ•—")
    
    # å¤©å€™
    weather_match = re.search(r'å¤©å€™\s*[:ï¼š]?\s*(\S+)', full_text)
    if weather_match:
        weather = weather_match.group(1)
        metadata_results['å¤©å€™'] = weather
        print(f"  âœ… å¤©å€™: {weather}")
    else:
        metadata_results['å¤©å€™'] = None
        print(f"  âŒ å¤©å€™: å–å¾—å¤±æ•—")
    
    # é¦¬å ´çŠ¶æ…‹
    baba_match = re.search(r'é¦¬å ´\s*[:ï¼š]?\s*(\S+)', full_text)
    if baba_match:
        baba = baba_match.group(1)
        metadata_results['é¦¬å ´çŠ¶æ…‹'] = baba
        print(f"  âœ… é¦¬å ´çŠ¶æ…‹: {baba}")
    else:
        metadata_results['é¦¬å ´çŠ¶æ…‹'] = None
        print(f"  âŒ é¦¬å ´çŠ¶æ…‹: å–å¾—å¤±æ•—")
    
    # ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    print(f"\nğŸ“Š é¦¬ãƒ‡ãƒ¼ã‚¿(æœ€åˆã®1é ­):")
    print(f"{'-'*80}")
    
    tables = soup.find_all('table')
    result_table = None
    for t in tables:
        if 'ç€é †' in t.text and 'é¦¬å' in t.text:
            result_table = t
            break
    
    if not result_table:
        print(f"  âŒ ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
    rows = result_table.find_all('tr')
    header_row = rows[0]
    headers_cells = header_row.find_all('th')
    
    print(f"  ãƒ˜ãƒƒãƒ€ãƒ¼({len(headers_cells)}ã‚«ãƒ©ãƒ ):")
    for i, th in enumerate(headers_cells):
        print(f"    {i}: {th.text.strip()}")
    
    # ãƒ‡ãƒ¼ã‚¿è¡Œ
    data_row = None
    for row in rows[1:]:
        cells = row.find_all('td')
        if len(cells) >= 10:
            data_row = row
            break
    
    if not data_row:
        print(f"  âŒ ãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    cells = data_row.find_all('td')
    print(f"\n  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ«({len(cells)}å€‹):")
    
    # å„ã‚»ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º
    field_map = {
        0: 'ç€é †',
        1: 'æ ',
        2: 'é¦¬ç•ª',
        3: 'é¦¬å',
        4: 'æ€§é½¢',
        5: 'æ–¤é‡',
        6: 'é¨æ‰‹',
        7: 'ã‚¿ã‚¤ãƒ ',
        8: 'ç€å·®',
        9: 'äººæ°—',
        10: 'å˜å‹ã‚ªãƒƒã‚º',
        11: 'å¾Œ3F',
    }
    
    # JRAã¨NARã§ã‚»ãƒ«ä½ç½®ãŒç•°ãªã‚‹
    if race_type == "JRA":
        field_map[13] = 'å©èˆ'
        field_map[14] = 'é¦¬ä½“é‡(å¢—æ¸›)'
    else:  # NAR
        field_map[12] = 'å©èˆ'
        field_map[13] = 'é¦¬ä½“é‡(å¢—æ¸›)'
    
    for i, cell in enumerate(cells):
        text = cell.text.strip()[:50]
        field_name = field_map.get(i, f'ã‚»ãƒ«{i}')
        
        if text:
            print(f"    âœ… {i}: {field_name} = {text}")
        else:
            print(f"    âš ï¸ {i}: {field_name} = (ç©º)")
    
    # é¦¬ä½“é‡(å¢—æ¸›)ã®ç¢ºèª
    weight_cell_index = 14 if race_type == "JRA" else 13
    if len(cells) > weight_cell_index:
        weight_text = cells[weight_cell_index].text.strip()
        if weight_text:
            print(f"\n  âœ… é¦¬ä½“é‡(å¢—æ¸›): {weight_text}")
        else:
            print(f"\n  âŒ é¦¬ä½“é‡(å¢—æ¸›): ç©º")
    else:
        print(f"\n  âŒ é¦¬ä½“é‡(å¢—æ¸›): ã‚»ãƒ«{weight_cell_index}ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    
    # horse_id
    horse_link = cells[3].find('a') if len(cells) > 3 else None
    if horse_link and 'href' in horse_link.attrs:
        horse_id_match = re.search(r'/horse/(\d+)', horse_link['href'])
        if horse_id_match:
            print(f"  âœ… horse_id: {horse_id_match.group(1)}")
        else:
            print(f"  âŒ horse_id: æŠ½å‡ºå¤±æ•—")
    else:
        print(f"  âŒ horse_id: ãƒªãƒ³ã‚¯ãªã—")

# JRAæ¤œè¨¼
verify_all_fields(
    "202406050811",
    "https://race.netkeiba.com/race/result.html?race_id=202406050811",
    "JRA"
)

# NARæ¤œè¨¼
verify_all_fields(
    "202030041501",
    "https://nar.netkeiba.com/race/result.html?race_id=202030041501",
    "NAR"
)

print(f"\n{'='*80}")
print("âœ… æ¤œè¨¼å®Œäº†")
print(f"{'='*80}")
