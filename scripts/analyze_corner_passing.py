#!/usr/bin/env python3
"""
ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã®åˆ†æ
JRAã¨NARã®è¤‡æ•°ãƒ¬ãƒ¼ã‚¹ã§ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèª
"""

import requests
from bs4 import BeautifulSoup
import re

def analyze_corner_passing(race_id, url_base, race_type, description):
    """ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’åˆ†æ"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ” {race_type}: {description}")
    print(f"{'='*80}\n")
    print(f"Race ID: {race_id}\n")
    
    url = f"{url_base}/race/result.html?race_id={race_id}"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    resp = requests.get(url, headers=headers, timeout=15)
    resp.encoding = 'EUC-JP'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    tables = soup.find_all('table')
    result_table = None
    for t in tables:
        if 'ç€é †' in t.text and 'é¦¬å' in t.text:
            result_table = t
            break
    
    if not result_table:
        print("âŒ ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ãªã—")
        return
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
    rows = result_table.find_all('tr')
    header_row = rows[0]
    headers = [th.text.strip() for th in header_row.find_all('th')]
    
    print(f"ğŸ“‹ ãƒ˜ãƒƒãƒ€ãƒ¼({len(headers)}ã‚«ãƒ©ãƒ ):")
    for i, h in enumerate(headers):
        if 'ã‚³ãƒ¼ãƒŠãƒ¼' in h or 'é€šé' in h:
            print(f"  âœ… {i}: {h}")
        else:
            print(f"  {i}: {h}")
    
    # ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã®ã‚«ãƒ©ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™
    corner_index = None
    for i, h in enumerate(headers):
        if 'ã‚³ãƒ¼ãƒŠãƒ¼' in h or 'é€šé' in h:
            corner_index = i
            break
    
    if corner_index is None:
        print("\nâŒ ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã‚«ãƒ©ãƒ ãªã—")
        return
    
    print(f"\nğŸ“Š ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ãƒ‡ãƒ¼ã‚¿(æœ€åˆã®5é ­):")
    print(f"{'-'*80}")
    
    # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ
    for row in rows[1:6]:
        cells = row.find_all('td')
        if len(cells) < 3:
            continue
        
        umaban = cells[2].text.strip() if len(cells) > 2 else ''
        horse_name = cells[3].text.strip() if len(cells) > 3 else ''
        
        if corner_index < len(cells):
            corner_data = cells[corner_index].text.strip()
            print(f"  é¦¬ç•ª{umaban} ({horse_name}): {corner_data}")
        else:
            print(f"  é¦¬ç•ª{umaban} ({horse_name}): ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    # 1é ­ç›®ã®è©³ç´°è§£æ
    print(f"\nğŸ“Š 1é ­ç›®ã®è©³ç´°è§£æ:")
    print(f"{'-'*80}")
    
    first_data_row = None
    for row in rows[1:]:
        cells = row.find_all('td')
        if len(cells) >= 3:
            first_data_row = row
            break
    
    if first_data_row and corner_index < len(first_data_row.find_all('td')):
        cells = first_data_row.find_all('td')
        umaban = cells[2].text.strip()
        corner_text = cells[corner_index].text.strip()
        
        print(f"  é¦¬ç•ª: {umaban}")
        print(f"  ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †(ç”Ÿãƒ‡ãƒ¼ã‚¿): '{corner_text}'")
        
        # ãƒ‘ãƒ¼ã‚¹
        # å½¢å¼: "1-2-3-4" ã¾ãŸã¯ "1-2" ãªã©
        if corner_text and '-' in corner_text:
            positions = corner_text.split('-')
            print(f"  ã‚³ãƒ¼ãƒŠãƒ¼æ•°: {len(positions)}")
            for i, pos in enumerate(positions, 1):
                print(f"    {i}ã‚³ãƒ¼ãƒŠãƒ¼: {pos}")
        else:
            print(f"  âš ï¸ ãƒ‘ãƒ¼ã‚¹ä¸å¯")

# ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
test_cases = [
    # JRA
    ("202406050811", "https://race.netkeiba.com", "JRA", "æœ‰é¦¬è¨˜å¿µ(èŠ2500m)"),
    ("202405050511", "https://race.netkeiba.com", "JRA", "æ±äº¬11R(èŠ1600m)"),
    ("202401010101", "https://race.netkeiba.com", "JRA", "æœ­å¹Œ1R(ãƒ€ãƒ¼ãƒˆ1000m)"),
    
    # NAR
    ("202030041501", "https://nar.netkeiba.com", "NAR", "é–€åˆ¥1R(ãƒ€ãƒ¼ãƒˆ1200m)"),
    ("202130041501", "https://nar.netkeiba.com", "NAR", "é–€åˆ¥1R(ãƒ€ãƒ¼ãƒˆ1000m)"),
]

print("ğŸ§ª ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ãƒ‡ãƒ¼ã‚¿æ§‹é€ åˆ†æ\n")

for race_id, url_base, race_type, description in test_cases:
    analyze_corner_passing(race_id, url_base, race_type, description)

print(f"\n{'='*80}")
print("âœ… åˆ†æå®Œäº†")
print(f"{'='*80}")
