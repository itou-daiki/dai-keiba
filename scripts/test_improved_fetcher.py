#!/usr/bin/env python3
"""
ãƒ¬ãƒ¼ã‚¹IDã‚’ç”Ÿæˆã—ã¦ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹æ–¹æ³•
ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã‹ã‚‰é–‹å‚¬æ—¥ã‚’å–å¾—ã—ã€ãã®æ—¥ã®ãƒ¬ãƒ¼ã‚¹IDã‚’æ¨æ¸¬ã—ã¦ç¢ºèª
"""

import requests
from bs4 import BeautifulSoup
import re
import time
from tqdm.auto import tqdm

def get_kaisai_dates_from_calendar(year, month, mode='JRA'):
    """ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã‹ã‚‰é–‹å‚¬æ—¥ã‚’å–å¾—"""
    base_domain = "race.netkeiba.com" if mode == 'JRA' else "nar.netkeiba.com"
    cal_url = f"https://{base_domain}/top/calendar.html?year={year}&month={month}"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        resp = session.get(cal_url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        day_links = soup.select('a[href*="race_list.html?kaisai_date="]')
        
        dates = set()
        for link in day_links:
            href = link.get('href')
            m = re.search(r'kaisai_date=(\d{8})', href)
            if m:
                dates.add(m.group(1))
        
        return sorted(list(dates))
        
    except Exception as e:
        print(f"  Error fetching calendar {year}/{month}: {e}")
        return []


def extract_race_ids_from_page(date_str, mode='JRA'):
    """
    é–‹å‚¬æ—¥ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰å®Ÿéš›ã®ãƒ¬ãƒ¼ã‚¹IDã‚’æŠ½å‡º
    ãƒšãƒ¼ã‚¸ã®HTMLã‚½ãƒ¼ã‚¹å†…ã«åŸ‹ã‚è¾¼ã¾ã‚Œã¦ã„ã‚‹race_idã‚’å…¨ã¦æ¢ã™
    """
    base_domain = "race.netkeiba.com" if mode == 'JRA' else "nar.netkeiba.com"
    list_url = f"https://{base_domain}/top/race_list.html?kaisai_date={date_str}"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        time.sleep(0.3)
        resp = session.get(list_url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        
        # HTMLã‚½ãƒ¼ã‚¹å…¨ä½“ã‹ã‚‰12æ¡ã®æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
        # race_idã®å½¢å¼: YYYYPPKKDDRR (å¹´4æ¡ + 8æ¡)
        # å¹´ã®éƒ¨åˆ†ã§çµã‚Šè¾¼ã‚€
        year = date_str[:4]
        pattern = rf'\b({year}\d{{8}})\b'
        
        race_ids = set()
        matches = re.findall(pattern, resp.text)
        
        for match in matches:
            if len(match) == 12:
                # ã•ã‚‰ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: å ´æ‰€ã‚³ãƒ¼ãƒ‰ãŒå¦¥å½“ã‹ç¢ºèª
                place_code = match[4:6]
                # JRA: 01-10, NAR: 30-65ãã‚‰ã„
                if mode == 'JRA':
                    if place_code in [f"{i:02d}" for i in range(1, 11)]:
                        race_ids.add(match)
                else:
                    if int(place_code) >= 30:
                        race_ids.add(match)
        
        return sorted(list(race_ids))
        
    except Exception as e:
        return []


def fetch_race_ids_improved(mode='JRA', start_year=2025, end_year=2026):
    """æ”¹è‰¯ç‰ˆã®ãƒ¬ãƒ¼ã‚¹IDå–å¾—"""
    print(f"\nğŸš€ {mode} Race ID Fetching ({start_year}-{end_year})...")
    
    all_ids = set()
    
    for year in range(start_year, end_year + 1):
        print(f"  ğŸ“… Processing {year}...")
        
        for month in range(1, 13):
            # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰é–‹å‚¬æ—¥ã‚’å–å¾—
            dates = get_kaisai_dates_from_calendar(year, month, mode)
            
            if not dates:
                continue
            
            # å„é–‹å‚¬æ—¥ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹IDã‚’æŠ½å‡º
            for date_str in tqdm(dates, desc=f"{year}/{month:02}", leave=False):
                race_ids = extract_race_ids_from_page(date_str, mode)
                all_ids.update(race_ids)
    
    print(f"\nâœ… Total IDs collected: {len(all_ids)}")
    return sorted(list(all_ids))


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”§ Improved ID Fetcher Test")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆ: 2025å¹´1æœˆã®ã¿
    print("\nğŸ“Š Testing JRA (2025/1 only)...")
    jra_ids = fetch_race_ids_improved(mode='JRA', start_year=2025, end_year=2025)
    
    if jra_ids:
        print(f"\nâœ… Sample JRA IDs (first 20):")
        for rid in jra_ids[:20]:
            print(f"  {rid}")
    else:
        print("\nâŒ No JRA IDs found")
    
    print("\n" + "=" * 60)
    print("\nğŸ“Š Testing NAR (2025/12 only)...")
    
    # NAR: 2025å¹´12æœˆã®ã¿ãƒ†ã‚¹ãƒˆ
    nar_dates = get_kaisai_dates_from_calendar(2025, 12, 'NAR')
    print(f"Found {len(nar_dates)} NAR dates in 2025/12")
    
    if nar_dates:
        print("\nTesting first NAR date...")
        nar_ids = extract_race_ids_from_page(nar_dates[0], 'NAR')
        print(f"Found {len(nar_ids)} NAR IDs on {nar_dates[0]}")
        if nar_ids:
            for rid in nar_ids[:10]:
                print(f"  {rid}")
