#!/usr/bin/env python3
"""
NAR Basic v2ã«ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †æŠ½å‡ºã‚’è¿½åŠ 
"""

import json

notebook_path = "/Users/itoudaiki/Program/dai-keiba/notebooks/Colab_NAR_Basic_v2.ipynb"

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

for i, cell in enumerate(nb['cells']):
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        
        if 'def scrape_race_basic(' in source:
            print(f"âœ… ã‚»ãƒ«{i}: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’ç™ºè¦‹")
            
            # NARã®ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
            # ã¾ãšã€ã‚³ãƒ¼ãƒŠãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
            insert_point = """        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = extract_metadata(soup, url)"""
            
            corner_extraction = """        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        metadata = extract_metadata(soup, url)
        
        # ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ãƒ†ãƒ¼ãƒ–ãƒ«å–å¾—(NAR)
        corner_data = {}
        for table in tables:
            if 'ã‚³ãƒ¼ãƒŠãƒ¼' in table.text and 'é€šé' in table.text:
                corner_rows = table.find_all('tr')
                for row in corner_rows:
                    cells = row.find_all('td')
                    if len(cells) >= 2:
                        corner_name = cells[0].text.strip()
                        corner_text = cells[1].text.strip()
                        corner_data[corner_name] = corner_text
                break"""
            
            source = source.replace(insert_point, corner_extraction)
            
            # å„é¦¬ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ™‚ã«ã‚³ãƒ¼ãƒŠãƒ¼é †ä½ã‚’è¿½åŠ 
            old_horse_id = """            # horse_id(ãƒªãƒ³ã‚¯ã‹ã‚‰æŠ½å‡º)
            horse_link = cells[3].find('a') if len(cells) > 3 else None
            if horse_link and 'href' in horse_link.attrs:
                horse_id_match = re.search(r'/horse/(\\d+)', horse_link['href'])
                if horse_id_match:
                    horse_data['horse_id'] = horse_id_match.group(1)
            
            race_data.append(horse_data)"""
            
            new_horse_id = """            # horse_id(ãƒªãƒ³ã‚¯ã‹ã‚‰æŠ½å‡º)
            horse_link = cells[3].find('a') if len(cells) > 3 else None
            if horse_link and 'href' in horse_link.attrs:
                horse_id_match = re.search(r'/horse/(\\d+)', horse_link['href'])
                if horse_id_match:
                    horse_data['horse_id'] = horse_id_match.group(1)
            
            # ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ä½ã®æŠ½å‡º(NAR: é¦¬ç•ªå·å½¢å¼)
            umaban = horse_data['é¦¬ç•ª']
            for corner_num in range(1, 5):
                corner_key = f'{corner_num}ã‚³ãƒ¼ãƒŠãƒ¼'
                if corner_key in corner_data:
                    corner_text = corner_data[corner_key]
                    # é¦¬ç•ªå·å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                    corner_text_clean = corner_text.replace('(', '').replace(')', '').replace('-', ',')
                    horses = [h.strip() for h in corner_text_clean.split(',') if h.strip()]
                    for j, horse_num in enumerate(horses, 1):
                        if horse_num == umaban:
                            horse_data[f'corner_{corner_num}'] = str(j)
                            break
            
            race_data.append(horse_data)"""
            
            source = source.replace(old_horse_id, new_horse_id)
            
            # ordered_columnsã«ã‚³ãƒ¼ãƒŠãƒ¼ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            old_columns = """        ordered_columns = [
            'æ—¥ä»˜', 'ä¼šå ´', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·', 'ãƒ¬ãƒ¼ã‚¹å', 'é‡è³', 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', 'è·é›¢', 'å›ã‚Š',
            'å¤©å€™', 'é¦¬å ´çŠ¶æ…‹', 'ç€é †', 'æ ', 'é¦¬ç•ª', 'é¦¬å', 'æ€§é½¢', 'æ–¤é‡', 'é¨æ‰‹', 'ã‚¿ã‚¤ãƒ ',
            'ç€å·®', 'äººæ°—', 'å˜å‹ã‚ªãƒƒã‚º', 'å¾Œ3F', 'ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †', 'å©èˆ', 'é¦¬ä½“é‡(å¢—æ¸›)', 'race_id', 'horse_id'
        ]"""
            
            new_columns = """        ordered_columns = [
            'æ—¥ä»˜', 'ä¼šå ´', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·', 'ãƒ¬ãƒ¼ã‚¹å', 'é‡è³', 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', 'è·é›¢', 'å›ã‚Š',
            'å¤©å€™', 'é¦¬å ´çŠ¶æ…‹', 'ç€é †', 'æ ', 'é¦¬ç•ª', 'é¦¬å', 'æ€§é½¢', 'æ–¤é‡', 'é¨æ‰‹', 'ã‚¿ã‚¤ãƒ ',
            'ç€å·®', 'äººæ°—', 'å˜å‹ã‚ªãƒƒã‚º', 'å¾Œ3F', 'ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †', 'corner_1', 'corner_2', 'corner_3', 'corner_4',
            'å©èˆ', 'é¦¬ä½“é‡(å¢—æ¸›)', 'race_id', 'horse_id'
        ]"""
            
            source = source.replace(old_columns, new_columns)
            
            cell['source'] = [line + '\n' for line in source.split('\n')]
            if cell['source'] and cell['source'][-1] == '\n':
                cell['source'][-1] = cell['source'][-1].rstrip('\n')
            
            print("  âœ… NARã‚³ãƒ¼ãƒŠãƒ¼é€šéé †æŠ½å‡ºã‚’è¿½åŠ ")
            print("  âœ… corner_1, corner_2, corner_3, corner_4 ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ")
            break

with open(notebook_path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print(f"\nğŸ’¾ ä¿å­˜å®Œäº†: {notebook_path}")
print("\nğŸ“ NAR Basic v2 æ›´æ–°å†…å®¹:")
print("  - ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰é¦¬ç•ªå·å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹")
print("  - å„é¦¬ã®é †ä½ã‚’æŠ½å‡ºã—ã¦corner_1~4ã«æ ¼ç´")
print("  - ç·ã‚«ãƒ©ãƒ æ•°: 27 â†’ 31ã‚«ãƒ©ãƒ ")
