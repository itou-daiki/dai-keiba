#!/usr/bin/env python3
"""
å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿å–å¾—æ¤œè¨¼(JRA & NAR)
Stage 1 â†’ Stage 2 â†’ Merge ã®å…¨å·¥ç¨‹ã‚’æ¤œè¨¼
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import io

print("ğŸ” å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿å–å¾—æ¤œè¨¼(JRA & NAR)")
print(f"{'='*80}\n")

# ========================================
# JRAæ¤œè¨¼
# ========================================

def verify_jra():
    """JRAã®å®Œå…¨æ¤œè¨¼"""
    print("ğŸ“Š JRAæ¤œè¨¼")
    print(f"{'-'*80}\n")
    
    race_id = "202406050811"  # æœ‰é¦¬è¨˜å¿µ
    
    # Stage 1: Basic
    print("Stage 1: Basic (26ã‚«ãƒ©ãƒ )")
    url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    resp = requests.get(url, headers=headers, timeout=15)
    resp.encoding = 'EUC-JP'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    title = soup.title.text if soup.title else ""
    metadata_fields = {
        'æ—¥ä»˜': bool(re.search(r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', title)),
        'ä¼šå ´': any(v in title for v in ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']),
        'ãƒ¬ãƒ¼ã‚¹ç•ªå·': bool(re.search(r'\d+R', title)),
        'ãƒ¬ãƒ¼ã‚¹å': bool(re.search(r'^([^|]+)', title)),
        'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—': bool(re.search(r'(èŠ|ãƒ€ãƒ¼ãƒˆ)', soup.text)),
        'è·é›¢': bool(re.search(r'\d+m', soup.text)),
        'å¤©å€™': bool(re.search(r'å¤©å€™', soup.text)),
        'é¦¬å ´çŠ¶æ…‹': bool(re.search(r'é¦¬å ´', soup.text)),
    }
    
    # ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    tables = soup.find_all('table')
    result_table = None
    for t in tables:
        if 'ç€é †' in t.text and 'é¦¬å' in t.text:
            result_table = t
            break
    
    horse_data_fields = {
        'ç€é †': False,
        'é¦¬ç•ª': False,
        'é¦¬å': False,
        'é¨æ‰‹': False,
        'ã‚¿ã‚¤ãƒ ': False,
        'horse_id': False,
    }
    
    if result_table:
        rows = result_table.find_all('tr')
        for row in rows:
            if row.find('th'):
                continue
            cells = row.find_all('td')
            if len(cells) >= 10:
                horse_data_fields['ç€é †'] = bool(cells[0].text.strip())
                horse_data_fields['é¦¬ç•ª'] = bool(cells[2].text.strip())
                horse_data_fields['é¦¬å'] = bool(cells[3].text.strip())
                horse_data_fields['é¨æ‰‹'] = bool(cells[6].text.strip())
                horse_data_fields['ã‚¿ã‚¤ãƒ '] = bool(cells[7].text.strip())
                
                horse_link = cells[3].find('a')
                if horse_link and 'href' in horse_link.attrs:
                    horse_data_fields['horse_id'] = bool(re.search(r'/horse/(\d+)', horse_link['href']))
                break
    
    stage1_success = sum(metadata_fields.values()) + sum(horse_data_fields.values())
    stage1_total = len(metadata_fields) + len(horse_data_fields)
    
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {sum(metadata_fields.values())}/{len(metadata_fields)}")
    for k, v in metadata_fields.items():
        status = "âœ…" if v else "âŒ"
        print(f"    {status} {k}")
    
    print(f"  é¦¬ãƒ‡ãƒ¼ã‚¿: {sum(horse_data_fields.values())}/{len(horse_data_fields)}")
    for k, v in horse_data_fields.items():
        status = "âœ…" if v else "âŒ"
        print(f"    {status} {k}")
    
    print(f"  Stage 1æˆåŠŸç‡: {stage1_success/stage1_total*100:.0f}% ({stage1_success}/{stage1_total})\n")
    
    # Stage 2: Details
    if horse_data_fields['horse_id']:
        print("Stage 2: Details (68ã‚«ãƒ©ãƒ )")
        
        # horse_idã‚’å–å¾—
        horse_link = result_table.find_all('tr')[1].find_all('td')[3].find('a')
        horse_id = re.search(r'/horse/(\d+)', horse_link['href']).group(1)
        
        # é¦¬å±¥æ­´
        history_url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
        resp2 = requests.get(history_url, headers=headers, timeout=15)
        resp2.encoding = 'EUC-JP'
        soup2 = BeautifulSoup(resp2.text, 'html.parser')
        
        tables2 = soup2.find_all('table')
        history_success = False
        past_races_count = 0
        
        if tables2:
            try:
                df = pd.read_html(io.StringIO(str(tables2[0])))[0]
                df = df.dropna(how='all')
                if 'æ—¥ä»˜' in df.columns:
                    past_races_count = min(len(df), 5)
                    history_success = True
            except:
                pass
        
        print(f"  é¦¬å±¥æ­´å–å¾—: {'âœ…' if history_success else 'âŒ'}")
        print(f"  éå»èµ°æ•°: {past_races_count}/5")
        
        # è¡€çµ±
        ped_url = f"https://db.netkeiba.com/horse/ped/{horse_id}/"
        resp3 = requests.get(ped_url, headers=headers, timeout=15)
        resp3.encoding = 'EUC-JP'
        soup3 = BeautifulSoup(resp3.text, 'html.parser')
        
        pedigree_success = 'çˆ¶' in soup3.text or 'æ¯' in soup3.text
        
        print(f"  è¡€çµ±ãƒšãƒ¼ã‚¸å–å¾—: {'âœ…' if pedigree_success else 'âŒ'}")
        
        stage2_fields = past_races_count * 13 + (3 if pedigree_success else 0)
        print(f"  Stage 2æˆåŠŸç‡: {stage2_fields/68*100:.0f}% ({stage2_fields}/68)\n")
    
    # Merge
    print("Merge: 94ã‚«ãƒ©ãƒ ")
    merge_success = stage1_success > 0 and (stage2_fields if horse_data_fields['horse_id'] else 0) > 0
    print(f"  çµåˆå¯èƒ½: {'âœ…' if merge_success else 'âŒ'}")
    print(f"  äºˆæƒ³ã‚«ãƒ©ãƒ æ•°: {26 + (68 if horse_data_fields['horse_id'] else 0)}\n")
    
    return {
        'stage1': stage1_success / stage1_total * 100,
        'stage2': stage2_fields / 68 * 100 if horse_data_fields['horse_id'] else 0,
        'merge': merge_success
    }

# ========================================
# NARæ¤œè¨¼
# ========================================

def verify_nar():
    """NARã®å®Œå…¨æ¤œè¨¼"""
    print("ğŸ“Š NARæ¤œè¨¼")
    print(f"{'-'*80}\n")
    
    race_id = "202030041501"  # é–€åˆ¥
    
    # Stage 1: Basic
    print("Stage 1: Basic (26ã‚«ãƒ©ãƒ )")
    url = f"https://nar.netkeiba.com/race/result.html?race_id={race_id}"
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    resp = requests.get(url, headers=headers, timeout=15)
    resp.encoding = 'EUC-JP'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    title = soup.title.text if soup.title else ""
    nar_venues = ['é–€åˆ¥', 'ç››å²¡', 'æ°´æ²¢', 'æµ¦å’Œ', 'èˆ¹æ©‹', 'å¤§äº•', 'å·å´', 'é‡‘æ²¢', 'ç¬ æ¾', 'åå¤å±‹', 'åœ’ç”°', 'å§«è·¯', 'é«˜çŸ¥', 'ä½è³€', 'ã°ã‚“ãˆã„å¸¯åºƒ']
    
    metadata_fields = {
        'æ—¥ä»˜': bool(re.search(r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', title)),
        'ä¼šå ´': any(v in title for v in nar_venues),
        'ãƒ¬ãƒ¼ã‚¹ç•ªå·': bool(re.search(r'\d+R', title)),
        'ãƒ¬ãƒ¼ã‚¹å': bool(re.search(r'^([^|]+)', title)),
        'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—': bool(re.search(r'(èŠ|ãƒ€ãƒ¼ãƒˆ|ãƒ€)', soup.text)),
        'è·é›¢': bool(re.search(r'\d+m', soup.text)),
        'å¤©å€™': bool(re.search(r'å¤©å€™', soup.text)),
        'é¦¬å ´çŠ¶æ…‹': bool(re.search(r'é¦¬å ´', soup.text)),
    }
    
    # ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    tables = soup.find_all('table')
    result_table = None
    for t in tables:
        if 'ç€é †' in t.text and 'é¦¬å' in t.text:
            result_table = t
            break
    
    horse_data_fields = {
        'ç€é †': False,
        'é¦¬ç•ª': False,
        'é¦¬å': False,
        'é¨æ‰‹': False,
        'ã‚¿ã‚¤ãƒ ': False,
        'horse_id': False,
    }
    
    if result_table:
        rows = result_table.find_all('tr')
        for row in rows:
            if row.find('th'):
                continue
            cells = row.find_all('td')
            if len(cells) >= 10:
                horse_data_fields['ç€é †'] = bool(cells[0].text.strip())
                horse_data_fields['é¦¬ç•ª'] = bool(cells[2].text.strip())
                horse_data_fields['é¦¬å'] = bool(cells[3].text.strip())
                horse_data_fields['é¨æ‰‹'] = bool(cells[6].text.strip())
                horse_data_fields['ã‚¿ã‚¤ãƒ '] = bool(cells[7].text.strip())
                
                horse_link = cells[3].find('a')
                if horse_link and 'href' in horse_link.attrs:
                    horse_data_fields['horse_id'] = bool(re.search(r'/horse/(\d+)', horse_link['href']))
                break
    
    stage1_success = sum(metadata_fields.values()) + sum(horse_data_fields.values())
    stage1_total = len(metadata_fields) + len(horse_data_fields)
    
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {sum(metadata_fields.values())}/{len(metadata_fields)}")
    for k, v in metadata_fields.items():
        status = "âœ…" if v else "âŒ"
        print(f"    {status} {k}")
    
    print(f"  é¦¬ãƒ‡ãƒ¼ã‚¿: {sum(horse_data_fields.values())}/{len(horse_data_fields)}")
    for k, v in horse_data_fields.items():
        status = "âœ…" if v else "âŒ"
        print(f"    {status} {k}")
    
    print(f"  Stage 1æˆåŠŸç‡: {stage1_success/stage1_total*100:.0f}% ({stage1_success}/{stage1_total})\n")
    
    # Stage 2ã¯çœç•¥(JRAã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)
    print("Stage 2: Details (çœç•¥ - JRAã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)\n")
    
    return {
        'stage1': stage1_success / stage1_total * 100,
        'stage2': 0,  # çœç•¥
        'merge': stage1_success > 0
    }

# ========================================
# å®Ÿè¡Œ
# ========================================

try:
    jra_result = verify_jra()
    time.sleep(1)
    nar_result = verify_nar()
    
    print(f"\n{'='*80}")
    print("ğŸ“Š æœ€çµ‚çµæœ")
    print(f"{'='*80}\n")
    
    print("JRA:")
    print(f"  Stage 1: {jra_result['stage1']:.0f}%")
    print(f"  Stage 2: {jra_result['stage2']:.0f}%")
    print(f"  Merge: {'âœ…' if jra_result['merge'] else 'âŒ'}\n")
    
    print("NAR:")
    print(f"  Stage 1: {nar_result['stage1']:.0f}%")
    print(f"  Merge: {'âœ…' if nar_result['merge'] else 'âŒ'}\n")
    
    overall_success = (jra_result['stage1'] + nar_result['stage1']) / 2
    print(f"ç·åˆæˆåŠŸç‡: {overall_success:.0f}%")
    
except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()
