#!/usr/bin/env python3
"""
åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: é–‹å‚¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã‹ã‚‰ç›´æ¥ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—
"""

import requests
from bs4 import BeautifulSoup
import re
import time

def test_schedule_page():
    """é‡è³ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” Testing Schedule Page\n")
    
    url = "https://race.netkeiba.com/top/schedule.html"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        resp = session.get(url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        print(f"âœ… Status Code: {resp.status_code}")
        print(f"ğŸ“„ Content Length: {len(resp.text)} chars\n")
        
        # race_idã‚’å«ã‚€ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        all_links = soup.find_all('a', href=True)
        race_id_links = [link for link in all_links if 'race_id' in link.get('href', '')]
        
        print(f"ğŸ”— Found {len(race_id_links)} links with race_id\n")
        
        race_ids = set()
        for link in race_id_links[:20]:
            href = link.get('href')
            text = link.get_text(strip=True)
            m = re.search(r'race_id=(\d+)', href)
            if m:
                rid = m.group(1)
                if len(rid) == 12:
                    race_ids.add(rid)
                    print(f"  {rid}: {text[:50]}")
        
        print(f"\nâœ… Total unique race IDs: {len(race_ids)}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")


def test_direct_race_result(race_id="202506010101"):
    """ãƒ¬ãƒ¼ã‚¹çµæœãƒšãƒ¼ã‚¸ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦HTMLã‚’ç¢ºèª"""
    print(f"\n\nğŸ” Testing Direct Race Result Page: {race_id}\n")
    
    url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        resp = session.get(url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        print(f"âœ… Status Code: {resp.status_code}")
        
        # ãƒ¬ãƒ¼ã‚¹åã‚’å–å¾—
        race_name = soup.find('h1', class_=re.compile('RaceName|race_name', re.I))
        if race_name:
            print(f"ğŸ“‹ Race Name: {race_name.get_text(strip=True)}")
        
        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
        result_table = soup.find('table', class_=re.compile('Result|race_table', re.I))
        if result_table:
            print(f"âœ… Result table found")
        else:
            print(f"âš ï¸  No result table found - might be a future race")
            
            # å‡ºé¦¬è¡¨ã‚’æ¢ã™
            shutuba_table = soup.find('table', class_=re.compile('Shutuba|horse', re.I))
            if shutuba_table:
                print(f"âœ… Shutuba (entry) table found")
        
    except Exception as e:
        print(f"âŒ Error: {e}")


def test_monthly_race_list(year=2025, month=1):
    """æœˆé–“ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‹ã‚‰å…¨ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—ã™ã‚‹åˆ¥ã®æ–¹æ³•ã‚’è©¦ã™"""
    print(f"\n\nğŸ” Testing Monthly Approach: {year}/{month}\n")
    
    # å„ç«¶é¦¬å ´ã®ã‚³ãƒ¼ãƒ‰ã‚’è©¦ã™
    # JRAç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰: 01=æœ­å¹Œ, 02=å‡½é¤¨, 03=ç¦å³¶, 04=æ–°æ½Ÿ, 05=æ±äº¬, 06=ä¸­å±±, 07=ä¸­äº¬, 08=äº¬éƒ½, 09=é˜ªç¥, 10=å°å€‰
    venues = {
        '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ', '05': 'æ±äº¬',
        '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½', '09': 'é˜ªç¥', '10': 'å°å€‰'
    }
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    all_race_ids = set()
    
    # 1æœˆã®å„æ—¥ã‚’è©¦ã™(1-31)
    for day in range(1, 32):
        date_str = f"{year}{month:02d}{day:02d}"
        
        # é–‹å‚¬ãŒã‚ã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã€race_listãƒšãƒ¼ã‚¸ã‚’è©¦ã™
        list_url = f"https://race.netkeiba.com/top/race_list.html?kaisai_date={date_str}"
        
        try:
            time.sleep(0.3)
            resp = session.get(list_url, headers=headers, timeout=10)
            resp.encoding = 'EUC-JP'
            
            # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§é–‹å‚¬ãŒã‚ã‚‹ã‹ç¢ºèª
            if "é–‹å‚¬ãªã—" in resp.text or "ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“" in resp.text:
                continue
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: ãƒ¬ãƒ¼ã‚¹åã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰race_idã‚’æ¨æ¸¬
            # race_idã®å½¢å¼: YYYYPPKKDDRR
            # YYYY=å¹´, PP=å ´æ‰€, KK=å›æ¬¡, DD=æ—¥æ¬¡, RR=ãƒ¬ãƒ¼ã‚¹ç•ªå·
            
            # ã¾ãšã€ãƒšãƒ¼ã‚¸å†…ã®å…¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰race_idãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
            text_content = resp.text
            race_id_pattern = re.findall(r'\b(20\d{10})\b', text_content)
            
            for rid in race_id_pattern:
                if len(rid) == 12:
                    all_race_ids.add(rid)
            
        except:
            continue
    
    print(f"âœ… Found {len(all_race_ids)} race IDs for {year}/{month}")
    if all_race_ids:
        print("\nSample IDs:")
        for rid in sorted(list(all_race_ids))[:10]:
            print(f"  {rid}")
    
    return all_race_ids


if __name__ == "__main__":
    test_schedule_page()
    test_direct_race_result("202506010101")
    race_ids = test_monthly_race_list(2025, 1)
