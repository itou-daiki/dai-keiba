#!/usr/bin/env python3
"""
NAR ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã®è©³ç´°åˆ†æ
ãƒ¬ãƒ¼ã‚¹çµæœãƒšãƒ¼ã‚¸ã®å…¨ä½“æ§‹é€ ã‚’ç¢ºèª
"""

import requests
from bs4 import BeautifulSoup

race_id = "202030041501"
url = f"https://nar.netkeiba.com/race/result.html?race_id={race_id}"

print(f"ğŸ” NAR ã‚³ãƒ¼ãƒŠãƒ¼é€šéé †ã®è©³ç´°åˆ†æ")
print(f"{'='*80}\n")
print(f"Race ID: {race_id}")
print(f"URL: {url}\n")

headers = {'User-Agent': 'Mozilla/5.0'}
resp = requests.get(url, headers=headers, timeout=15)
resp.encoding = 'EUC-JP'
soup = BeautifulSoup(resp.text, 'html.parser')

# å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºèª
tables = soup.find_all('table')
print(f"ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}\n")

for i, table in enumerate(tables):
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«{i+1}:")
    print(f"{'-'*80}")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã®ä¸€éƒ¨ã‚’è¡¨ç¤º
    text = table.text.strip()[:200]
    print(f"  å†…å®¹: {text}...")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
    headers_cells = table.find_all('th')
    if headers_cells:
        print(f"  ãƒ˜ãƒƒãƒ€ãƒ¼: {[th.text.strip() for th in headers_cells[:10]]}")
    
    # ã‚³ãƒ¼ãƒŠãƒ¼é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    if 'ã‚³ãƒ¼ãƒŠãƒ¼' in table.text or 'é€šé' in table.text:
        print(f"  âœ… ã‚³ãƒ¼ãƒŠãƒ¼é–¢é€£ã‚ã‚Š")
    
    print()

# ãƒšãƒ¼ã‚¸å…¨ä½“ã§ã‚³ãƒ¼ãƒŠãƒ¼é–¢é€£ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œç´¢
print(f"\n{'='*80}")
print(f"ğŸ“Š ãƒšãƒ¼ã‚¸å…¨ä½“ã§ã®ã‚³ãƒ¼ãƒŠãƒ¼é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢:")
print(f"{'='*80}\n")

full_text = soup.text

keywords = ['ã‚³ãƒ¼ãƒŠãƒ¼', 'é€šéé †', '1ã‚³ãƒ¼ãƒŠãƒ¼', '2ã‚³ãƒ¼ãƒŠãƒ¼', '3ã‚³ãƒ¼ãƒŠãƒ¼', '4ã‚³ãƒ¼ãƒŠãƒ¼']
for keyword in keywords:
    if keyword in full_text:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‘¨è¾ºã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        index = full_text.find(keyword)
        context = full_text[max(0, index-50):min(len(full_text), index+100)]
        print(f"âœ… '{keyword}' ç™ºè¦‹:")
        print(f"   {context.strip()}")
        print()
