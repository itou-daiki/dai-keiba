#!/usr/bin/env python3
"""
2æ®µéšã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®å®Œå…¨æ¤œè¨¼(2020-2026å¹´)
Stage 1 â†’ Stage 2 â†’ Merge â†’ ã‚«ãƒ©ãƒ ã‚ºãƒ¬æ¤œè¨¼
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import os
import io
from datetime import datetime

# ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEST_DIR = "/Users/itoudaiki/Program/dai-keiba/data/test_2stage"
os.makedirs(TEST_DIR, exist_ok=True)

print("ğŸ§ª 2æ®µéšã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œå…¨æ¤œè¨¼(2020-2026å¹´)")
print(f"{'='*80}\n")

# ========================================
# Stage 1: Basic (26ã‚«ãƒ©ãƒ )
# ========================================

def scrape_basic(race_id):
    """Stage 1: åŸºæœ¬æƒ…å ±å–å¾—(26ã‚«ãƒ©ãƒ )"""
    url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
    
    try:
        time.sleep(0.5)
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=15)
        resp.encoding = 'EUC-JP'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        title = soup.title.text if soup.title else ""
        full_text = soup.text
        
        metadata = {
            'æ—¥ä»˜': '', 'ä¼šå ´': '', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·': '', 'ãƒ¬ãƒ¼ã‚¹å': '', 'é‡è³': '',
            'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—': '', 'è·é›¢': '', 'å›ã‚Š': '', 'å¤©å€™': '', 'é¦¬å ´çŠ¶æ…‹': '', 'race_id': race_id
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡º
        if title:
            race_name_match = re.search(r'^([^|]+)', title)
            if race_name_match:
                race_name = re.sub(r'\s*(çµæœ|æ‰•æˆ»).*$', '', race_name_match.group(1).strip())
                metadata['ãƒ¬ãƒ¼ã‚¹å'] = race_name
                if 'G1' in race_name or 'Gâ… ' in race_name:
                    metadata['é‡è³'] = 'G1'
            
            date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', title)
            if date_match:
                metadata['æ—¥ä»˜'] = f"{date_match.group(1)}/{int(date_match.group(2)):02d}/{int(date_match.group(3)):02d}"
            
            for venue in ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']:
                if venue in title:
                    metadata['ä¼šå ´'] = venue
                    break
            
            race_num_match = re.search(r'(\d+)R', title)
            if race_num_match:
                metadata['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = race_num_match.group(0)
        
        # æœ¬æ–‡ã‹ã‚‰
        course_match = re.search(r'(èŠ|ãƒ€ãƒ¼ãƒˆ|ãƒ€)\s*(\d+)m', full_text)
        if course_match:
            metadata['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'] = 'èŠ' if 'èŠ' in course_match.group(1) else 'ãƒ€ãƒ¼ãƒˆ'
            metadata['è·é›¢'] = course_match.group(2)
        
        if 'å³' in full_text:
            metadata['å›ã‚Š'] = 'å³'
        elif 'å·¦' in full_text:
            metadata['å›ã‚Š'] = 'å·¦'
        
        weather_match = re.search(r'å¤©å€™\s*[:ï¼š]\s*(\S+)', full_text)
        if weather_match:
            metadata['å¤©å€™'] = weather_match.group(1)
        
        baba_match = re.search(r'é¦¬å ´\s*[:ï¼š]\s*(\S+)', full_text)
        if baba_match:
            metadata['é¦¬å ´çŠ¶æ…‹'] = baba_match.group(1)
        
        # ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«
        tables = soup.find_all('table')
        result_table = None
        for t in tables:
            if 'ç€é †' in t.text and 'é¦¬å' in t.text:
                result_table = t
                break
        
        if not result_table:
            return None
        
        rows = result_table.find_all('tr')
        race_data = []
        
        for row in rows:
            if row.find('th'):
                continue
            cells = row.find_all('td')
            if len(cells) < 10:
                continue
            
            # åŸºæœ¬æƒ…å ±ã‚’è¾æ›¸ã§æ§‹ç¯‰
            horse_data = {
                'æ—¥ä»˜': metadata['æ—¥ä»˜'],
                'ä¼šå ´': metadata['ä¼šå ´'],
                'ãƒ¬ãƒ¼ã‚¹ç•ªå·': metadata['ãƒ¬ãƒ¼ã‚¹ç•ªå·'],
                'ãƒ¬ãƒ¼ã‚¹å': metadata['ãƒ¬ãƒ¼ã‚¹å'],
                'é‡è³': metadata['é‡è³'],
                'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—': metadata['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'],
                'è·é›¢': metadata['è·é›¢'],
                'å›ã‚Š': metadata['å›ã‚Š'],
                'å¤©å€™': metadata['å¤©å€™'],
                'é¦¬å ´çŠ¶æ…‹': metadata['é¦¬å ´çŠ¶æ…‹'],
                'ç€é †': cells[0].text.strip(),
                'æ ': '',
                'é¦¬ç•ª': cells[2].text.strip() if len(cells) > 2 else '',
                'é¦¬å': cells[3].text.strip() if len(cells) > 3 else '',
                'æ€§é½¢': cells[4].text.strip() if len(cells) > 4 else '',
                'æ–¤é‡': cells[5].text.strip() if len(cells) > 5 else '',
                'é¨æ‰‹': cells[6].text.strip() if len(cells) > 6 else '',
                'ã‚¿ã‚¤ãƒ ': cells[7].text.strip() if len(cells) > 7 else '',
                'ç€å·®': cells[8].text.strip() if len(cells) > 8 else '',
                'äººæ°—': cells[9].text.strip() if len(cells) > 9 else '',
                'å˜å‹ã‚ªãƒƒã‚º': cells[10].text.strip() if len(cells) > 10 else '',
                'å¾Œ3F': cells[11].text.strip() if len(cells) > 11 else '',
                'å©èˆ': cells[18].text.strip() if len(cells) > 18 else '',
                'é¦¬ä½“é‡(å¢—æ¸›)': cells[14].text.strip() if len(cells) > 14 else '',
                'race_id': race_id,
                'horse_id': ''
            }
            
            # æ ç•ª
            waku_img = cells[1].find('img') if len(cells) > 1 else None
            if waku_img and 'alt' in waku_img.attrs:
                waku_match = re.search(r'æ (\d+)', waku_img['alt'])
                if waku_match:
                    horse_data['æ '] = waku_match.group(1)
            
            # horse_id
            horse_link = cells[3].find('a') if len(cells) > 3 else None
            if horse_link and 'href' in horse_link.attrs:
                horse_id_match = re.search(r'/horse/(\d+)', horse_link['href'])
                if horse_id_match:
                    horse_data['horse_id'] = horse_id_match.group(1)
            
            race_data.append(horse_data)
        
        # DataFrameã«å¤‰æ›(ã‚«ãƒ©ãƒ é †åºã‚’æ˜ç¤º)
        ordered_columns = [
            'æ—¥ä»˜', 'ä¼šå ´', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·', 'ãƒ¬ãƒ¼ã‚¹å', 'é‡è³', 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', 'è·é›¢', 'å›ã‚Š',
            'å¤©å€™', 'é¦¬å ´çŠ¶æ…‹', 'ç€é †', 'æ ', 'é¦¬ç•ª', 'é¦¬å', 'æ€§é½¢', 'æ–¤é‡', 'é¨æ‰‹', 'ã‚¿ã‚¤ãƒ ',
            'ç€å·®', 'äººæ°—', 'å˜å‹ã‚ªãƒƒã‚º', 'å¾Œ3F', 'å©èˆ', 'é¦¬ä½“é‡(å¢—æ¸›)', 'race_id', 'horse_id'
        ]
        
        df = pd.DataFrame(race_data)[ordered_columns]
        return df
    
    except Exception as e:
        print(f"  âŒ Stage 1ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ========================================
# Stage 2: Details (68ã‚«ãƒ©ãƒ )
# ========================================

def scrape_details(horse_id, race_date):
    """Stage 2: é¦¬å±¥æ­´å–å¾—(68ã‚«ãƒ©ãƒ )"""
    
    details = {
        'race_id': '',
        'horse_id': horse_id
    }
    
    # éå»5èµ°ã®åˆæœŸåŒ–
    for i in range(1, 6):
        prefix = f'past_{i}'
        for field in ['date', 'rank', 'time', 'run_style', 'race_name', 'last_3f', 
                      'horse_weight', 'jockey', 'condition', 'odds', 'weather', 'distance', 'course_type']:
            details[f'{prefix}_{field}'] = ''
    
    # è¡€çµ±ã®åˆæœŸåŒ–
    details['father'] = ''
    details['mother'] = ''
    details['bms'] = ''
    
    try:
        time.sleep(0.5)
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        # ãƒ¬ãƒ¼ã‚¹å±¥æ­´å–å¾—
        url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
        resp = requests.get(url, headers=headers, timeout=15)
        resp.encoding = 'EUC-JP'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        tables = soup.find_all('table')
        if not tables:
            return details
        
        df = pd.read_html(io.StringIO(str(tables[0])))[0]
        df = df.dropna(how='all')
        df.columns = df.columns.astype(str).str.replace(r'\s+', '', regex=True)
        
        if 'æ—¥ä»˜' in df.columns:
            df['date_obj'] = pd.to_datetime(df['æ—¥ä»˜'], format='%Y/%m/%d', errors='coerce')
            df = df.dropna(subset=['date_obj'])
            
            current_date = pd.to_datetime(race_date)
            df = df[df['date_obj'] < current_date]
            df = df.sort_values('date_obj', ascending=False)
            df = df.head(5)
            
            for i, row in enumerate(df.itertuples(), 1):
                prefix = f'past_{i}'
                
                details[f'{prefix}_date'] = getattr(row, 'æ—¥ä»˜', '')
                details[f'{prefix}_rank'] = str(getattr(row, 'ç€é †', ''))
                details[f'{prefix}_time'] = str(getattr(row, 'ã‚¿ã‚¤ãƒ ', ''))
                details[f'{prefix}_race_name'] = str(getattr(row, 'ãƒ¬ãƒ¼ã‚¹å', ''))
                details[f'{prefix}_last_3f'] = str(getattr(row, 'ä¸Šã‚Š', ''))
                details[f'{prefix}_horse_weight'] = str(getattr(row, 'é¦¬ä½“é‡', ''))
                details[f'{prefix}_jockey'] = str(getattr(row, 'é¨æ‰‹', ''))
                details[f'{prefix}_condition'] = str(getattr(row, 'é¦¬å ´', ''))
                details[f'{prefix}_odds'] = str(getattr(row, 'å˜å‹', '') or getattr(row, 'ã‚ªãƒƒã‚º', ''))
                details[f'{prefix}_weather'] = str(getattr(row, 'å¤©æ°—', ''))
                
                dist_text = str(getattr(row, 'è·é›¢', ''))
                dist_match = re.search(r'(èŠ|ãƒ€|éšœ)(\d+)', dist_text)
                if dist_match:
                    course_type = dist_match.group(1)
                    details[f'{prefix}_course_type'] = 'èŠ' if course_type == 'èŠ' else 'ãƒ€ãƒ¼ãƒˆ' if course_type == 'ãƒ€' else 'éšœå®³'
                    details[f'{prefix}_distance'] = dist_match.group(2)
                
                details[f'{prefix}_run_style'] = '3'
        
        return details
    
    except Exception as e:
        return details

# ========================================
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
# ========================================

# 2020-2026å¹´ã®å®Ÿåœ¨ã™ã‚‹ãƒ¬ãƒ¼ã‚¹(å„å¹´2ãƒ¬ãƒ¼ã‚¹)
test_races = {
    "2020å¹´": [
        ("202001010101", "æœ­å¹Œ1R"),
        ("202005050811", "æ±äº¬11R"),
    ],
    "2021å¹´": [
        ("202101010202", "æœ­å¹Œ2R"),
        ("202105050711", "æ±äº¬11R"),
    ],
    "2022å¹´": [
        ("202201010101", "æœ­å¹Œ1R"),
    ],
    "2023å¹´": [
        ("202301010303", "æœ­å¹Œ3R"),
    ],
    "2024å¹´": [
        ("202401010101", "æœ­å¹Œ1R"),
        ("202406050811", "ä¸­å±±11R(æœ‰é¦¬è¨˜å¿µ)"),
    ],
}

all_results = []

for year, races in test_races.items():
    print(f"\n{'='*80}")
    print(f"ğŸ“… {year}")
    print(f"{'='*80}\n")
    
    for race_id, description in races:
        print(f"ğŸ‡ {description} (ID: {race_id})")
        print(f"{'-'*80}")
        
        # Stage 1
        print(f"  Stage 1: åŸºæœ¬æƒ…å ±å–å¾—...")
        df_basic = scrape_basic(race_id)
        
        if df_basic is None or df_basic.empty:
            print(f"  âŒ Stage 1å¤±æ•—")
            continue
        
        print(f"  âœ… Stage 1æˆåŠŸ: {len(df_basic)}é ­, {len(df_basic.columns)}ã‚«ãƒ©ãƒ ")
        
        # Stage 2 (æœ€åˆã®1é ­ã®ã¿ãƒ†ã‚¹ãƒˆ)
        if df_basic.iloc[0]['horse_id']:
            print(f"  Stage 2: è©³ç´°æƒ…å ±å–å¾—...")
            horse_id = df_basic.iloc[0]['horse_id']
            race_date = df_basic.iloc[0]['æ—¥ä»˜']
            
            details = scrape_details(horse_id, race_date)
            details_filled = sum(1 for v in details.values() if v)
            
            print(f"  âœ… Stage 2æˆåŠŸ: {details_filled}/68ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰")
            
            # Merge
            print(f"  Merge: ãƒ‡ãƒ¼ã‚¿çµåˆ...")
            merged = {**df_basic.iloc[0].to_dict(), **details}
            total_cols = len(merged)
            print(f"  âœ… MergeæˆåŠŸ: {total_cols}ã‚«ãƒ©ãƒ ")
            
            all_results.append({
                'year': year,
                'race_id': race_id,
                'description': description,
                'stage1_cols': len(df_basic.columns),
                'stage2_fields': details_filled,
                'merged_cols': total_cols,
                'success': total_cols == 94
            })
        
        print()

# æœ€çµ‚ã‚µãƒãƒªãƒ¼
print(f"\n{'='*80}")
print(f"ğŸ“Š æœ€çµ‚ã‚µãƒãƒªãƒ¼")
print(f"{'='*80}\n")

for r in all_results:
    status = "âœ…" if r['success'] else "âŒ"
    print(f"{status} {r['year']} {r['description']}")
    print(f"    Stage1: {r['stage1_cols']}ã‚«ãƒ©ãƒ , Stage2: {r['stage2_fields']}/68, Merge: {r['merged_cols']}ã‚«ãƒ©ãƒ ")

success_count = sum(1 for r in all_results if r['success'])
print(f"\næˆåŠŸç‡: {success_count}/{len(all_results)} ({success_count/len(all_results)*100:.0f}%)")
