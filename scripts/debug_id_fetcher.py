#!/usr/bin/env python3
"""
ID Fetcher ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Colab_ID_Fetcher.ipynb ã®å•é¡Œã‚’è¨ºæ–­ã—ã¾ã™
"""

import requests
from bs4 import BeautifulSoup
import re
import time

def test_jra_calendar(year=2025, month=1):
    """JRAã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” Testing JRA Calendar: {year}/{month}")
    
    base_domain = "race.netkeiba.com"
    cal_url = f"https://{base_domain}/top/calendar.html?year={year}&month={month}"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        resp = session.get(cal_url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        print(f"  âœ… Status Code: {resp.status_code}")
        print(f"  ğŸ“„ Content Length: {len(resp.text)} chars")
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        day_links = soup.select('a[href*="race_list.html?kaisai_date="]')
        print(f"  ğŸ”— Found {len(day_links)} day links")
        
        dates = []
        for link in day_links[:5]:  # æœ€åˆã®5ã¤ã ã‘è¡¨ç¤º
            href = link.get('href')
            m = re.search(r'kaisai_date=(\d{8})', href)
            if m:
                date_str = m.group(1)
                dates.append(date_str)
                print(f"    - {date_str}: {href}")
        
        if not dates:
            print("  âš ï¸  No dates found! Checking HTML structure...")
            # HTMLã®ä¸€éƒ¨ã‚’è¡¨ç¤º
            print("\n  ğŸ“‹ Sample HTML (first 1000 chars):")
            print(resp.text[:1000])
            
            # å…¨ã¦ã®ãƒªãƒ³ã‚¯ã‚’ç¢ºèª
            all_links = soup.find_all('a', href=True)
            print(f"\n  ğŸ”— Total links found: {len(all_links)}")
            if all_links:
                print("  Sample links:")
                for link in all_links[:10]:
                    print(f"    - {link.get('href')}")
        
        return dates
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []


def test_race_list(date_str="20250105"):
    """ãƒ¬ãƒ¼ã‚¹ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸ã®ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” Testing JRA Race List: {date_str}")
    
    base_domain = "race.netkeiba.com"
    list_url = f"https://{base_domain}/top/race_list.html?kaisai_date={date_str}"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        resp = session.get(list_url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        print(f"  âœ… Status Code: {resp.status_code}")
        print(f"  ğŸ“„ Content Length: {len(resp.text)} chars")
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ãƒ¬ãƒ¼ã‚¹IDãƒªãƒ³ã‚¯ã‚’æ¢ã™
        race_links = soup.select('a[href*="race_id="]')
        print(f"  ğŸ”— Found {len(race_links)} race links")
        
        race_ids = set()
        for link in race_links[:10]:  # æœ€åˆã®10å€‹ã ã‘è¡¨ç¤º
            href = link.get('href')
            m = re.search(r'race_id=(\d+)', href)
            if m:
                race_id = m.group(1)
                if len(race_id) == 12:
                    race_ids.add(race_id)
                    print(f"    - {race_id}: {href}")
        
        if not race_ids:
            print("  âš ï¸  No race IDs found! Checking HTML structure...")
            print("\n  ğŸ“‹ Sample HTML (first 1000 chars):")
            print(resp.text[:1000])
            
            # å…¨ã¦ã®ãƒªãƒ³ã‚¯ã‚’ç¢ºèª
            all_links = soup.find_all('a', href=True)
            print(f"\n  ğŸ”— Total links found: {len(all_links)}")
            if all_links:
                print("  Sample links:")
                for link in all_links[:10]:
                    print(f"    - {link.get('href')}")
        
        return list(race_ids)
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []


def test_nar_calendar(year=2025, month=12):
    """NARã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” Testing NAR Calendar: {year}/{month}")
    
    base_domain = "nar.netkeiba.com"
    cal_url = f"https://{base_domain}/top/calendar.html?year={year}&month={month}"
    
    session = requests.Session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        resp = session.get(cal_url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        print(f"  âœ… Status Code: {resp.status_code}")
        print(f"  ğŸ“„ Content Length: {len(resp.text)} chars")
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        day_links = soup.select('a[href*="race_list.html?kaisai_date="]')
        print(f"  ğŸ”— Found {len(day_links)} day links")
        
        dates = []
        for link in day_links[:5]:  # æœ€åˆã®5ã¤ã ã‘è¡¨ç¤º
            href = link.get('href')
            m = re.search(r'kaisai_date=(\d{8})', href)
            if m:
                date_str = m.group(1)
                dates.append(date_str)
                print(f"    - {date_str}: {href}")
        
        if not dates:
            print("  âš ï¸  No dates found! Checking HTML structure...")
            print("\n  ğŸ“‹ Sample HTML (first 1000 chars):")
            print(resp.text[:1000])
        
        return dates
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”§ ID Fetcher Diagnostic Tool")
    print("=" * 60)
    
    # JRAãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ“Š JRA Testing")
    print("=" * 60)
    
    jra_dates = test_jra_calendar(2025, 1)
    if jra_dates:
        print(f"\nâœ… Found {len(jra_dates)} dates in JRA calendar")
        # æœ€åˆã®æ—¥ä»˜ã§ãƒ¬ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚’ãƒ†ã‚¹ãƒˆ
        test_race_list(jra_dates[0])
    else:
        print("\nâŒ No dates found in JRA calendar - HTML structure may have changed")
    
    # NARãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ“Š NAR Testing")
    print("=" * 60)
    
    nar_dates = test_nar_calendar(2025, 12)
    if nar_dates:
        print(f"\nâœ… Found {len(nar_dates)} dates in NAR calendar")
    else:
        print("\nâŒ No dates found in NAR calendar - HTML structure may have changed")
    
    print("\n" + "=" * 60)
    print("ğŸ Diagnostic Complete")
    print("=" * 60)
