#!/usr/bin/env python3
"""
ä¿®æ­£å¾Œã®æ ãƒ»å©èˆå–å¾—ã‚’ãƒ†ã‚¹ãƒˆ
"""

import json
import requests
from bs4 import BeautifulSoup
import re

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰é–¢æ•°ã‚’æŠ½å‡ºã—ã¦ãƒ†ã‚¹ãƒˆ
notebook_path = "/Users/itoudaiki/Program/dai-keiba/notebooks/Colab_JRA_Basic_v2.ipynb"

with open(notebook_path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–¢æ•°ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å–å¾—
for cell in nb['cells']:
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        if 'def extract_metadata(' in source or 'def scrape_race_basic(' in source:
            exec(source)

# ãƒ†ã‚¹ãƒˆ
race_id = "202406050811"
print(f"ğŸ§ª æ ãƒ»å©èˆå–å¾—ãƒ†ã‚¹ãƒˆ (JRA)")
print(f"{'='*80}\n")
print(f"Race ID: {race_id}\n")

df = scrape_race_basic(race_id)

if df is not None:
    print(f"âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸ: {len(df)}é ­\n")
    
    # æ ã¨å©èˆã®å–å¾—çŠ¶æ³
    waku_filled = df['æ '].notna().sum() + (df['æ '] != '').sum()
    stable_filled = df['å©èˆ'].notna().sum() + (df['å©èˆ'] != '').sum()
    
    print(f"ğŸ“Š å–å¾—çŠ¶æ³:")
    print(f"  æ : {waku_filled}/{len(df)} ({waku_filled/len(df)*100:.0f}%)")
    print(f"  å©èˆ: {stable_filled}/{len(df)} ({stable_filled/len(df)*100:.0f}%)\n")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    print(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿(æœ€åˆã®3é ­):")
    print(df[['é¦¬å', 'æ ', 'å©èˆ']].head(3).to_string(index=False))
    
    if waku_filled == len(df) and stable_filled == len(df):
        print(f"\nâœ… æ ãƒ»å©èˆã¨ã‚‚ã«100%å–å¾—æˆåŠŸ!")
    else:
        print(f"\nâš ï¸ ä¸€éƒ¨æ¬ æã‚ã‚Š")
else:
    print(f"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—")
