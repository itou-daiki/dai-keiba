#!/usr/bin/env python3
"""
Êû†„Å®Âé©Ëàé„ÅÆ„Çª„É´‰ΩçÁΩÆ„ÇíÁ¢∫Ë™ç
"""

import requests
from bs4 import BeautifulSoup
import re

# JRA„É¨„Éº„Çπ
jra_race_id = "202406050811"
jra_url = f"https://race.netkeiba.com/race/result.html?race_id={jra_race_id}"

print("üîç JRA„É¨„Éº„ÇπÁµêÊûú„ÉÜ„Éº„Éñ„É´ÂàÜÊûê")
print(f"{'='*80}\n")

headers = {'User-Agent': 'Mozilla/5.0'}
resp = requests.get(jra_url, headers=headers, timeout=15)
resp.encoding = 'EUC-JP'
soup = BeautifulSoup(resp.text, 'html.parser')

# „É¨„Éº„ÇπÁµêÊûú„ÉÜ„Éº„Éñ„É´
tables = soup.find_all('table')
result_table = None
for t in tables:
    if 'ÁùÄÈ†Ü' in t.text and 'È¶¨Âêç' in t.text:
        result_table = t
        break

if result_table:
    rows = result_table.find_all('tr')
    
    # „Éò„ÉÉ„ÉÄ„ÉºË°å
    header_row = rows[0]
    headers_cells = header_row.find_all('th')
    print("üìã „Éò„ÉÉ„ÉÄ„Éº:")
    for i, th in enumerate(headers_cells):
        print(f"  {i}: {th.text.strip()}")
    
    # „Éá„Éº„ÇøË°å(ÊúÄÂàù„ÅÆÈ¶¨)
    print(f"\nüìã „Éá„Éº„ÇøË°å(ÊúÄÂàù„ÅÆÈ¶¨):")
    data_row = None
    for row in rows[1:]:
        cells = row.find_all('td')
        if len(cells) >= 10:
            data_row = row
            break
    
    if data_row:
        cells = data_row.find_all('td')
        print(f"  Á∑è„Çª„É´Êï∞: {len(cells)}\n")
        
        for i, cell in enumerate(cells):
            text = cell.text.strip()[:50]
            
            # Êû†Áï™„ÇíÊé¢„Åô
            if cell.find('img'):
                img = cell.find('img')
                if 'alt' in img.attrs:
                    print(f"  {i}: {text} (ÁîªÂÉèalt: {img['alt']})")
                else:
                    print(f"  {i}: {text} (ÁîªÂÉè„ÅÇ„Çä)")
            else:
                print(f"  {i}: {text}")
        
        # Êû†Áï™„ÅÆ‰ΩçÁΩÆ„ÇíÁâπÂÆö
        print(f"\nüîç Êû†Áï™:")
        for i, cell in enumerate(cells):
            img = cell.find('img')
            if img and 'alt' in img.attrs and 'Êû†' in img['alt']:
                print(f"  „Çª„É´{i}: {img['alt']}")
        
        # Âé©Ëàé„ÅÆ‰ΩçÁΩÆ„ÇíÁâπÂÆö
        print(f"\nüîç Âé©Ëàé:")
        for i, cell in enumerate(cells):
            text = cell.text.strip()
            if 'ÁæéÊµ¶' in text or 'Ê†óÊù±' in text or 'ÂåóÊµ∑ÈÅì' in text or 'ÂÖµÂ∫´' in text:
                print(f"  „Çª„É´{i}: {text}")

# NAR„É¨„Éº„Çπ
print(f"\n{'='*80}\n")
print("üîç NAR„É¨„Éº„ÇπÁµêÊûú„ÉÜ„Éº„Éñ„É´ÂàÜÊûê")
print(f"{'='*80}\n")

nar_race_id = "202030041501"
nar_url = f"https://nar.netkeiba.com/race/result.html?race_id={nar_race_id}"

resp2 = requests.get(nar_url, headers=headers, timeout=15)
resp2.encoding = 'EUC-JP'
soup2 = BeautifulSoup(resp2.text, 'html.parser')

tables2 = soup2.find_all('table')
result_table2 = None
for t in tables2:
    if 'ÁùÄÈ†Ü' in t.text and 'È¶¨Âêç' in t.text:
        result_table2 = t
        break

if result_table2:
    rows2 = result_table2.find_all('tr')
    
    # „Éò„ÉÉ„ÉÄ„ÉºË°å
    header_row2 = rows2[0]
    headers_cells2 = header_row2.find_all('th')
    print("üìã „Éò„ÉÉ„ÉÄ„Éº:")
    for i, th in enumerate(headers_cells2):
        print(f"  {i}: {th.text.strip()}")
    
    # „Éá„Éº„ÇøË°å
    print(f"\nüìã „Éá„Éº„ÇøË°å(ÊúÄÂàù„ÅÆÈ¶¨):")
    data_row2 = None
    for row in rows2[1:]:
        cells = row.find_all('td')
        if len(cells) >= 10:
            data_row2 = row
            break
    
    if data_row2:
        cells2 = data_row2.find_all('td')
        print(f"  Á∑è„Çª„É´Êï∞: {len(cells2)}\n")
        
        for i, cell in enumerate(cells2):
            text = cell.text.strip()[:50]
            
            if cell.find('img'):
                img = cell.find('img')
                if 'alt' in img.attrs:
                    print(f"  {i}: {text} (ÁîªÂÉèalt: {img['alt']})")
                else:
                    print(f"  {i}: {text} (ÁîªÂÉè„ÅÇ„Çä)")
            else:
                print(f"  {i}: {text}")
