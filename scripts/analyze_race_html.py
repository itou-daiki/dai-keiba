#!/usr/bin/env python3
"""
å®Ÿéš›ã®ãƒ¬ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ã‹ã‚‰å…¨ã¦ã®è¦ç´ ã‚’è©³ç´°ã«åˆ†æ
"""

import requests
from bs4 import BeautifulSoup
import re

def deep_analyze(race_id):
    """å¾¹åº•çš„ã«HTMLæ§‹é€ ã‚’åˆ†æ"""
    url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
    
    print(f"\n{'='*80}")
    print(f"ğŸ” å¾¹åº•åˆ†æ: {race_id}")
    print(f"{'='*80}\n")
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    resp = requests.get(url, headers=headers, timeout=15)
    resp.encoding = 'EUC-JP'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    # 1. ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æƒ…å ±æŠ½å‡º
    print("ğŸ“ ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«:")
    title = soup.title.text if soup.title else ""
    print(f"  {title}\n")
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰è§£æ
    if title:
        # ãƒ¬ãƒ¼ã‚¹å
        race_name_match = re.search(r'^([^|]+)', title)
        if race_name_match:
            print(f"  ãƒ¬ãƒ¼ã‚¹å: {race_name_match.group(1).strip()}")
        
        # æ—¥ä»˜
        date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', title)
        if date_match:
            print(f"  æ—¥ä»˜: {date_match.group(0)}")
        
        # ä¼šå ´
        venue_match = re.search(r'(æœ­å¹Œ|å‡½é¤¨|ç¦å³¶|æ–°æ½Ÿ|æ±äº¬|ä¸­å±±|ä¸­äº¬|äº¬éƒ½|é˜ªç¥|å°å€‰)', title)
        if venue_match:
            print(f"  ä¼šå ´: {venue_match.group(1)}")
        
        # ãƒ¬ãƒ¼ã‚¹ç•ªå·
        race_num_match = re.search(r'(\d+)R', title)
        if race_num_match:
            print(f"  ãƒ¬ãƒ¼ã‚¹ç•ªå·: {race_num_match.group(0)}")
    
    # 2. å…¨divã‚¯ãƒ©ã‚¹ã‚’åˆ—æŒ™
    print("\nğŸ“ ä¸»è¦ãªdivã‚¯ãƒ©ã‚¹:")
    for div in soup.find_all('div', class_=True)[:20]:
        classes = ' '.join(div.get('class', []))
        text = div.text.strip()[:50]
        if text:
            print(f"  .{classes}: {text}")
    
    # 3. ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
    print("\nğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«:")
    for elem in soup.select('dl.racedata, .race_otherdata, p.smalltxt'):
        print(f"  {elem.name}.{' '.join(elem.get('class', []))}: {elem.text.strip()[:100]}")
    
    # 4. æ­£è¦è¡¨ç¾ã§å…¨ä½“ã‹ã‚‰æŠ½å‡º
    print("\nğŸ“ æ­£è¦è¡¨ç¾ãƒãƒƒãƒ:")
    full_text = soup.text
    
    # å¤©å€™
    weather_match = re.search(r'å¤©å€™\s*[:ï¼š]\s*(\S+)', full_text)
    if weather_match:
        print(f"  å¤©å€™: {weather_match.group(1)}")
    
    # é¦¬å ´
    condition_match = re.search(r'é¦¬å ´\s*[:ï¼š]\s*(\S+)', full_text)
    if condition_match:
        print(f"  é¦¬å ´: {condition_match.group(1)}")
    
    # èŠ/ãƒ€ãƒ¼ãƒˆçŠ¶æ…‹
    turf_match = re.search(r'èŠ\s*[:ï¼š]\s*(\S+)', full_text)
    if turf_match:
        print(f"  èŠ: {turf_match.group(1)}")
    
    dirt_match = re.search(r'ãƒ€ãƒ¼ãƒˆ\s*[:ï¼š]\s*(\S+)', full_text)
    if dirt_match:
        print(f"  ãƒ€ãƒ¼ãƒˆ: {dirt_match.group(1)}")
    
    # ã‚³ãƒ¼ã‚¹
    course_match = re.search(r'(èŠ|ãƒ€ãƒ¼ãƒˆ|ãƒ€|éšœå®³)\s*(\d+)m', full_text)
    if course_match:
        print(f"  ã‚³ãƒ¼ã‚¹: {course_match.group(1)} {course_match.group(2)}m")
    
    # å›ã‚Š
    if 'å³' in full_text:
        print(f"  å›ã‚Š: å³")
    elif 'å·¦' in full_text:
        print(f"  å›ã‚Š: å·¦")

if __name__ == "__main__":
    # è¤‡æ•°ã®race_idã§ãƒ†ã‚¹ãƒˆ
    test_ids = [
        "202001010101",  # 2020å¹´ æœ­å¹Œ
        "202405050811",  # 2024å¹´ æ±äº¬(ã‚ˆã‚Šæ–°ã—ã„)
        "202030041501",  # NAR
    ]
    
    for rid in test_ids:
        deep_analyze(rid)
