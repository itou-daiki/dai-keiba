"""
ç®¡ç†ç”»é¢ï¼ˆç°¡ç´ ç‰ˆï¼‰- ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å°‚ç”¨

ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¯Google Colabã§å®Ÿè¡Œã—ã€
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯å­¦ç¿’ã¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚
"""

import streamlit as st
import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime

# ãƒ‘ã‚¹ã®è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(project_root, 'ml'))

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from db_helper import KeibaDatabase, get_data_stats
    import train_model  # å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯
except ImportError as e:
    st.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.info("train_model.py ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ml/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
    st.stop()

st.set_page_config(page_title="AIç«¶é¦¬ ç®¡ç†ç”»é¢ï¼ˆå­¦ç¿’å°‚ç”¨ï¼‰", layout="wide", page_icon="ğŸ‡")

st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ ç®¡ç†ç”»é¢ï¼ˆå­¦ç¿’å°‚ç”¨ï¼‰")

st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å°‚ç”¨ã§ã™ã€‚

**ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æµã‚Œ:**
1. ğŸ“Š **Google Colab**: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° + å‰å‡¦ç† + ç‰¹å¾´é‡ç”Ÿæˆ â†’ SQLite
2. ğŸ§  **ã“ã®ã‚¢ãƒ—ãƒª**: SQLiteã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ â†’ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜
3. ğŸŒ **å…¬é–‹ãƒšãƒ¼ã‚¸**: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ â†’ äºˆæ¸¬ â†’ è¡¨ç¤º
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
db_path = st.sidebar.text_input("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹", value="keiba_data.db")

# ãƒ¢ãƒ¼ãƒ‰é¸æŠ
mode_val = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰", ["JRA", "NAR"])

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å­˜åœ¨ç¢ºèª
if not os.path.exists(db_path):
    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
    st.info("""
    **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆæ–¹æ³•:**
    1. Google Colabã§ `colab_data_pipeline.ipynb` ã‚’é–‹ã
    2. ã™ã¹ã¦ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ
    3. ç”Ÿæˆã•ã‚ŒãŸ `keiba_data.db` ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    4. ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®
    """)
    st.stop()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
try:
    db = KeibaDatabase(db_path)
    stats = db.get_statistics(mode_val)
except Exception as e:
    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã®è¡¨ç¤º
st.sidebar.markdown("---")
st.sidebar.markdown(f"### ğŸ“Š {mode_val}ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
st.sidebar.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{stats['total_records']:,}")
st.sidebar.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°", f"{stats['unique_races']:,}")
st.sidebar.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯é¦¬æ•°", f"{stats['unique_horses']:,}")
st.sidebar.metric("å‹ç‡", f"{stats['win_rate']:.2%}")
st.sidebar.metric("ãƒ‡ãƒ¼ã‚¿é®®åº¦", db.get_data_freshness(mode_val))

st.sidebar.markdown("---")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
tab1, tab2 = st.tabs(["ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèª"])

# =============================================================================
# ã‚¿ãƒ–1: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# =============================================================================
with tab1:
    st.header("ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")

    st.markdown("""
    SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

    **å­¦ç¿’ã®è¨­å®š:**
    - TimeSeriesSplit 5-fold ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    - Early Stoppingï¼ˆ30ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
    - å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    """)

    # å­¦ç¿’è¨­å®š
    col1, col2 = st.columns(2)

    with col1:
        is_tuning = st.checkbox(
            "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆOptunaï¼‰",
            value=False,
            help="æœ‰åŠ¹ã«ã™ã‚‹ã¨å­¦ç¿’æ™‚é–“ãŒå¤§å¹…ã«å¢—åŠ ã—ã¾ã™ãŒã€ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™"
        )

    with col2:
        n_trials = 50
        if is_tuning:
            n_trials = st.slider("æœ€é©åŒ–è©¦è¡Œå›æ•°", 10, 200, 50, step=10)

    # å­¦ç¿’å®Ÿè¡Œãƒœã‚¿ãƒ³
    start_training = st.button("ğŸš€ å­¦ç¿’é–‹å§‹", type="primary", use_container_width=True)

    if start_training:
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        model_dir = os.path.join(project_root, "ml", "models")
        os.makedirs(model_dir, exist_ok=True)

        if mode_val == "NAR":
            model_name = "lgbm_model_nar.pkl"
        else:
            model_name = "lgbm_model.pkl"

        model_path = os.path.join(model_dir, model_name)

        try:
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            with st.spinner("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                df_train = db.get_processed_data(mode_val)
                st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df_train):,}ä»¶")

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
            meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
            feature_cols = [c for c in df_train.columns if c not in meta_cols and c not in ['target_win', 'target_top3']]

            X = df_train[feature_cols].fillna(0)
            y = df_train['target_win'].fillna(0)

            st.info(f"ğŸ“Š ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
            st.info(f"ğŸ¯ ç›®çš„å¤‰æ•°: target_winï¼ˆå‹ç‡: {y.mean():.2%}ï¼‰")

            # ä¸€æ™‚çš„ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆtrain_model.pyãŒCSVã‚’æœŸå¾…ã™ã‚‹ãŸã‚ï¼‰
            import tempfile
            temp_csv = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8')
            temp_csv_path = temp_csv.name
            df_train.to_csv(temp_csv_path, index=False)
            temp_csv.close()

            st.info(f"ğŸ“ ä¸€æ™‚CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {len(df_train):,}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")

            # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
            best_params = None
            if is_tuning:
                with st.spinner(f"âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ä¸­ï¼ˆ{n_trials}è©¦è¡Œï¼‰..."):
                    st.warning("ã“ã‚Œã«ã¯æ•°ååˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...")
                    try:
                        # Optunaæœ€é©åŒ–ã®å®Ÿè¡Œ
                        opt_result = train_model.optimize_hyperparameters(
                            temp_csv_path,
                            n_trials=n_trials,
                            use_timeseries_split=True
                        )

                        if opt_result:
                            best_params = opt_result['best_params']
                            st.success(f"âœ… æœ€é©åŒ–å®Œäº†: AUC={opt_result['best_auc']:.4f}")

                            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                            with st.expander("ğŸ” æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
                                st.json(best_params)
                        else:
                            st.warning("âš ï¸ æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã¾ã™")
                    except Exception as e:
                        st.error(f"âŒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                        import traceback
                        st.code(traceback.format_exc())

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            with st.spinner("ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­ï¼ˆTimeSeriesSplit 5-fold CV + å…¨ãƒ‡ãƒ¼ã‚¿å­¦ç¿’ï¼‰..."):
                try:
                    # TimeSeriesSplit CV + å­¦ç¿’
                    result = train_model.train_and_save_model(
                        data_path=temp_csv_path,
                        model_path=model_path,
                        params=best_params,
                        use_timeseries_split=True,
                        optimize_hyperparams=False,  # æ—¢ã«æœ€é©åŒ–æ¸ˆã¿ã®å ´åˆã¯False
                        find_threshold=True,
                        calibrate=False
                    )

                    if result:
                        st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†: {model_path}")

                        # å­¦ç¿’çµæœã‚’è¡¨ç¤º
                        st.markdown("### ğŸ“Š å­¦ç¿’çµæœ")

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("AUC", f"{result['auc']:.4f}")
                        with col2:
                            st.metric("Accuracy", f"{result['accuracy']:.4f}")
                        with col3:
                            st.metric("F1 Score", f"{result['f1']:.4f}")
                        with col4:
                            st.metric("å‹ç‡", f"{result['win_rate']:.2%}")

                        # CVçµæœã‚’è¡¨ç¤ºï¼ˆTimeSeriesSplitã®å ´åˆï¼‰
                        if result.get('cv_scores'):
                            st.markdown("#### ğŸ“ˆ äº¤å·®æ¤œè¨¼çµæœï¼ˆTimeSeriesSplit 5-foldï¼‰")
                            cv_df = pd.DataFrame({
                                'Metric': ['AUC', 'Accuracy', 'Precision', 'Recall', 'F1'],
                                'Mean': [
                                    f"{np.mean(result['cv_scores']['auc']):.4f}" if result['cv_scores'].get('auc') else 'N/A',
                                    f"{np.mean(result['cv_scores']['accuracy']):.4f}" if result['cv_scores'].get('accuracy') else 'N/A',
                                    f"{np.mean(result['cv_scores']['precision']):.4f}" if result['cv_scores'].get('precision') else 'N/A',
                                    f"{np.mean(result['cv_scores']['recall']):.4f}" if result['cv_scores'].get('recall') else 'N/A',
                                    f"{np.mean(result['cv_scores']['f1']):.4f}" if result['cv_scores'].get('f1') else 'N/A',
                                ],
                                'Std': [
                                    f"Â±{np.std(result['cv_scores']['auc']):.4f}" if result['cv_scores'].get('auc') else 'N/A',
                                    f"Â±{np.std(result['cv_scores']['accuracy']):.4f}" if result['cv_scores'].get('accuracy') else 'N/A',
                                    f"Â±{np.std(result['cv_scores']['precision']):.4f}" if result['cv_scores'].get('precision') else 'N/A',
                                    f"Â±{np.std(result['cv_scores']['recall']):.4f}" if result['cv_scores'].get('recall') else 'N/A',
                                    f"Â±{np.std(result['cv_scores']['f1']):.4f}" if result['cv_scores'].get('f1') else 'N/A',
                                ]
                            })
                            st.dataframe(cv_df, use_container_width=True)

                        # Feature Importanceã‚’è¡¨ç¤º
                        if result.get('feature_importance'):
                            with st.expander("ğŸ” é‡è¦ãªç‰¹å¾´é‡ TOP 20"):
                                fi_df = pd.DataFrame(result['feature_importance'])
                                st.dataframe(fi_df, use_container_width=True)
                    else:
                        st.error("âŒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ")

                except Exception as e:
                    st.error(f"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
                    import traceback
                    st.code(traceback.format_exc())
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    try:
                        os.remove(temp_csv_path)
                    except:
                        pass

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯ train_model.train_and_save_model() å†…ã§è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã™

            # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            st.balloons()
            st.success("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            st.code(traceback.format_exc())

# =============================================================================
# ã‚¿ãƒ–2: ãƒ‡ãƒ¼ã‚¿ç¢ºèª
# =============================================================================
with tab2:
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèª")

    st.markdown(f"### {mode_val}ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦")

    # çµ±è¨ˆæƒ…å ±
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{stats['total_records']:,}")
        st.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{stats['earliest_date']}")
    with col2:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°", f"{stats['unique_races']:,}")
        st.metric("ï½", f"{stats['latest_date']}")
    with col3:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯é¦¬æ•°", f"{stats['unique_horses']:,}")
        st.metric("å‹ç‡", f"{stats['win_rate']:.2%}")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    st.markdown("### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­10ä»¶ï¼‰")

    try:
        sample_df = db.get_processed_data(mode_val, limit=10)
        st.dataframe(sample_df, use_container_width=True)
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
    st.markdown("### ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ")

    try:
        features = db.get_feature_names(mode_val)
        st.info(f"ç‰¹å¾´é‡æ•°: {len(features)}")

        # ãƒ¡ã‚¿ã‚«ãƒ©ãƒ ã¨ç‰¹å¾´é‡ã‚’åˆ†é›¢
        meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †', 'target_win', 'target_top3']
        feature_cols = [f for f in features if f not in meta_cols]

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ãƒ¡ã‚¿ã‚«ãƒ©ãƒ :**")
            for col in meta_cols:
                if col in features:
                    st.text(f"â€¢ {col}")

        with col2:
            st.markdown(f"**äºˆæ¸¬ç‰¹å¾´é‡ï¼ˆ{len(feature_cols)}å€‹ï¼‰:**")
            for col in feature_cols[:20]:  # æœ€åˆã®20å€‹ã®ã¿è¡¨ç¤º
                st.text(f"â€¢ {col}")
            if len(feature_cols) > 20:
                st.text(f"... ä»– {len(feature_cols) - 20}å€‹")

    except Exception as e:
        st.error(f"ç‰¹å¾´é‡ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
**ğŸ“š ä½¿ã„æ–¹:**
1. Google Colabã§ `colab_data_pipeline.ipynb` ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
2. `keiba_data.db` ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«é…ç½®
3. ã“ã®ã‚¢ãƒ—ãƒªã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
4. å…¬é–‹ãƒšãƒ¼ã‚¸ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
""")
