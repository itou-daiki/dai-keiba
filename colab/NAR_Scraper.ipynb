{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# NAR Scraping Notebook\n",
                "\n",
                "地方競馬（NAR）のデータをスクレイピングし、Google Drive上のデータセットに追加します。"
            ],
            "metadata": {
                "id": "intro_md"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# 1. Google Driveのマウント\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# ★★★ 設定項目 ★★★\n",
                "# scraperフォルダが存在するパス (Google Drive上のパス)\n",
                "# 例: '/content/drive/MyDrive/dai-keiba'\n",
                "PROJECT_PATH = '/content/drive/MyDrive/dai-keiba'\n",
                "\n",
                "if not os.path.exists(PROJECT_PATH):\n",
                "    print(f\"Error: Path {PROJECT_PATH} does not exist. Please check your Drive structure.\")\n",
                "else:\n",
                "    print(f\"Project path found: {PROJECT_PATH}\")\n",
                "    os.chdir(PROJECT_PATH)\n",
                "    sys.path.append(PROJECT_PATH)\n"
            ],
            "metadata": {
                "id": "mount_drive"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 2. 必要なライブラリのインポート\n",
                "try:\n",
                "    import pandas as pd\n",
                "    import requests\n",
                "    import bs4\n",
                "except ImportError:\n",
                "    !pip install pandas requests beautifulsoup4\n",
                "    import pandas as pd\n",
                "    import requests\n",
                "    import bs4\n",
                "\n",
                "from datetime import datetime, date\n",
                "from scraper.auto_scraper import scrape_nar_year\n",
                "import time\n"
            ],
            "metadata": {
                "id": "imports"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 3. スクレイピング実行関数の定義\n",
                "\n",
                "def nar_scrape_execution(year_str, start_date=None, end_date=None):\n",
                "    CSV_FILE_PATH_NAR = os.path.join(PROJECT_PATH, \"database_nar.csv\")\n",
                "    print(f\"Using CSV Path: {CSV_FILE_PATH_NAR}\")\n",
                "\n",
                "    def save_callback(df_new):\n",
                "        if df_new is None or df_new.empty: return\n",
                "        \n",
                "        if os.path.exists(CSV_FILE_PATH_NAR):\n",
                "            try:\n",
                "                existing = pd.read_csv(CSV_FILE_PATH_NAR, dtype={'race_id': str, 'horse_id': str})\n",
                "                combined = pd.concat([existing, df_new], ignore_index=True)\n",
                "                # Deduplicate\n",
                "                if 'race_id' in combined.columns and '馬 番' in combined.columns:\n",
                "                    combined = combined.drop_duplicates(subset=['race_id', '馬 番'], keep='last')\n",
                "                combined.to_csv(CSV_FILE_PATH_NAR, index=False)\n",
                "                print(f\"  [Saved] {len(df_new)} rows added. Total: {len(combined)}\")\n",
                "            except Exception as e:\n",
                "                print(f\"Read Error: {e}, overwriting.\")\n",
                "                df_new.to_csv(CSV_FILE_PATH_NAR, index=False)\n",
                "        else:\n",
                "            df_new.to_csv(CSV_FILE_PATH_NAR, index=False)\n",
                "            print(f\"  [Created] {CSV_FILE_PATH_NAR} with {len(df_new)} rows.\")\n",
                "\n",
                "    print(f\"Starting NAR Scraping for {year_str} ({start_date} ~ {end_date})\")\n",
                "    \n",
                "    # Load existing IDs to skip\n",
                "    existing_ids = set()\n",
                "    if os.path.exists(CSV_FILE_PATH_NAR):\n",
                "        try:\n",
                "             df_e = pd.read_csv(CSV_FILE_PATH_NAR, usecols=['race_id'], dtype={'race_id': str})\n",
                "             existing_ids = set(df_e['race_id'].astype(str))\n",
                "             print(f\"  Loaded {len(existing_ids)} existing race IDs to skip.\")\n",
                "        except:\n",
                "             pass\n",
                "\n",
                "    scrape_nar_year(year_str, start_date=start_date, end_date=end_date, save_callback=save_callback, existing_race_ids=existing_ids)\n"
            ],
            "metadata": {
                "id": "def_exec"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 4. 実行パラメータの設定と開始\n",
                "# -----------------------------\n",
                "TARGET_YEAR = \"2024\"\n",
                "TARGET_MONTH = 1  # ★何月を取得するか指定 (Noneの場合は全期間、1〜12を指定)\n",
                "\n",
                "import calendar\n",
                "from datetime import date\n",
                "\n",
                "START_DATE = None\n",
                "END_DATE = None\n",
                "\n",
                "if TARGET_MONTH:\n",
                "    # 指定した月の1日〜末日を設定\n",
                "    _, last_day = calendar.monthrange(int(TARGET_YEAR), int(TARGET_MONTH))\n",
                "    START_DATE = date(int(TARGET_YEAR), int(TARGET_MONTH), 1)\n",
                "    END_DATE = date(int(TARGET_YEAR), int(TARGET_MONTH), last_day)\n",
                "    print(f\"Targeting specific month: {START_DATE} to {END_DATE}\")\n",
                "else:\n",
                "    # 自動判定ロジック (既存データの翌日から)\n",
                "    CSV_FILE_PATH_NAR = os.path.join(PROJECT_PATH, \"database_nar.csv\")\n",
                "    if os.path.exists(CSV_FILE_PATH_NAR):\n",
                "        try:\n",
                "            df_exist = pd.read_csv(CSV_FILE_PATH_NAR)\n",
                "            if '日付' in df_exist.columns and not df_exist.empty:\n",
                "                 df_exist['date_obj'] = pd.to_datetime(df_exist['日付'], format='%Y年%m月%d日', errors='coerce')\n",
                "                 last_date = df_exist['date_obj'].max()\n",
                "                 if pd.notna(last_date):\n",
                "                     START_DATE = last_date.date()\n",
                "                     print(f\"既存データの最終日時: {last_date.date()} -> 続きから取得します\")\n",
                "        except Exception as e:\n",
                "            print(f\"既存データ確認エラー: {e}\")\n",
                "\n",
                "print(f\"Scraping Target: {TARGET_YEAR}, Start: {START_DATE}, End: {END_DATE}\")\n",
                "nar_scrape_execution(TARGET_YEAR, start_date=START_DATE, end_date=END_DATE)\n"
            ],
            "metadata": {
                "id": "run_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 5. データ加工 (Feature Engineering) の実行\n",
                "# ----------------------------------------\n",
                "# スクレイピングした database_nar.csv から学習用データを生成します\n",
                "from ml.feature_engineering import calculate_features\n",
                "\n",
                "INPUT_CSV_NAR = os.path.join(PROJECT_PATH, \"database_nar.csv\")\n",
                "OUTPUT_CSV_NAR = os.path.join(PROJECT_PATH, \"processed_data_nar.csv\")\n",
                "\n",
                "if os.path.exists(INPUT_CSV_NAR):\n",
                "    print(\"Starting Feature Engineering (NAR)...\")\n",
                "    calculate_features(INPUT_CSV_NAR, OUTPUT_CSV_NAR)\n",
                "    print(\"Done!\")\n",
                "else:\n",
                "    print(\"Error: database_nar.csv not found.\")\n"
            ],
            "metadata": {
                "id": "feature_eng_nar"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}