"""
ç®¡ç†ç”»é¢ï¼ˆç°¡ç´ ç‰ˆï¼‰- ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å°‚ç”¨

ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¯Google Colabã§å®Ÿè¡Œã—ã€
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯å­¦ç¿’ã¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚
"""

import streamlit as st
import sys
import os
import pandas as pd
from datetime import datetime

# ãƒ‘ã‚¹ã®è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(project_root, 'ml'))

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import train_model
    from db_helper import KeibaDatabase, get_data_stats
except ImportError as e:
    st.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

st.set_page_config(page_title="AIç«¶é¦¬ ç®¡ç†ç”»é¢ï¼ˆå­¦ç¿’å°‚ç”¨ï¼‰", layout="wide", page_icon="ğŸ‡")

st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ ç®¡ç†ç”»é¢ï¼ˆå­¦ç¿’å°‚ç”¨ï¼‰")

st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å°‚ç”¨ã§ã™ã€‚

**ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æµã‚Œ:**
1. ğŸ“Š **Google Colab**: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° + å‰å‡¦ç† + ç‰¹å¾´é‡ç”Ÿæˆ â†’ SQLite
2. ğŸ§  **ã“ã®ã‚¢ãƒ—ãƒª**: SQLiteã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ â†’ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜
3. ğŸŒ **å…¬é–‹ãƒšãƒ¼ã‚¸**: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ â†’ äºˆæ¸¬ â†’ è¡¨ç¤º
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
db_path = st.sidebar.text_input("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹", value="keiba_data.db")

# ãƒ¢ãƒ¼ãƒ‰é¸æŠ
mode_val = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰", ["JRA", "NAR"])

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å­˜åœ¨ç¢ºèª
if not os.path.exists(db_path):
    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
    st.info("""
    **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆæ–¹æ³•:**
    1. Google Colabã§ `colab_data_pipeline.ipynb` ã‚’é–‹ã
    2. ã™ã¹ã¦ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ
    3. ç”Ÿæˆã•ã‚ŒãŸ `keiba_data.db` ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    4. ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®
    """)
    st.stop()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
try:
    db = KeibaDatabase(db_path)
    stats = db.get_statistics(mode_val)
except Exception as e:
    st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã®è¡¨ç¤º
st.sidebar.markdown("---")
st.sidebar.markdown(f"### ğŸ“Š {mode_val}ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
st.sidebar.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{stats['total_records']:,}")
st.sidebar.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°", f"{stats['unique_races']:,}")
st.sidebar.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯é¦¬æ•°", f"{stats['unique_horses']:,}")
st.sidebar.metric("å‹ç‡", f"{stats['win_rate']:.2%}")
st.sidebar.metric("ãƒ‡ãƒ¼ã‚¿é®®åº¦", db.get_data_freshness(mode_val))

st.sidebar.markdown("---")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
tab1, tab2 = st.tabs(["ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèª"])

# =============================================================================
# ã‚¿ãƒ–1: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# =============================================================================
with tab1:
    st.header("ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")

    st.markdown("""
    SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

    **å­¦ç¿’ã®è¨­å®š:**
    - TimeSeriesSplit 5-fold ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    - Early Stoppingï¼ˆ30ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
    - å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    """)

    # å­¦ç¿’è¨­å®š
    col1, col2 = st.columns(2)

    with col1:
        is_tuning = st.checkbox(
            "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆOptunaï¼‰",
            value=False,
            help="æœ‰åŠ¹ã«ã™ã‚‹ã¨å­¦ç¿’æ™‚é–“ãŒå¤§å¹…ã«å¢—åŠ ã—ã¾ã™ãŒã€ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™"
        )

    with col2:
        n_trials = 50
        if is_tuning:
            n_trials = st.slider("æœ€é©åŒ–è©¦è¡Œå›æ•°", 10, 200, 50, step=10)

    # å­¦ç¿’å®Ÿè¡Œãƒœã‚¿ãƒ³
    start_training = st.button("ğŸš€ å­¦ç¿’é–‹å§‹", type="primary", use_container_width=True)

    if start_training:
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        model_dir = os.path.join(project_root, "ml", "models")
        os.makedirs(model_dir, exist_ok=True)

        if mode_val == "NAR":
            model_name = "lgbm_model_nar.pkl"
        else:
            model_name = "lgbm_model.pkl"

        model_path = os.path.join(model_dir, model_name)

        try:
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            with st.spinner("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                df_train = db.get_processed_data(mode_val)
                st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df_train):,}ä»¶")

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
            meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
            feature_cols = [c for c in df_train.columns if c not in meta_cols and c not in ['target_win', 'target_top3']]

            X = df_train[feature_cols].fillna(0)
            y = df_train['target_win'].fillna(0)

            st.info(f"ğŸ“Š ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
            st.info(f"ğŸ¯ ç›®çš„å¤‰æ•°: target_winï¼ˆå‹ç‡: {y.mean():.2%}ï¼‰")

            # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
            best_params = None
            if is_tuning:
                with st.spinner(f"âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ä¸­ï¼ˆ{n_trials}è©¦è¡Œï¼‰..."):
                    st.warning("ã“ã‚Œã«ã¯æ•°ååˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...")
                    # Optunaæœ€é©åŒ–ã®å®Ÿè¡Œ
                    # æ³¨: train_model.pyã«æœ€é©åŒ–é–¢æ•°ãŒå¿…è¦
                    # opt_result = train_model.optimize_hyperparameters(X, y, n_trials=n_trials)
                    # best_params = opt_result['best_params']
                    st.info("âš ï¸ Optunaæœ€é©åŒ–ã¯ train_model.py ã«å®Ÿè£…ãŒå¿…è¦ã§ã™")

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            with st.spinner("ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­..."):
                # TimeSeriesSplit CV + å­¦ç¿’
                # æ³¨: train_model.pyã«å­¦ç¿’é–¢æ•°ãŒå¿…è¦
                # result = train_model.train_and_save_model(
                #     X, y,
                #     model_path=model_path,
                #     params=best_params
                # )
                st.info("âš ï¸ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¯ train_model.py ã«å®Ÿè£…ãŒå¿…è¦ã§ã™")

                # ä»®ã®æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†: {model_path}")

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
            meta_path = model_path.replace('.pkl', '_meta.json')
            import json

            metadata = {
                "model_id": f"lgbm_model_{mode_val.lower()}",
                "model_type": "LightGBM Binary Classification",
                "target": "target_win",
                "trained_at": datetime.now().isoformat(),
                "data_source": db_path,
                "data_stats": {
                    "total_records": len(df_train),
                    "win_rate": float(y.mean())
                },
                "features": feature_cols,
                "hyperparameters": best_params or {},
                "training_config": {
                    "use_timeseries_split": True,
                    "n_folds": 5,
                    "hyperparameter_optimization": is_tuning,
                    "n_trials": n_trials if is_tuning else None
                }
            }

            with open(meta_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            st.success(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {meta_path}")

            # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            st.balloons()
            st.success("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            st.code(traceback.format_exc())

# =============================================================================
# ã‚¿ãƒ–2: ãƒ‡ãƒ¼ã‚¿ç¢ºèª
# =============================================================================
with tab2:
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèª")

    st.markdown(f"### {mode_val}ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦")

    # çµ±è¨ˆæƒ…å ±
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{stats['total_records']:,}")
        st.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{stats['earliest_date']}")
    with col2:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°", f"{stats['unique_races']:,}")
        st.metric("ï½", f"{stats['latest_date']}")
    with col3:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯é¦¬æ•°", f"{stats['unique_horses']:,}")
        st.metric("å‹ç‡", f"{stats['win_rate']:.2%}")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    st.markdown("### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­10ä»¶ï¼‰")

    try:
        sample_df = db.get_processed_data(mode_val, limit=10)
        st.dataframe(sample_df, use_container_width=True)
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
    st.markdown("### ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ")

    try:
        features = db.get_feature_names(mode_val)
        st.info(f"ç‰¹å¾´é‡æ•°: {len(features)}")

        # ãƒ¡ã‚¿ã‚«ãƒ©ãƒ ã¨ç‰¹å¾´é‡ã‚’åˆ†é›¢
        meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †', 'target_win', 'target_top3']
        feature_cols = [f for f in features if f not in meta_cols]

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ãƒ¡ã‚¿ã‚«ãƒ©ãƒ :**")
            for col in meta_cols:
                if col in features:
                    st.text(f"â€¢ {col}")

        with col2:
            st.markdown(f"**äºˆæ¸¬ç‰¹å¾´é‡ï¼ˆ{len(feature_cols)}å€‹ï¼‰:**")
            for col in feature_cols[:20]:  # æœ€åˆã®20å€‹ã®ã¿è¡¨ç¤º
                st.text(f"â€¢ {col}")
            if len(feature_cols) > 20:
                st.text(f"... ä»– {len(feature_cols) - 20}å€‹")

    except Exception as e:
        st.error(f"ç‰¹å¾´é‡ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
**ğŸ“š ä½¿ã„æ–¹:**
1. Google Colabã§ `colab_data_pipeline.ipynb` ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
2. `keiba_data.db` ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«é…ç½®
3. ã“ã®ã‚¢ãƒ—ãƒªã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
4. å…¬é–‹ãƒšãƒ¼ã‚¸ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
""")
