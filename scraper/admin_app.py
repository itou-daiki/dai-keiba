import streamlit as st
import subprocess
import os
import sys
import pandas as pd
from datetime import date, datetime
import time
import plotly.graph_objects as go

# Add ml to path
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'ml'))
try:
    import train_model
except ImportError:
    st.error("Failed to import train_model. Make sure ml/train_model.py exists.")



# Set page config
st.set_page_config(page_title="JRA ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ‘ãƒãƒ«", layout="wide")

st.title("ğŸ‡ JRA ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç®¡ç†ãƒ‘ãƒãƒ«")
st.markdown("ã“ã“ã§JRAå…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€`database.csv` ã‚’æ›´æ–°ã—ã¾ã™ã€‚")

# --- Session State for Process Management ---
if 'process' not in st.session_state:
    st.session_state.process = None
if 'logs' not in st.session_state:
    st.session_state.logs = []
if 'is_running' not in st.session_state:
    st.session_state.is_running = False

# --- UI Layout (No Sidebar) ---
st.markdown("### âš™ï¸ è¨­å®š")

col1, col2 = st.columns(2)

with col1:
    year = st.selectbox("å¯¾è±¡å¹´", ["2025", "2024"], index=0, disabled=st.session_state.is_running)

with col2:
    default_start = date(int(year), 1, 1)
    default_end = date(int(year), 12, 31)
    
    date_range = st.date_input(
        "å–å¾—æœŸé–“ (é–‹å§‹æ—¥ - çµ‚äº†æ—¥)",
        value=(default_start, default_start),
        min_value=date(2020, 1, 1),
        max_value=date(2030, 12, 31),
        disabled=st.session_state.is_running
    )

start_date_str = ""
end_date_str = ""

if isinstance(date_range, tuple):
    if len(date_range) == 2:
        start_d, end_d = date_range
        start_date_str = start_d.strftime("%Y-%m-%d")
        end_date_str = end_d.strftime("%Y-%m-%d")
        st.info(f"é¸æŠç¯„å›²: {start_date_str} ã€œ {end_date_str}")
    elif len(date_range) == 1:
        st.warning("çµ‚äº†æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
else:
    st.warning("æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")

col_btn_1, col_btn_2 = st.columns([1, 1])

with col_btn_1:
    if st.button("ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", type="primary", disabled=st.session_state.is_running):
        if not start_date_str or not end_date_str:
            st.error("æœ‰åŠ¹ãªæœŸé–“ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state.is_running = True
            st.session_state.logs = []
            
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            cmd = [
                sys.executable, "-u", "scraper/auto_scraper.py", 
                "--jra_year", year,
                "--jra_date_start", start_date_str,
                "--jra_date_end", end_date_str
            ]
            
            try:
                # Use Popen
                p = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                    cwd=project_root
                )
                st.session_state.process = p
                st.rerun()
                
            except Exception as e:
                st.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                st.session_state.is_running = False

with col_btn_2:
    if st.button("ğŸ›‘ åœæ­¢", type="secondary", disabled=not st.session_state.is_running):
        if st.session_state.process:
            st.session_state.process.terminate()
            st.session_state.process = None
        st.session_state.is_running = False
        st.error("å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
        st.rerun()

# --- Log Streaming Area ---
st.markdown("### ğŸ“œ å®Ÿè¡Œãƒ­ã‚°")
log_container = st.empty()

if st.session_state.is_running and st.session_state.process:
    p = st.session_state.process
    # Read output non-blocking? logic in Streamlit loop is tricky.
    # We loop here reading one line at a time then rerun? No, that hangs UI.
    # Streamlit runs top-down. We can read available lines.
    
    import fcntl
    
    # Set non-blocking
    fd = p.stdout.fileno()
    fl = fcntl.fcntl(fd, fcntl.F_GETFL)
    fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
    
    try:
        # Read all available
        chunk = p.stdout.read()
        if chunk:
            for line in chunk.splitlines():
                if line:
                    st.session_state.logs.append(line)
    except Exception:
        pass
        
    # Check if finished
    if p.poll() is not None:
        st.session_state.is_running = False
        st.session_state.process = None
        st.success("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.rerun()
    else:
        # Rerun to keep updating logs
        time.sleep(0.5)
        st.rerun()

# Display logs
if st.session_state.logs:
    log_text = "\n".join(st.session_state.logs[-20:])
    log_container.code(log_text)

# --- Data Preview ---
st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
csv_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "database.csv")

col_prev_1, col_prev_2 = st.columns([1, 4])
with col_prev_1:
    if st.button("ğŸ”„ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"):
        st.rerun()

if os.path.exists(csv_path):
    try:
        df = pd.read_csv(csv_path)
        st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•° (è¡Œ)", len(df))
        st.dataframe(df.tail(20), use_container_width=True)
    except Exception as e:
        st.error(f"database.csv ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {e}")
else:
    st.warning("database.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

st.markdown("---")
st.caption("ä½¿ã„æ–¹: ãƒ‡ãƒ¼ã‚¿å–å¾—å¾Œã€å¿…ãš git ã§å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦å…¬é–‹ã‚µã‚¤ãƒˆã«åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚")

# --- ML Management Section ---
st.markdown("---")
st.markdown("## ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç† (MLOps)")

# MLflow Instructions
with st.expander("â„¹ï¸ MLflow (å®Ÿé¨“ç®¡ç†) ã®ä½¿ã„æ–¹"):
    st.markdown("""
    å®Ÿé¨“ã®å±¥æ­´ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç²¾åº¦ã€ãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ **MLflow** ã§è‡ªå‹•è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚
    è©³ç´°ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ãã ã•ã„ã€‚
    ```bash
    mlflow ui
    ```
    (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ãƒˆ: http://127.0.0.1:5000)
    """)

tab_train, tab_tune, tab_upload = st.tabs(["ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ§ª ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Optuna)", "ğŸ“¤ ãƒªãƒã‚¸ãƒˆãƒªæ›´æ–°"])

# --- Tab 1: Training ---
with tab_train:
    st.markdown("### ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    
    # Use best params if available
    use_best_params = False
    if 'best_params' in st.session_state:
        st.success("âœ… ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸæœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
        use_best_params = st.checkbox("æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ã™ã‚‹", value=True)
        if use_best_params:
            st.json(st.session_state['best_params'])
    
    if st.button("ğŸ§  ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹", type="primary"):
        with st.spinner("å­¦ç¿’ä¸­..."):
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            data_path = os.path.join(project_root, "ml", "processed_data.csv")
            model_dir = os.path.join(project_root, "ml", "models")
            os.makedirs(model_dir, exist_ok=True)
            model_path = os.path.join(model_dir, "lgbm_model.pkl")
            
            params = st.session_state['best_params'] if use_best_params else None
            
            if not os.path.exists(data_path):
                st.error(f"ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
            else:
                try:
                    results = train_model.train_and_save_model(data_path, model_path, params=params)
                    if results:
                        st.success("å­¦ç¿’å®Œäº†ï¼")
                        st.session_state['ml_results'] = results
                    else:
                        st.error("å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã©ï¼‰ã€‚")
                except Exception as e:
                    st.error(f"å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    if 'ml_results' in st.session_state:
        res = st.session_state['ml_results']
        
        # Metrics
        st.markdown("#### å­¦ç¿’çµæœ")
        m_col1, m_col2, m_col3 = st.columns(3)
        m_col1.metric("Accuracy", f"{res['accuracy']:.4f}")
        m_col2.metric("AUC", f"{res['auc']:.4f}")
        m_col3.metric("Positive Rate", f"{res['positive_rate']:.2%}")
        
        # Plots
        st.markdown("#### è©³ç´°åˆ†æ")
        p_col1, p_col2 = st.columns(2)
        
        with p_col1:
            # Learning Curve
            if 'evals_result' in res and res['evals_result']:
                evals = res['evals_result']
                if 'train' in evals and 'auc' in evals['train']:
                    fig_lc = go.Figure()
                    fig_lc.add_trace(go.Scatter(y=evals['train']['auc'], mode='lines', name='Train AUC'))
                    if 'valid' in evals and 'auc' in evals['valid']:
                        fig_lc.add_trace(go.Scatter(y=evals['valid']['auc'], mode='lines', name='Valid AUC'))
                    fig_lc.update_layout(title="å­¦ç¿’æ›²ç·š (AUC)", xaxis_title="Rounds", yaxis_title="AUC")
                    st.plotly_chart(fig_lc, use_container_width=True)
                else:
                    st.info("å­¦ç¿’å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.info("å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        with p_col2:
            # Feature Importance
            if 'feature_importance' in res:
                fi = pd.DataFrame(res['feature_importance'])
                if not fi.empty:
                    fig_fi = go.Figure(go.Bar(
                        x=fi['Value'],
                        y=fi['Feature'],
                        orientation='h'
                    ))
                    fig_fi.update_layout(
                        title="ç‰¹å¾´é‡é‡è¦åº¦ (Top 20)",
                        yaxis=dict(autorange="reversed"),
                        xaxis_title="Importance (Gain)"
                    )
                    st.plotly_chart(fig_fi, use_container_width=True)
                else:
                    st.info("ç‰¹å¾´é‡é‡è¦åº¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# --- Tab 2: Tuning ---
with tab_tune:
    st.markdown("### ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è‡ªå‹•æ¢ç´¢ (Optuna)")
    st.info("AIãŒæ§˜ã€…ãªè¨­å®šã‚’è©¦ã—ã¦ã€ç²¾åº¦(AUC)ãŒæœ€ã‚‚é«˜ããªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚")
    
    n_trials = st.slider("è©¦è¡Œå›æ•° (å¤šã„ã»ã©é«˜ç²¾åº¦ã§ã™ãŒæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)", 5, 100, 20)
    
    if st.button("ğŸ§ª ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã™ã‚‹"):
        with st.spinner(f"æœ€é©åŒ–ä¸­... {n_trials}å›ã®è©¦è¡Œã‚’è¡Œã„ã¾ã™ã€‚"):
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            data_path = os.path.join(project_root, "ml", "processed_data.csv")
            
            try:
                opt_res = train_model.optimize_hyperparameters(data_path, n_trials=n_trials)
                if opt_res:
                    st.success(f"æœ€é©åŒ–å®Œäº†ï¼ Best AUC: {opt_res['best_auc']:.4f}")
                    st.session_state['best_params'] = opt_res['best_params']
                    st.json(opt_res['best_params'])
                    st.markdown("ğŸ‘‰ **ã€Œãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ã‚¿ãƒ–ã«æˆ»ã£ã¦ã€ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚**")
                else:
                    st.error("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- Tab 3: Upload ---
with tab_upload:
    st.markdown("### ãƒªãƒã‚¸ãƒˆãƒªã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.warning("âš ï¸ Gitã®è¨­å®šï¼ˆSSHéµãªã©ï¼‰ãŒã‚µãƒ¼ãƒãƒ¼ä¸Šã§æ­£ã—ãè¡Œã‚ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
    
    commit_msg = st.text_input("ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", value=f"Update model: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    if st.button("ğŸ“¤ ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (Git Push)"):
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_path_rel = "ml/models/lgbm_model.pkl" # Relative to root
        
        cmds = [
            ["git", "add", model_path_rel],
            ["git", "commit", "-m", commit_msg],
            ["git", "push", "origin", "main"] # Start with main
        ]
        
        st.markdown("#### å®Ÿè¡Œãƒ­ã‚°")
        status_area = st.empty()
        
        all_success = True
        for cmd in cmds:
            try:
                result = subprocess.run(cmd, cwd=project_root, capture_output=True, text=True)
                if result.returncode == 0:
                    status_area.success(f"OK: {' '.join(cmd)}")
                else:
                    # git commit returns 1 if nothing to commit, which is fine-ish but we should warn
                    if "nothing to commit" in result.stdout:
                         status_area.info(f"Info: {result.stdout}")
                    else:
                        status_area.error(f"Error: {' '.join(cmd)}\n{result.stderr}")
                        all_success = False
                        break
            except Exception as e:
                status_area.error(f"Command failed: {e}")
                all_success = False
                break
        
        if all_success:
            st.success("âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")

