import streamlit as st
import subprocess
import os
import sys
import pandas as pd
from datetime import date, datetime
import time
import plotly.graph_objects as go

# Add ml to path
# Add ml to path
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'ml'))
try:
    import train_model
    import feature_engineering
    import importlib
    importlib.reload(train_model)
    importlib.reload(feature_engineering)
except ImportError:
    st.error("Failed to import train_model. Make sure ml/train_model.py exists.")



# Set page config
st.set_page_config(page_title="JRA ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ‘ãƒãƒ«", layout="wide")

st.title("ğŸ‡ JRA ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç®¡ç†ãƒ‘ãƒãƒ«")
st.markdown("ã“ã“ã§JRAå…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€`database.csv` ã‚’æ›´æ–°ã—ã¾ã™ã€‚")

# --- Session State for Process Management ---
if 'process' not in st.session_state:
    st.session_state.process = None
if 'logs' not in st.session_state:
    st.session_state.logs = []
if 'is_running' not in st.session_state:
    st.session_state.is_running = False

# --- UI Layout (No Sidebar) ---
st.markdown("### âš™ï¸ è¨­å®š")

col1, col2 = st.columns(2)

with col1:
    year = st.selectbox("å¯¾è±¡å¹´", ["2025", "2024"], index=0, disabled=st.session_state.is_running)

with col2:
    default_start = date(int(year), 1, 1)
    default_end = date(int(year), 12, 31)
    
    date_range = st.date_input(
        "å–å¾—æœŸé–“ (é–‹å§‹æ—¥ - çµ‚äº†æ—¥)",
        value=(default_start, default_start),
        min_value=date(2020, 1, 1),
        max_value=date(2030, 12, 31),
        disabled=st.session_state.is_running
    )

start_date_str = ""
end_date_str = ""

if isinstance(date_range, tuple):
    if len(date_range) == 2:
        start_d, end_d = date_range
        start_date_str = start_d.strftime("%Y-%m-%d")
        end_date_str = end_d.strftime("%Y-%m-%d")
        st.info(f"é¸æŠç¯„å›²: {start_date_str} ã€œ {end_date_str}")
    elif len(date_range) == 1:
        st.warning("çµ‚äº†æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
else:
    st.warning("æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")

col_btn_1, col_btn_2 = st.columns([1, 1])

with col_btn_1:
    if st.button("ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", type="primary", disabled=st.session_state.is_running):
        if not start_date_str or not end_date_str:
            st.error("æœ‰åŠ¹ãªæœŸé–“ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state.is_running = True
            st.session_state.logs = []
            
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            cmd = [
                sys.executable, "-u", "scraper/auto_scraper.py", 
                "--start", start_date_str,
                "--end", end_date_str
            ]
            
            try:
                # Use Popen
                p = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                    cwd=project_root
                )
                st.session_state.process = p
                st.rerun()
                
            except Exception as e:
                st.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                st.session_state.is_running = False

with col_btn_2:
    if st.button("ğŸ›‘ åœæ­¢", type="secondary", disabled=not st.session_state.is_running):
        if st.session_state.process:
            st.session_state.process.terminate()
            st.session_state.process = None
        st.session_state.is_running = False
        st.error("å‡¦ç†ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
        st.rerun()

# --- Log Streaming Area ---
st.markdown("### ğŸ“œ å®Ÿè¡Œãƒ­ã‚°")
log_container = st.empty()

if st.session_state.is_running and st.session_state.process:
    p = st.session_state.process
    # Read output non-blocking? logic in Streamlit loop is tricky.
    # We loop here reading one line at a time then rerun? No, that hangs UI.
    # Streamlit runs top-down. We can read available lines.
    
    import fcntl
    
    # Set non-blocking
    fd = p.stdout.fileno()
    fl = fcntl.fcntl(fd, fcntl.F_GETFL)
    fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
    
    try:
        # Read all available
        chunk = p.stdout.read()
        if chunk:
            for line in chunk.splitlines():
                if line:
                    st.session_state.logs.append(line)
    except Exception:
        pass
        
    # Check if finished
    if p.poll() is not None:
        st.session_state.is_running = False
        st.session_state.process = None
        st.success("å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        st.rerun()
    else:
        # Rerun to keep updating logs
        time.sleep(0.5)
        st.rerun()

# Display logs
if st.session_state.logs:
    log_text = "\n".join(st.session_state.logs[-20:])
    log_container.code(log_text)

# --- Data Preview ---
st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
csv_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "database.csv")

col_prev_1, col_prev_2 = st.columns([1, 4])
with col_prev_1:
    if st.button("ğŸ”„ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"):
        st.rerun()

if os.path.exists(csv_path):
    try:
        df = pd.read_csv(csv_path)
        st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•° (è¡Œ)", len(df))
        st.dataframe(df,use_container_width=True)
    except Exception as e:
        st.error(f"database.csv ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {e}")
else:
    st.warning("database.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

st.markdown("---")
st.caption("ä½¿ã„æ–¹: ãƒ‡ãƒ¼ã‚¿å–å¾—å¾Œã€å¿…ãš git ã§å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦å…¬é–‹ã‚µã‚¤ãƒˆã«åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚")

# --- ML Management Section ---
st.markdown("---")
st.markdown("## ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç† (MLOps)")

# MLflow Instructions
with st.expander("â„¹ï¸ MLflow (å®Ÿé¨“ç®¡ç†) ã®ä½¿ã„æ–¹"):
    st.markdown("""
    å®Ÿé¨“ã®å±¥æ­´ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç²¾åº¦ã€ãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ **MLflow** ã§è‡ªå‹•è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚
    è©³ç´°ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦ãã ã•ã„ã€‚
    ```bash
    mlflow ui
    ```
    (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ãƒˆ: http://127.0.0.1:5000)
    """)

tab_ml, tab_upload = st.tabs(["ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ & ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", "ğŸ“¤ ãƒªãƒã‚¸ãƒˆãƒªæ›´æ–°"])

# --- Tab 1: ML (Training & Tuning) ---
with tab_ml:
    st.markdown("### ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®è¨­å®š")
    
    col_conf_1, col_conf_2 = st.columns(2)
    
    with col_conf_1:
        is_tuning = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Optuna) ã‚’å®Ÿè¡Œã™ã‚‹", value=False)
        
        n_trials = 20
        if is_tuning:
            st.info("AIãŒæœ€é©ãªè¨­å®šã‚’æ¢ç´¢ã—ã¦ã‹ã‚‰å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚")
            n_trials = st.slider("è©¦è¡Œå›æ•°", 5, 100, 20)
        else:
            if 'best_params' in st.session_state:
                st.success("âœ… å‰å›ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸæœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚")
                if st.checkbox("æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç ´æ£„ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™"):
                    del st.session_state['best_params']
                    st.rerun()
            else:
                st.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å­¦ç¿’ã—ã¾ã™ã€‚")

    with col_conf_2:
        st.markdown(f"""
        **å®Ÿè¡Œå†…å®¹:**
        1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç† (æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®åæ˜ )
        2. {'ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (æœ€é©åŒ–)' if is_tuning else 'è¨­å®šã®ç¢ºèª'}
        3. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ (LightGBM)
        """)
        
        btn_label = "ğŸ§ª ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ï¼† å­¦ç¿’é–‹å§‹" if is_tuning else "ğŸ§  å­¦ç¿’é–‹å§‹"
        start_process = st.button(btn_label, type="primary")

    if start_process:
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        data_path = os.path.join(project_root, "ml", "processed_data.csv")
        db_path = os.path.join(project_root, "database.csv")
        model_dir = os.path.join(project_root, "ml", "models")
        os.makedirs(model_dir, exist_ok=True)
        model_path = os.path.join(model_dir, "lgbm_model.pkl")

        # 1. Preprocess
        with st.spinner("1/3 ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­..."):
            if os.path.exists(db_path):
               feature_engineering.calculate_features(db_path, data_path)
            else:
               st.error("database.csvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
               st.stop()
        
        # 2. Tuning (if selected)
        if is_tuning:
            with st.spinner(f"2/3 ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ ({n_trials} trials)..."):
                try:
                    opt_res = train_model.optimize_hyperparameters(data_path, n_trials=n_trials)
                    if opt_res:
                        st.success(f"æœ€é©åŒ–å®Œäº†ï¼ Best AUC: {opt_res['best_auc']:.4f}")
                        st.session_state['best_params'] = opt_res['best_params']
                    else:
                        st.error("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å­¦ç¿’ã‚’ç¶šè¡Œã—ã¾ã™ã€‚")
                except Exception as e:
                     st.error(f"æœ€é©åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 3. Training
        step_label = "3/3" if is_tuning else "2/2"
        with st.spinner(f"{step_label} ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­..."):
            params = st.session_state.get('best_params', None)
            
            try:
                results = train_model.train_and_save_model(data_path, model_path, params=params)
                if results:
                    st.success("å­¦ç¿’å®Œäº†ï¼")
                    st.session_state['ml_results'] = results
                else:
                    st.error("å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    # Display Results
    if 'ml_results' in st.session_state:
        st.markdown("---")
        res = st.session_state['ml_results']
        
        st.markdown("#### ğŸ“Š å­¦ç¿’çµæœãƒ¬ãƒãƒ¼ãƒˆ")
        m_col1, m_col2, m_col3 = st.columns(3)
        m_col1.metric("Accuracy", f"{res['accuracy']:.4f}")
        m_col2.metric("AUC", f"{res['auc']:.4f}")
        m_col3.metric("Positive Rate", f"{res['positive_rate']:.2%}")
        
        p_col1, p_col2 = st.columns(2)
        with p_col1:
            if 'evals_result' in res and res['evals_result']:
                evals = res['evals_result']
                if 'train' in evals and 'auc' in evals['train']:
                    fig_lc = go.Figure()
                    fig_lc.add_trace(go.Scatter(y=evals['train']['auc'], mode='lines', name='Train AUC'))
                    if 'valid' in evals and 'auc' in evals['valid']:
                        fig_lc.add_trace(go.Scatter(y=evals['valid']['auc'], mode='lines', name='Valid AUC'))
                    fig_lc.update_layout(title="å­¦ç¿’æ›²ç·š (AUC)", xaxis_title="Rounds", yaxis_title="AUC")
                    st.plotly_chart(fig_lc, use_container_width=True)
            else:
                st.info("å­¦ç¿’å±¥æ­´ãªã—")

        with p_col2:
            if 'feature_importance' in res:
                fi = pd.DataFrame(res['feature_importance'])
                if not fi.empty:
                    fig_fi = go.Figure(go.Bar(
                        x=fi['Value'], y=fi['Feature'], orientation='h'
                    ))
                    fig_fi.update_layout(
                        title="ç‰¹å¾´é‡é‡è¦åº¦ (Top 20)",
                        yaxis=dict(autorange="reversed"),
                        xaxis_title="Importance (Gain)"
                    )
                    st.plotly_chart(fig_fi, use_container_width=True)
            else:
                st.info("ç‰¹å¾´é‡é‡è¦åº¦ãªã—")



# --- Tab 3: Upload ---
with tab_upload:
    st.markdown("### ãƒªãƒã‚¸ãƒˆãƒªã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.warning("âš ï¸ Gitã®è¨­å®šï¼ˆSSHéµãªã©ï¼‰ãŒã‚µãƒ¼ãƒãƒ¼ä¸Šã§æ­£ã—ãè¡Œã‚ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
    
    commit_msg = st.text_input("ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", value=f"Update model: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    if st.button("ğŸ“¤ ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (Git Push)"):
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        model_path_rel = "ml/models/lgbm_model.pkl" # Relative to root
        
        cmds = [
            ["git", "add", model_path_rel],
            ["git", "commit", "-m", commit_msg],
            ["git", "push", "origin", "main"] # Start with main
        ]
        
        st.markdown("#### å®Ÿè¡Œãƒ­ã‚°")
        status_area = st.empty()
        
        all_success = True
        for cmd in cmds:
            try:
                result = subprocess.run(cmd, cwd=project_root, capture_output=True, text=True)
                if result.returncode == 0:
                    status_area.success(f"OK: {' '.join(cmd)}")
                else:
                    # git commit returns 1 if nothing to commit, which is fine-ish but we should warn
                    if "nothing to commit" in result.stdout:
                         status_area.info(f"Info: {result.stdout}")
                    else:
                        status_area.error(f"Error: {' '.join(cmd)}\n{result.stderr}")
                        all_success = False
                        break
            except Exception as e:
                status_area.error(f"Command failed: {e}")
                all_success = False
                break
        
        if all_success:
            st.success("âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")

