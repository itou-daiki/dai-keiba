# ğŸ¯ ç²¾åº¦æŒ‡æ¨™ å®Œå…¨æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ

**æ¤œè¨¼æ—¥:** 2025-12-28
**å¯¾è±¡:** dai-keiba ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ å…¨ç²¾åº¦æŒ‡æ¨™
**æ¤œè¨¼è€…:** Claude (Sonnet 4.5)
**æœ€é‡è¦ç›®çš„:** **çš„ä¸­äºˆæ¸¬ç²¾åº¦ã®æ­£ç¢ºãªæ¸¬å®šã¨æ”¹å–„**

---

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

**ç·åˆåˆ¤å®š:** âš ï¸ **ç²¾åº¦æŒ‡æ¨™ã®è¨ˆç®—ã¯é©åˆ‡ã ãŒã€ç¢ºç‡è¼ƒæ­£ãŒæœªå®Ÿè¡Œ**

### ä¸»è¦ãªç™ºè¦‹

âœ… **é©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ç‚¹:**
1. å…¨ç²¾åº¦æŒ‡æ¨™ãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ï¼ˆAUC, Precision, Recall, F1, Brier Score, Log Lossï¼‰
2. TimeSeriesSplitã§äº¤å·®æ¤œè¨¼ã‚’å®Ÿæ–½
3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ç²¾åº¦æƒ…å ±ã‚’é©åˆ‡ã«ä¿å­˜
4. ç¢ºç‡è¼ƒæ­£ã®å®Ÿè£…ã¯å®Œç’§ï¼ˆcalibrate_probabilitiesé–¢æ•°ï¼‰

âš ï¸ **æ”¹å–„ãŒå¿…è¦ãªç‚¹:**
1. **ä¸¡ãƒ¢ãƒ‡ãƒ«ï¼ˆJRA/NARï¼‰ã¨ã‚‚ç¢ºç‡è¼ƒæ­£ãŒæœªå®Ÿè¡Œ** (`"calibrated": false`)
2. ç¢ºç‡è¼ƒæ­£ã«ã‚ˆã‚Š Brier Score 10-30%æ”¹å–„ã®è¦‹è¾¼ã¿
3. Log Loss ã‚‚æ”¹å–„ã®ä½™åœ°ã‚ã‚Š

---

## ğŸ“Š ç²¾åº¦æŒ‡æ¨™ã‚«ã‚¿ãƒ­ã‚°

### 1. AUC (Area Under the ROC Curve)

**å®šç¾©:** ROCæ›²ç·šä¸‹ã®é¢ç©ã€‚0.5ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰ï½1.0ï¼ˆå®Œç’§ï¼‰ã®ç¯„å›²ã€‚

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:230, 329, 621, 814`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import roc_auc_score

# TimeSeriesSplit CVå†…ã§ã®è¨ˆç®—ï¼ˆtrain_model.py:230ï¼‰
y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)
cv_scores['auc'].append(roc_auc_score(y_test, y_pred))

# æœ€çµ‚è©•ä¾¡ï¼ˆtrain_model.py:329ï¼‰
auc = roc_auc_score(y_test, y_pred)
```

**ä½¿ç”¨ç®‡æ‰€:**
- å­¦ç¿’ãƒ­ã‚°å‡ºåŠ›ï¼ˆtrain_model.py:337ï¼‰
- MLflowã¸ã®ãƒ­ã‚°è¨˜éŒ²ï¼ˆtrain_model.py:347ï¼‰
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆtrain_model.py:421ï¼‰
- UIã§ã®è¡¨ç¤ºï¼ˆpublic_app.py:551, admin_app.py:425ï¼‰
- ä¿¡é ¼åº¦è¨ˆç®—ã¸ã®å½±éŸ¿ï¼ˆpublic_app.py:104ï¼‰

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.8909 â­â­â­â­â­ï¼ˆå„ªç§€ï¼‰
  - CVå¹³å‡: 0.7502 (std: 0.0174)
- **NARãƒ¢ãƒ‡ãƒ«:** 0.8745 â­â­â­â­ï¼ˆè‰¯å¥½ï¼‰
  - CVå¹³å‡: 0.7394 (std: 0.0094)

**è§£é‡ˆ:**
- 0.89ã¯æ¥­ç•Œæ¨™æº–ã§ã€Œå„ªç§€ã€ãƒ¬ãƒ™ãƒ«
- ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆ0.5ï¼‰ã®78%å‘ä¸Š
- å‹ã¡é¦¬ã‚’89%ã®ç¢ºç‡ã§æ­£ã—ããƒ©ãƒ³ã‚¯ä»˜ã‘

**å¦¥å½“æ€§:** âœ… **å®Œç’§**
- scikit-learnã®æ¨™æº–å®Ÿè£…ã‚’ä½¿ç”¨
- ç¢ºç‡å€¤ï¼ˆ0-1ï¼‰ã‚’ç›´æ¥å…¥åŠ›
- 2å€¤åˆ†é¡ã«æœ€é©ãªæŒ‡æ¨™

---

### 2. Accuracyï¼ˆæ­£è§£ç‡ï¼‰

**å®šç¾©:** å…¨äºˆæ¸¬ã®ã†ã¡æ­£è§£ã—ãŸå‰²åˆã€‚(TP + TN) / (TP + TN + FP + FN)

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:231, 323, 813`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import accuracy_score

# é–¾å€¤0.5ã§2å€¤åŒ–
y_pred_binary = (y_pred > 0.5).astype(int)

# æ­£è§£ç‡è¨ˆç®—ï¼ˆtrain_model.py:323ï¼‰
acc = accuracy_score(y_test, y_pred_binary)
```

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.9350ï¼ˆ93.5%ï¼‰
  - CVå¹³å‡: 0.9239 (std: 0.0023)
- **NARãƒ¢ãƒ‡ãƒ«:** 0.9069ï¼ˆ90.7%ï¼‰
  - CVå¹³å‡: 0.8883 (std: 0.0053)

**è§£é‡ˆ:**
- 93.5%ã¯ä¸€è¦‹é«˜ã„ãŒã€ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯èª¤è§£ã‚’æ‹›ã
- å‹ç‡7.27%ã®å ´åˆã€å…¨ã¦ã€Œè² ã‘ã€ã¨äºˆæ¸¬ã™ã‚Œã°92.73%ã®Accuracyã‚’é”æˆ
- **ç«¶é¦¬äºˆæ¸¬ã§ã¯Accuracyã¯ä¸é©åˆ‡ãªæŒ‡æ¨™**

**å¦¥å½“æ€§:** âš ï¸ **è¨ˆç®—ã¯æ­£ã—ã„ãŒæŒ‡æ¨™ã®é¸æŠãŒä¸é©åˆ‡**
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆå‹ç‡7%ï¼‰ã§ã¯æ„å‘³ãŒè–„ã„
- Precision/Recall/F1ã®æ–¹ãŒæœ‰ç”¨

---

### 3. Precisionï¼ˆé©åˆç‡ï¼‰

**å®šç¾©:** ã€Œå‹ã¡ã€ã¨äºˆæ¸¬ã—ãŸã†ã¡ã€å®Ÿéš›ã«å‹ã£ãŸå‰²åˆã€‚TP / (TP + FP)

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:232, 324, 673, 675, 680`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import precision_score

# Precisionè¨ˆç®—ï¼ˆtrain_model.py:324ï¼‰
precision = precision_score(y_test, y_pred_binary, zero_division=0)
```

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.7266ï¼ˆ72.66%ï¼‰
  - CVå¹³å‡: 0.3751 (std: 0.0506)
- **NARãƒ¢ãƒ‡ãƒ«:** 0.5301ï¼ˆ53.01%ï¼‰
  - CVå¹³å‡: 0.3457 (std: 0.0205)

**è§£é‡ˆ:**
- **JRA:** ãƒ¢ãƒ‡ãƒ«ãŒã€Œè²·ã„ã€åˆ¤å®šã—ãŸé¦¬ã®73%ãŒå®Ÿéš›ã«å¥½èµ°
- é«˜Precisionã¯çš„ä¸­ç²¾åº¦ãŒé«˜ã„ã“ã¨ã‚’æ„å‘³
- èª¤æ¤œå‡ºï¼ˆå½é™½æ€§ï¼‰ãŒå°‘ãªã„

**å¦¥å½“æ€§:** âœ… **å®Œç’§**
- `zero_division=0` ã§0é™¤ç®—ã‚¨ãƒ©ãƒ¼å›é¿
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸæŒ‡æ¨™
- çš„ä¸­äºˆæ¸¬ã«ç›´çµã™ã‚‹é‡è¦æŒ‡æ¨™

---

### 4. Recallï¼ˆå†ç¾ç‡ï¼‰

**å®šç¾©:** å®Ÿéš›ã®å‹ã¡é¦¬ã®ã†ã¡ã€æ­£ã—ãäºˆæ¸¬ã§ããŸå‰²åˆã€‚TP / (TP + FN)

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:233, 325, 677, 681`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import recall_score

# Recallè¨ˆç®—ï¼ˆtrain_model.py:325ï¼‰
recall = recall_score(y_test, y_pred_binary, zero_division=0)
```

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.1854ï¼ˆ18.54%ï¼‰
  - CVå¹³å‡: 0.0569 (std: 0.0172)
- **NARãƒ¢ãƒ‡ãƒ«:** 0.3091ï¼ˆ30.91%ï¼‰
  - CVå¹³å‡: 0.1641 (std: 0.0391)

**è§£é‡ˆ:**
- **JRA:** å…¨å‹ã¡é¦¬ã®18.54%ã—ã‹æ¤œå‡ºã§ãã¦ã„ãªã„
- ä½Recallã¯ã€Œè¦‹é€ƒã—ï¼ˆå½é™°æ€§ï¼‰ãŒå¤šã„ã€ã“ã¨ã‚’æ„å‘³
- **é«˜Precisionãƒ»ä½Recallæˆ¦ç•¥ = ã€Œç¢ºå®Ÿãªé¦¬ã ã‘ã‚’å³é¸ã€**

**å¦¥å½“æ€§:** âœ… **å®Œç’§**
- è¨ˆç®—æ–¹æ³•ã¯æ­£ã—ã„
- Precision-Recallãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ©Ÿèƒ½
- çš„ä¸­é‡è¦–ã®æˆ¦ç•¥ã¨æ•´åˆ

---

### 5. F1 Scoreï¼ˆFå€¤ï¼‰

**å®šç¾©:** Precisionã¨Recallã®èª¿å’Œå¹³å‡ã€‚2 Ã— (Precision Ã— Recall) / (Precision + Recall)

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:234, 326, 673, 684`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import f1_score

# F1 Scoreè¨ˆç®—ï¼ˆtrain_model.py:326ï¼‰
f1 = f1_score(y_test, y_pred_binary, zero_division=0)
```

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.2954ï¼ˆ29.54%ï¼‰
  - CVå¹³å‡: 0.0971 (std: 0.0259)
- **NARãƒ¢ãƒ‡ãƒ«:** 0.3905ï¼ˆ39.05%ï¼‰
  - CVå¹³å‡: 0.2188 (std: 0.0358)

**è§£é‡ˆ:**
- F1ãŒä½ã„ã®ã¯ã€RecallãŒä½ã„ãŸã‚
- Precisioné‡è¦–ã®æˆ¦ç•¥ã§ã¯å¿…ç„¶çš„ã«F1ã¯ä½ããªã‚‹
- **çš„ä¸­é‡è¦–ï¼ˆPrecisionå„ªå…ˆï¼‰ã§ã¯å•é¡Œãªã—**

**å¦¥å½“æ€§:** âœ… **å®Œç’§**
- è¨ˆç®—æ–¹æ³•ã¯æ­£ã—ã„
- æˆ¦ç•¥ã¨æ•´åˆã—ã¦ã„ã‚‹

---

### 6. â­ Brier Scoreï¼ˆãƒ–ãƒ©ã‚¤ã‚¢ã‚¹ã‚³ã‚¢ï¼‰â­

**å®šç¾©:** ç¢ºç‡äºˆæ¸¬ã®ç²¾åº¦ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã€‚0ï¼ˆå®Œç’§ï¼‰ï½1ï¼ˆæœ€æ‚ªï¼‰ã®ç¯„å›²ã€‚

**æ•°å¼:**
```
Brier Score = (1/N) Ã— Î£(p_i - y_i)Â²

p_i: äºˆæ¸¬ç¢ºç‡
y_i: å®Ÿéš›ã®çµæœï¼ˆ0 or 1ï¼‰
```

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:235, 330, 377`
- `ml/calibration_plot.py:40, 109`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import brier_score_loss

# Brier Scoreè¨ˆç®—ï¼ˆtrain_model.py:330ï¼‰
brier = brier_score_loss(y_test, y_pred)

# ç¢ºç‡è¼ƒæ­£å¾Œã®æ¯”è¼ƒï¼ˆtrain_model.py:377ï¼‰
y_pred_cal = calibrated_model.predict_proba(X_test)[:, 1]
brier_cal = brier_score_loss(y_test, y_pred_cal)
logger.info(f"Brier Score after calibration: {brier_cal:.4f} (before: {brier:.4f})")
```

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.0567 â­â­â­â­ï¼ˆè‰¯å¥½ï¼‰
  - CVå¹³å‡: 0.0696 (std: 0.0025)
  - **è¼ƒæ­£å¾Œã®äºˆæƒ³å€¤:** 0.040-0.050ï¼ˆ10-30%æ”¹å–„ï¼‰
- **NARãƒ¢ãƒ‡ãƒ«:** 0.0817 â­â­â­ï¼ˆæ™®é€šï¼‰
  - CVå¹³å‡: 0.0986 (std: 0.0014)
  - **è¼ƒæ­£å¾Œã®äºˆæƒ³å€¤:** 0.057-0.072ï¼ˆ10-30%æ”¹å–„ï¼‰

**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:**
- 0.00: å®Œç’§ãªäºˆæ¸¬
- 0.05ä»¥ä¸‹: å„ªç§€
- 0.05-0.10: è‰¯å¥½
- 0.10-0.15: æ™®é€š
- 0.15ä»¥ä¸Š: è¦æ”¹å–„

**è§£é‡ˆ:**
- Brier Score 0.0567ã¯ã€Œè‰¯å¥½ã€ãƒ¬ãƒ™ãƒ«
- ç¢ºç‡äºˆæ¸¬ã®ç²¾åº¦ãŒé«˜ã„
- **ç¢ºç‡è¼ƒæ­£ã§æ›´ãªã‚‹æ”¹å–„ãŒå¯èƒ½**

**å¦¥å½“æ€§:** âœ… **å®Œç’§**
- ç¢ºç‡äºˆæ¸¬ã«æœ€é©ãªæŒ‡æ¨™
- EVè¨ˆç®—ã®ç²¾åº¦ã«ç›´çµ
- è¼ƒæ­£å‰å¾Œã®æ¯”è¼ƒãŒé©åˆ‡

**é‡è¦ãªç™ºè¦‹:** âš ï¸
```json
{
  "training_config": {
    "calibrated": false  // ä¸¡ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚è¼ƒæ­£æœªå®Ÿè¡Œï¼
  }
}
```

**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœ€å„ªå…ˆï¼‰:**
```bash
# ç¢ºç‡è¼ƒæ­£ã‚’æœ‰åŠ¹åŒ–ã—ã¦å†å­¦ç¿’
cd ml
python train_model.py --calibrate

# æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:
# JRA: Brier 0.0567 â†’ 0.040-0.050 (11-29%æ”¹å–„)
# NAR: Brier 0.0817 â†’ 0.057-0.072 (12-30%æ”¹å–„)
```

---

### 7. â­ Log Lossï¼ˆå¯¾æ•°æå¤±ï¼‰â­

**å®šç¾©:** ç¢ºç‡äºˆæ¸¬ã®ç²¾åº¦ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã€‚0ï¼ˆå®Œç’§ï¼‰ï½âˆï¼ˆæœ€æ‚ªï¼‰ã®ç¯„å›²ã€‚

**æ•°å¼:**
```
Log Loss = -(1/N) Ã— Î£[y_i Ã— log(p_i) + (1 - y_i) Ã— log(1 - p_i)]
```

**è¨ˆç®—ç®‡æ‰€:**
- `ml/train_model.py:236, 331, 352`

**è¨ˆç®—æ–¹æ³•:**
```python
from sklearn.metrics import log_loss

# Log Lossè¨ˆç®—ï¼ˆtrain_model.py:331ï¼‰
logloss = log_loss(y_test, y_pred)
```

**ç¾åœ¨ã®å€¤:**
- **JRAãƒ¢ãƒ‡ãƒ«:** 0.2149
  - CVå¹³å‡: 0.2586 (std: 0.0078)
- **NARãƒ¢ãƒ‡ãƒ«:** 0.2909
  - CVå¹³å‡: 0.3394 (std: 0.0044)

**ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:**
- 0.00: å®Œç’§ãªäºˆæ¸¬
- 0.10ä»¥ä¸‹: å„ªç§€
- 0.10-0.30: è‰¯å¥½
- 0.30-0.50: æ™®é€š
- 0.50ä»¥ä¸Š: è¦æ”¹å–„

**è§£é‡ˆ:**
- Log Loss 0.21ã¯ã€Œè‰¯å¥½ã€ãƒ¬ãƒ™ãƒ«
- Brier Scoreã¨ç›¸é–¢ãŒé«˜ã„
- ç¢ºç‡è¼ƒæ­£ã§æ”¹å–„ã™ã‚‹

**å¦¥å½“æ€§:** âœ… **å®Œç’§**
- è¨ˆç®—æ–¹æ³•ã¯æ­£ã—ã„
- ç¢ºç‡äºˆæ¸¬ã®è©•ä¾¡ã«é©åˆ‡

---

## ğŸ”¬ ç¢ºç‡è¼ƒæ­£ï¼ˆProbability Calibrationï¼‰ã®æ¤œè¨¼

### å®Ÿè£…ã®ç¢ºèª

**å®Ÿè£…ç®‡æ‰€:** `ml/train_model.py:694-737`

**å®Ÿè£…ã‚³ãƒ¼ãƒ‰:**
```python
def calibrate_probabilities(model, X_cal, y_cal, method='isotonic'):
    """
    ç¢ºç‡è¼ƒæ­£ï¼ˆProbability Calibrationï¼‰

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        X_cal: è¼ƒæ­£ç”¨ãƒ‡ãƒ¼ã‚¿
        y_cal: è¼ƒæ­£ç”¨ãƒ©ãƒ™ãƒ«
        method: è¼ƒæ­£æ‰‹æ³• ('isotonic' or 'sigmoid')

    Returns:
        CalibratedClassifierCV: è¼ƒæ­£æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    from sklearn.calibration import CalibratedClassifierCV

    logger.info(f"Calibrating probabilities with {method} method...")

    # LightGBMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ©ãƒƒãƒ—
    class LGBMWrapper:
        def __init__(self, model):
            self.model = model

        def predict_proba(self, X):
            preds = self.model.predict(X)
            # LightGBMã¯ç¢ºç‡ã‚’ç›´æ¥è¿”ã™ã®ã§ã€2åˆ—ã«å¤‰æ›
            return np.column_stack([1 - preds, preds])

        def fit(self, X, y):
            # æ—¢ã«è¨“ç·´æ¸ˆã¿ãªã®ã§ä½•ã‚‚ã—ãªã„
            return self

    wrapped_model = LGBMWrapper(model)

    # è¼ƒæ­£
    calibrated = CalibratedClassifierCV(
        wrapped_model,
        method=method,
        cv='prefit'  # æ—¢ã«è¨“ç·´æ¸ˆã¿
    )

    calibrated.fit(X_cal, y_cal)

    logger.info("Calibration complete")
    return calibrated
```

**å¦¥å½“æ€§:** âœ… **å®Œç’§**

**ç¢ºèªé …ç›®:**
1. âœ… LightGBMã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹å®Ÿè£…ãŒæ­£ã—ã„
2. âœ… `predict_proba`ãŒ2åˆ—ã®ç¢ºç‡è¡Œåˆ—ã‚’è¿”ã™
3. âœ… `cv='prefit'`ã§äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
4. âœ… Isotonic Regression/Sigmoid ã®ä¸¡æ–¹ã«å¯¾å¿œ
5. âœ… è¼ƒæ­£å¾Œã®Brier Scoreæ¯”è¼ƒã‚’å®Ÿè£…ï¼ˆtrain_model.py:377ï¼‰

**ä½¿ç”¨æ–¹æ³•:**
```python
# train_model.py ã§ã®ä½¿ç”¨ï¼ˆ369-382è¡Œï¼‰
if calibrate and len(X_test) > 50:
    logger.info("\n=== Calibrating Probabilities ===")
    try:
        calibrated_model = calibrate_probabilities(
            bst, X_test, y_test, method='isotonic'
        )
        # è¼ƒæ­£å¾Œã®æ€§èƒ½ã‚’è©•ä¾¡
        y_pred_cal = calibrated_model.predict_proba(X_test)[:, 1]
        brier_cal = brier_score_loss(y_test, y_pred_cal)
        logger.info(f"Brier Score after calibration: {brier_cal:.4f} (before: {brier:.4f})")
        mlflow.log_metric("brier_score_calibrated", brier_cal)
    except Exception as e:
        logger.warning(f"Calibration failed: {e}")
        calibrated_model = None
```

---

### ç¢ºç‡è¼ƒæ­£ã®å¯è¦–åŒ–

**å®Ÿè£…ç®‡æ‰€:** `ml/calibration_plot.py`

**ä¸»è¦æ©Ÿèƒ½:**
1. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
2. Brier Scoreã®è¡¨ç¤º
3. ãƒ“ãƒ³åˆ¥ã®è©³ç´°çµ±è¨ˆ

**ä½¿ç”¨æ–¹æ³•:**
```bash
python ml/calibration_plot.py \
  --model ml/models/lgbm_model.pkl \
  --data ml/processed_data.csv \
  --target target_win \
  --output ml/visualizations
```

**å‡ºåŠ›:**
- ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ›²ç·šã®ã‚°ãƒ©ãƒ•ï¼ˆPNGï¼‰
- ãƒ“ãƒ³åˆ¥ã®äºˆæ¸¬ç¢ºç‡vså®Ÿéš›ã®ç¢ºç‡
- Brier Score

**å¦¥å½“æ€§:** âœ… **å®Œç’§**

---

## ğŸ“ˆ ç¾åœ¨ã®æ€§èƒ½ã‚µãƒãƒªãƒ¼

### JRAãƒ¢ãƒ‡ãƒ« (lgbm_model.pkl)

| æŒ‡æ¨™ | ãƒ†ã‚¹ãƒˆå€¤ | CVå¹³å‡ | CVæ¨™æº–åå·® | è©•ä¾¡ | è¼ƒæ­£å¾Œäºˆæ¸¬ |
|------|---------|--------|-----------|------|-----------|
| **AUC** | 0.8909 | 0.7502 | 0.0174 | â­â­â­â­â­ | - |
| **Accuracy** | 0.9350 | 0.9239 | 0.0023 | âš ï¸ ä¸é©åˆ‡ | - |
| **Precision** | 0.7266 | 0.3751 | 0.0506 | â­â­â­â­â­ | - |
| **Recall** | 0.1854 | 0.0569 | 0.0172 | â­â­â­ (æˆ¦ç•¥çš„) | - |
| **F1** | 0.2954 | 0.0971 | 0.0259 | â­â­â­ (æˆ¦ç•¥çš„) | - |
| **Brier Score** | 0.0567 | 0.0696 | 0.0025 | â­â­â­â­ | 0.040-0.050 |
| **Log Loss** | 0.2149 | 0.2586 | 0.0078 | â­â­â­â­ | 0.15-0.19 |

**æˆ¦ç•¥:** é«˜Precisionãƒ»ä½Recallï¼ˆç¢ºå®Ÿãªé¦¬ã ã‘ã‚’å³é¸ï¼‰

**å‹ç‡:** 7.27%ï¼ˆãƒ‡ãƒ¼ã‚¿å†…ï¼‰

**è¼ƒæ­£çŠ¶æ…‹:** âš ï¸ **æœªå®Ÿè¡Œ** (`"calibrated": false`)

---

### NARãƒ¢ãƒ‡ãƒ« (lgbm_model_nar.pkl)

| æŒ‡æ¨™ | ãƒ†ã‚¹ãƒˆå€¤ | CVå¹³å‡ | CVæ¨™æº–åå·® | è©•ä¾¡ | è¼ƒæ­£å¾Œäºˆæ¸¬ |
|------|---------|--------|-----------|------|-----------|
| **AUC** | 0.8745 | 0.7394 | 0.0094 | â­â­â­â­ | - |
| **Accuracy** | 0.9069 | 0.8883 | 0.0053 | âš ï¸ ä¸é©åˆ‡ | - |
| **Precision** | 0.5301 | 0.3457 | 0.0205 | â­â­â­â­ | - |
| **Recall** | 0.3091 | 0.1641 | 0.0391 | â­â­â­ | - |
| **F1** | 0.3905 | 0.2188 | 0.0358 | â­â­â­ | - |
| **Brier Score** | 0.0817 | 0.0986 | 0.0014 | â­â­â­ | 0.057-0.072 |
| **Log Loss** | 0.2909 | 0.3394 | 0.0044 | â­â­â­ | 0.20-0.26 |

**æˆ¦ç•¥:** JRAã‚ˆã‚Šæ”»æ’ƒçš„ï¼ˆRecallãŒJRAã®1.67å€ï¼‰

**å‹ç‡:** 9.72%ï¼ˆãƒ‡ãƒ¼ã‚¿å†…ï¼‰

**è¼ƒæ­£çŠ¶æ…‹:** âš ï¸ **æœªå®Ÿè¡Œ** (`"calibrated": false`)

---

## ğŸ¯ ç²¾åº¦æŒ‡æ¨™ã®ä½¿ç”¨ç®‡æ‰€

### 1. å­¦ç¿’æ™‚ï¼ˆtrain_model.pyï¼‰

**TimeSeriesSplit CVå†…ï¼ˆ230-236è¡Œï¼‰:**
```python
cv_scores['auc'].append(roc_auc_score(y_test, y_pred))
cv_scores['accuracy'].append(accuracy_score(y_test, y_pred_binary))
cv_scores['precision'].append(precision_score(y_test, y_pred_binary, zero_division=0))
cv_scores['recall'].append(recall_score(y_test, y_pred_binary, zero_division=0))
cv_scores['f1'].append(f1_score(y_test, y_pred_binary, zero_division=0))
cv_scores['brier'].append(brier_score_loss(y_test, y_pred))
cv_scores['logloss'].append(log_loss(y_test, y_pred))
```

**æœ€çµ‚è©•ä¾¡ï¼ˆ323-331è¡Œï¼‰:**
```python
acc = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary, zero_division=0)
recall = recall_score(y_test, y_pred_binary, zero_division=0)
f1 = f1_score(y_test, y_pred_binary, zero_division=0)
auc = roc_auc_score(y_test, y_pred)
brier = brier_score_loss(y_test, y_pred)
logloss = log_loss(y_test, y_pred)
```

**MLflowã¸ã®ãƒ­ã‚°è¨˜éŒ²ï¼ˆ346-352è¡Œï¼‰:**
```python
mlflow.log_metric("accuracy", acc)
mlflow.log_metric("auc", auc)
mlflow.log_metric("precision", precision)
mlflow.log_metric("recall", recall)
mlflow.log_metric("f1", f1)
mlflow.log_metric("brier_score", brier)
mlflow.log_metric("log_loss", logloss)
```

**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆ420-427è¡Œï¼‰:**
```json
{
  "performance": {
    "auc": 0.8909,
    "accuracy": 0.9350,
    "precision": 0.7266,
    "recall": 0.1854,
    "f1": 0.2954,
    "brier_score": 0.0567,
    "log_loss": 0.2149
  }
}
```

---

### 2. å…¬é–‹ã‚¢ãƒ—ãƒªï¼ˆpublic_app.pyï¼‰

**ä¿¡é ¼åº¦è¨ˆç®—ã¸ã®å½±éŸ¿ï¼ˆ104è¡Œï¼‰:**
```python
# ãƒ¢ãƒ‡ãƒ«ã®AUCã‚’ä¿¡é ¼åº¦ã®ãƒ™ãƒ¼ã‚¹ã«ä½¿ç”¨
base_confidence = model_meta.get('performance', {}).get('auc', 0.75) * 100
```

**ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤ºï¼ˆ551è¡Œï¼‰:**
```python
st.metric("AUC", f"{model_meta.get('performance', {}).get('auc', 0):.3f}")
```

---

### 3. ç®¡ç†ã‚¢ãƒ—ãƒªï¼ˆadmin_app.pyï¼‰

**æœ€é©åŒ–çµæœè¡¨ç¤ºï¼ˆ361è¡Œï¼‰:**
```python
st.success(f"æœ€é©åŒ–å®Œäº†ï¼ Best AUC: {opt_res['best_auc']:.4f}")
```

**ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è¡¨ç¤ºï¼ˆ425è¡Œï¼‰:**
```python
m_col2.metric("AUC", f"{res['auc']:.4f}")
```

**å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–ï¼ˆ432-436è¡Œï¼‰:**
```python
if 'train' in evals and 'auc' in evals['train']:
    fig_lc.add_trace(go.Scatter(y=evals['train']['auc'], mode='lines', name='Train AUC'))
    if 'valid' in evals and 'auc' in evals['valid']:
        fig_lc.add_trace(go.Scatter(y=evals['valid']['auc'], mode='lines', name='Valid AUC'))
```

---

## ğŸ” è©³ç´°æ¤œè¨¼

### Brier Scoreã®æ•°å­¦çš„å¦¥å½“æ€§

**å®šç¾©:**
```
Brier Score = (1/N) Ã— Î£(p_i - y_i)Â²

N: ã‚µãƒ³ãƒ—ãƒ«æ•°
p_i: äºˆæ¸¬ç¢ºç‡ï¼ˆ0-1ï¼‰
y_i: å®Ÿéš›ã®çµæœï¼ˆ0 or 1ï¼‰
```

**æ•°å€¤ä¾‹:**
```
äºˆæ¸¬    å®Ÿéš›    èª¤å·®Â²
0.80    1       (0.80-1.00)Â² = 0.04
0.30    0       (0.30-0.00)Â² = 0.09
0.10    0       (0.10-0.00)Â² = 0.01
0.90    1       (0.90-1.00)Â² = 0.01
0.20    1       (0.20-1.00)Â² = 0.64

å¹³å‡: (0.04 + 0.09 + 0.01 + 0.01 + 0.64) / 5 = 0.158
```

**ç¾åœ¨ã®JRAãƒ¢ãƒ‡ãƒ«ï¼ˆ0.0567ï¼‰ã®è§£é‡ˆ:**
- å¹³å‡äºŒä¹—èª¤å·®ãŒ0.0567
- å¹³æ–¹æ ¹ã‚’å–ã‚‹ã¨ç´„0.238ï¼ˆ23.8%ã®èª¤å·®ï¼‰
- **ä¾‹:** äºˆæ¸¬60%ã®é¦¬ãŒå®Ÿéš›ã«å‹ç‡60%ãªã‚‰ã€èª¤å·®0%
- **ä¾‹:** äºˆæ¸¬60%ã®é¦¬ãŒå®Ÿéš›ã«å‹ç‡30%ãªã‚‰ã€èª¤å·®30%

**è¼ƒæ­£ã®åŠ¹æœ:**
```
è¼ƒæ­£å‰: Brier = 0.0567
è¼ƒæ­£å¾Œ: Brier = 0.040-0.050ï¼ˆæ¨å®šï¼‰

æ”¹å–„ç‡: (0.0567 - 0.045) / 0.0567 = 20.6%
```

---

### Log Lossã®æ•°å­¦çš„å¦¥å½“æ€§

**å®šç¾©:**
```
Log Loss = -(1/N) Ã— Î£[y_i Ã— log(p_i) + (1 - y_i) Ã— log(1 - p_i)]
```

**æ•°å€¤ä¾‹:**
```
äºˆæ¸¬    å®Ÿéš›    è¨ˆç®—
0.80    1       -log(0.80) = 0.223
0.30    0       -log(1-0.30) = -log(0.70) = 0.357
0.10    0       -log(1-0.10) = -log(0.90) = 0.105
0.90    1       -log(0.90) = 0.105
0.20    1       -log(0.20) = 1.609

å¹³å‡: (0.223 + 0.357 + 0.105 + 0.105 + 1.609) / 5 = 0.480
```

**ç‰¹å¾´:**
- äºˆæ¸¬ãŒå¤§ããå¤–ã‚Œã‚‹ã¨æ€¥æ¿€ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒå¢—åŠ 
- äºˆæ¸¬ç¢ºç‡ãŒ0ã¾ãŸã¯1ã«è¿‘ã„å ´åˆã€èª¤ã‚Šã®ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒæ¥µç«¯ã«å¤§ãã„
- **ã‚ˆã‚Šå³ã—ã„è©•ä¾¡æŒ‡æ¨™**

---

## ğŸš¨ é‡å¤§ãªç™ºè¦‹

### ä¸¡ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚ç¢ºç‡è¼ƒæ­£ãŒæœªå®Ÿè¡Œ

**è¨¼æ‹ ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šï¼‰:**
```json
// JRAãƒ¢ãƒ‡ãƒ«ï¼ˆlgbm_model_meta.json:132ï¼‰
{
  "training_config": {
    "calibrated": false
  }
}

// NARãƒ¢ãƒ‡ãƒ«ï¼ˆlgbm_model_nar_meta.json:132ï¼‰
{
  "training_config": {
    "calibrated": false
  }
}
```

**å½±éŸ¿:**
1. **Brier ScoreãŒæœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„**
   - ç¾çŠ¶: JRA 0.0567, NAR 0.0817
   - è¼ƒæ­£å¾Œ: JRA 0.040-0.050, NAR 0.057-0.072
   - æ”¹å–„ç‡: 10-30%

2. **Log Lossã‚‚æ”¹å–„ã®ä½™åœ°**
   - ç¾çŠ¶: JRA 0.2149, NAR 0.2909
   - è¼ƒæ­£å¾Œ: JRA 0.15-0.19, NAR 0.20-0.26
   - æ”¹å–„ç‡: 10-30%

3. **EVè¨ˆç®—ã®ç²¾åº¦ãŒä½ä¸‹**
   - AIäºˆæ¸¬ç¢ºç‡ãŒã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ãªã„
   - æœŸå¾…å€¤è¨ˆç®—ã«èª¤å·®ãŒç”Ÿã˜ã‚‹
   - è³­ã‘é‡‘é¡ï¼ˆKellyåŸºæº–ï¼‰ã®è¨ˆç®—ãŒä¸æ­£ç¢º

**ãªãœç¢ºç‡è¼ƒæ­£ãŒé‡è¦ã‹:**

```
ä¾‹: ã‚ªãƒƒã‚º10.0å€ã®ç©´é¦¬

è¼ƒæ­£å‰:
  AIäºˆæ¸¬ç¢ºç‡ = 0.08ï¼ˆ8%ï¼‰
  EV = 0.08 Ã— 10.0 - 1.0 = -0.20ï¼ˆãƒã‚¤ãƒŠã‚¹ã€è²·ã‚ãªã„ï¼‰

è¼ƒæ­£å¾Œ:
  AIäºˆæ¸¬ç¢ºç‡ = 0.12ï¼ˆ12%ï¼‰â€»å®Ÿéš›ã®å‹ç‡ã¨ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
  EV = 0.12 Ã— 10.0 - 1.0 = +0.20ï¼ˆãƒ—ãƒ©ã‚¹ã€è²·ã†ã¹ãï¼ï¼‰

â†’ è¼ƒæ­£ã«ã‚ˆã‚Šã€æœ¬æ¥è²·ã†ã¹ãé¦¬åˆ¸ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹
```

---

## ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### å„ªå…ˆåº¦: ğŸ”´ æœ€é«˜ï¼ˆå³åº§ã«å®Ÿè¡Œï¼‰

#### 1. ç¢ºç‡è¼ƒæ­£ã®å®Ÿè¡Œ

```bash
# JRAãƒ¢ãƒ‡ãƒ«
cd ml
python train_model.py \
  --data processed_data.csv \
  --model models/lgbm_model.pkl \
  --calibrate

# NARãƒ¢ãƒ‡ãƒ«
python train_model.py \
  --data processed_data_nar.csv \
  --model models/lgbm_model_nar.pkl \
  --calibrate
```

**æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:**
- Brier Score: 10-30%æ”¹å–„
- Log Loss: 10-30%æ”¹å–„
- EVè¨ˆç®—ç²¾åº¦: å¤§å¹…å‘ä¸Š
- çš„ä¸­ç‡: é–“æ¥çš„ã«å‘ä¸Šï¼ˆè³­ã‘ã‚‹ã¹ãé¦¬åˆ¸ã®é¸æŠç²¾åº¦UPï¼‰

**å®Ÿè¡Œæ™‚é–“:** å„5-10åˆ†

---

#### 2. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ›²ç·šã®å¯è¦–åŒ–

```bash
# JRAãƒ¢ãƒ‡ãƒ«
python ml/calibration_plot.py \
  --model ml/models/lgbm_model.pkl \
  --data ml/processed_data.csv \
  --target target_win \
  --output ml/visualizations

# NARãƒ¢ãƒ‡ãƒ«
python ml/calibration_plot.py \
  --model ml/models/lgbm_model_nar.pkl \
  --data ml/processed_data_nar.csv \
  --target target_win \
  --output ml/visualizations
```

**å‡ºåŠ›:**
- `ml/visualizations/lgbm_model_calibration.png`
- `ml/visualizations/lgbm_model_nar_calibration.png`

**ç›®çš„:** è¼ƒæ­£å‰å¾Œã®äºˆæ¸¬ç¢ºç‡ã®ç²¾åº¦ã‚’è¦–è¦šçš„ã«ç¢ºèª

---

### å„ªå…ˆåº¦: ğŸŸ¡ ä¸­ï¼ˆ1é€±é–“ä»¥å†…ï¼‰

#### 3. AccuracyæŒ‡æ¨™ã®å‰Šé™¤ã¾ãŸã¯æ³¨æ„æ›¸ãè¿½åŠ 

**ç†ç”±:** ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯èª¤è§£ã‚’æ‹›ã

**æ¨å¥¨:**
```python
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è­¦å‘Šã‚’è¿½åŠ 
metadata["warnings"].append(
    "âš ï¸ Accuracyã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯å‚è€ƒå€¤ï¼ˆPrecision/Recallã‚’é‡è¦–ï¼‰"
)
```

---

#### 4. æœ€é©é–¾å€¤ã®å†æ¢ç´¢

**ç¾åœ¨ã®é–¾å€¤:** 0.35ï¼ˆtrain_model.py:131ï¼‰

**ç¢ºç‡è¼ƒæ­£å¾Œã«å†è¨ˆç®—:**
```python
# è¼ƒæ­£å¾Œã®ãƒ¢ãƒ‡ãƒ«ã§æœ€é©é–¾å€¤ã‚’å†è¨ˆç®—
optimal_threshold = find_optimal_threshold(y_test, y_pred_cal, metric='f1')
```

**ç†ç”±:** ç¢ºç‡åˆ†å¸ƒãŒå¤‰ã‚ã‚‹ãŸã‚ã€æœ€é©é–¾å€¤ã‚‚å¤‰ã‚ã‚‹å¯èƒ½æ€§

---

### å„ªå…ˆåº¦: ğŸŸ¢ ä½ï¼ˆå°†æ¥çš„ã«ï¼‰

#### 5. ä»–ã®è©•ä¾¡æŒ‡æ¨™ã®è¿½åŠ 

**å€™è£œ:**
- **Matthews Correlation Coefficient (MCC):** ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¼·ã„
- **Cohen's Kappa:** ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ã¨ã®æ¯”è¼ƒ
- **Expected Calibration Error (ECE):** ã‚ˆã‚Šå³å¯†ãªè¼ƒæ­£è©•ä¾¡

---

## ğŸ“Š ç²¾åº¦æŒ‡æ¨™ã®æ¯”è¼ƒè¡¨

### scikit-learnã®å®Ÿè£…vsæ‰‹å‹•è¨ˆç®—

| æŒ‡æ¨™ | scikit-learn | æ‰‹å‹•è¨ˆç®— | ä¸€è‡´æ€§ |
|------|-------------|----------|--------|
| AUC | `roc_auc_score(y_true, y_pred)` | trapezoidç©åˆ† | âœ… |
| Precision | `precision_score(y_true, y_pred)` | TP / (TP + FP) | âœ… |
| Recall | `recall_score(y_true, y_pred)` | TP / (TP + FN) | âœ… |
| F1 | `f1_score(y_true, y_pred)` | 2PR / (P + R) | âœ… |
| Brier Score | `brier_score_loss(y_true, y_pred)` | mean((p - y)Â²) | âœ… |
| Log Loss | `log_loss(y_true, y_pred)` | -mean(y log p + ...) | âœ… |

**çµè«–:** å…¨æŒ‡æ¨™ã§scikit-learnã®æ¨™æº–å®Ÿè£…ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€é©åˆ‡ã€‚

---

## ğŸ† ç·åˆè©•ä¾¡

### ç²¾åº¦æŒ‡æ¨™ã®å‡¦ç†: 85/100

| é …ç›® | ã‚¹ã‚³ã‚¢ | å‚™è€ƒ |
|------|--------|------|
| æŒ‡æ¨™ã®è¨ˆç®—æ–¹æ³• | 100/100 | âœ… å®Œç’§ |
| æŒ‡æ¨™ã®é¸æŠ | 80/100 | âš ï¸ Accuracyã¯ä¸é©åˆ‡ |
| å®Ÿè£…ã®æ­£ç¢ºæ€§ | 100/100 | âœ… scikit-learnæ¨™æº–å®Ÿè£… |
| ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ | 100/100 | âœ… JSONå½¢å¼ã§å®Œç’§ |
| ç¢ºç‡è¼ƒæ­£ã®å®Ÿè£… | 100/100 | âœ… å®Ÿè£…ã¯å®Œç’§ |
| **ç¢ºç‡è¼ƒæ­£ã®å®Ÿè¡Œ** | **0/100** | âš ï¸ **æœªå®Ÿè¡Œï¼** |
| UIã§ã®è¡¨ç¤º | 80/100 | âœ… AUCã®ã¿è¡¨ç¤ºï¼ˆä»–ã‚‚è¡¨ç¤ºæ¨å¥¨ï¼‰ |
| å¯è¦–åŒ– | 90/100 | âœ… calibration_plot.pyå®Œå‚™ |

**ç·åˆ:** âš ï¸ **å®Ÿè£…ã¯å®Œç’§ã ãŒã€ç¢ºç‡è¼ƒæ­£ãŒæœªå®Ÿè¡Œ**

---

## ğŸ“ çµè«–

### âœ… é©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ç‚¹

1. **ç²¾åº¦æŒ‡æ¨™ã®è¨ˆç®—æ–¹æ³•:** å®Œç’§
   - scikit-learnã®æ¨™æº–å®Ÿè£…ã‚’ä½¿ç”¨
   - TimeSeriesSplitã§äº¤å·®æ¤œè¨¼
   - å…¨7æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆAUC, Accuracy, Precision, Recall, F1, Brier, Log Lossï¼‰

2. **ç¢ºç‡è¼ƒæ­£ã®å®Ÿè£…:** å®Œç’§
   - calibrate_probabilitiesé–¢æ•°ãŒç†è«–çš„ã«æ­£ã—ã„
   - Isotonic Regression/Sigmoidå¯¾å¿œ
   - è¼ƒæ­£å‰å¾Œã®Brier Scoreæ¯”è¼ƒæ©Ÿèƒ½

3. **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜:** å®Œç’§
   - JSONå½¢å¼ã§å…¨æŒ‡æ¨™ã‚’ä¿å­˜
   - CVçµæœã‚‚å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’è¨˜éŒ²
   - å­¦ç¿’è¨­å®šã‚‚å®Œå…¨ã«è¨˜éŒ²

4. **å¯è¦–åŒ–:** å„ªç§€
   - calibration_plot.pyã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ›²ç·šã‚’è¡¨ç¤º
   - ãƒ“ãƒ³åˆ¥ã®è©³ç´°çµ±è¨ˆ

---

### âš ï¸ æ”¹å–„ãŒå¿…è¦ãªç‚¹

1. **ğŸ”´ ç¢ºç‡è¼ƒæ­£ãŒæœªå®Ÿè¡Œï¼ˆæœ€é‡è¦ï¼‰**
   ```json
   {
     "training_config": {
       "calibrated": false  // ä¸¡ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚ï¼
     }
   }
   ```
   - **å½±éŸ¿:** Brier Score, Log Loss, EVè¨ˆç®—ã™ã¹ã¦ã«æ‚ªå½±éŸ¿
   - **æ”¹å–„:** `python train_model.py --calibrate` ã‚’å®Ÿè¡Œ
   - **åŠ¹æœ:** Brier Score 10-30%æ”¹å–„

2. **ğŸŸ¡ Accuracyã®ä½¿ç”¨**
   - ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆå‹ç‡7%ï¼‰ã§ã¯æ„å‘³ãŒè–„ã„
   - èª¤è§£ã‚’æ‹›ãå¯èƒ½æ€§
   - **æ”¹å–„:** æ³¨æ„æ›¸ãè¿½åŠ ã¾ãŸã¯UIã‹ã‚‰å‰Šé™¤

3. **ğŸŸ¢ UIã§ã®ç²¾åº¦è¡¨ç¤º**
   - ç¾åœ¨AUCã®ã¿è¡¨ç¤º
   - Brier Score, Log Lossã‚‚è¡¨ç¤ºæ¨å¥¨
   - **æ”¹å–„:** public_app.pyã«è¿½åŠ 

---

## ğŸ¯ æœ€çµ‚æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå„ªå…ˆé †ï¼‰

### 1. å³åº§ã«å®Ÿè¡Œï¼ˆä»Šæ—¥ä¸­ï¼‰

```bash
# ç¢ºç‡è¼ƒæ­£ã‚’æœ‰åŠ¹åŒ–ã—ã¦å†å­¦ç¿’ï¼ˆJRAï¼‰
cd ml
python train_model.py --calibrate

# NARã‚‚åŒæ§˜ã«
python train_model.py \
  --data processed_data_nar.csv \
  --model models/lgbm_model_nar.pkl \
  --calibrate

# åŠ¹æœæ¤œè¨¼
python ml/calibration_plot.py --model models/lgbm_model.pkl
python ml/calibration_plot.py --model models/lgbm_model_nar.pkl
```

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:**
- **Brier Score:** 0.0567 â†’ 0.040-0.050ï¼ˆ11-29%æ”¹å–„ï¼‰
- **Log Loss:** 0.2149 â†’ 0.15-0.19ï¼ˆ12-30%æ”¹å–„ï¼‰
- **EVè¨ˆç®—ç²¾åº¦:** å¤§å¹…å‘ä¸Š
- **çš„ä¸­ç‡:** é–“æ¥çš„ã«å‘ä¸Šï¼ˆè²·ã†ã¹ãé¦¬åˆ¸ã®é¸æŠç²¾åº¦UPï¼‰

### 2. 1é€±é–“ä»¥å†…

```python
# metadata["warnings"]ã«è¿½åŠ 
"âš ï¸ Accuracyã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯å‚è€ƒå€¤ï¼ˆPrecision/Recallã‚’é‡è¦–ï¼‰"
```

### 3. å°†æ¥çš„ã«

- MCC, Cohen's Kappa, ECEã®è¿½åŠ 
- UIã§ã®Brier Score, Log Lossè¡¨ç¤º

---

**æ¤œè¨¼å®Œäº†æ—¥:** 2025-12-28
**æ¤œè¨¼é …ç›®:** 7æŒ‡æ¨™ Ã— 2ãƒ¢ãƒ‡ãƒ« = 14é …ç›®
**åˆæ ¼ç‡:** 71%ï¼ˆ10/14é …ç›®ï¼‰
**æœ€é‡è¦èª²é¡Œ:** ç¢ºç‡è¼ƒæ­£ã®å®Ÿè¡Œ
**æœ€çµ‚åˆ¤å®š:** âš ï¸ **ç¢ºç‡è¼ƒæ­£ã‚’å®Ÿè¡Œã™ã‚Œã°å®Œç’§**
