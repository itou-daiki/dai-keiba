# 🔍 競馬予測システム 信頼性監査レポート

**作成日:** 2025年12月21日
**監査範囲:** プロジェクト全体（スクレイピング、学習、予測）
**監査方法:** コードレベルでの詳細分析

---

## 📋 エグゼクティブサマリー

### 総合評価: ⚠️ **要改善**

| 項目 | 評価 | スコア |
|------|------|--------|
| **アーキテクチャ** | 良好 | 7/10 |
| **データ品質** | 不十分 | 4/10 |
| **モデリング** | 問題あり | 5/10 |
| **信頼性** | 低い | 3/10 |
| **運用性** | 不安定 | 4/10 |

### 結論

このシステムは**教育目的やプロトタイプとしては優秀**ですが、**本番運用には重大な問題**があります。

**致命的な問題:**
1. 🔴 **ルックアヘッドバイアス**: 未来のデータで学習→過去をテスト（精度の過大評価）
2. 🔴 **ターゲット変数の誤り**: 3着以内=勝ち（実際の配当と不一致）
3. 🔴 **データ量不足**: 656行では機械学習に不十分
4. 🟡 **エラーハンドリング不足**: 本番環境で失敗しやすい

**優れている点:**
- ✅ 包括的な特徴量エンジニアリング（30+特徴量）
- ✅ JRA/NAR両対応の設計
- ✅ 会場特性の詳細なデータベース
- ✅ ユーザーフレンドリーなUI

---

## 🏗️ 1. システムアーキテクチャ

### 1.1 プロジェクト構造

```
dai-keiba/
├── public_app.py              # 予測UI (613行)
├── scraper/
│   ├── auto_scraper.py       # 統合スクレイパー (1,352行)
│   ├── race_scraper.py       # 過去走取得 (313行)
│   └── odds_scraper.py       # オッズ取得 (242行)
├── ml/
│   ├── feature_engineering.py # 特徴量生成 (964行)
│   ├── train_model.py        # モデル学習 (430行)
│   ├── venue_characteristics.py # 会場データ (586行)
│   └── run_style_analyzer.py # 脚質分析 (255行)
└── database.csv              # 学習データ (656行) ⚠️
```

### 1.2 データフロー

```
┌─────────────┐     ┌──────────┐     ┌─────────────┐     ┌────────┐     ┌─────────┐
│スクレイピング│ --> │CSV保存   │ --> │特徴量生成   │ --> │学習    │ --> │予測     │
│auto_scraper │     │database  │     │process_data │     │LightGBM│     │EV計算   │
└─────────────┘     └──────────┘     └─────────────┘     └────────┘     └─────────┘
```

**評価:** 🟢 **アーキテクチャは明確で保守性が高い**

---

## 🕷️ 2. スクレイピングシステム

### 2.1 実装概要

**主要機能:**
- `scraper/auto_scraper.py`: エントリーポイント、キャッシュ管理
- `scraper/race_scraper.py`: 馬の過去データ取得
- `scraper/odds_scraper.py`: オッズ取得（リトライ付き）

**データソース:**
- JRA: `https://race.netkeiba.com/`
- NAR: `https://nar.netkeiba.com/`

### 2.2 優れている点 ✅

**1. グローバルキャッシュ機能**
```python
# auto_scraper.py: 25行目
HORSE_HISTORY_CACHE = {}
```
- 同じ馬のデータを複数回取得しない
- メモリ効率が良い（短期実行の場合）

**2. 日付フィルタリング**
```python
# 240-246行: 未来のデータを除外
past_df = past_df[past_df['date_obj'] < current_race_date]
```
- ルックアヘッドバイアスを一部回避

**3. 過去5走データの自動取得**
- 各馬について最新5走分を取得
- 時系列データとして利用可能

### 2.3 問題点 🔴

#### 問題1: データ検証の欠如

**現状:**
```python
# 273-275行
except Exception as e:
    print(f"Error scraping {race_id}: {e}")
    return None
```

**問題:**
- 取得データの妥当性チェックなし
- 着順が"除外"や"中止"の場合の処理が不完全
- カラム数の不一致を検出できない

**影響:** 🔴 **異常データが学習データに混入→モデル精度低下**

#### 問題2: エラーハンドリングの不足

**現状:**
- 単純な`try-except`のみ
- エラー種類別の処理なし
- リトライ機構なし（odds_scraper以外）

**推奨:**
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def scrape_with_retry(url):
    # スクレイピング処理
    pass
```

#### 問題3: レート制限対策が不十分

**現状:**
```python
time.sleep(1)  # 1秒待機のみ
```

**問題:**
- 連続リクエストでIP BANのリスク
- netkeiba.comの利用規約違反の可能性

**推奨:**
- ランダム待機時間（1-3秒）
- リクエスト数の制限（1分あたり10件など）
- User-Agentの設定

#### 問題4: メモリリーク懸念

**現状:**
```python
HORSE_HISTORY_CACHE = {}  # 無制限に成長
```

**問題:**
- 長時間実行でメモリ枯渇
- 1000頭分キャッシュすると数百MB消費

**推奨:**
```python
from functools import lru_cache

@lru_cache(maxsize=100)  # 最大100頭までキャッシュ
def get_horse_history(horse_id):
    pass
```

### 2.4 HTMLパース処理の脆弱性

**現状:**
```python
# race_scraper.py: 36-46行
table = soup.select_one("table.db_h_race_results")
if not table:
    # フォールバック: "着順"を含むテーブルを探す
    tables = soup.find_all("table")
    for t in tables:
        if "着順" in t.text:
            table = t
            break
```

**問題:**
- サイト構造変更に脆弱
- テーブル誤認識のリスク
- バージョン管理なし

**推奨:**
- スキーマ定義とバリデーション
- サイト構造変更の検出機構
- 複数バージョンのパーサー維持

### 2.5 スクレイピング総合評価

| 項目 | 評価 | 備考 |
|------|------|------|
| **機能性** | 🟢 良好 | 必要なデータを取得できている |
| **堅牢性** | 🔴 低い | エラー処理が不十分 |
| **保守性** | 🟡 普通 | HTMLパース処理が脆弱 |
| **パフォーマンス** | 🟡 普通 | 並行処理なし |

**総合:** 🟡 **基本機能は動作するが、本番運用には改善必須**

---

## 🧮 3. 特徴量エンジニアリング

### 3.1 実装概要

**特徴量の種類:** 合計 **30+個**

1. **時間減衰加重平均** (9個)
   - 着順、走法、上り3F、馬体重、オッズ、天候、体重変化、間隔、スピード
   - 重み: `[1.0, 0.82, 0.67, 0.55, 0.45]` (λ=0.2)

2. **コース適性** (3個)
   - 芝適性、ダート適性、距離適性

3. **馬場・天候適性** (2個)
   - 良馬場平均、重馬場平均

4. **レース間隔** (3個)
   - 休養明けフラグ、間隔カテゴリ、連闘フラグ

5. **騎手相性** (1個)

6. **レースクラス** (3個)
   - クラスコード、重賞フラグ、年齢制限

7. **中央/地方** (4個)
   - JRA/NAR適性、転入馬フラグ

8. **基本情報** (5個)
   - 年齢、コースタイプ、距離、回り、天候、馬場

9. **会場特性×馬タイプ** (11個) ※`use_venue_features=True`の場合
   - 脚質、会場相性、枠番有利度など

### 3.2 優れている点 ✅

**1. 時間減衰加重平均の実装**
```python
# 241-243行
weights = [math.exp(-lambda_decay * (i-1)) for i in range(1, 6)]
# lambda=0.2 → [1.0, 0.82, 0.67, 0.55, 0.45]
```

**利点:**
- 最近の成績を重視
- 古い成績の影響を減衰
- 時系列の変化を捉える

**2. 包括的な特徴量設計**
- コース適性、馬場適性、騎手相性など多角的
- ドメイン知識を活用

**3. JRA/NAR区別**
- 中央と地方の違いを考慮
- 転入馬の特徴を捉える

### 3.3 致命的な問題 🔴

#### 問題1: 時系列データ処理のバグ

**場所:** `add_history_features()` (20-228行)

**問題:**
```python
# 76-78行のコメント
# Remove shifting loop that overwrites data
# We will use existing columns directly
```

**実態:**
- `add_history_features()`関数は**何もしていない**
- `past_1_*`から`past_5_*`の列は**スクレイピング時に既に存在**
- この関数は**実質的に無意味**

**影響:** 🟡 機能に影響はないが、設計が不明瞭

#### 問題2: NaN処理の不統一

**現状:**
```python
# 254-332行
df[f"past_{i}_rank"] = df[col].fillna(18)      # なぜ18?
df[f"past_{i}_last_3f"] = df[col].fillna(40.0) # なぜ40秒?
df[f"past_{i}_horse_weight"] = df[col].fillna(470.0)  # なぜ470kg?
```

**問題:**
1. **根拠不明なデフォルト値**
   - 18位は最下位想定だが、出走頭数は可変
   - 40秒は遅いタイムだが、距離により異なる

2. **欠損情報の喪失**
   - 「データなし」と「実際に18位」を区別できない
   - モデルが欠損パターンを学習できない

3. **バイアスの導入**
   - 新馬は全て同じデフォルト値になる
   - 過去走が少ない馬が不利に

**推奨:**
```python
# オプション1: 欠損フラグを追加
df[f"past_{i}_rank_missing"] = df[col].isna().astype(int)
df[f"past_{i}_rank"] = df[col].fillna(df[col].median())

# オプション2: -1などの特殊値
df[f"past_{i}_rank"] = df[col].fillna(-1)
```

#### 問題3: ターゲット変数の定義ミス 🔴🔴🔴

**場所:** 949-952行

**現状:**
```python
if 'rank' in processed.columns:
    processed['target_top3'] = (processed['rank'] <= 3).astype(int)
else:
    processed['target_top3'] = 0
```

**問題:**
1. **配当との不一致**
   - 単勝は1着のみ配当
   - 複勝は1-3着だが、配当額が異なる
   - 3着以内を同等に扱うのは誤り

2. **モデルの目的不明確**
   - 何を予測したいのか？
   - 単勝？複勝？3連単？

3. **期待値計算との矛盾**
   - EV計算は単勝オッズを使用
   - しかしモデルは「3着以内の確率」を出力
   - **根本的なロジックの矛盾**

**正しい定義:**
```python
# 単勝予測の場合
processed['target_win'] = (processed['rank'] == 1).astype(int)

# または回帰問題
# target = 着順そのもの（1-18）
```

**影響:** 🔴🔴🔴 **モデルの予測精度が実用に耐えない可能性が高い**

#### 問題4: 会場特性機能の未使用

**場所:** 753-921行

**問題:**
```python
# public_app.py: 171行
X_df = process_data(df, use_venue_features=False)  # ← False!
```

- せっかく実装した高度な特徴量（11個）が**使われていない**
- モデルを再学習しない限り有効化できない
- ドキュメント化されていない

**影響:** 🟡 潜在的な精度向上の機会を逃している

### 3.4 特徴量エンジニアリング総合評価

| 項目 | 評価 | 備考 |
|------|------|------|
| **網羅性** | 🟢 優秀 | 30+特徴量は十分 |
| **ドメイン知識** | 🟢 良好 | 競馬の知見が反映されている |
| **実装品質** | 🟡 普通 | バグや不統一あり |
| **ターゲット設計** | 🔴 不適切 | 根本的な誤り |

**総合:** 🟡 **設計は良いが、ターゲット変数の問題が致命的**

---

## 🤖 4. モデル学習

### 4.1 実装概要

**アルゴリズム:** LightGBM (Gradient Boosting Decision Tree)

**パラメータ:**
```python
lgb_params = {
    'objective': 'binary',       # 2値分類
    'metric': 'auc',             # AUC最大化
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
}
```

**学習データ:**
- `database.csv`: **656行** ⚠️
- `database_nar.csv`: **2,175行**

### 4.2 致命的な問題 🔴🔴🔴

#### 問題1: ルックアヘッドバイアス

**場所:** train_model.py: 46行

**現状:**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

**問題:**
- **ランダム分割**により、未来のデータで学習→過去のデータでテスト可能
- これは**不正行為**（未来を見て予測）
- 実際の予測性能が大幅に過大評価される

**例:**
```
学習データ: 2024/1/1, 2024/6/1, 2024/12/1
テストデータ: 2024/3/1, 2024/9/1

→ 2024/6/1と2024/12/1のデータを使って、2024/3/1を予測している！
```

**正しい方法:**
```python
# train_model.py: 295-421行に実装済みだが、未使用
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(X):
    # 時系列順に分割
```

**影響:** 🔴🔴🔴 **報告されている精度（AUC 0.8など）は実際より大幅に高い可能性**

#### 問題2: データ量の絶対的不足

**現状:**
- JRAデータ: **656行**
- NARデータ: **2,175行**

**問題:**
- 機械学習には少なすぎる
- 特徴量30個に対して、サンプル数が不足
- **過学習のリスクが極めて高い**

**目安:**
- 最低でも特徴量数の10倍以上（300行）
- 実用的には1,000行以上
- 高精度には10,000行以上

**現状の評価:**
```
特徴量数: 30
サンプル数: 656
比率: 21.9サンプル/特徴量

→ 🔴 不足（理想は100以上）
```

**影響:** 🔴 **モデルが過学習し、未知データに対して精度が大幅に低下**

#### 問題3: ハイパーパラメータ最適化の未実施

**実装状況:**
```python
# train_model.py: 128-186行
def optimize_hyperparameters(data_path, n_trials=50):
    # Optuna実装済み
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=n_trials)
    return study.best_params
```

**問題:**
- 実装されているが、`main()`で呼び出されていない
- デフォルトパラメータで学習
- 最適化の余地がある

**影響:** 🟡 精度向上の機会を逃している

#### 問題4: 評価指標の不適切さ

**現状:**
```python
# 93-96行
y_pred_binary = [1 if p > 0.5 else 0 for p in y_pred]
acc = accuracy_score(y_test, y_pred_binary)
auc = roc_auc_score(y_test, y_pred)
```

**問題:**
1. **Accuracyは不均衡データで無意味**
   - 3着以内: 約17%（3/18）
   - 3着外: 約83%（15/18）
   - 全て「3着外」と予測しても83%の精度！

2. **AUCのみでは不十分**
   - AUCは順位の正確さを測る
   - しかし競馬予測では**確率の絶対値**が重要
   - 例: 10%と予測して、実際に10%勝つか？

3. **キャリブレーションの未評価**
   - 確率予測の正確さを評価していない
   - Brier ScoreやLog Lossが必要

**推奨:**
```python
from sklearn.metrics import brier_score_loss, log_loss

# 確率の精度を評価
brier = brier_score_loss(y_test, y_pred)
logloss = log_loss(y_test, y_pred)

# キャリブレーションプロット
from sklearn.calibration import calibration_curve
prob_true, prob_pred = calibration_curve(y_test, y_pred, n_bins=10)
```

**影響:** 🔴 **モデルの実力を正しく評価できていない**

#### 問題5: クロスバリデーションの未実施

**実装状況:**
```python
# train_model.py: 188-293行
def train_with_cross_validation(data_path, params=None, n_splits=5):
    # 実装済み
    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    # ...
```

**問題:**
- 実装されているが、デフォルトでは実行されない
- 1回の分割のみで評価
- 精度の分散がわからない

**影響:** 🟡 精度の信頼性が低い

### 4.3 モデル学習総合評価

| 項目 | 評価 | 備考 |
|------|------|------|
| **データ量** | 🔴 不足 | 656行は少なすぎる |
| **分割方法** | 🔴 不適切 | ルックアヘッドバイアス |
| **評価指標** | 🔴 不十分 | キャリブレーション未評価 |
| **最適化** | 🟡 未実施 | 実装はある |

**総合:** 🔴 **根本的な問題が複数あり、信頼性が低い**

---

## 🎯 5. 予測システム (public_app.py)

### 5.1 実装概要

**フロー:**
1. レース選択
2. 出馬表スクレイピング
3. 特徴量生成
4. モデル予測（3着以内の確率）
5. EV計算

### 5.2 EV計算の実装

**基本式:**
```python
ev = (adjusted_p * w * o) - 1.0
```

**パラメータ:**

| 項目 | JRA中央 | NAR地方 |
|------|---------|---------|
| **◎の重み** | 1.3 | 1.8 |
| **◯の重み** | 1.15 | 1.4 |
| **▲の重み** | 1.08 | 1.2 |
| **安全閾値** | 8% | 5% |
| **確率調整** | なし | p×0.9+0.05 |

**会場特性補正:**
- 長直線: 人気薄有利（◎×0.95）
- 短直線: 人気馬有利（◎×1.05）
- 小回り: 先行有利（◎×1.03）
- 急坂: パワー馬有利（◎×1.02）

### 5.3 問題点 🔴

#### 問題1: 主観的な印の補正係数

**現状:**
```python
mark_weights = {"◎": 1.3, "◯": 1.15, ...}
```

**問題:**
1. **係数の根拠が不明**
   - なぜ◎は1.3なのか？
   - データ分析に基づいていない

2. **ユーザーの「印」が正確という保証なし**
   - ユーザーが適当に印をつける可能性
   - AI予測を無意味にする

3. **主観と客観の混在**
   - AI予測（客観）と印（主観）を混ぜている
   - どちらが正しいか不明

**影響:** 🟡 AI予測の価値が不明確

#### 問題2: 会場特性補正の二重適用

**現状:**
```python
# 412-438行
if straight > 500:
    mark_weights["◎"] *= 0.95  # 直線長いので人気薄有利
```

**問題:**
- 会場特性は既に特徴量として入力されている（はず）
- モデルが既に学習済みの情報を再度補正
- **二重補正になり、過剰補正のリスク**

**ただし:**
- 現在は`use_venue_features=False`なので、実際には補正されていない
- この補正は、会場特性をモデルが学習していない場合の**代替策**

**影響:** 🟡 会場特性機能を有効化した場合、矛盾が発生

#### 問題3: モデル出力とEV計算の不一致

**モデル出力:**
```python
# 3着以内の確率
p_top3 = model.predict_proba(X)[:, 1]
```

**EV計算:**
```python
# 単勝オッズを使用
ev = (p_top3 * mark_weight * 単勝オッズ) - 1.0
```

**問題:**
- **モデルは3着以内の確率を出力**
- **EVは単勝（1着のみ）の計算**
- **根本的な矛盾**

**正しい計算:**
```python
# 1着の確率を使うべき
ev = (p_win * mark_weight * 単勝オッズ) - 1.0

# または複勝の場合
ev = (p_top3 * 複勝オッズ) - 1.0
```

**影響:** 🔴🔴 **EV計算が数学的に誤っている**

#### 問題4: Kelly基準の未実装

**現状:**
```python
# 495-496行
kelly = 0.0  # プレースホルダー
```

**問題:**
- 画面には「推奨度(Kelly)」と表示
- しかし常に0.0
- ユーザーに誤解を与える

**Kelly基準とは:**
```python
# 最適な賭け金の割合
kelly = (p * odds - 1) / (odds - 1)

# 例: 確率20%、オッズ7倍
# kelly = (0.2 * 7 - 1) / (7 - 1) = 0.4 / 6 = 6.7%
```

**影響:** 🟡 機能が不完全

#### 問題5: オッズ取得の不安定性

**現状:**
```python
# 287-314行
current_odds = auto_scraper.scrape_odds_for_race(race_id, mode=mode_val)
```

**問題:**
- オッズが取得できない場合の処理が不十分
- 0.0のオッズで計算すると EV = -1.0 になる
- エラーメッセージが不親切

**影響:** 🟡 ユーザー体験が悪い

### 5.4 予測システム総合評価

| 項目 | 評価 | 備考 |
|------|------|------|
| **UI/UX** | 🟢 良好 | Streamlitで使いやすい |
| **機能性** | 🟡 普通 | 基本機能は動作 |
| **正確性** | 🔴 低い | EV計算に誤り |
| **堅牢性** | 🟡 普通 | エラー処理が不足 |

**総合:** 🟡 **見た目は良いが、計算ロジックに問題**

---

## 📊 6. データ品質の問題

### 6.1 データ量

| データセット | 行数 | 評価 |
|-------------|------|------|
| database.csv (JRA) | 656 | 🔴 不足 |
| database_nar.csv (NAR) | 2,175 | 🟡 やや不足 |

**機械学習に必要なデータ量:**
- 最低: 特徴量×10 = 300行
- 推奨: 1,000行以上
- 理想: 10,000行以上

**現状:** 🔴 **JRAは明らかに不足、NARも十分とは言えない**

### 6.2 データ品質チェックの欠如

**問題:**
1. **異常値検出なし**
   - 着順>18の場合
   - タイム<0の場合
   - オッズ=0の場合

2. **データ一貫性の未確認**
   - カラム数の変動
   - データ型の不一致
   - 日付フォーマットの違い

3. **欠損データの分析なし**
   - どの特徴量が欠損しやすいか
   - 欠損パターンに意味があるか

**推奨:**
```python
# データプロファイリング
import pandas_profiling

profile = df.profile_report(title="Data Quality Report")
profile.to_file("data_quality.html")
```

### 6.3 データバイアス

**潜在的な問題:**
1. **時期の偏り**
   - 特定の年・月に集中している可能性
   - 季節変動を捉えられない

2. **会場の偏り**
   - 特定の会場のデータが多い可能性
   - マイナー会場のデータが少ない

3. **クラスの偏り**
   - 新馬・未勝利が多く、重賞が少ない可能性
   - モデルが重賞レースに対応できない

**確認方法:**
```python
# 時期の分布
df['日付'].value_counts().plot()

# 会場の分布
df['会場'].value_counts()

# クラスの分布
df['レース名'].str.extract(r'(新馬|未勝利|1勝|2勝|3勝|OP|G1|G2|G3)').value_counts()
```

---

## 🐛 7. エッジケースの未処理

### 7.1 レース中止/除外

**問題:**
```python
# 着順列に "中止" や "除外" が入る可能性
df['rank'] = pd.to_numeric(df['着 順'], errors='coerce')  # NaNになる
```

**影響:**
- 学習データに不正なサンプルが混入
- モデル精度低下

**推奨:**
```python
# 中止/除外をフィルタリング
valid_ranks = ['1', '2', '3', ..., '18']
df = df[df['着 順'].isin(valid_ranks)]
```

### 7.2 新馬戦

**問題:**
- 過去走データがない
- `fillna()`で全て埋めるため、全馬が同じ特徴量になる
- モデルが予測できない

**推奨:**
```python
# 新馬戦フラグを追加
df['is_new_horse'] = (df['past_1_rank'].isna()).astype(int)
```

### 7.3 障害レース

**問題:**
- 距離が3000m以上になる
- モデルが対応できない可能性

**推奨:**
- 障害レースを除外
- または別モデルを作成

### 7.4 地方競馬の特殊性

**未対応の要素:**
- ナイター開催
- ダートのみの会場
- 中央からの転入馬（一部対応済み）

---

## 🔒 8. セキュリティ・運用上の問題

### 8.1 レート制限違反のリスク

**現状:**
```python
time.sleep(1)  # 1秒のみ
```

**問題:**
- netkeiba.comの利用規約違反の可能性
- IP BAN のリスク
- 法的リスク

**推奨:**
- robots.txtの確認
- 利用規約の遵守
- APIの使用検討

### 8.2 メモリ管理

**問題:**
```python
HORSE_HISTORY_CACHE = {}  # 無限に成長
```

**影響:**
- 長時間実行でメモリ枯渇
- システムクラッシュ

### 8.3 データベース未使用

**問題:**
- SQLite実装があるが使われていない
- CSV読み込みが遅い

**推奨:**
- SQLiteへの移行
- インデックスの作成

---

## ✅ 9. 優先度別改善策

### 🔴 優先度: 最高（即時対応必須）

#### 1. ルックアヘッドバイアスの解消

**現状の問題:**
```python
# train_model.py: 46行
train_test_split(X, y, test_size=0.2, random_state=42)  # ランダム分割
```

**修正:**
```python
# TimeSeriesSplitを使用
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    # 学習・評価
```

**期待効果:**
- 🔴 精度が大幅に低下する可能性（現在は過大評価）
- ✅ 実際の予測性能が明確になる

#### 2. ターゲット変数の再定義

**現状の問題:**
```python
target_top3 = (rank <= 3).astype(int)  # 3着以内
```

**修正案1: 単勝予測**
```python
target_win = (rank == 1).astype(int)  # 1着のみ
```

**修正案2: 回帰問題**
```python
target = rank  # 着順そのもの（1-18）
```

**修正案3: 多クラス分類**
```python
# 1着、2-3着、4-6着、7着以下
target_class = pd.cut(rank, bins=[0, 1, 3, 6, 18], labels=[0, 1, 2, 3])
```

**期待効果:**
- ✅ EV計算と整合性が取れる
- ✅ モデルの目的が明確になる

#### 3. データ量の増加

**現状:** 656行（JRA）、2,175行（NAR）

**目標:**
- 短期: 1,000行以上
- 中期: 5,000行以上
- 長期: 10,000行以上

**方法:**
1. 過去3年分のデータを取得（ドキュメントに記載あり）
2. より多くの会場・レースをスクレイピング
3. データ拡張技術の検討

**期待効果:**
- ✅ 過学習リスクの低減
- ✅ モデル精度の向上

### 🟡 優先度: 高（早期対応推奨）

#### 4. データ検証パイプラインの構築

**実装:**
```python
import pandas as pd
from pandera import Column, DataFrameSchema, Check

# スキーマ定義
schema = DataFrameSchema({
    "着 順": Column(int, Check.in_range(1, 18)),
    "タイム": Column(float, Check.greater_than(0)),
    "単勝 オッズ": Column(float, Check.greater_than(0)),
    # ... 他のカラム
})

# 検証
try:
    schema.validate(df)
except SchemaError as e:
    print(f"データ品質エラー: {e}")
```

**期待効果:**
- ✅ 異常データの混入防止
- ✅ データ品質の可視化

#### 5. エラーハンドリングの強化

**実装:**
```python
from tenacity import retry, stop_after_attempt, wait_exponential
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def scrape_with_retry(url):
    try:
        # スクレイピング処理
        pass
    except RequestException as e:
        logger.error(f"ネットワークエラー: {e}")
        raise
    except ParseError as e:
        logger.error(f"パースエラー: {e}")
        raise
```

**期待効果:**
- ✅ システムの安定性向上
- ✅ デバッグの容易化

#### 6. キャリブレーションの評価

**実装:**
```python
from sklearn.calibration import calibration_curve
import matplotlib.pyplot as plt

# キャリブレーションプロット
prob_true, prob_pred = calibration_curve(y_test, y_pred, n_bins=10)

plt.plot(prob_pred, prob_true, marker='o')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('Predicted Probability')
plt.ylabel('True Probability')
plt.title('Calibration Curve')
plt.show()

# Brier Score
from sklearn.metrics import brier_score_loss
brier = brier_score_loss(y_test, y_pred)
print(f"Brier Score: {brier:.4f}")  # 低いほど良い
```

**期待効果:**
- ✅ 確率予測の精度を評価
- ✅ モデルの信頼性向上

### 🟢 優先度: 中（余裕があれば対応）

#### 7. ハイパーパラメータ最適化の実施

**実装:**
```python
# train_model.py: 128-186行の関数を使用
best_params = optimize_hyperparameters(data_path, n_trials=100)
model = train_model(data_path, model_path, params=best_params)
```

**期待効果:**
- ✅ 精度向上（+2-5%）

#### 8. 特徴量選択

**実装:**
```python
import shap

# SHAP値で重要度分析
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# 上位20特徴量を選択
feature_importance = np.abs(shap_values).mean(axis=0)
top_features = np.argsort(feature_importance)[-20:]
```

**期待効果:**
- ✅ 過学習リスクの低減
- ✅ 計算速度の向上

#### 9. 会場特性機能の有効化

**手順:**
1. `python ml/retrain_with_venue_features.py`
2. `public_app.py`を編集（2箇所）
3. A/Bテストで効果検証

**期待効果:**
- ✅ 精度向上（+5-10%の可能性）

#### 10. データベース移行

**実装:**
```python
# db/database.py を使用
from db.database import Database

db = Database('database.db')
db.migrate_from_csv('database.csv')
```

**期待効果:**
- ✅ クエリ速度10倍以上

---

## 📈 10. 期待される効果

### 改善前 vs 改善後（予測）

| 項目 | 改善前 | 改善後（予測） |
|------|--------|---------------|
| **AUC** | 0.80? | 0.65-0.75（現実的） |
| **的中率（単勝）** | 不明 | 5-10% |
| **回収率** | 不明 | 70-85% |
| **データ量** | 656行 | 5,000行+ |
| **システム安定性** | 低い | 高い |

**注意:**
- 改善前のAUC 0.80は**過大評価の可能性が高い**
- ルックアヘッドバイアスを解消すると、精度は大幅に低下する見込み
- しかしこれが**実際の予測性能**

### 競馬予測の現実

**一般的な統計:**
- プロの予想家: 的中率10-15%、回収率80-90%
- 素人: 的中率5%、回収率50-70%
- AI: 的中率8-12%、回収率70-85%

**このシステムの目標:**
- 的中率: 8-10%
- 回収率: 75-80%
- 長期的に損失を最小化

**重要な認識:**
- 競馬で長期的に利益を出すのは極めて難しい
- 控除率（JRA: 20-25%）があるため、期待値は常にマイナス
- このシステムは「損失を減らす」ことが目的

---

## 🎯 11. 最終結論

### 11.1 システムの現状評価

**プロトタイプとしての評価: 🟢 優秀**
- アーキテクチャが明確
- 包括的な特徴量設計
- ユーザーフレンドリーなUI
- 教育目的には十分

**本番運用としての評価: 🔴 不適切**
- ルックアヘッドバイアスによる過大評価
- ターゲット変数の定義ミス
- データ量の絶対的不足
- エラーハンドリング不足

### 11.2 信頼性の判定

| アルゴリズム | 信頼性 | 妥当性 | 総合 |
|-------------|--------|--------|------|
| **スクレイピング** | 🟡 中 | 🟢 高 | 🟡 |
| **特徴量エンジニアリング** | 🟡 中 | 🟡 中 | 🟡 |
| **モデル学習** | 🔴 低 | 🔴 低 | 🔴 |
| **予測・EV計算** | 🔴 低 | 🔴 低 | 🔴 |

**総合判定: 🔴 信頼性・妥当性ともに不十分**

### 11.3 推奨される対応

#### オプション1: プロトタイプとして維持

**適用場面:**
- 学習・教育目的
- アイデア検証
- デモンストレーション

**対応:**
- 現状のまま使用
- ただし、「精度は参考値」と明記
- 実際の賭けには使用しない

#### オプション2: 本格的な改修

**対応順序:**
1. 🔴 データ量を5,000行以上に増やす（最優先）
2. 🔴 TimeSeriesSplitで再学習
3. 🔴 ターゲット変数を「1着のみ」に変更
4. 🟡 データ検証パイプラインを構築
5. 🟡 キャリブレーション評価を追加

**期間:** 1-2ヶ月

**効果:**
- 実際の予測性能が明確に
- システムの信頼性向上
- 本番運用の可能性

#### オプション3: 部分的な改善

**対応:**
- 🔴 データ量の増加のみ実施
- 🟡 エラーハンドリング強化
- 現状のアルゴリズムは維持

**期間:** 1-2週間

**効果:**
- 安定性の向上
- ただし精度の過大評価は継続

---

## 📝 12. 付録: チェックリスト

### データ品質チェックリスト

- [ ] データ量: 最低1,000行以上
- [ ] 欠損率: 各カラム20%以下
- [ ] 異常値: 着順1-18、タイム>0、オッズ>0
- [ ] データ型: 全て正しい型に変換済み
- [ ] 重複: 同一レースIDのレコードが1つのみ
- [ ] 時系列: 日付順にソート済み

### モデル学習チェックリスト

- [ ] 時系列分割: TimeSeriesSplit使用
- [ ] クロスバリデーション: 5-fold以上
- [ ] ハイパーパラメータ最適化: Optuna実施
- [ ] 評価指標: AUC、Brier Score、Log Loss
- [ ] キャリブレーション: プロット確認
- [ ] 特徴量重要度: SHAP値分析

### 本番運用チェックリスト

- [ ] エラーハンドリング: 全ての例外をキャッチ
- [ ] ロギング: INFO以上のログ記録
- [ ] リトライ機構: 3回以上
- [ ] レート制限: 1秒以上の待機
- [ ] タイムアウト: 10秒以内
- [ ] メモリ管理: キャッシュのサイズ制限

---

## 🔗 関連ドキュメント

- `docs/VENUE_FEATURES.md`: 会場特性機能の詳細
- `docs/HOTFIX_VENUE_FEATURES.md`: 互換性問題の修正
- `docs/EV_ANALYSIS.md`: EV計算の分析
- `IMPROVEMENTS.md`: 実装済みの改善内容

---

**レポート終了**
