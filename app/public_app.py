import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
import json
import plotly.express as px
import plotly.graph_objects as go
import time

# Add paths
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(PROJECT_ROOT, 'scraper'))
sys.path.append(os.path.join(PROJECT_ROOT, 'ml'))

try:
    import importlib
    import auto_scraper
    importlib.reload(auto_scraper) # Force reload to apply fixes
    from feature_engineering import process_data
    from db_helper import KeibaDatabase
except ImportError as e:
    st.error(f"Import Error: {e}")

st.set_page_config(page_title="AI Keiba Predictor", layout="wide")

# --- Utils ---
@st.cache_resource
def load_model(mode="JRA"):
    model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/lgbm_model_nar.pkl" if mode == "NAR" else "ml/models/lgbm_model.pkl")
    if os.path.exists(model_path):
        with open(model_path, 'rb') as f:
            return pickle.load(f)
    return None

@st.cache_resource
def load_model_metadata(mode="JRA"):
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã‚€"""
    meta_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/lgbm_model_nar_meta.json" if mode == "NAR" else "ml/models/lgbm_model_meta.json")
    if os.path.exists(meta_path):
        with open(meta_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

@st.cache_resource
def load_history_csv(mode):
    """éå»ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ (é«˜é€ŸåŒ–)"""
    csv_path = os.path.join(PROJECT_ROOT, "data", "raw", "database_nar.csv" if mode == "NAR" else "database.csv")
    if os.path.exists(csv_path):
        try:
            # é«˜é€ŸåŒ–ã®ãŸã‚ã«å¿…è¦ãªåˆ—ã ã‘...ã¨ã„ããŸã„ãŒã€æ±ç”¨æ€§ã‚’è€ƒãˆå…¨èª­ã¿è¾¼ã¿
            return pd.read_csv(csv_path, dtype={'horse_id': str, 'race_id': str})
        except:
            pass
    return None

def get_data_freshness(mode="JRA"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—ï¼ˆSQLå¯¾å¿œï¼‰"""
    db_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "keiba_data.db")
    if os.path.exists(db_path):
        try:
            db = KeibaDatabase(db_path)
            freshness = db.get_data_freshness(mode)
            return freshness, 0  # é®®åº¦æƒ…å ±ã‚’æ–‡å­—åˆ—ã§è¿”ã™
        except Exception as e:
            st.warning(f"ãƒ‡ãƒ¼ã‚¿é®®åº¦ã®å–å¾—ã«å¤±æ•—: {e}")
            return "ä¸æ˜", -1
    return "DBãªã—", -1
    return None, None

def calculate_confidence_score(ai_prob, model_meta, jockey_compat=None, course_compat=None, distance_compat=None, is_rest_comeback=0):
    """
    äºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰

    Args:
        ai_prob: AIäºˆæ¸¬ç¢ºç‡ï¼ˆ0-1ï¼‰
        model_meta: ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        jockey_compat: é¨æ‰‹ç›¸æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        course_compat: ã‚³ãƒ¼ã‚¹é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        distance_compat: è·é›¢é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        is_rest_comeback: ä¼‘é¤Šæ˜ã‘ãƒ•ãƒ©ã‚°ï¼ˆ1=True, 0=Falseï¼‰

    Returns:
        int: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
    """
    if not model_meta:
        return 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # ===== 1. ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦: ãƒ¢ãƒ‡ãƒ«ã®AUCã‹ã‚‰ç®—å‡º =====
    base_confidence = model_meta.get('performance', {}).get('auc', 0.75) * 100

    # ===== 2. ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹èª¿æ•´ =====
    data_size = model_meta.get('data_stats', {}).get('total_records', 0)
    if data_size < 1000:
        data_penalty = -20  # ãƒ‡ãƒ¼ã‚¿é‡å°‘ãªã„
    elif data_size < 3000:
        data_penalty = -8
    elif data_size < 5000:
        data_penalty = -3
    else:
        data_penalty = 0

    # ===== 3. äºˆæ¸¬ç¢ºç‡ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé€£ç¶šçš„ãªèª¿æ•´ï¼‰ =====
    # 0.5ã‹ã‚‰é›¢ã‚Œã‚‹ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒç¢ºä¿¡ã‚’æŒã£ã¦ã„ã‚‹ï¼‰
    # 0.5ã«è¿‘ã„ã»ã©ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒè¿·ã£ã¦ã„ã‚‹ï¼‰
    distance_from_uncertain = abs(ai_prob - 0.5)

    # è·é›¢ã«åŸºã¥ãä¿¡é ¼åº¦ãƒœãƒ¼ãƒŠã‚¹: 0.5é›¢ã‚Œã¦ã„ã‚‹ã¨æœ€å¤§+20ã€0.0ã ã¨-20
    # å¼ã‚’èª¿æ•´ã—ã¦ç¯„å›²ã‚’æ‹¡å¤§
    prob_bonus = (distance_from_uncertain * 2 - 0.25) * 40

    # ã•ã‚‰ã«æ¥µç«¯ãªäºˆæ¸¬ï¼ˆ<0.05 or >0.95ï¼‰ã«ã¯è¿½åŠ ãƒœãƒ¼ãƒŠã‚¹
    if ai_prob < 0.05 or ai_prob > 0.95:
        prob_bonus += 12

    # AIç¢ºç‡ãŒæ¥µç«¯ã«ä½ã„å ´åˆã¯ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§ï¼‰
    if ai_prob < 0.08:
        prob_bonus -= 10

    # ===== 4. é©æ€§ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆæ–°è¦è¿½åŠ ï¼‰ =====
    compat_bonus = 0

    # åˆ©ç”¨å¯èƒ½ãªé©æ€§ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ
    compat_scores = []
    if jockey_compat is not None and not pd.isna(jockey_compat):
        compat_scores.append(jockey_compat)
    if course_compat is not None and not pd.isna(course_compat):
        compat_scores.append(course_compat)
    if distance_compat is not None and not pd.isna(distance_compat):
        compat_scores.append(distance_compat)

    if compat_scores:
        avg_compat = sum(compat_scores) / len(compat_scores)
        min_compat = min(compat_scores)

        # å¹³å‡é©æ€§ã«ã‚ˆã‚‹èª¿æ•´
        if avg_compat >= 9:
            compat_bonus = +15  # å…¨ã¦é«˜é©æ€§
        elif avg_compat >= 7:
            compat_bonus = +8
        elif avg_compat >= 5:
            compat_bonus = 0
        elif avg_compat >= 3:
            compat_bonus = -12
        else:
            compat_bonus = -25  # ãƒ‡ãƒ¼ã‚¿å“è³ªãŒä½ã„

        # æœ€ä½ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹è¿½åŠ ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆã„ãšã‚Œã‹ã®é©æ€§ãŒæ¥µç«¯ã«ä½ã„å ´åˆï¼‰
        if min_compat < 3:
            compat_bonus -= 15  # è‡´å‘½çš„ãªä¸é©æ€§
        elif min_compat < 5:
            compat_bonus -= 8

    # ===== 5. ä¼‘é¤Šæ˜ã‘ãƒ»é–“éš”ã«ã‚ˆã‚‹èª¿æ•´ (æ–°è¦è¿½åŠ ) =====
    interval_penalty = 0
    if is_rest_comeback == 1:
        interval_penalty = -10 # é•·æœŸä¼‘é¤Šæ˜ã‘ã¯ä¸ç¢ºå®šè¦ç´ ãŒå¤šã„

    # ===== æœ€çµ‚è¨ˆç®— =====
    confidence = base_confidence + data_penalty + prob_bonus + compat_bonus + interval_penalty

    # ç¯„å›²ã‚’æ‹¡å¤§: 20-95ï¼ˆã‚ˆã‚Šå·®åˆ¥åŒ–ï¼‰
    return int(max(20, min(95, confidence)))

def predict_race_logic(df, model, model_meta):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦AIäºˆæ¸¬ã¨ä¿¡é ¼åº¦è¨ˆç®—ã‚’è¡Œã†
    """
    try:
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆä¼šå ´ç‰¹æ€§ã‚ã‚Šï¼‰
        X_df = process_data(df, use_venue_features=True)

        # Align features with model
        if hasattr(model, 'feature_name'):
             model_features = model.feature_name()
             # Ensure all features exist
             for f in model_features:
                 if f not in X_df.columns:
                     X_df[f] = 0
             
             X_pred = X_df[model_features].fillna(0)
        else:
             # Fallback for older sklearn models or if feature_name not available
             meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
             features = [c for c in X_df.columns if c not in meta_cols and c != 'target_win']
             X_pred = X_df[features].select_dtypes(include=['number']).fillna(0)

        # Predict
        probs = model.predict(X_pred)

        df['AI_Prob'] = probs
        df['AI_Score'] = (probs * 100).astype(int)

        # Calculate Confidence
        confidences = []
        for idx, p in enumerate(probs):
            jockey_c = X_df['jockey_compatibility'].iloc[idx] if 'jockey_compatibility' in X_df.columns else None
            distance_c = X_df['distance_compatibility'].iloc[idx] if 'distance_compatibility' in X_df.columns else None
            
            # Course compatibility
            course_c = None
            if 'turf_compatibility' in X_df.columns and 'dirt_compatibility' in X_df.columns:
                if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df.columns:
                    course_type = df['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[idx]
                    if 'èŠ' in str(course_type):
                        course_c = X_df['turf_compatibility'].iloc[idx]
                    elif 'ãƒ€' in str(course_type):
                        course_c = X_df['dirt_compatibility'].iloc[idx]
                else:
                    course_c = X_df['turf_compatibility'].iloc[idx] # Default

            is_rest = X_df['is_rest_comeback'].iloc[idx] if 'is_rest_comeback' in X_df.columns else 0

            conf = calculate_confidence_score(p, model_meta, jockey_c, course_c, distance_c, is_rest)
            confidences.append(conf)

        df['Confidence'] = confidences

        # Merge relevant features back to df
        cols_to_merge = [
            'turf_compatibility', 'dirt_compatibility', 
            'jockey_compatibility', 'distance_compatibility', 
            'weighted_avg_speed', 'weighted_avg_rank'
        ]
        for c in cols_to_merge:
            if c in X_df.columns:
                df[c] = X_df[c]
                
        return df
    except Exception as e:
        import traceback
        st.error(f"Prediction Error: {e}")
        st.code(traceback.format_exc())
        return None

def load_schedule_data(mode="JRA"):
    json_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "temp", "todays_data_nar.json" if mode == "NAR" else "todays_data.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# --- UI ---
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Logic Explanation
with st.expander("â„¹ï¸ ã“ã®AIäºˆæƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ã¤ã„ã¦ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)"):
    st.markdown("""
    ### ğŸ§  AIäºˆæƒ³ã®ä»•çµ„ã¿
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**LightGBM**ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€éå»ã®è†¨å¤§ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ1ç€ï¼ˆå‹åˆ©ï¼‰ã®ç¢ºç‡ã€ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
    
    #### ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
    - **åŸºæœ¬æƒ…å ±**: æ ç•ªã€é¦¬ç•ªã€é¦¬é½¢ã€æ–¤é‡ã€é¨æ‰‹
    - **éå»5èµ°ã®æˆç¸¾**: ç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã€ä¸Šã‚Š3Fã€é€šéé †ï¼ˆè„šè³ªï¼‰ã€é¦¬ä½“é‡ã€é¦¬å ´çŠ¶æ…‹ã€**å¤©æ°—**ã€**æœ€çµ‚ã‚ªãƒƒã‚º**
    - **ç›´è¿‘é‡è¦–**: éå»ã®ãƒ¬ãƒ¼ã‚¹ã¯ç›´è¿‘ã®ã‚‚ã®ã»ã©é‡è¦è¦–ã™ã‚‹ã€Œæ™‚é–“æ¸›è¡°ã€å‡¦ç†ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
    
    #### ğŸ¯ æœŸå¾…å€¤ (EV) ã¨ã¯ï¼Ÿ
    ã€Œãã®é¦¬åˆ¸ã‚’è²·ã„ç¶šã‘ãŸã¨ãã«ã€æœ€çµ‚çš„ã«ã„ãã‚‰å„²ã‹ã‚‹ã‹ã€ã®æŒ‡æ¨™ã§ã™ã€‚
    
    $$
    \text{èª¿æ•´å¾ŒæœŸå¾…å€¤} = (\text{AIã®å‹ç‡} \times \text{ã‚ãªãŸã®å°} \times \text{ã‚ªãƒƒã‚º}) - 1.0
    $$
    
    - **ãƒ—ãƒ©ã‚¹ (0ä»¥ä¸Š)**: è²·ãˆã°è²·ã†ã»ã©å„²ã‹ã‚‹ãƒãƒ£ãƒ³ã‚¹ãŒã‚ã‚‹é¦¬ï¼ˆæ¨å¥¨ï¼ï¼‰
    - **ãƒã‚¤ãƒŠã‚¹**: å‹ã¤ç¢ºç‡ã«æ¯”ã¹ã¦ã‚ªãƒƒã‚ºãŒä½ã™ãã‚‹ï¼ˆå‰²ã«åˆã‚ãªã„ï¼‰é¦¬
    - **ã‚ãªãŸã®å°**: AIã®äºˆæ¸¬ã«ã€ã‚ãªãŸã®ç›´æ„Ÿï¼ˆâ—ã‚„â—¯ï¼‰ã‚’ãƒŸãƒƒã‚¯ã‚¹ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚AIã ã‘ã§ãªãã€ã‚ãªãŸã®ç›¸é¦¬çœ¼ã‚‚åæ˜ ã•ã‚Œã¾ã™ã€‚

    #### ğŸ‡ ä¸­å¤®ç«¶é¦¬ vs ğŸŒ™ åœ°æ–¹ç«¶é¦¬
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¼šå ´ã‹ã‚‰è‡ªå‹•çš„ã«ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã¨åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰ã‚’åˆ¤å®šã—ã€ãã‚Œãã‚Œã«æœ€é©åŒ–ã•ã‚ŒãŸæœŸå¾…å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    **ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.3å€, â—¯=1.15å€ï¼ˆæ§ãˆã‚ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚

    **åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.8å€, â—¯=1.4å€ï¼ˆç©æ¥µçš„ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„

    #### ğŸ“Š ä¿¡é ¼æ€§å‘ä¸Šã®å–ã‚Šçµ„ã¿
    - **ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: è¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ï¼ˆAUCï¼‰ã€ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¸¸æ™‚è¡¨ç¤º
    - **äºˆæ¸¬ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: å„äºˆæ¸¬ã«ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’0-100%ã§æ•°å€¤åŒ–
    - **ãƒ‡ãƒ¼ã‚¿æ–°é®®åº¦**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’è¡¨ç¤ºï¼ˆ3æ—¥ä»¥å†…ãŒç†æƒ³ï¼‰
    - **æ³¨æ„å–šèµ·**: ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³ã‚„äºˆæ¸¬ã®é™ç•Œã‚’æ˜ç¤º
    - **é€æ˜æ€§**: ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ»é™ç•Œã‚’éš ã•ãšé–‹ç¤º
    """)

# --- Admin Menu ---
st.markdown("### è¨­å®š")
mode = st.radio("é–‹å‚¬ãƒ¢ãƒ¼ãƒ‰ (Mode)", ["JRA (ä¸­å¤®ç«¶é¦¬)", "NAR (åœ°æ–¹ç«¶é¦¬)"], horizontal=True)
mode_val = "JRA" if "JRA" in mode else "NAR"

with st.expander("ğŸ› ï¸ ç®¡ç†ãƒ„ãƒ¼ãƒ« (ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°ãªã©)"):
    col_admin_1, col_admin_2 = st.columns([1, 1])
    with col_admin_1:
         if st.button("ğŸ“… ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’æ›´æ–° (ä»Šå¾Œ1é€±é–“)"):
            with st.spinner(f"{mode_val}ã®æœ€æ–°ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ä¸­..."):
                success, msg = auto_scraper.scrape_todays_schedule(mode=mode_val)
                if success:
                    st.success(msg)
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {msg}")
    
    with col_admin_2:
         if st.button("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿"):
             st.cache_resource.clear()
             st.success("ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ¬¡å›äºˆæ¸¬æ™‚ã«å†ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# --- Analysis Mode Selection ---
st.markdown("### åˆ†æãƒ¢ãƒ¼ãƒ‰")
analysis_mode = st.radio("æ©Ÿèƒ½ã‚’é¸æŠ", ["ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ", "ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹ã‚’æ¢ã™ (ä¸€æ‹¬åˆ†æ)"], horizontal=True)

st.markdown("---")

# --- Race Selection ---
st.subheader("ğŸ“ ãƒ¬ãƒ¼ã‚¹é¸æŠ")

schedule_data = load_schedule_data(mode=mode_val)
race_id = None

if schedule_data and "races" in schedule_data:
    races = schedule_data['races']
    
    # 1. Filter by Date
    dates = sorted(list(set([r.get('date', 'Unknown') for r in races])))
    
    if analysis_mode == "ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ":
        # Layout columns for selection
        col_date, col_venue, col_race = st.columns(3)
        
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        # Filter races by date
        todays_races = [r for r in races if r.get('date') == selected_date]
        
        if todays_races:
            # 2. Filter by Venue
            venues = sorted(list(set([r['venue'] for r in todays_races])))
            
            with col_venue:
                selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ", venues)
                
            # Filter races by venue
            venue_races = [r for r in todays_races if r['venue'] == selected_venue]
            
            # 3. Select Race
            # Sort by race number
            venue_races.sort(key=lambda x: int(x['number']) if str(x['number']).isdigit() else 0)
            
            race_options = {f"{r['number']}R: {r['name']}": r['id'] for r in venue_races}
            
            with col_race:
                selected_label = st.selectbox("3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list(race_options.keys()))
                if selected_label:
                    race_id = race_options[selected_label]
        else:
            st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    elif analysis_mode == "ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹ã‚’æ¢ã™ (ä¸€æ‹¬åˆ†æ)":
        st.info("ğŸ’¡ **æ©Ÿèƒ½èª¬æ˜**: æŒ‡å®šã—ãŸæ—¥ã®å…¨ãƒ¬ãƒ¼ã‚¹ã‚’AIãŒåˆ†æã—ã€ä¿¡é ¼åº¦ãŒé«˜ã„ã€Œå …ã„ãƒ¬ãƒ¼ã‚¹ã€ã®ã¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚")
        
        col_date, col_venue_multi = st.columns([1, 2])
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        todays_races = [r for r in races if r.get('date') == selected_date]
        if todays_races:
            venues = sorted(list(set([r.get('venue', 'Unknown') for r in todays_races])))
            
            with col_venue_multi:
                 selected_venues = st.multiselect("2. é–‹å‚¬åœ°ã‚’é¸æŠ (ç©ºæ¬„ã§å…¨ä¼šå ´)", venues, default=venues)
            
            target_races = [r for r in todays_races if not selected_venues or r.get('venue') in selected_venues]
            st.write(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°: {len(target_races)} ãƒ¬ãƒ¼ã‚¹")
            
            confidence_threshold = st.slider("ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (ã“ã‚Œä»¥ä¸Šã®ä¿¡é ¼åº¦ã®ãƒ¬ãƒ¼ã‚¹ã‚’è¡¨ç¤º)", 0, 100, 80)
            
            if st.button("ğŸš€ ä¸€æ‹¬åˆ†æã‚’é–‹å§‹ã™ã‚‹", type="primary"):
                 if not target_races:
                     st.warning("å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                 else:
                     with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                         # from app.public_app import load_model, load_model_metadata
                         model = load_model(mode_val)
                         model_meta = load_model_metadata(mode_val)
                     
                     if not model:
                         st.error("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                     else:
                         results_container = st.container()
                         progress_bar = st.progress(0)
                         status_text = st.empty()
                         
                         solid_races_data = []
                         
                         for i, race in enumerate(target_races):
                             r_name = f"{race['venue']}{race['number']}R: {race['name']}"
                             status_text.text(f"åˆ†æä¸­ ({i+1}/{len(target_races)}): {r_name}...")
                             
                             try:
                                 # 1. Scrape with cached history
                                 if i > 0: time.sleep(1) 
                                 history_df_cache = load_history_csv(mode_val)
                                 df_race = auto_scraper.scrape_shutuba_data(race['id'], mode=mode_val, history_df=history_df_cache)
                                 
                                 if df_race is not None and not df_race.empty:
                                     # 2. Predict
                                     processed_df = predict_race_logic(df_race, model, model_meta)
                                     
                                     if processed_df is not None:
                                         # 3. Find Top Horses (Top 3)
                                         processed_df = processed_df.sort_values('AI_Score', ascending=False)
                                         
                                         top_horse = processed_df.iloc[0]
                                         conf = top_horse['Confidence']
                                         
                                         # Construct Multi-Horse String
                                         picks_str = []
                                         marks = ["â—", "â—¯", "â–²", "â–³", "â˜†"]
                                         
                                         # Helper for circled numbers (local scope)
                                         def to_circled_num_local(n):
                                             try:
                                                 n = int(n)
                                                 if 1 <= n <= 20:
                                                     return chr(9311 + n)
                                                 return f"({n})"
                                             except:
                                                 return ""

                                         for rank in range(min(5, len(processed_df))):
                                             h = processed_df.iloc[rank]
                                             m = marks[rank]
                                             h_num = h.get('é¦¬ ç•ª', '')
                                             c_num = to_circled_num_local(h_num)
                                             picks_str.append(f"{m} {c_num} {h['é¦¬å']} ({h['AI_Score']}%)")
                                         
                                         picks_display = " / ".join(picks_str)

                                         if conf >= confidence_threshold:
                                             solid_races_data.append({
                                                 "ä¼šå ´": race['venue'],
                                                 "R": f"{race['number']}R",
                                                 "ãƒ¬ãƒ¼ã‚¹å": race['name'],
                                                 "AIäºˆæƒ³ (â—/â—¯/â–²/â–³/â˜†)": picks_display,
                                                  # "æœ¬å‘½é¦¬": top_horse['é¦¬å'], # Removed in favor of multi-display
                                                 "ä¿¡é ¼åº¦": f"{conf}%",
                                                 # "AIæŒ‡æ•°": f"{score}%", # Included in string
                                                 "race_id": race['id']
                                             })
                             
                             except Exception as e:
                                 print(f"Error analyzing {race['id']}: {e}")
                                 
                             progress_bar.progress((i + 1) / len(target_races))
                         
                         status_text.success(f"å®Œäº†ï¼ {len(target_races)}ãƒ¬ãƒ¼ã‚¹ä¸­ã€æ¡ä»¶ã‚’æº€ãŸã™ãƒ¬ãƒ¼ã‚¹ã¯ {len(solid_races_data)} ä»¶ã§ã—ãŸã€‚")
                         
                         if solid_races_data:
                             st.markdown("### ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹å€™è£œ")
                             res_df = pd.DataFrame(solid_races_data)
                             st.dataframe(res_df, use_container_width=True)
                             st.info("è©³ç´°ã‚’è¦‹ãŸã„å ´åˆã¯ã€ä¸Šã®ã€Œå€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æã€ãƒ¢ãƒ¼ãƒ‰ã§è©²å½“ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                         else:
                             st.warning("æ¡ä»¶ã‚’æº€ãŸã™å …ã„ãƒ¬ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä¿¡é ¼åº¦åŸºæº–ã‚’ä¸‹ã’ã¦ã¿ã¦ãã ã•ã„ã€‚")
        else:
             st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
else:
    st.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    # No fallback text input for now to keep it clean, or keep it inside Individual mode if needed.
    # But existing code had it. Let's omitting it for Batch mode safety.
    if analysis_mode == "ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ":
         race_id = st.text_input("ãƒ¬ãƒ¼ã‚¹IDç›´æ¥å…¥åŠ› (12æ¡)", value="202305021211")


# Main Analysis
if race_id:
    st.header(f"ãƒ¬ãƒ¼ã‚¹åˆ†æ: {race_id}")

    # Load Model and Metadata
    model = load_model(mode=mode_val)
    model_meta = load_model_metadata(mode=mode_val)
    last_updated, days_ago = get_data_freshness(mode=mode_val)

    # Display Model Information and Data Freshness
    with st.expander("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ª", expanded=False):
        if model_meta:
            col_info1, col_info2, col_info3 = st.columns(3)

            with col_info1:
                st.metric(
                    "ãƒ¢ãƒ‡ãƒ«AUCï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰",
                    f"{model_meta.get('performance', {}).get('auc', 0):.3f}",
                    help="0.5=ãƒ©ãƒ³ãƒ€ãƒ ã€1.0=å®Œå…¨äºˆæ¸¬ã€‚0.75ä»¥ä¸ŠãŒç›®å®‰"
                )
                st.caption(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é‡: {model_meta.get('data_stats', {}).get('total_records', 0):,}ä»¶")

            with col_info2:
                if last_updated:
                    freshness_color = "ğŸŸ¢" if days_ago <= 3 else "ğŸŸ¡" if days_ago <= 7 else "ğŸ”´"
                    st.metric(
                        "ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°",
                        f"{days_ago}æ—¥å‰",
                        delta=f"{freshness_color} {last_updated}"
                    )
                else:
                    st.metric("ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°", "ä¸æ˜")

            with col_info3:
                data_size = model_meta.get('data_stats', {}).get('total_records', 0)
                if data_size < 1000:
                    quality = "âš ï¸ å°è¦æ¨¡"
                    quality_help = "ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ãŸã‚ã€äºˆæ¸¬ç²¾åº¦ã¯é™å®šçš„ã§ã™"
                elif data_size < 3000:
                    quality = "ğŸŸ¡ ä¸­è¦æ¨¡"
                    quality_help = "ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™"
                else:
                    quality = "ğŸŸ¢ ååˆ†"
                    quality_help = "ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã§å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™"

                st.metric("ãƒ‡ãƒ¼ã‚¿å“è³ª", quality, help=quality_help)

            # Warnings
            if model_meta.get('warnings'):
                st.warning("**âš ï¸ æ³¨æ„äº‹é …:**\n" + "\n".join([f"- {w}" for w in model_meta['warnings']]))
        else:
            st.info("ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    button_analyze = st.button("ğŸš€ ã“ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã™ã‚‹ (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»AIäºˆæ¸¬)", type="primary", use_container_width=True)

    if button_analyze:
        if not race_id:
             st.error("ãƒ¬ãƒ¼ã‚¹IDãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        elif not model:
             st.error(f"ãƒ¢ãƒ‡ãƒ« ({mode_val}) ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ç®¡ç†ç”»é¢ã§å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            # === å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ– ===
            st.markdown("---")
            st.subheader("ğŸ”„ AIäºˆæ¸¬å‡¦ç†ãƒ•ãƒ­ãƒ¼")

            # ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()

            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å–å¾—
            status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 1/4:** å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            progress_bar.progress(25)
            history_df_cache = load_history_csv(mode_val)
            df = auto_scraper.scrape_shutuba_data(race_id, mode=mode_val, history_df=history_df_cache)

            if df is not None and not df.empty:
                status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 1/4: å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—2-4: AIäºˆæ¸¬ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆå…±é€šé–¢æ•°åŒ–ï¼‰
                status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 2-4:** ç‰¹å¾´é‡è¨ˆç®—ãƒ»AIäºˆæ¸¬ãƒ»ä¿¡é ¼åº¦ç®—å‡ºã‚’å®Ÿè¡Œä¸­...")
                progress_bar.progress(60)
                
                if model:
                    processed_df = predict_race_logic(df, model, model_meta)
                    
                    if processed_df is not None:
                         df = processed_df
                         status_text.success("âœ… AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                         progress_bar.progress(100)
                    else:
                         status_text.error("âŒ äºˆæ¸¬å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                         df['AI_Prob'] = 0.0
                         df['AI_Score'] = 0.0
                else:
                     status_text.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                     df['AI_Prob'] = 0.0
                     df['AI_Score'] = 0.0

                # 4. Display
                # Store in session state to persist edits
                st.session_state[f'data_{race_id}'] = df

                # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                st.markdown("---")
                st.success("ğŸ‰ **AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼** ä¸‹è¨˜ã®çµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # Show Data if available
    if f'data_{race_id}' in st.session_state:
        df_display = st.session_state[f'data_{race_id}'].copy()

        # === ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã®è¡¨ç¤º ===
        st.markdown("---")
        st.subheader("ğŸ‡ ãƒ¬ãƒ¼ã‚¹æ¦‚è¦")

        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±
        col_r1, col_r2, col_r3, col_r4 = st.columns(4)
        with col_r1:
            # Try multiple possible column names for venue
            venue = "ä¸æ˜"
            for col in ['ä¼šå ´', 'venue', 'ç«¶é¦¬å ´', 'å ´æ‰€']:
                if col in df_display.columns and len(df_display) > 0:
                    venue = df_display[col].iloc[0]
                    if pd.notna(venue) and venue != "":
                        break

            # If still unknown, try to extract from race_id (first 4 digits indicate place code)
            if venue == "ä¸æ˜" and race_id and len(race_id) >= 6:
                try:
                    place_code = int(race_id[4:6])
                    place_map = {
                        1: "æœ­å¹Œ", 2: "å‡½é¤¨", 3: "ç¦å³¶", 4: "æ–°æ½Ÿ", 5: "æ±äº¬",
                        6: "ä¸­å±±", 7: "ä¸­äº¬", 8: "äº¬éƒ½", 9: "é˜ªç¥", 10: "å°å€‰",
                        30: "é–€åˆ¥", 35: "ç››å²¡", 36: "æ°´æ²¢", 42: "æµ¦å’Œ", 43: "èˆ¹æ©‹",
                        44: "å¤§äº•", 45: "å·å´", 46: "é‡‘æ²¢", 47: "ç¬ æ¾", 48: "åå¤å±‹",
                        50: "åœ’ç”°", 51: "å§«è·¯", 54: "é«˜çŸ¥", 55: "ä½è³€", 3: "å¸¯åºƒ"
                    }
                    venue = place_map.get(place_code, "ä¸æ˜")
                except:
                    pass

            st.metric("é–‹å‚¬å ´", venue)
        with col_r2:
            race_name = df_display['ãƒ¬ãƒ¼ã‚¹å'].iloc[0] if 'ãƒ¬ãƒ¼ã‚¹å' in df_display.columns else "ä¸æ˜"
            st.metric("ãƒ¬ãƒ¼ã‚¹å", race_name if len(str(race_name)) < 20 else str(race_name)[:17] + "...")
        with col_r3:
            course_type = df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0] if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns else "ä¸æ˜"
            distance = df_display['è·é›¢'].iloc[0] if 'è·é›¢' in df_display.columns else "ä¸æ˜"
            st.metric("ã‚³ãƒ¼ã‚¹", f"{course_type} {distance}m")
        with col_r4:
            num_horses = len(df_display)
            st.metric("å‡ºèµ°é ­æ•°", f"{num_horses}é ­")

        # AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼
        if 'AI_Score' in df_display.columns and 'Confidence' in df_display.columns:
            avg_confidence = df_display['Confidence'].mean()
            max_ai_score = df_display['AI_Score'].max()
            st.info(f"ğŸ“Š **AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼**: æœ€é«˜AIå‹ç‡ {max_ai_score}% | å¹³å‡ä¿¡é ¼åº¦ {avg_confidence:.0f}%")

        # ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã®è©³ç´°è¡¨ç¤º
        venue = df_display['ä¼šå ´'].iloc[0] if 'ä¼šå ´' in df_display.columns else None
        if venue:
            try:
                from ml.venue_characteristics import get_venue_characteristics
                venue_char = get_venue_characteristics(venue)

                if venue_char:
                    st.markdown("#### ğŸŸï¸ ã‚³ãƒ¼ã‚¹ç‰¹æ€§")

                    col_c1, col_c2, col_c3, col_c4 = st.columns(4)

                    # ç›´ç·šè·é›¢
                    with col_c1:
                        straight = venue_char.get('turf_straight', 0)
                        if straight:
                            straight_label = "é•·ã„" if straight > 500 else "çŸ­ã„" if straight < 300 else "æ¨™æº–"
                            st.metric("ç›´ç·šè·é›¢", f"{straight}m", delta=straight_label)
                        else:
                            st.metric("ç›´ç·šè·é›¢", "ä¸æ˜")

                    # å‹¾é…ï¼ˆå‚¾æ–œï¼‰
                    with col_c2:
                        slope = venue_char.get('slope', 'normal')
                        slope_map = {
                            'steep': 'æ€¥å‚ã‚ã‚Š',
                            'moderate': 'ç·©ã‚„ã‹ãªå‚',
                            'flat': 'å¹³å¦',
                            'normal': 'æ¨™æº–'
                        }
                        slope_label = slope_map.get(slope, slope)
                        slope_icon = "â›°ï¸" if slope == 'steep' else "ğŸ”ï¸" if slope == 'moderate' else "â”"
                        st.metric("å‹¾é…ï¼ˆå‚¾æ–œï¼‰", slope_label, delta=slope_icon)

                    # ã‚³ãƒ¼ã‚¹å¹…
                    with col_c3:
                        track_width = venue_char.get('track_width', 'standard')
                        width_map = {
                            'narrow': 'å°å›ã‚Š',
                            'standard': 'æ¨™æº–',
                            'wide': 'åºƒã„ã‚³ãƒ¼ã‚¹'
                        }
                        width_label = width_map.get(track_width, track_width)
                        st.metric("ã‚³ãƒ¼ã‚¹å¹…", width_label)

                    # å¤–æ æœ‰åˆ©åº¦
                    with col_c4:
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        if outer_advantage > 1.05:
                            outer_label = "å¤–æ æœ‰åˆ©"
                            outer_delta = "â†‘"
                        elif outer_advantage < 0.95:
                            outer_label = "å†…æ æœ‰åˆ©"
                            outer_delta = "â†“"
                        else:
                            outer_label = "å…¬å¹³"
                            outer_delta = "="
                        st.metric("æ ç•ªå‚¾å‘", outer_label, delta=outer_delta)

                    # ç‰¹æ€§ã®å½±éŸ¿èª¬æ˜
                    with st.expander("ğŸ’¡ ã“ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ãŒEVè¨ˆç®—ã«ä¸ãˆã‚‹å½±éŸ¿", expanded=False):
                        st.markdown(f"""
                        #### ğŸŸï¸ {venue}ã®ç‰¹æ€§

                        **1. ç›´ç·šè·é›¢: {straight}m ({straight_label})**
                        - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: äººæ°—é¦¬ã‚„ã‚„ä¸åˆ© (-5%)ã€ç©´é¦¬ã‚„ã‚„æœ‰åˆ© (+5%)
                        - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: äººæ°—é¦¬æœ‰åˆ© (+5%)ã€ç©´é¦¬ä¸åˆ© (-5%)
                        - ç†ç”±: é•·ã„ç›´ç·šã¯å·®ã—é¦¬ã«æœ‰åˆ©ã€çŸ­ã„ç›´ç·šã¯é€ƒã’ãƒ»å…ˆè¡Œé¦¬ã«æœ‰åˆ©

                        **2. å‹¾é…ï¼ˆå‚¾æ–œï¼‰: {slope_label}**
                        - æ€¥å‚ã‚ã‚Š: äººæ°—é¦¬ï¼ˆãƒ‘ãƒ¯ãƒ¼ãŒã‚ã‚‹é¦¬ï¼‰ãŒæœ‰åˆ© (+2%)
                        - ç†ç”±: å‚ã‚’ç™»ã‚‹éš›ã«é¦¬åŠ›ãŒå¿…è¦ã§ã€å®Ÿç¸¾é¦¬ãŒå„ªä½
                        - è©²å½“ç«¶é¦¬å ´: ä¸­å±±ã€é˜ªç¥ãªã©

                        **3. ã‚³ãƒ¼ã‚¹å¹…: {width_label}**
                        - å°å›ã‚Š: äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ© (+3%)
                        - ç†ç”±: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãã€å™¨ç”¨ã•ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹

                        **4. æ ç•ªå‚¾å‘: {outer_label}**
                        - å¤–æ æœ‰åˆ©ãªå ´åˆ: 6-8æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´ (Ã—{outer_advantage:.2f})
                        - å†…æ æœ‰åˆ©ãªå ´åˆ: 1-3æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´

                        âš ï¸ ã“ã‚Œã‚‰ã®èª¿æ•´ã¯æœŸå¾…å€¤(EV)è¨ˆç®—æ™‚ã«è‡ªå‹•çš„ã«é©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
                        """)
            except Exception as e:
                pass  # venue_characteristics ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        # Prepare Editor DF
        # Columns: Horse, Prob, Odds, Mark
        if 'Odds' not in df_display.columns:
             # Try to get scraped odds if available
             if 'å˜å‹' in df_display.columns:
                 df_display['Odds'] = pd.to_numeric(df_display['å˜å‹'], errors='coerce').fillna(0.0)
             else:
                 df_display['Odds'] = 0.0
        
        # Select appropriate course compatibility
        # If 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' contains 'èŠ', use turf, else dirt
        # Default to turf if unknown
        is_turf_race = True
        if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
             # Check first row (all same race)
             c_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
             if 'ãƒ€' in c_type:
                 is_turf_race = False

        if is_turf_race:
             df_display['course_compatibility'] = df_display.get('turf_compatibility', 10.0)
        else:
             df_display['course_compatibility'] = df_display.get('dirt_compatibility', 10.0)

        # === é©æ€§ã‚¹ã‚³ã‚¢ã‚’é©æ€§åº¦ã«å¤‰æ›ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„æ–¹ãŒè‰¯ã„ï¼‰ ===
        # å…ƒã®å€¤ã¯ã€Œå¹³å‡ç€é †ã€ï¼ˆå°ã•ã„æ–¹ãŒè‰¯ã„ï¼‰
        # é©æ€§åº¦ = 10 - å¹³å‡ç€é †ï¼ˆ0-10ç‚¹ã€é«˜ã„æ–¹ãŒè‰¯ã„ï¼‰

        for compat_col in ['jockey_compatibility', 'distance_compatibility', 'course_compatibility']:
            if compat_col in df_display.columns:
                # 10 - å€¤ ã§åè»¢ï¼ˆãŸã ã—ã€0-10ã®ç¯„å›²ã«åˆ¶é™ï¼‰
                df_display[compat_col] = df_display[compat_col].apply(
                    lambda x: max(0, min(10, 10 - x)) if pd.notna(x) else 5.0
                )

        rename_map = {
            'AI_Score': 'AIã‚¹ã‚³ã‚¢(%)',
            'Confidence': 'ä¿¡é ¼åº¦',
            'Odds': 'ç¾åœ¨ã‚ªãƒƒã‚º',
            'æ€§é½¢': 'å¹´é½¢',
            'é¦¬ ç•ª': 'é¦¬ç•ª',
            'jockey_compatibility': 'é¨æ‰‹é©æ€§åº¦',
            'distance_compatibility': 'è·é›¢é©æ€§åº¦',
            'course_compatibility': 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦',
            'weighted_avg_speed': 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'
        }
             
        # Ensure all display columns exist
        defaults = {
            'jockey_compatibility': 10.0,
            'distance_compatibility': 10.0,
            'weighted_avg_speed': 16.0,
            'Confidence': 50
        }
        for c, v in defaults.items():
            if c not in df_display.columns:
                df_display[c] = v

        # Add Mark column BEFORE selecting display columns
        if 'äºˆæƒ³å°' not in df_display.columns:
            df_display['äºˆæƒ³å°'] = ""

        # Display columns with äºˆæƒ³å° next to é¦¬å
        display_cols = ['æ ', 'é¦¬ ç•ª', 'é¦¬å', 'äºˆæƒ³å°', 'æ€§é½¢', 'AI_Score', 'Confidence', 'Odds', 'jockey_compatibility', 'course_compatibility', 'distance_compatibility']


        edited_df = df_display[display_cols].copy()
        edited_df.rename(columns=rename_map, inplace=True)
        
        st.subheader("ğŸ“ äºˆæƒ³ãƒ»ã‚ªãƒƒã‚ºå…¥åŠ›")
        
        col_input_1, col_input_2 = st.columns([3, 1])
        with col_input_1:
             st.info("ã€Œäºˆæƒ³å°ã€ã‚„ã€Œç¾åœ¨ã‚ªãƒƒã‚ºã€ã‚’ç·¨é›†ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœŸå¾…å€¤(EV)ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
        with col_input_2:
             if st.button("ğŸ”„ æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—"):
                 with st.spinner("æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
                     try:
                         current_odds = auto_scraper.scrape_odds_for_race(race_id, mode=mode_val)
                         # Update session state df
                         if current_odds:
                             odds_map = {x['number']: x['odds'] for x in current_odds}
                             
                             target_df = st.session_state[f'data_{race_id}']
                             
                             # Update 'å˜å‹' and 'Odds'
                             def update_odds(row):
                                 try:
                                     num = int(row['é¦¬ ç•ª'])
                                     return odds_map.get(num, row.get('Odds', 0.0))
                                 except:
                                     return row.get('Odds', 0.0)
                                 
                             target_df['Odds'] = target_df.apply(update_odds, axis=1)
                             target_df['å˜å‹'] = target_df['Odds'] # Sync
                             
                             st.session_state[f'data_{race_id}'] = target_df
                             st.success("ã‚ªãƒƒã‚ºã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                             st.rerun()
                         else:
                             st.warning("ã‚ªãƒƒã‚ºã®å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                     except Exception as e:
                         st.error(f"ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        
        edited_df = st.data_editor(
            edited_df,
            column_config={
                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                    "AIæœŸå¾…åº¦",
                    help="1ç€ï¼ˆå‹åˆ©ï¼‰ã® AIäºˆæ¸¬ç¢ºç‡",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ä¿¡é ¼åº¦": st.column_config.ProgressColumn(
                    "äºˆæ¸¬ä¿¡é ¼åº¦",
                    help="ã“ã®äºˆæ¸¬ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ï¼ˆãƒ¢ãƒ‡ãƒ«AUCã€ãƒ‡ãƒ¼ã‚¿é‡ã€äºˆæ¸¬ç¢ºç‡ã‚’è€ƒæ…®ï¼‰",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç¾åœ¨ã‚ªãƒƒã‚º": st.column_config.NumberColumn(
                    "ç¾åœ¨ã‚ªãƒƒã‚º",
                    help="æœ€æ–°ã®å˜å‹ã‚ªãƒƒã‚ºã‚’å…¥åŠ›",
                    step=0.1,
                    format="%.1f"
                ),
                "AIæœŸå¾…å€¤": st.column_config.NumberColumn(
                    "AIæœŸå¾…å€¤",
                    help="ç´”ç²‹ãªæœŸå¾…å€¤ï¼ˆå°è£œæ­£ãªã—ï¼‰= (AIç¢ºç‡ Ã— ã‚ªãƒƒã‚º) - 1.0",
                    format="%.2f"
                ),
                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(
                    "èª¿æ•´å¾ŒæœŸå¾…å€¤",
                    help="AIã®äºˆæ¸¬ã«ã‚ãªãŸã®ã€Œå°ã€ã¨ã€Œä¼šå ´ç‰¹æ€§ã€ã‚’åŠ å‘³ã—ãŸã€æœ€çµ‚çš„ãªã€å„²ã‹ã‚Šã‚„ã™ã•ã€ã§ã™ã€‚ã“ã“ãŒãƒ—ãƒ©ã‚¹ã®é¦¬ã‚’ç‹™ãŠã†ï¼",
                    format="%.2f"
                ),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(
                    "æ¨å¥¨åº¦(Kelly)",
                    help="ã‚±ãƒªãƒ¼åŸºæº–ã«ã‚ˆã‚‹æ¨å¥¨è³­ã‘ç‡ (ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨åº¦)",
                    format="%.1f%%",
                    min_value=0,
                    max_value=30, # Max display scale (usually >30% is rare)
                ),
                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                    "äºˆæƒ³å°",
                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                    required=False,
                    help="äºˆæƒ³å°ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€èª¿æ•´å¾ŒæœŸå¾…å€¤ã«åæ˜ ã•ã‚Œã¾ã™"
                ),
                "é¨æ‰‹é©æ€§åº¦": st.column_config.ProgressColumn(
                    "é¨æ‰‹é©æ€§åº¦",
                    help="ã“ã®é¨æ‰‹ã¨ã®ç›¸æ€§ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                ),
                "ã‚³ãƒ¼ã‚¹é©æ€§åº¦": st.column_config.ProgressColumn(
                    "ã‚³ãƒ¼ã‚¹é©æ€§åº¦",
                    help="èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ ç›¸æ€§ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                ),
                "è·é›¢é©æ€§åº¦": st.column_config.ProgressColumn(
                    "è·é›¢é©æ€§åº¦",
                    help="ã“ã®è·é›¢ã§ã®ç›¸æ€§ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                )
            },
            hide_index=True,
            num_rows="fixed"  
        )
        
        # Calculate EV with JRA/NAR distinction
        # Determine race type from user's mode selection (as primary source)
        race_type = mode_val  # Use user's selected mode (JRA or NAR) as primary source of truth
        venue = ''  # Initialize venue

        # Get venue information if available
        if 'ä¼šå ´' in df_display.columns and len(df_display) > 0:
            venue = df_display['ä¼šå ´'].iloc[0]

            # If venue is available, use it to verify/override race_type for accuracy
            if venue:
                try:
                    import sys
                    import os
                    sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(__file__)), 'ml'))
                    from race_classifier import classify_race_type
                    venue_based_type = classify_race_type(venue)
                    # Use venue-based classification (more accurate than mode selection)
                    race_type = venue_based_type
                except:
                    # Fallback: manual classification
                    jra_venues = ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']
                    race_type = 'JRA' if venue in jra_venues else 'NAR'

        # EV calculation with race type AND venue specific parameters
        # Import venue characteristics
        venue_char = None
        try:
            from ml.venue_characteristics import get_venue_characteristics, get_distance_category
            if venue:
                venue_char = get_venue_characteristics(venue)
        except Exception as e:
            # Silently fail if venue characteristics not available
            pass

        # Base parameters by race type
        if race_type == 'JRA':
            # === ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰è¨­å®š ===
            # ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚ã€‚AIäºˆæ¸¬ã®ä¿¡é ¼æ€§ãŒé«˜ã„
            mark_weights = {
                "â—": 1.3,   # æœ¬å‘½: æ§ãˆã‚ã«1.3å€
                "â—¯": 1.15,  # å¯¾æŠ—: 1.15å€
                "â–²": 1.08,  # å˜ç©´: 1.08å€
                "â–³": 1.03,  # é€£ä¸‹: 1.03å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.08  # AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–ï¼ˆä¿¡é ¼æ€§é‡è¦–ï¼‰
            venue_info = f"ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰" + (f" - {venue}" if venue else "")
        else:
            # === åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰è¨­å®š ===
            # ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„ã€‚å¤§ç©´ç‹™ã„ã‚‚æœ‰åŠ¹
            mark_weights = {
                "â—": 1.8,   # æœ¬å‘½: ç©æ¥µçš„ã«1.8å€
                "â—¯": 1.4,   # å¯¾æŠ—: 1.4å€
                "â–²": 1.2,   # å˜ç©´: 1.2å€
                "â–³": 1.1,   # é€£ä¸‹: 1.1å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.05  # AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–ï¼ˆä½ç¢ºç‡ã§ã‚‚ç‹™ã†ä¾¡å€¤ã‚ã‚Šï¼‰
            venue_info = f"ğŸŒ™ åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰" + (f" - {venue}" if venue else "")

        # Venue-specific adjustments
        venue_features = []
        if venue_char:
            # ç›´ç·šè·é›¢ã«ã‚ˆã‚‹èª¿æ•´
            straight = venue_char.get('turf_straight', 300)
            if straight and straight > 500:  # é•·ã„ç›´ç·šï¼ˆæ–°æ½Ÿãªã©ï¼‰
                mark_weights["â—"] *= 0.95  # äººæ°—é¦¬ã‚„ã‚„ä¸åˆ©
                mark_weights["â–³"] *= 1.05  # ç©´é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("é•·ç›´ç·š")
            elif straight and straight < 300:  # çŸ­ã„ç›´ç·šï¼ˆä¸­å±±ã€å‡½é¤¨ãªã©ï¼‰
                mark_weights["â—"] *= 1.05  # äººæ°—é¦¬æœ‰åˆ©
                mark_weights["â–³"] *= 0.95  # ç©´é¦¬ä¸åˆ©
                venue_features.append("çŸ­ç›´ç·š")

            # ã‚³ãƒ¼ã‚¹å¹…ã«ã‚ˆã‚‹èª¿æ•´
            track_width = venue_char.get('track_width')
            if track_width == 'narrow':  # ç‹­ã„ã‚³ãƒ¼ã‚¹
                mark_weights["â—"] *= 1.03  # å…ˆè¡Œæœ‰åˆ©ã€äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("å°å›ã‚Š")
            elif track_width == 'wide':  # åºƒã„ã‚³ãƒ¼ã‚¹
                # é¦¬ç¾¤ãŒåºƒãŒã‚Šã‚„ã™ãã€å±•é–‹æ¬¡ç¬¬
                pass

            # å‹¾é…ã«ã‚ˆã‚‹èª¿æ•´
            slope = venue_char.get('slope')
            if slope == 'steep':  # æ€¥å‚ã‚ã‚Šï¼ˆä¸­å±±ãªã©ï¼‰
                mark_weights["â—"] *= 1.02  # ãƒ‘ãƒ¯ãƒ¼ã‚ã‚‹äººæ°—é¦¬æœ‰åˆ©
                venue_features.append("å‚ã‚ã‚Š")

        if venue_features:
            venue_info += f" ({', '.join(venue_features)})"

        st.info(venue_info)

        # === ç¢ºç‡è¼ƒæ­£ã®ãƒã‚§ãƒƒã‚¯ ===
        is_calibrated = False
        if model_meta and 'training_config' in model_meta:
             is_calibrated = model_meta['training_config'].get('calibrated', False)

        # Uncalibrated NAR Correction (Global application for consistency)
        if race_type == 'NAR' and not is_calibrated:
             # åœ°æ–¹ç«¶é¦¬ã‹ã¤æœªè¼ƒæ­£ã®å ´åˆã®ã¿ã€ä¿å®ˆçš„ãªèª¿æ•´ã‚’è¡Œã†
             # ã“ã‚Œã«ã‚ˆã‚Šã€è¡¨ç¤ºã•ã‚Œã‚‹AIã‚¹ã‚³ã‚¢ã¨EVè¨ˆç®—ã«ä½¿ã‚ã‚Œã‚‹ç¢ºç‡ãŒä¸€è‡´ã™ã‚‹
             def adjust_nar_prob_row(row):
                 p = row['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
                 new_p = p * 0.9 + 0.05
                 return int(new_p * 100)
             
             edited_df['AIã‚¹ã‚³ã‚¢(%)'] = edited_df.apply(adjust_nar_prob_row, axis=1)
             st.caption("â„¹ï¸ NARèª¿æ•´: AIã‚¹ã‚³ã‚¢ã¨æœŸå¾…å€¤ã‚’ä¿å®ˆçš„ã«è£œæ­£ã—ã¾ã—ãŸï¼ˆæœªè¼ƒæ­£ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ï¼‰")

        probs = edited_df['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
        odds = edited_df['ç¾åœ¨ã‚ªãƒƒã‚º']
        marks = edited_df['äºˆæƒ³å°']

        # Get run style compatibility if available
        # Get run style compatibility if available
        run_style_compatibility = None
        if 'venue_run_style_compatibility' in edited_df.columns:
            run_style_compatibility = edited_df['venue_run_style_compatibility']

        # Get frame (æ ) for venue-specific frame advantage
        frames = None
        if 'æ ' in edited_df.columns:
            frames = edited_df['æ ']

        evs_pure = []      # ç´”ç²‹EVï¼ˆå°è£œæ­£ãªã—ï¼‰
        evs_adjusted = []  # èª¿æ•´å¾ŒEVï¼ˆå°è£œæ­£ã‚ã‚Šï¼‰
        kellys = []

        evs_pure = []      # ç´”ç²‹EVï¼ˆå°è£œæ­£ãªã—ï¼‰
        evs_adjusted = []  # èª¿æ•´å¾ŒEVï¼ˆå°è£œæ­£ã‚ã‚Šï¼‰
        kellys = []
        bias_reasons_list = [] # è£œæ­£ç†ç”±ãƒªã‚¹ãƒˆ

        for idx, (p, o, m) in enumerate(zip(probs, odds, marks)):
            reasons = [] # ã“ã®é¦¬ã®è£œæ­£ç†ç”±
            
            # Safety filter (race type specific)
            if p < safety_threshold:
                ev_pure = -1.0
                ev_adj = -1.0
                kelly = 0.0
                reasons.append("ç¢ºç‡éä½(é™¤å¤–)")
            else:
                w = mark_weights.get(m, 1.0)
                if w != 1.0:
                     reasons.append(f"å°{m} (x{w:.2f})")
                
                # Already adjusted in Dataframe if needed
                adjusted_p = p

                # Apply run style compatibility if available
                if run_style_compatibility is not None:
                    run_compat = run_style_compatibility.iloc[idx]
                    if not pd.isna(run_compat) and run_compat != 1.0:
                        # è„šè³ªç›¸æ€§ãŒè‰¯ã„é¦¬ã¯æœŸå¾…å€¤ã‚’ä¸Šã’ã‚‹
                        adjusted_p *= run_compat
                        reasons.append(f"è„šè³ªé©æ€§ (x{run_compat:.2f})")

                # Apply frame advantage if available
                if frames is not None and venue_char:
                    frame = frames.iloc[idx]
                    if not pd.isna(frame):
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        try:
                            frame_num = int(frame)
                            if frame_num >= 6 and outer_advantage > 1.0:  # å¤–æ æœ‰åˆ©
                                adjusted_p *= outer_advantage
                                reasons.append(f"å¤–æ æœ‰åˆ© (x{outer_advantage:.2f})")
                            elif frame_num <= 3 and outer_advantage > 1.0:  # å†…æ ä¸åˆ©
                                penalty = 2.0 - outer_advantage
                                adjusted_p *= penalty
                                reasons.append(f"å†…æ ä¸åˆ© (x{penalty:.2f})")
                            
                            # å†…æ æœ‰åˆ©ãªå ´åˆ(outer_advantage < 1.0)
                            elif frame_num <= 3 and outer_advantage < 1.0:
                                bonus = 2.0 - outer_advantage
                                adjusted_p *= bonus
                                reasons.append(f"å†…æ æœ‰åˆ© (x{bonus:.2f})")
                            elif frame_num >= 6 and outer_advantage < 1.0:
                                adjusted_p *= outer_advantage
                                reasons.append(f"å¤–æ ä¸åˆ© (x{outer_advantage:.2f})")
                                
                        except: pass

                # ç´”ç²‹EV: å°è£œæ­£ãªã—ï¼ˆçµ±è¨ˆçš„ã«æ­£ã—ã„ï¼‰
                ev_pure = (adjusted_p * o) - 1.0

                # èª¿æ•´å¾ŒEV: å°è£œæ­£ã‚ã‚Šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»è¦³ã‚’åæ˜ ï¼‰
                ev_adj = (adjusted_p * w * o) - 1.0

                # Kelly criterion (placeholder for now)
                kelly = 0.0
            
            evs_pure.append(ev_pure)
            evs_adjusted.append(ev_adj)
            kellys.append(kelly)
            bias_reasons_list.append(", ".join(reasons) if reasons else "-")

        edited_df['AIæœŸå¾…å€¤'] = evs_pure
        edited_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = evs_adjusted
        edited_df['æ¨å¥¨åº¦(Kelly)'] = kellys
        edited_df['è£œæ­£å†…å®¹'] = bias_reasons_list

        # === AIæœŸå¾…åº¦TOP5ã®ã‚°ãƒ©ãƒ•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡¨ç¤ºï¼‰ ===
        st.markdown("---")
        st.subheader("ğŸ“Š AIæœŸå¾…åº¦ TOP5 åˆ†æ")

        # TOP5ã‚’èª¿æ•´å¾ŒæœŸå¾…å€¤ã§ã‚½ãƒ¼ãƒˆï¼ˆå°è£œæ­£ã‚’å«ã‚€ï¼‰
        top5_df = edited_df.nlargest(5, 'èª¿æ•´å¾ŒæœŸå¾…å€¤')

        # 1. æ¨ªæ£’ã‚°ãƒ©ãƒ•: AIç¢ºç‡ vs æœŸå¾…å€¤
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots

        fig_top5 = make_subplots(
            rows=1, cols=2,
            subplot_titles=("AIå‹ç‡äºˆæ¸¬ TOP5", "èª¿æ•´å¾ŒæœŸå¾…å€¤ TOP5"),
            specs=[[{"type": "bar"}, {"type": "bar"}]]
        )

        # å·¦: AIå‹ç‡
        fig_top5.add_trace(
            go.Bar(
                y=top5_df['é¦¬å'],
                x=top5_df['AIã‚¹ã‚³ã‚¢(%)'],
                orientation='h',
                name='AIå‹ç‡',
                marker=dict(color='lightblue'),
                text=top5_df['AIã‚¹ã‚³ã‚¢(%)'].apply(lambda x: f'{x}%'),
                textposition='auto'
            ),
            row=1, col=1
        )

        # å³: èª¿æ•´å¾ŒæœŸå¾…å€¤
        colors = ['green' if ev > 0 else 'red' for ev in top5_df['èª¿æ•´å¾ŒæœŸå¾…å€¤']]
        fig_top5.add_trace(
            go.Bar(
                y=top5_df['é¦¬å'],
                x=top5_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'],
                orientation='h',
                name='èª¿æ•´å¾ŒæœŸå¾…å€¤',
                marker=dict(color=colors),
                text=top5_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'].apply(lambda x: f'{x:.2f}'),
                textposition='auto'
            ),
            row=1, col=2
        )

        fig_top5.update_xaxes(title_text="AIå‹ç‡ (%)", row=1, col=1)
        fig_top5.update_xaxes(title_text="èª¿æ•´å¾ŒæœŸå¾…å€¤", row=1, col=2)
        fig_top5.update_yaxes(autorange="reversed", row=1, col=1)
        fig_top5.update_yaxes(autorange="reversed", row=1, col=2)
        fig_top5.update_layout(height=400, showlegend=False)

        st.plotly_chart(fig_top5, use_container_width=True)

        # è£œæ­£å†…å®¹ã®è¡¨ç¤º
        st.markdown("##### â„¹ï¸ æœŸå¾…å€¤èª¿æ•´ã®è©³ç´° (TOP5)")
        st.dataframe(
            top5_df[['äºˆæƒ³å°', 'é¦¬å', 'ç¾åœ¨ã‚ªãƒƒã‚º', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'è£œæ­£å†…å®¹']],
            column_config={
                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(format="%.2f"),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(format="%.1f%%", max_value=30),
            },
            hide_index=True,
            use_container_width=True
        )

        # 2. é©æ€§ã‚¹ã‚³ã‚¢æ¯”è¼ƒï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰
        st.markdown("#### ğŸ¯ TOP5 é©æ€§åº¦æ¯”è¼ƒ")

        compatibility_cols = ['é¨æ‰‹é©æ€§åº¦', 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 'è·é›¢é©æ€§åº¦']
        compat_data = []
        for idx, row in top5_df.iterrows():
            compat_data.append({
                'é¦¬å': row['é¦¬å'],
                'é¨æ‰‹é©æ€§åº¦': row.get('é¨æ‰‹é©æ€§åº¦', 5.0),
                'ã‚³ãƒ¼ã‚¹é©æ€§åº¦': row.get('ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 5.0),
                'è·é›¢é©æ€§åº¦': row.get('è·é›¢é©æ€§åº¦', 5.0)
            })

        compat_df = pd.DataFrame(compat_data)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢ã«10ç‚¹æº€ç‚¹ã«å¤‰æ›æ¸ˆã¿ï¼‰
        heatmap_data = []
        for col in compatibility_cols:
            heatmap_data.append([val for val in compat_df[col]])

        fig_heatmap = go.Figure(data=go.Heatmap(
            z=heatmap_data,
            x=compat_df['é¦¬å'],
            y=compatibility_cols,
            colorscale='RdYlGn',
            text=[[f'{val:.1f}' for val in compat_df[col]] for col in compatibility_cols],
            texttemplate='%{text}',
            textfont={"size": 12},
            colorbar=dict(title="é©æ€§åº¦<br>(10ç‚¹æº€ç‚¹)")
        ))

        fig_heatmap.update_layout(
            title="é©æ€§åº¦ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰",
            xaxis_title="é¦¬å",
            height=300
        )

        st.plotly_chart(fig_heatmap, use_container_width=True)

        # 3. äºˆæ¸¬çµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰
        with st.expander("ğŸ’¡ äºˆæ¸¬çµæœã®è¦‹æ–¹ãƒ»è§£é‡ˆã‚¬ã‚¤ãƒ‰", expanded=False):
            st.markdown("""
            ### ğŸ“ˆ å„æŒ‡æ¨™ã®æ„å‘³

            **1. AIã‚¹ã‚³ã‚¢ï¼ˆAIå‹ç‡äºˆæ¸¬ï¼‰**
            - AIãŒäºˆæ¸¬ã—ãŸ1ç€ã«ãªã‚‹ç¢ºç‡ï¼ˆ%ï¼‰
            - **ç›®å®‰**: 10%ä»¥ä¸Šãªã‚‰æœ‰åŠ›å€™è£œã€15%ä»¥ä¸Šãªã‚‰æœ¬å‘½å€™è£œ
            - âš ï¸ æ³¨æ„: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆç®¡ç†ãƒšãƒ¼ã‚¸ã§å†å­¦ç¿’æ¨å¥¨ï¼‰

            **2. ä¿¡é ¼åº¦ï¼ˆäºˆæ¸¬ä¿¡é ¼åº¦ï¼‰**
            - ã“ã®äºˆæ¸¬ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ï¼ˆ20-95%ï¼‰
            - ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®:
              - ãƒ¢ãƒ‡ãƒ«AUCï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰
              - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é‡
              - AIäºˆæ¸¬ç¢ºç‡ï¼ˆæ¥µç«¯ãªå€¤ã»ã©ä¿¡é ¼åº¦é«˜ï¼‰
              - é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ãƒ»è·é›¢ï¼‰
            - **ç›®å®‰**: 70%ä»¥ä¸Šãªã‚‰é«˜ä¿¡é ¼ã€50%ä»¥ä¸‹ãªã‚‰è¦æ³¨æ„

            **3. æœŸå¾…å€¤ï¼ˆEV: Expected Valueï¼‰**

            **AIæœŸå¾…å€¤ï¼ˆç´”ç²‹EVï¼‰:**
            - çµ±è¨ˆçš„ã«æ­£ã—ã„æœŸå¾…å€¤ï¼ˆå°è£œæ­£ãªã—ï¼‰
            - **è¨ˆç®—å¼**: `(èª¿æ•´å¾ŒAIç¢ºç‡ Ã— ã‚ªãƒƒã‚º) - 1.0`
            - é•·æœŸçš„ãªåç›Šæ€§ã‚’è©•ä¾¡ã™ã‚‹å®¢è¦³çš„æŒ‡æ¨™

            **èª¿æ•´å¾ŒæœŸå¾…å€¤ï¼ˆå°è£œæ­£ã‚ã‚Šï¼‰:**
            - äºˆæƒ³å°ã‚’åæ˜ ã—ãŸæœŸå¾…å€¤
            - **è¨ˆç®—å¼**: `(èª¿æ•´å¾ŒAIç¢ºç‡ Ã— å°è£œæ­£ Ã— ã‚ªãƒƒã‚º) - 1.0`
            - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»è¦³çš„åˆ¤æ–­ã‚’å«ã‚€

            **ç›®å®‰**:
              - EV > 0.2 â†’ å¼·ã„è²·ã„æ¨å¥¨
              - EV > 0.0 â†’ è²·ã„æ¨å¥¨
              - EV < 0.0 â†’ è¦‹é€ã‚Šæ¨å¥¨

            **ä½¿ã„åˆ†ã‘**:
              - **AIæœŸå¾…å€¤**: å®¢è¦³çš„ãªåˆ¤æ–­ã«ä½¿ç”¨ï¼ˆçµ±è¨ˆçš„ã«æ­£ã—ã„ï¼‰
              - **èª¿æ•´å¾ŒæœŸå¾…å€¤**: å°ã‚’ä»˜ã‘ãŸé¦¬ã®æœ€çµ‚åˆ¤æ–­ã«ä½¿ç”¨

            **4. é©æ€§åº¦ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ãƒ»è·é›¢ï¼‰**
            - éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ã—ãŸé©æ€§åº¦ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰
            - **æ•°å€¤ãŒé«˜ã„ã»ã©è‰¯ã„** (10ç‚¹=æŠœç¾¤ã®ç›¸æ€§ã€0ç‚¹=ç›¸æ€§æ‚ªã„)
            - 7ç‚¹ä»¥ä¸Š: æŠœç¾¤ã®ç›¸æ€§
            - 5ç‚¹ä»¥ä¸Š: è‰¯å¥½
            - 3ç‚¹ä»¥ä¸‹: ã‚„ã‚„ä¸å®‰
            - 5ç‚¹å‰å¾Œ: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆæ¨™æº–å€¤ï¼‰

            **5. ã‚³ãƒ¼ã‚¹ç‰¹æ€§ï¼ˆå‚¾æ–œãƒ»ç›´ç·šè·é›¢ãƒ»ã‚³ãƒ¼ã‚¹å¹…ãƒ»æ ç•ªï¼‰**
            - **å‹¾é…ï¼ˆå‚¾æ–œï¼‰**: æ€¥å‚ã‚ã‚Šã®ç«¶é¦¬å ´ã§ã¯äººæ°—é¦¬ãŒæœ‰åˆ©ï¼ˆ+2%ï¼‰
              - ä¸­å±±ã€é˜ªç¥ãªã©: å‚ã§ãƒ‘ãƒ¯ãƒ¼ãŒå¿…è¦ãªãŸã‚å®Ÿç¸¾é¦¬ãŒå„ªä½
            - **ç›´ç·šè·é›¢**:
              - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: å·®ã—é¦¬æœ‰åˆ©ã€ç©´é¦¬ãƒãƒ£ãƒ³ã‚¹ï¼ˆäººæ°—é¦¬-5%ã€ç©´é¦¬+5%ï¼‰
              - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: é€ƒã’ãƒ»å…ˆè¡Œé¦¬æœ‰åˆ©ã€äººæ°—é¦¬å …ã„ï¼ˆäººæ°—é¦¬+5%ï¼‰
            - **ã‚³ãƒ¼ã‚¹å¹…**:
              - å°å›ã‚Šã‚³ãƒ¼ã‚¹: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãå™¨ç”¨ãªé¦¬ãŒæœ‰åˆ©ï¼ˆäººæ°—é¦¬+3%ï¼‰
            - **æ ç•ªå‚¾å‘**:
              - å¤–æ æœ‰åˆ©ãªç«¶é¦¬å ´: 6-8æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´
              - å†…æ æœ‰åˆ©ãªç«¶é¦¬å ´: 1-3æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´

            âš ï¸ **ã“ã‚Œã‚‰ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã¯ã€ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™**

            ### ğŸ¯ æ¨å¥¨ã•ã‚Œã‚‹ä½¿ã„æ–¹

            1. **TOP5ã‚°ãƒ©ãƒ•**ã§AIæœŸå¾…åº¦ã®é«˜ã„é¦¬ã‚’ç¢ºèª
            2. **æœŸå¾…å€¤(EV)ãŒãƒ—ãƒ©ã‚¹**ã®é¦¬ã«æ³¨ç›®
            3. **ä¿¡é ¼åº¦ãŒ70%ä»¥ä¸Š**ã®äºˆæ¸¬ã‚’å„ªå…ˆ
            4. **é©æ€§åº¦**ã§ç›¸æ€§ã‚’ç¢ºèªï¼ˆç‰¹ã«é¨æ‰‹é©æ€§åº¦ã¯é‡è¦ï¼‰
            5. **ç¾åœ¨ã‚ªãƒƒã‚º**ã¨**äºˆæƒ³å°**ã‚’å…¥åŠ›ã—ã¦EVã‚’æœ€çµ‚èª¿æ•´

            ### âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

            - **ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå¿…è¦**: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€Œ3ç€ä»¥å†…ã€ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
            - ç®¡ç†ãƒšãƒ¼ã‚¸ã§ä¸¡ãƒ¢ãƒ‡ãƒ«ï¼ˆJRA/NARï¼‰ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„
            - å†å­¦ç¿’å¾Œã€AIç¢ºç‡ã¯5-15%ã®ç¯„å›²ï¼ˆ1ç€ç¢ºç‡ã¨ã—ã¦å¦¥å½“ï¼‰ã«ãªã‚Šã¾ã™
            """)

        st.markdown("---")
        st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")

        # Highlight high EV and Kelly
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]

        st.dataframe(
            edited_df.style
            .format({
                'æ¨å¥¨åº¦(Kelly)': lambda x: '-' if x <= 0 else f'{x:.1f}%',
                'AIæœŸå¾…å€¤': '{:.2f}',
                'èª¿æ•´å¾ŒæœŸå¾…å€¤': '{:.2f}'
            })
            .applymap(lambda x: 'background-color: #d4edda' if x > 0 else '', subset=['AIæœŸå¾…å€¤', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'æ¨å¥¨åº¦(Kelly)'])
        )



        # Visualization
        st.markdown("---")
        st.subheader("ğŸ” å€‹åˆ¥é¦¬ã®è©³ç´°åˆ†æ")

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼šé¦¬ã®è©³ç´°åˆ†æã‚’ç”Ÿæˆ
        def create_horse_analysis(horse_name, df_display, edited_df):
            """å€‹åˆ¥é¦¬ã®èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆã¨éå»5èµ°ã®æ¨ç§»ã‚’ç”Ÿæˆ"""
            # Find row
            row = df_display[df_display['é¦¬å'] == horse_name].iloc[0]

            # --- Scoring Logic (Lower rank is better, so Invert) ---
            def rank_to_score(r):
                if pd.isna(r) or r > 18: return 0
                return max(0, min(10, (14 - r) * (10/13)))

            # Calculate scores
            sp_val = row.get('weighted_avg_speed', 16.0)
            score_speed = max(0, min(10, (sp_val - 15.0) * 5))
            j_val = row.get('jockey_compatibility', 10.0)
            score_jockey = rank_to_score(j_val)
            c_val = row.get('course_compatibility', 10.0)
            score_course = rank_to_score(c_val)
            d_val = row.get('distance_compatibility', 10.0)
            score_dist = rank_to_score(d_val)
            rank_val = row.get('weighted_avg_rank', 10.0)
            score_form = rank_to_score(rank_val)

            # Radar Chart
            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=[score_speed, score_form, score_jockey, score_course, score_dist, score_speed],
                theta=['ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å®Ÿç¸¾(ç€é †)', 'é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§'],
                fill='toself',
                name=horse_name,
                line=dict(color='#1f77b4')
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 10])),
                height=300,
                margin=dict(l=40, r=40, t=40, b=40)
            )

            # Past 5 Runs Line Chart
            history_data = []
            for i in range(5, 0, -1):
                if f"past_{i}_rank" in row and pd.notna(row[f"past_{i}_rank"]):
                    history_data.append({
                        "Run": f"{i}èµ°å‰",
                        "ç€é †": row[f"past_{i}_rank"],
                        "3Fã‚¿ã‚¤ãƒ ": row[f"past_{i}_last_3f"]
                    })

            if history_data:
                hist_df = pd.DataFrame(history_data)
                from plotly.subplots import make_subplots
                fig_line = make_subplots(specs=[[{"secondary_y": True}]])
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['ç€é †'], name="ç€é †", mode='lines+markers', line=dict(color='#ff7f0e')), secondary_y=False)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['3Fã‚¿ã‚¤ãƒ '], name="ä¸Šã‚Š3F", mode='lines+markers', line=dict(dash='dot', color='#2ca02c')), secondary_y=True)
                fig_line.update_layout(height=300, margin=dict(l=40, r=40, t=40, b=40))
                fig_line.update_yaxes(title_text="ç€é †", autorange="reversed", secondary_y=False)
                fig_line.update_yaxes(title_text="ä¸Šã‚Š3F (ç§’)", secondary_y=True)
            else:
                fig_line = go.Figure()
                fig_line.add_annotation(text="éå»ãƒ‡ãƒ¼ã‚¿ãªã—")
                fig_line.update_layout(height=300)

            # Get prediction summary
            pred_row = edited_df[edited_df['é¦¬å'] == horse_name].iloc[0]

            return fig_radar, fig_line, pred_row

        try:
            # === åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠ ===
            st.info("ğŸ’¡ åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯AIæœŸå¾…åº¦ä¸Šä½5é ­ï¼‰")

            # Get all horses sorted by AI Score
            all_horses = edited_df.sort_values('AIã‚¹ã‚³ã‚¢(%)', ascending=False)['é¦¬å'].tolist()
            default_horses = top5_df['é¦¬å'].tolist()
            
            # Ensure default horses are in the options (sanity check)
            default_horses = [h for h in default_horses if h in all_horses]

            selected_horses = st.multiselect(
                "åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠ",
                options=all_horses,
                default=default_horses
            )

            for idx, horse_name in enumerate(selected_horses):
                with st.expander(f"**{idx+1}ä½: {horse_name}**", expanded=(idx < 2)):  # 1-2ä½ã¯å±•é–‹è¡¨ç¤º
                    fig_radar, fig_line, pred_row = create_horse_analysis(horse_name, df_display, edited_df)

                    # Prediction Summary
                    col_s1, col_s2, col_s3, col_s4, col_s5 = st.columns(5)
                    with col_s1:
                        st.metric("AIå‹ç‡", f"{pred_row['AIã‚¹ã‚³ã‚¢(%)']}%")
                    with col_s2:
                        st.metric("ä¿¡é ¼åº¦", f"{pred_row['ä¿¡é ¼åº¦']}%")
                    with col_s3:
                        ai_ev_val = pred_row['AIæœŸå¾…å€¤']
                        st.metric("AIæœŸå¾…å€¤", f"{ai_ev_val:.2f}")
                    with col_s4:
                        adj_ev_val = pred_row['èª¿æ•´å¾ŒæœŸå¾…å€¤']
                        ev_delta = "è²·ã„æ¨å¥¨" if adj_ev_val > 0 else "è¦‹é€ã‚Š"
                        st.metric("èª¿æ•´å¾ŒEV", f"{adj_ev_val:.2f}", delta=ev_delta)
                    with col_s5:
                        odds_val = pred_row.get('ç¾åœ¨ã‚ªãƒƒã‚º', 0.0)
                        st.metric("ã‚ªãƒƒã‚º", f"{odds_val:.1f}å€")

                    # Charts
                    col_c1, col_c2 = st.columns(2)
                    with col_c1:
                        st.markdown("**èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ**")
                        st.plotly_chart(fig_radar, use_container_width=True)
                    with col_c2:
                        st.markdown("**éå»5èµ°ã®æ¨ç§»**")
                        st.plotly_chart(fig_line, use_container_width=True)

            # === ãŠã™ã™ã‚ã®è²·ã„æ–¹ææ¡ˆ ===
            st.markdown("---")
            st.subheader("ğŸ« AIãŠã™ã™ã‚ã®è²·ã„æ–¹")
            
            # Budget Input
            budget = st.number_input("ğŸ’° äºˆç®— (å††)", min_value=100, step=100, value=1000, help="ã“ã®äºˆç®—ã«åˆã‚ã›ã¦è³¼å…¥é‡‘é¡ã‚’é…åˆ†ã—ã¾ã™")

            # Logic for betting recommendations using 'edited_df' (which includes updated Odds/Marks)
            sorted_df = edited_df.sort_values('èª¿æ•´å¾ŒæœŸå¾…å€¤', ascending=False)
            top1 = sorted_df.iloc[0]
            top2 = sorted_df.iloc[1] if len(sorted_df) > 1 else None
            top3 = sorted_df.iloc[2] if len(sorted_df) > 2 else None
            
            # Helper for circled numbers
            def to_circled_num(n):
                try:
                    n = int(n)
                    if 1 <= n <= 20:
                        return chr(9311 + n)
                    return f"({n})"
                except:
                    return ""

            # Helper to format horse name with circle num
            def fmt_horse(row):
                num = row.get('é¦¬ ç•ª', '')
                name = row['é¦¬å']
                c_num = to_circled_num(num)
                return f"{c_num} {name}".strip()

            # Cards Layout
            col_bet1, col_bet2, col_bet3 = st.columns(3)

            # 1. ğŸ¯ Tankei (Tansho/Fukusho)
            with col_bet1:
                st.markdown("#### ğŸ¯ å˜ç³» (WIN/PLACE)")
                if top1['AIã‚¹ã‚³ã‚¢(%)'] >= 10 and top1['ä¿¡é ¼åº¦'] >= 60 and top1['èª¿æ•´å¾ŒæœŸå¾…å€¤'] > 0:
                    bet_type = "å˜å‹ (WIN)" if top1['AIã‚¹ã‚³ã‚¢(%)'] >= 20 else "è¤‡å‹ (PLACE)"
                    
                    # Allocation: 50% of budget for Tankei focus
                    amount = int((budget * 0.5) / 100) * 100
                    if amount < 100: amount = 100
                    
                    st.success(f"**{bet_type}**")
                    st.metric(fmt_horse(top1), f"{amount}å††", delta=f"EV: {top1['èª¿æ•´å¾ŒæœŸå¾…å€¤']:.2f}")
                    st.caption(f"ä¿¡é ¼åº¦: {top1['ä¿¡é ¼åº¦']}%")
                else:
                    st.info("æ¡ä»¶ã«åˆã†è»¸é¦¬ãŒã„ã¾ã›ã‚“")
                    st.caption("è¦‹é€ã‚Š (No Bet)")

            # 2. ğŸ”„ Renkei (Umaren/Wide)
            with col_bet2:
                st.markdown("#### ğŸ”„ é€£ç³» (EXACTA/WIDE)")
                if top1['AIã‚¹ã‚³ã‚¢(%)'] >= 30:
                    # Solid Favorite -> Nagashi
                    st.success("**é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ æµã—**")
                    targets = []
                    if top2 is not None: targets.append(fmt_horse(top2))
                    if top3 is not None: targets.append(fmt_horse(top3))
                    
                    # Allocation: Budget / points
                    points = len(targets)
                    if points > 0:
                        amount_per_point = int((budget / points) / 100) * 100 
                        if amount_per_point < 100: amount_per_point = 100
                        st.write(f"è»¸: **{fmt_horse(top1)}**")
                        st.write(f"ç´: {', '.join(targets)}")
                        st.metric("1ç‚¹ã‚ãŸã‚Š", f"{amount_per_point}å††", help=f"åˆè¨ˆ {(amount_per_point * points)}å††")
                    else:
                        st.write("ç›¸æ‰‹é¦¬ä¸è¶³")
                elif top1['AIã‚¹ã‚³ã‚¢(%)'] < 20:
                     # Confused -> Box
                     st.warning("**é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ BOX**")
                     box_horses = [fmt_horse(row) for i, row in sorted_df.head(5).iterrows()][:4] # Top 4 box = 6 points
                     
                     points = 6 # 4C2
                     amount_per_point = int((budget / points) / 100) * 100
                     if amount_per_point < 100: amount_per_point = 100
                     
                     st.write(f"æ¨å¥¨: {', '.join(box_horses)}")
                     st.caption("æ··æˆ¦æ¨¡æ§˜ã§ã™")
                     st.metric("1ç‚¹ã‚ãŸã‚Š", f"{amount_per_point}å††", help=f"4é ­BOX (6ç‚¹): {amount_per_point * 6}å††")
                else:
                     st.info("**é¦¬é€£ ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**")
                     st.caption("é©å®œèª¿æ•´ã—ã¦ãã ã•ã„")
                     st.write(f"1åˆ—ç›®: {fmt_horse(top1)}")
                     targets = []
                     if top2 is not None: targets.append(fmt_horse(top2))
                     if top3 is not None: targets.append(fmt_horse(top3))
                     st.write(f"2åˆ—ç›®: {', '.join(targets)}")

            # 3. ğŸ§¨ Aname (Longshot)
            with col_bet3:
                st.markdown("#### ğŸ§¨ ç©´ç›® (LONGSHOT)")
                # Find high EV but low probability (Score < 15%)
                longshots = sorted_df[
                    (sorted_df['AIã‚¹ã‚³ã‚¢(%)'] < 15) & 
                    (sorted_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] > 0.3) &
                    (sorted_df['ä¿¡é ¼åº¦'] >= 40)
                ]
                
                if not longshots.empty:
                    ls_horse = longshots.iloc[0]
                    st.error(f"**ç‹™ã„ç›®: {fmt_horse(ls_horse)}**")
                    st.metric("æœŸå¾…å€¤", f"{ls_horse['èª¿æ•´å¾ŒæœŸå¾…å€¤']:.2f}", delta="High EV")
                    st.write(f"å˜ã‚ªãƒƒã‚º: {ls_horse.get('ç¾åœ¨ã‚ªãƒƒã‚º', 0)}å€")
                    st.caption("ãƒ¯ã‚¤ãƒ‰ãƒ»è¤‡å‹ã®ç´ã«æ¨å¥¨")
                else:
                    st.info("æ¨å¥¨ã§ãã‚‹ç©´é¦¬ãªã—")
                    st.caption("å …ã„æ±ºç€ã®å¯èƒ½æ€§å¤§")
                    
        except Exception as e:
            st.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.text(traceback.format_exc())
