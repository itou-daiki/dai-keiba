import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
import json
import plotly.express as px
import plotly.graph_objects as go
import time
import logging
from datetime import datetime
import re
import importlib
import joblib

# Setup logger
logger = logging.getLogger(__name__)

# Add paths
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(PROJECT_ROOT, 'scraper'))
sys.path.append(os.path.join(PROJECT_ROOT, 'ml'))
sys.path.append(PROJECT_ROOT) # Add root for 'ml.feature_engineering' access

try:
    # -------------------------------------------------------------
    # Custom Modules
    # -------------------------------------------------------------
    #from scraper.auto_scraper import scrape_shutuba_data
    from scraper import auto_scraper
    from feature_engineering import process_data_v2 as process_data
    # Try importing from ml package first (correct structure)
    try:
        from ml.db_helper import KeibaDatabase
    except ImportError:
        # Fallback to root (local dev)
        from db_helper import KeibaDatabase
except ImportError as e:
    # This is critical if we rely on DB, but for public app we might use parquet
    print(f"Warning: KeibaDatabase import failed: {e}")
    KeibaDatabase = None

st.set_page_config(page_title="AI Keiba Predictor", layout="wide")

# --- Utils ---
@st.cache_resource
def load_model(mode="JRA"):
    import joblib  # Ensure import inside function for safety
    model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/lgbm_model_nar.pkl" if mode == "NAR" else "ml/models/lgbm_model.pkl")
    if os.path.exists(model_path):
        try:
            return joblib.load(model_path)
        except Exception as e:
            st.error(f"Failed to load model with joblib: {e}")
            return None
    return None

@st.cache_resource
def load_model_metadata(mode="JRA"):
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã‚€"""
    meta_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/lgbm_model_nar_meta.json" if mode == "NAR" else "ml/models/lgbm_model_meta.json")
    if os.path.exists(meta_path):
        with open(meta_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

@st.cache_resource
def load_history_csv(mode):
    """éå»ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ (é«˜é€ŸåŒ–: Parquetå„ªå…ˆ + ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–)"""
    base_dir = os.path.join(PROJECT_ROOT, "data", "raw")
    filename_base = "database_nar" if mode == "NAR" else "database"
    
    # Check Parquet first
    parquet_path = os.path.join(base_dir, f"{filename_base}.parquet")
    csv_path = os.path.join(base_dir, f"{filename_base}.csv")
    
    # Optimization: Load only necessary columns
    usecols = [
        'horse_id', 'race_id', 'æ—¥ä»˜', 'ç€ é †', 'ã‚¿ã‚¤ãƒ ', 'ãƒ¬ãƒ¼ã‚¹å', 
        'å¾Œ3F', 'é¦¬ä½“é‡(å¢—æ¸›)', 'é¨æ‰‹', 'é¦¬å ´çŠ¶æ…‹', 'å˜å‹ ã‚ªãƒƒã‚º', 
        'å¤©å€™', 'è·é›¢', 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', 'father', 'mother', 'bms'
    ]

    # Memory Efficient Dtypes
    dtypes = {
        'horse_id': 'category',
        'race_id': 'category',
        'ç€ é †': 'str', # Mixed types often, safe as str then coerce
        'é¨æ‰‹': 'category',
        'é¦¬å ´çŠ¶æ…‹': 'category',
        'å¤©å€™': 'category',
        'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—': 'category',
        'father': 'category',
        'mother': 'category',
        'bms': 'category',
        'å˜å‹ ã‚ªãƒƒã‚º': 'float32'
    }

    df = None
    
    if os.path.exists(parquet_path):
        try:
            # Parquet is efficient, but we can cast types after load
            df = pd.read_parquet(parquet_path, columns=usecols)
        except:
             try:
                 df = pd.read_parquet(parquet_path) # Fallback
             except Exception as e:
                 st.warning(f"Parquet load failed: {e}")
            
    elif os.path.exists(csv_path):
        try:
            df = pd.read_csv(
                csv_path, 
                usecols=lambda c: c in usecols, 
                dtype=dtypes,
                low_memory=True
            )
        except Exception as e:
            st.warning(f"CSV load failed: {e}")
            
    if df is not None:
        # Key Mismatch Fix & Type enforcement
        if 'horse_id' in df.columns:
            df['horse_id'] = df['horse_id'].astype(str).str.replace(r'\.0$', '', regex=True).astype('category')
        if 'race_id' in df.columns:
            df['race_id'] = df['race_id'].astype(str).str.replace(r'\.0$', '', regex=True).astype('category')
            
        # Optimize numeric columns
        for col in ['å˜å‹ ã‚ªãƒƒã‚º', 'ã‚¿ã‚¤ãƒ ', 'å¾Œ3F']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')
                
        return df
        
    return None

@st.cache_resource
def load_stats(mode="JRA"):
    """çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹æˆç¸¾ãªã©ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰"""
    stats_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/feature_stats_nar.pkl" if mode == "NAR" else "ml/models/feature_stats.pkl")
    if os.path.exists(stats_path):
        try:
            with open(stats_path, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            st.warning(f"Stats load error: {e}")
    return None

def get_data_freshness(mode="JRA"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—ï¼ˆParquetå„ªå…ˆï¼‰"""
    base_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "raw")
    filename_base = "database_nar" if mode == "NAR" else "database"
    
    # Check Parquet first
    target_path = os.path.join(base_dir, f"{filename_base}.parquet")
    if not os.path.exists(target_path):
        target_path = os.path.join(base_dir, f"{filename_base}.csv")
    
    if os.path.exists(target_path):
        try:
            mtime = os.path.getmtime(target_path)
            dt = datetime.fromtimestamp(mtime)
            freshness = dt.strftime('%Y-%m-%d %H:%M')
            
            # é®®åº¦åˆ¤å®š (3æ—¥ä»¥å†…ãªã‚‰0=å®‰å…¨ã€ãã‚Œä»¥ä¸Šã¯æ—¥æ•°)
            days_diff = (datetime.now() - dt).days
            return freshness, days_diff
        except Exception as e:
            st.warning(f"ãƒ‡ãƒ¼ã‚¿é®®åº¦ã®å–å¾—ã«å¤±æ•—: {e}")
            return "ä¸æ˜", -1
    return "ãƒ‡ãƒ¼ã‚¿ãªã—", -1

def calculate_confidence_score(row, ai_prob, model_meta, jockey_compat=None, course_compat=None, distance_compat=None, is_rest_comeback=0, has_history=True):
    """
    äºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰

    Args:
        ai_prob: AIäºˆæ¸¬ç¢ºç‡ï¼ˆ0-1ï¼‰
        model_meta: ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        jockey_compat: é¨æ‰‹ç›¸æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        course_compat: ã‚³ãƒ¼ã‚¹é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        distance_compat: è·é›¢é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        is_rest_comeback: ä¼‘é¤Šæ˜ã‘ãƒ•ãƒ©ã‚°ï¼ˆ1=True, 0=Falseï¼‰
        has_history: éå»èµ°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ã©ã†ã‹ (True/False)

    Returns:
        int: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
    """
    if not model_meta:
        return 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # ===== 1. ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦: å›ºå®šå€¤ï¼ˆå¤©äº•åŠ¹æœã‚’è§£æ¶ˆã™ã‚‹ãŸã‚å¤§å¹…ã«ä¸‹ã’ã‚‹ï¼‰ =====
    # å®Œå…¨ã«ãƒ•ãƒ©ãƒƒãƒˆãªçŠ¶æ…‹ã‚’30ã¨ã—ã€åŠ ç‚¹ã§ä¼¸ã°ã™æ–¹å¼ã«å¤‰æ›´
    base_confidence = 30.0

    # ===== 2. ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹èª¿æ•´ =====
    data_size = model_meta.get('data_stats', {}).get('total_records', 0)
    if data_size < 1000:
        data_penalty = -20  # ãƒ‡ãƒ¼ã‚¿é‡å°‘ãªã„
    elif data_size < 3000:
        data_penalty = -8
    elif data_size < 5000:
        data_penalty = -3
    else:
        data_penalty = 0

    # ===== 3. äºˆæ¸¬ç¢ºç‡ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé€£ç¶šçš„ãªèª¿æ•´ï¼‰ =====
    # 0.5ã‹ã‚‰é›¢ã‚Œã‚‹ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒç¢ºä¿¡ã‚’æŒã£ã¦ã„ã‚‹ï¼‰
    # 0.5ã«è¿‘ã„ã»ã©ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒè¿·ã£ã¦ã„ã‚‹ï¼‰
    distance_from_uncertain = abs(ai_prob - 0.5)

    # è·é›¢ã«åŸºã¥ãä¿¡é ¼åº¦ãƒœãƒ¼ãƒŠã‚¹: 0.5é›¢ã‚Œã¦ã„ã‚‹ã¨æœ€å¤§+20ã€0.0ã ã¨-20
    # å¼ã‚’èª¿æ•´ã—ã¦ç¯„å›²ã‚’æ‹¡å¤§
    prob_bonus = (distance_from_uncertain * 2 - 0.25) * 40

    # ã•ã‚‰ã«æ¥µç«¯ãªäºˆæ¸¬ï¼ˆ<0.10 or >0.90ï¼‰ã«ã¯è¿½åŠ ãƒœãƒ¼ãƒŠã‚¹ (Top 3ç”¨ã«èª¿æ•´)
    if ai_prob < 0.10 or ai_prob > 0.90:
        prob_bonus += 12

    # AIç¢ºç‡ãŒæ¥µç«¯ã«ä½ã„å ´åˆã¯ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§ï¼‰
    if ai_prob < 0.15:
        prob_bonus -= 10

    # ===== 4. é©æ€§ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆæ–°è¦è¿½åŠ ï¼‰ =====
    compat_bonus = 0

    # åˆ©ç”¨å¯èƒ½ãªé©æ€§ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ
    compat_scores = []
    if jockey_compat is not None and not pd.isna(jockey_compat):
        compat_scores.append(jockey_compat)
    if course_compat is not None and not pd.isna(course_compat):
        compat_scores.append(course_compat)
    if distance_compat is not None and not pd.isna(distance_compat):
        compat_scores.append(distance_compat)

    if compat_scores:
        avg_compat = sum(compat_scores) / len(compat_scores)
        min_compat = min(compat_scores)

        # å¹³å‡é©æ€§ã«ã‚ˆã‚‹èª¿æ•´ (Lower is Better, since these are Ranks 1-18)
        # 1.0 - 4.0: Excellent
        # 4.1 - 8.0: Good
        # 8.1 - 12.0: Average
        # 12.1+: Poor
        
        if avg_compat <= 3.5:
            compat_bonus = +50  # å…¨ã¦é«˜é©æ€§ (Rank 1-3) -> æ¥µã‚ã¦å¼·åŠ›ãªè£œæ­£
        elif avg_compat <= 7.0:
            compat_bonus = +25  # è‰¯é©æ€§ (Rank 4-7)
        elif avg_compat <= 11.0:
            compat_bonus = 0    # å¹³å‡çš„
        elif avg_compat <= 14.0:
            compat_bonus = -30  # ä¸é©æ€§
        else:
            compat_bonus = -60  # è‡´å‘½çš„ (Rank 15-18)

        # æœ€ä½ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹è¿½åŠ ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆã„ãšã‚Œã‹ã®é©æ€§ãŒæ¥µç«¯ã«ä½ã„å ´åˆ = RankãŒå¤§ãã„ï¼‰
        if max(compat_scores) > 13.0:
            compat_bonus -= 15  # è‡´å‘½çš„ãªä¸é©æ€§ã‚’æŠ±ãˆã¦ã„ã‚‹
        elif max(compat_scores) > 10.0:
            compat_bonus -= 5


    # ===== 5. ä¼‘é¤Šæ˜ã‘ãƒ»é–“éš”ã«ã‚ˆã‚‹èª¿æ•´ (æ–°è¦è¿½åŠ ) =====
    interval_penalty = 0
    if is_rest_comeback == 1:
        interval_penalty = -10 # é•·æœŸä¼‘é¤Šæ˜ã‘ã¯ä¸ç¢ºå®šè¦ç´ ãŒå¤šã„
        
    # ===== 6. åˆå‡ºèµ°ãƒ»å±¥æ­´ãªã—ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£ (æ–°è¦è¿½åŠ ) =====
    history_penalty = 0
    if not has_history:
        history_penalty = -40 # ãƒ‡ãƒ¼ã‚¿ãŒå…¨ããªã„é¦¬ã¯ä¿¡é ¼ã§ããªã„

    # ===== 7. å‰èµ°æˆç¸¾ã«ã‚ˆã‚‹è£œæ­£ (æ–°è¦è¿½åŠ ) =====
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›: å‰èµ°æˆç¸¾ã‚’å¼·ãåæ˜ 
    past_rank_bonus = 0
    past_1_rank = row.get('past_1_rank')

    if pd.notna(past_1_rank):
        try:
            p1 = float(past_1_rank)
            if p1 <= 1.0:
                past_rank_bonus = +15 # å‰èµ°1ç€ã¯å‹¢ã„ã‚ã‚Š
            elif p1 <= 3.0:
                past_rank_bonus = +8  # å‰èµ°å¥½èµ°
            elif p1 >= 10.0:
                past_rank_bonus = -15 # å‰èµ°å¤§æ•—ã¯å‰²ã‚Šå¼•ã
        except:
            pass
            
    # ===== æœ€çµ‚è¨ˆç®— =====
    confidence = base_confidence + data_penalty + prob_bonus + compat_bonus + interval_penalty + history_penalty + past_rank_bonus

    # ç¯„å›²ã‚’æ‹¡å¤§: 20-95ï¼ˆã‚ˆã‚Šå·®åˆ¥åŒ–ï¼‰
    return int(max(20, min(95, confidence)))

def predict_race_logic(df, model, model_meta, stats=None, mode="JRA"):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦AIäºˆæ¸¬ã¨ä¿¡é ¼åº¦è¨ˆç®—ã‚’è¡Œã†
    stats: çµ±è¨ˆæƒ…å ±ã®è¾æ›¸ï¼ˆinferenceç”¨ï¼‰
    mode: "JRA" or "NAR" (Default: "JRA")
    """
    try:
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆä¼šå ´ç‰¹æ€§ã‚ã‚Šï¼‰
        # inference mode: pass stats (default to empty dict if None to force Inference Path)
        X_df = process_data(df, use_venue_features=True, input_stats=stats if stats is not None else {})

        # Align features with model
        if hasattr(model, 'feature_name'):
             model_features = model.feature_name()
             # Ensure all features exist and log missing ones
             missing_features = []
             for f in model_features:
                 if f not in X_df.columns:
                     missing_features.append(f)
                     X_df[f] = 0

             if missing_features:
                 logger.warning(f"âš ï¸  Missing features defaulted to 0 (first 10): {missing_features[:10]}")
                 if len(missing_features) > 10:
                     logger.warning(f"... and {len(missing_features)-10} more missing features")

             X_pred = X_df[model_features].copy()
             # Fill NA with 0 (consistent with Admin App)
             X_pred = X_pred.fillna(0)
             
             # Category Handling (Crucial for LightGBM)
             for col in X_pred.select_dtypes(include=['object']).columns:
                 X_pred[col] = X_pred[col].astype('category')

        else:
             # Fallback for older sklearn models or if feature_name not available
             meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
             features = [c for c in X_df.columns if c not in meta_cols and c != 'target_win']
             X_pred = X_df[features].select_dtypes(include=['number']).fillna(0)

        # Predict (Robust logic synced with Admin App)
        if hasattr(model, 'predict_proba'):
             probs = model.predict_proba(X_pred)[:, 1]
        else:
             probs = model.predict(X_pred)

        df['AI_Prob'] = probs
        df['AI_Score'] = (probs * 100).astype(float) # Ensure float for downstream calcs
        
        # Save X_df to session state for debugging
        st.session_state['last_features'] = X_df

        # Calculate Confidence
        confidences = []
        for idx, p in enumerate(probs):
            jockey_c = X_df['jockey_compatibility'].iloc[idx] if 'jockey_compatibility' in X_df.columns else None
            distance_c = X_df['distance_compatibility'].iloc[idx] if 'distance_compatibility' in X_df.columns else None
            
            # Course compatibility
            course_c = None
            if 'turf_compatibility' in X_df.columns and 'dirt_compatibility' in X_df.columns:
                if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df.columns:
                    course_type = df['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[idx]
                    if 'èŠ' in str(course_type):
                        course_c = X_df['turf_compatibility'].iloc[idx]
                    elif 'ãƒ€' in str(course_type):
                        course_c = X_df['dirt_compatibility'].iloc[idx]
                else:
                    course_c = X_df['turf_compatibility'].iloc[idx] # Default

            is_rest = X_df['is_rest_comeback'].iloc[idx] if 'is_rest_comeback' in X_df.columns else 0
            
            # Check for history (using raw df columns if available, or heuristic on X_df)
            has_history = True
            if 'past_1_rank' in df.columns:
                 val = df['past_1_rank'].iloc[idx]
                 if pd.isna(val) or val == 0 or val == "":
                     has_history = False
            
            conf = calculate_confidence_score(df.iloc[idx], p, model_meta, jockey_c, course_c, distance_c, is_rest, has_history)
            confidences.append(conf)

        df['Confidence'] = confidences

        # DæŒ‡æ•° calc moved after feature merge


        # Merge relevant features back to df
        cols_to_merge = [
            'turf_compatibility', 'dirt_compatibility',
            'jockey_compatibility', 'distance_compatibility',
            'weighted_avg_speed', 'weighted_avg_rank',
            'dd_frame_bias', 'dd_run_style_bias',
            'jockey_win_rate', 'course_distance_record',
            'good_condition_avg', 'heavy_condition_avg',
            'stable_win_rate', 'jockey_top3_rate',
            'trend_rank', 'growth_factor',
            # éå»æˆç¸¾ãƒ‡ãƒ¼ã‚¿ã‚‚è¿½åŠ 
            'past_1_rank', 'past_2_rank', 'past_3_rank', 'past_4_rank', 'past_5_rank',
            'past_1_last_3f', 'past_2_last_3f', 'past_3_last_3f',
            # è¡€çµ±çµ±è¨ˆ
            'sire_win_rate', 'bms_win_rate'
        ]
        for c in cols_to_merge:
            if c in X_df.columns:
                df[c] = X_df[c]

        # course_compatibilityã‚’å‹•çš„ã«ç”Ÿæˆï¼ˆã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦èŠ/ãƒ€ãƒ¼ãƒˆã‚’é¸æŠï¼‰
        if 'turf_compatibility' in df.columns and 'dirt_compatibility' in df.columns:
            if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df.columns:
                df['course_compatibility'] = df.apply(
                    lambda row: row['turf_compatibility'] if 'èŠ' in str(row.get('ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', ''))
                               else row['dirt_compatibility'] if 'ãƒ€' in str(row.get('ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', ''))
                               else row['turf_compatibility'],  # Default to turf
                    axis=1
                )
            else:
                # ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ä¸æ˜ã®å ´åˆã¯èŠã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
                df['course_compatibility'] = df['turf_compatibility']
        elif 'turf_compatibility' in df.columns:
            df['course_compatibility'] = df['turf_compatibility']
        elif 'dirt_compatibility' in df.columns:
            df['course_compatibility'] = df['dirt_compatibility']
        else:
            df['course_compatibility'] = 5.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        # === D-Index Calculation (Refactored) ===
        import scoring
        importlib.reload(scoring) # Ensure latest logic
        
        # Load Weights (Mode Specific)
        d_index_conf_path = os.path.join(PROJECT_ROOT, "config", f"d_index_config_{mode.lower()}.json")
        default_weights = {'ai': 0.4, 'compat': 0.5, 'blood': 0.1}
        weights = default_weights
        if os.path.exists(d_index_conf_path):
            try:
                with open(d_index_conf_path, 'r') as f:
                    weights = json.load(f)
            except:
                pass
        # Fallback
        elif os.path.exists(os.path.join(PROJECT_ROOT, "config", "d_index_config.json")):
             try:
                with open(os.path.join(PROJECT_ROOT, "config", "d_index_config.json"), 'r') as f:
                    weights = json.load(f)
             except:
                pass
        
        df['Compat_Index'] = df.apply(lambda row: scoring.calculate_pure_compat(
            row, 
            weights.get('compat_sub_weights', {'jockey': 0.4, 'distance': 0.3, 'course': 0.3})
        ), axis=1)
        df['Bloodline_Index'] = df.apply(scoring.calculate_bloodline_index, axis=1)
        df['D_Index'] = df.apply(lambda row: scoring.calculate_d_index(row, weights), axis=1)
        return df
    except Exception as e:
        import traceback
        st.error(f"Prediction Error: {e}")
        st.code(traceback.format_exc())
        return None

def load_schedule_data(mode="JRA"):
    json_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "temp", "todays_data_nar.json" if mode == "NAR" else "todays_data.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# --- UI ---
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Logic Explanation
with st.expander("â„¹ï¸ ã“ã®AIäºˆæƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ã¤ã„ã¦ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)"):
    st.markdown("""
    ### ğŸ§  AIäºˆæƒ³ã®ä»•çµ„ã¿
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**LightGBM**ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€éå»ã®è†¨å¤§ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ1ç€ï¼ˆå‹åˆ©ï¼‰ã®ç¢ºç‡ã€ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
    
    #### ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
    - **åŸºæœ¬æƒ…å ±**: æ ç•ªã€é¦¬ç•ªã€é¦¬é½¢ã€æ–¤é‡ã€é¨æ‰‹
    - **éå»5èµ°ã®æˆç¸¾**: ç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã€ä¸Šã‚Š3Fã€é€šéé †ï¼ˆè„šè³ªï¼‰ã€é¦¬ä½“é‡ã€é¦¬å ´çŠ¶æ…‹ã€**å¤©æ°—**ã€**æœ€çµ‚ã‚ªãƒƒã‚º**
    - **ç›´è¿‘é‡è¦–**: éå»ã®ãƒ¬ãƒ¼ã‚¹ã¯ç›´è¿‘ã®ã‚‚ã®ã»ã©é‡è¦è¦–ã™ã‚‹ã€Œæ™‚é–“æ¸›è¡°ã€å‡¦ç†ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
    
    #### ğŸ¯ æœŸå¾…å€¤ (EV) ã¨ã¯ï¼Ÿ
    ã€Œãã®é¦¬åˆ¸ã‚’è²·ã„ç¶šã‘ãŸã¨ãã«ã€æœ€çµ‚çš„ã«ã„ãã‚‰å„²ã‹ã‚‹ã‹ã€ã®æŒ‡æ¨™ã§ã™ã€‚
    
    $$
    \text{èª¿æ•´å¾ŒæœŸå¾…å€¤} = (\text{AIã®å‹ç‡} \times \text{ã‚ãªãŸã®å°} \times \text{ã‚ªãƒƒã‚º}) - 1.0
    $$
    
    - **ãƒ—ãƒ©ã‚¹ (0ä»¥ä¸Š)**: è²·ãˆã°è²·ã†ã»ã©å„²ã‹ã‚‹ãƒãƒ£ãƒ³ã‚¹ãŒã‚ã‚‹é¦¬ï¼ˆæ¨å¥¨ï¼ï¼‰
    - **ãƒã‚¤ãƒŠã‚¹**: å‹ã¤ç¢ºç‡ã«æ¯”ã¹ã¦ã‚ªãƒƒã‚ºãŒä½ã™ãã‚‹ï¼ˆå‰²ã«åˆã‚ãªã„ï¼‰é¦¬
    - **ã‚ãªãŸã®å°**: AIã®äºˆæ¸¬ã«ã€ã‚ãªãŸã®ç›´æ„Ÿï¼ˆâ—ã‚„â—¯ï¼‰ã‚’ãƒŸãƒƒã‚¯ã‚¹ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚AIã ã‘ã§ãªãã€ã‚ãªãŸã®ç›¸é¦¬çœ¼ã‚‚åæ˜ ã•ã‚Œã¾ã™ã€‚

    #### ğŸ‡ ä¸­å¤®ç«¶é¦¬ vs ğŸŒ™ åœ°æ–¹ç«¶é¦¬
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¼šå ´ã‹ã‚‰è‡ªå‹•çš„ã«ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã¨åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰ã‚’åˆ¤å®šã—ã€ãã‚Œãã‚Œã«æœ€é©åŒ–ã•ã‚ŒãŸæœŸå¾…å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    **ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.3å€, â—¯=1.15å€ï¼ˆæ§ãˆã‚ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚

    **åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.8å€, â—¯=1.4å€ï¼ˆç©æ¥µçš„ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„

    #### ğŸ“Š ä¿¡é ¼æ€§å‘ä¸Šã®å–ã‚Šçµ„ã¿
    - **ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: è¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ï¼ˆAUCï¼‰ã€ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¸¸æ™‚è¡¨ç¤º
    - **äºˆæ¸¬ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: å„äºˆæ¸¬ã«ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’0-100%ã§æ•°å€¤åŒ–
    - **ãƒ‡ãƒ¼ã‚¿æ–°é®®åº¦**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’è¡¨ç¤ºï¼ˆ3æ—¥ä»¥å†…ãŒç†æƒ³ï¼‰
    - **æ³¨æ„å–šèµ·**: ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³ã‚„äºˆæ¸¬ã®é™ç•Œã‚’æ˜ç¤º
    - **é€æ˜æ€§**: ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ»é™ç•Œã‚’éš ã•ãšé–‹ç¤º
    """)


# -------------------------------------------------------------
# Triple Umatan (SPAT4 Loto) Logic
# -------------------------------------------------------------
def render_triple_umatan_section(target_races, mode_val):
    """
    ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ï¼ˆã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼ãªã©ï¼‰ç”¨ã®äºˆæƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    3ãƒ¬ãƒ¼ã‚¹åˆ†ã®äºˆæƒ³ã‚’ä¸€æ‹¬ã§è¡Œã„ã€è²·ã„ç›®ã‚’ç”Ÿæˆã™ã‚‹
    """
    st.markdown("### ğŸ¯ SP: ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ (Triple Exacta) äºˆæƒ³")
    st.info("ğŸ’¡ **æ©Ÿèƒ½èª¬æ˜**: æŒ‡å®šã—ãŸ3ãƒ¬ãƒ¼ã‚¹ï¼ˆé€šå¸¸ã¯æœ€çµ‚3ãƒ¬ãƒ¼ã‚¹ï¼‰ã®é¦¬å˜ï¼ˆ1ç€ãƒ»2ç€ï¼‰ã‚’ã™ã¹ã¦çš„ä¸­ã•ã›ã‚‹ã€Œãƒˆãƒªãƒ—ãƒ«é¦¬å˜ã€ã®è²·ã„ç›®ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    if not target_races or len(target_races) < 3:
        st.error("âš ï¸ ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å°‘ãªãã¨ã‚‚3ãƒ¬ãƒ¼ã‚¹å¿…è¦ã§ã™ã€‚")
        return

    # 1. Race Selection
    st.subheader("1. å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã®é¸æŠ")
    
    # Sort by number first
    sorted_races = sorted(target_races, key=lambda x: int(x['number']) if str(x['number']).isdigit() else 0)
    
    # Try to find flagged races
    flagged_races = [r for r in sorted_races if r.get('is_triple', False)]
    
    if len(flagged_races) >= 3:
        # Used flagged races
        default_selections = flagged_races[:3] # Assumption: Triple is exactly 3
    else:
        # Fallback to Last 3
        default_selections = sorted_races[-3:] if len(sorted_races) >= 3 else sorted_races
    
    last_3 = default_selections # Rename for compatibility with existing variable usage
    
    race_options_list = [f"{r['number']}R: {r['name']}" for r in sorted_races]
    
    col_sel_1, col_sel_2, col_sel_3 = st.columns(3)
    
    # Defaults
    def get_idx(r): return filter_race_idx(sorted_races, r)
    
    # Dynamic Key Suffix (Date + Venue)
    if sorted_races:
        rk = f"{sorted_races[0].get('date','')} {sorted_races[0].get('venue','')}"
    else:
        rk = "unknown"

    with col_sel_1:
        idx1 = sorted_races.index(last_3[0]) if len(last_3) > 0 else 0
        r1_label = st.selectbox("1ãƒ¬ãƒ¼ã‚¹ç›®", race_options_list, index=idx1, key=f"tu_r1_{rk}")
    with col_sel_2:
        idx2 = sorted_races.index(last_3[1]) if len(last_3) > 1 else 1
        r2_label = st.selectbox("2ãƒ¬ãƒ¼ã‚¹ç›®", race_options_list, index=idx2, key=f"tu_r2_{rk}")
    with col_sel_3:
        idx3 = sorted_races.index(last_3[2]) if len(last_3) > 2 else 2
        r3_label = st.selectbox("3ãƒ¬ãƒ¼ã‚¹ç›®", race_options_list, index=idx3, key=f"tu_r3_{rk}")

    selected_race_objs = []
    for label in [r1_label, r2_label, r3_label]:
        # Find object
        found = next((r for r in sorted_races if f"{r['number']}R: {r['name']}" == label), None)
        if found: selected_race_objs.append(found)

    # Session state key for Triple Umatan
    if 'tu_active' not in st.session_state:
        st.session_state['tu_active'] = False

    if st.button("ğŸš€ ãƒˆãƒªãƒ—ãƒ«é¦¬å˜äºˆæƒ³ã‚’é–‹å§‹", type="primary"):
        st.session_state['tu_active'] = True
        
    if st.session_state['tu_active']:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ / é–‰ã˜ã‚‹"):
            st.session_state['tu_active'] = False
            st.rerun()

        model = load_model(mode_val)
        model_meta = load_model_metadata(mode_val)
        stats = load_stats(mode_val)
        
        if not model:
            st.error("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return

        st.markdown("---")
        st.subheader("2. å„ãƒ¬ãƒ¼ã‚¹ã®åˆ†æãƒ»è²·ã„ç›®æ§‹ç¯‰")

        # Container for results
        results_container = st.container()
        
        total_combinations = 1
        prediction_summaries = []

        with st.spinner("3ãƒ¬ãƒ¼ã‚¹åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­..."):
            history_df_cache = load_history_csv(mode_val) # Load once
            
            for i, race in enumerate(selected_race_objs):
                with results_container:
                    st.markdown(f"#### {i+1}ãƒ¬ãƒ¼ã‚¹ç›®: {race['venue']}{race['number']}R {race['name']}")
                    
                    # Analyze
                    df_race = auto_scraper.scrape_shutuba_data(race['id'], mode=mode_val, history_df=history_df_cache)
                    if df_race is None or df_race.empty:
                        st.error(f"ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—: {race['id']}")
                        return

                    processed_df = predict_race_logic(df_race, model, model_meta, stats=stats, mode=mode_val)
                     # Odds Bias (Simple apply for Triple Umatan)
                    if processed_df is not None:
                        # 1. Restore AI Score
                        processed_df['AIã‚¹ã‚³ã‚¢(%)'] = processed_df['AI_Prob'] * 100

                        # 2. Prepare D-Index (DæŒ‡æ•°)
                        if 'D_Index' in processed_df.columns:
                            processed_df['DæŒ‡æ•°'] = processed_df['D_Index']
                        else:
                            processed_df['DæŒ‡æ•°'] = processed_df['AIã‚¹ã‚³ã‚¢(%)']
                            
                        # 3. Add Info Columns (Compatibility & History)
                        # Map internal names to display names AND convert to 0-10 score (Higher is Better)
                        # Logic matches individual analysis: 10 - (avg_rank / 2)
                        def convert_compat_score(x):
                            if pd.isna(x): return 5.0
                            return max(0, min(10, 10 - (x / 2)))

                        if 'jockey_compatibility' in processed_df.columns:
                            processed_df['é¨æ‰‹é©æ€§åº¦'] = processed_df['jockey_compatibility'].apply(convert_compat_score).round(1)
                        if 'distance_compatibility' in processed_df.columns:
                            processed_df['è·é›¢é©æ€§åº¦'] = processed_df['distance_compatibility'].apply(convert_compat_score).round(1)
                        if 'course_compatibility' in processed_df.columns:
                            processed_df['ã‚³ãƒ¼ã‚¹é©æ€§åº¦'] = processed_df['course_compatibility'].apply(convert_compat_score).round(1)
                            
                        # Add Weighted Avg Speed if available
                        if 'weighted_avg_speed' in processed_df.columns:
                             processed_df['å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'] = processed_df['weighted_avg_speed'].round(1)

                        if 'past_1_rank' in processed_df.columns:
                            processed_df['å‰èµ°ç€é †'] = processed_df['past_1_rank'].fillna('-')
                            
                        # Use odds if available
                        if 'å˜å‹' in processed_df.columns:
                            processed_df['ç¾åœ¨ã‚ªãƒƒã‚º'] = pd.to_numeric(processed_df['å˜å‹'], errors='coerce').fillna(0.0)
                        
                        # Add confidence
                        processed_df['ä¿¡é ¼åº¦'] = processed_df.apply(
                            lambda row: calculate_confidence_score(row, row['AI_Prob'], model_meta), axis=1
                        )

                        # Sort by D-Index
                        processed_df = processed_df.sort_values("DæŒ‡æ•°", ascending=False)
                        
                        # Add 'äºˆæƒ³å°' column (Empty by default)
                        processed_df['äºˆæƒ³å°'] = ""
                        
                        # Add 'èª¿æ•´å¾ŒæœŸå¾…å€¤' (Initial estimation)
                        # Formula: (AI_Prob * Odds * Mark_Bias) - 1.0 (Assume No Mark initially)
                        # Note: Simple estimation.
                        if 'ç¾åœ¨ã‚ªãƒƒã‚º' in processed_df.columns:
                             processed_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = (processed_df['AI_Prob'] * processed_df['ç¾åœ¨ã‚ªãƒƒã‚º']) - 1.0
                        else:
                             processed_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = 0.0

                        # Calculate Gap
                        gap = 0.0
                        if len(processed_df) >= 2:
                            gap = processed_df.iloc[0]['DæŒ‡æ•°'] - processed_df.iloc[1]['DæŒ‡æ•°']
                        
                        # Top Candidates (Show ALL)
                        # top_horses = processed_df.head(6) # Removed limit
                        top_horses = processed_df
                        
                        # Display Top 4
                        st.write(f"**GAPå€¤:** {gap:.1f}")
                        
                        # Define columns to show
                        # Create Pedigree Column
                        if 'father' in processed_df.columns and 'mother' in processed_df.columns:
                             processed_df['è¡€çµ±'] = processed_df.apply(
                                 lambda r: f"{r['father']} / {r['mother']}" + (f" ({r['bms']})" if pd.notna(r.get('bms')) else ""), 
                                 axis=1
                             )
                        else:
                             processed_df['è¡€çµ±'] = "-"
                             
                        cols_show = ['æ ', 'é¦¬ ç•ª', 'é¦¬å', 'äºˆæƒ³å°', 'DæŒ‡æ•°', 'AIã‚¹ã‚³ã‚¢(%)', 'ä¿¡é ¼åº¦', 'ç¾åœ¨ã‚ªãƒƒã‚º', 'èª¿æ•´å¾ŒæœŸå¾…å€¤']
                        # Add optional columns if they exist
                        for col in ['é¨æ‰‹é©æ€§åº¦', 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 'è·é›¢é©æ€§åº¦', 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å‰èµ°ç€é †']:
                            if col in processed_df.columns:
                                cols_show.append(col)
                        cols_show.append('è¡€çµ±')
                                
                        # Interactive Editor
                        st.data_editor(
                            top_horses[cols_show],
                            height=300, # Taller for full list
                            hide_index=True,
                            column_config={
                                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                                    "AIå‹ç‡", format="%d%%", min_value=0, max_value=100
                                ),
                                "DæŒ‡æ•°": st.column_config.ProgressColumn(
                                    "DæŒ‡æ•°", format="%.1f", min_value=0, max_value=100
                                ),
                                "ä¿¡é ¼åº¦": st.column_config.NumberColumn(
                                    "ä¿¡é ¼åº¦", format="%d%%"
                                ),
                                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                                    "äºˆæƒ³å°",
                                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                                    required=False,
                                    width="small"
                                ),
                                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(
                                    "èª¿æ•´å¾ŒæœŸå¾…å€¤", format="%.2f"
                                ),
                                "å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰": st.column_config.NumberColumn(
                                    "å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰", format="%.1f m/s"
                                ),
                                "é¨æ‰‹é©æ€§åº¦": st.column_config.ProgressColumn(
                                    "é¨æ‰‹é©æ€§", format="%.1f", min_value=0, max_value=10
                                ),
                                "ã‚³ãƒ¼ã‚¹é©æ€§åº¦": st.column_config.ProgressColumn(
                                    "ã‚³ãƒ¼ã‚¹é©æ€§", format="%.1f", min_value=0, max_value=10
                                ),
                                "è·é›¢é©æ€§åº¦": st.column_config.ProgressColumn(
                                    "è·é›¢é©æ€§", format="%.1f", min_value=0, max_value=10
                                ),
                            },
                             key=f"editor_{race['id']}_{i}" # Unique key for state persistence
                        )
                        
                        # === Data Missing Alerts (Triple Umatan) ===
                        edited_df = top_horses # Use top_horses as source for checks
                        
                        def to_circled(n):
                            try:
                                n_int = int(n)
                                if 1 <= n_int <= 20: return chr(9311 + n_int)
                                return str(n)
                            except: return str(n)

                        unknown_history = []
                        if 'å‰èµ°ç€é †' in edited_df.columns:
                            unknown_history = [f"{to_circled(row['é¦¬ ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[edited_df['å‰èµ°ç€é †'] == 0].iterrows()]
                            
                        unknown_jockey = []
                        hidden_gems = []
                        if 'é¨æ‰‹é©æ€§åº¦' in edited_df.columns:
                            # 5.0 is the fallback score for missing data
                            jockey_missing_mask = (edited_df['é¨æ‰‹é©æ€§åº¦'] == 5.0)
                            unknown_jockey = [f"{to_circled(row['é¦¬ ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[jockey_missing_mask].iterrows()]
                            
                            if 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦' in edited_df.columns and 'è·é›¢é©æ€§åº¦' in edited_df.columns:
                                 potential_mask = (edited_df['ã‚³ãƒ¼ã‚¹é©æ€§åº¦'] >= 7.0) | (edited_df['è·é›¢é©æ€§åº¦'] >= 7.0)
                                 hidden_gems = [f"{to_circled(row['é¦¬ ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[jockey_missing_mask & potential_mask].iterrows()]
                
                        if unknown_history or unknown_jockey:
                             st.warning("âš ï¸ ä¸€éƒ¨ã®é¦¬ã«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãŒã‚ã‚Šã¾ã™")
                             cols_alert = st.columns(2)
                             with cols_alert[0]:
                                 if unknown_history:
                                     st.info(f"**åˆå‡ºèµ°ãƒ»å±¥æ­´ãªã—**: {', '.join(unknown_history)}")
                             with cols_alert[1]:
                                 if unknown_jockey:
                                     st.info(f"**é¨æ‰‹ãƒ‡ãƒ¼ã‚¿ä¸è¶³**: {', '.join(unknown_jockey)}")
                                 if hidden_gems:
                                     st.success(f"âœ¨ **é¨æ‰‹ã¯æœªçŸ¥æ•°ã§ã™ãŒã€é¦¬ã®é©æ€§ã¯é«˜ã„**: {', '.join(hidden_gems)}")
                        
                        # Suggestion
                        st.caption("ğŸ‘‡ ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š (AIæ¨å¥¨: 1ç€å€™è£œ=ä¸Šä½2é ­, 2ç€å€™è£œ=ä¸Šä½4é ­)")
                        
                        # Logic similar to 'Renkei' in main app
                        if gap >= 15.0: # Solid Favorite
                             st.info(f"ğŸ¦¾ **é‰„æ¿** (Gap {gap:.1f}): 1ç€å€™è£œã‚’çµã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                        elif gap < 10.0: # Confusion
                             st.warning(f"ğŸŒªï¸ **æ··æˆ¦** (Gap {gap:.1f}): BOXè²·ã„ãªã©ã‚‚æ¤œè¨ã—ã¦ãã ã•ã„")
                        else: # Standard
                             st.success(f"âš–ï¸ **æ¨™æº–** (Gap {gap:.1f}): ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„ãƒ¬ãƒ¼ã‚¹ã§ã™")
                        
                        # Fixed Defaults based on user request (2x4)
                        default_1st = top_horses['é¦¬ ç•ª'].iloc[:2].tolist() # Top 2
                        default_2nd = top_horses['é¦¬ ç•ª'].iloc[:4].tolist() # Top 4
                        
                        all_nums = processed_df['é¦¬ ç•ª'].tolist()
                        
                        c1, c2 = st.columns(2)
                        with c1:
                            sel_1st = st.multiselect(f"{i+1}R: 1ç€å€™è£œ", all_nums, default=default_1st, key=f"tu_1st_{i}")
                        with c2:
                            sel_2nd = st.multiselect(f"{i+1}R: 2ç€å€™è£œ", all_nums, default=default_2nd, key=f"tu_2nd_{i}")
                        
                        # Calculate Race Combinations (Umatan Formation)
                        # Logic: sum(1 for h1 in sel_1st for h2 in sel_2nd if h1 != h2)
                        race_points = sum(1 for h1 in sel_1st for h2 in sel_2nd if h1 != h2)
                        
                        st.markdown(f"**ç‚¹æ•°:** {race_points}ç‚¹")
                        total_combinations *= race_points
                        
                        # Store summary text
                        h_map = dict(zip(processed_df['é¦¬ ç•ª'], processed_df['é¦¬å']))
                        summary_txt = f"**{race['number']}R**: 1ç€[{','.join(sel_1st)}] â†’ 2ç€[{','.join(sel_2nd)}]"
                        prediction_summaries.append(summary_txt)
                        
                        st.markdown("---")

        # 3. Final Summary
        st.subheader("3. è²·ã„ç›®ã¾ã¨ã‚")
        st.success(f"**åˆè¨ˆç‚¹æ•°: {total_combinations}ç‚¹**")
        cost_50 = total_combinations * 50
        cost_100 = total_combinations * 100
        
        st.metric("æ¨å®šè³¼å…¥é‡‘é¡ (50å††/ç‚¹)", f"{cost_50:,}å††")
        st.metric("æ¨å®šè³¼å…¥é‡‘é¡ (100å††/ç‚¹)", f"{cost_100:,}å††")
        
        st.markdown("#### æ§‹æˆ")
        for s in prediction_summaries:
            st.write(s)

        st.warning("âš ï¸ ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ã¯50å††ã‹ã‚‰è³¼å…¥å¯èƒ½ã§ã™ï¼ˆSPAT4ï¼‰ã€‚ã‚ªãƒƒã‚ºã«ã‚ˆã‚‹ã‚¬ãƒŸï¼ˆãƒˆãƒªã‚¬ãƒŸï¼‰ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚")


# -------------------------------------------------------------
# WIN5 (JRA) Logic
# -------------------------------------------------------------
def render_win5_section(target_races, mode_val):
    """
    WIN5ç”¨ã®äºˆæƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    5ãƒ¬ãƒ¼ã‚¹åˆ†ã®äºˆæƒ³ã‚’ä¸€æ‹¬ã§è¡Œã„ã€è²·ã„ç›®ã‚’ç”Ÿæˆã™ã‚‹
    """
    st.markdown("### ğŸ‘‘ WIN5 (5é‡å‹å˜å‹å¼) äºˆæƒ³")
    st.info("ğŸ’¡ **æ©Ÿèƒ½èª¬æ˜**: æŒ‡å®šã—ãŸ5ãƒ¬ãƒ¼ã‚¹ï¼ˆé€šå¸¸ã¯å„å ´ã®ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒ¼ã‚¹ä»˜è¿‘ï¼‰ã®1ç€é¦¬ã‚’ã™ã¹ã¦çš„ä¸­ã•ã›ã‚‹ã€ŒWIN5ã€ã®è²·ã„ç›®ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    if not target_races or len(target_races) < 5:
        st.error("âš ï¸ ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å°‘ãªãã¨ã‚‚5ãƒ¬ãƒ¼ã‚¹å¿…è¦ã§ã™ã€‚")
        return

    # 1. Race Selection
    st.subheader("1. å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã®é¸æŠ")
    
    # Defaults
    sorted_races = sorted(target_races, key=lambda x: int(x['number']) if str(x['number']).isdigit() else 0)
    
    # Try to find flagged races
    flagged_races = [r for r in sorted_races if r.get('is_win5', False)]
    
    if len(flagged_races) >= 5:
        default_selections = flagged_races[:5]
    else:
        # Fallback Heuristic
        priority_races = [r for r in sorted_races if str(r['number']) in ['10', '11']]
        priority_races.sort(key=lambda x: int(x['number']))
        
        if len(priority_races) >= 5:
             default_selections = priority_races[-5:]
        elif len(priority_races) > 0:
             remainder = [r for r in sorted_races if r not in priority_races]
             needed = 5 - len(priority_races)
             fill = remainder[-needed:] if len(remainder) >= needed else remainder
             default_selections = fill + priority_races
             default_selections.sort(key=lambda x: int(x['number']))
        else:
             default_selections = sorted_races[-5:] if len(sorted_races) >= 5 else sorted_races
    
    # Get all distinct venues from target_races
    all_venues = sorted(list(set([r['venue'] for r in target_races])))
    
    cols_sel = st.columns(5)
    selected_races_indices = []
    
    for i in range(5):
        with cols_sel[i]:
            st.markdown(f"**{i+1}ãƒ¬ãƒ¼ã‚¹ç›®**")
            
            # 1. Determine Default for this slot
            def_race = default_selections[i] if i < len(default_selections) else sorted_races[0]
            
            # 2. Select Venue
            def_venue_idx = all_venues.index(def_race['venue']) if def_race['venue'] in all_venues else 0
            sel_venue = st.selectbox("ä¼šå ´", all_venues, index=def_venue_idx, key=f"win5_v{i}", label_visibility="collapsed")
            
            # 3. Filter Races by Venue
            venue_races = [r for r in sorted_races if r['venue'] == sel_venue]
            if not venue_races: venue_races = [def_race] # Fallback
            
            # 4. Select Race
            race_opts = [f"{r['number']}R: {r['name']}" for r in venue_races]
            
            # Try to match default race if venue wasn't changed
            if def_race['venue'] == sel_venue:
                 def_label = f"{def_race['number']}R: {def_race['name']}"
                 def_race_idx = race_opts.index(def_label) if def_label in race_opts else 0
            else:
                 def_race_idx = 0
            
            sel_label = st.selectbox("ãƒ¬ãƒ¼ã‚¹", race_opts, index=def_race_idx, key=f"win5_r{i}", label_visibility="collapsed")
            
            found = next((r for r in venue_races if f"{r['number']}R: {r['name']}" == sel_label), None)
            if found: selected_races_indices.append(found)

    # Session state key for WIN5
    if 'win5_active' not in st.session_state:
        st.session_state['win5_active'] = False

    if st.button("ğŸš€ WIN5 äºˆæƒ³ã‚’é–‹å§‹", type="primary"):
        st.session_state['win5_active'] = True
        
    if st.session_state['win5_active']:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ / é–‰ã˜ã‚‹"):
            st.session_state['win5_active'] = False
            st.rerun()

        model = load_model(mode_val)
        model_meta = load_model_metadata(mode_val)
        stats = load_stats(mode_val)
        
        if not model:
            st.error("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return

        st.markdown("---")
        st.subheader("2. å„ãƒ¬ãƒ¼ã‚¹ã®åˆ†æãƒ»è²·ã„ç›®æ§‹ç¯‰")

        results_container = st.container()
        
        total_combinations = 1
        prediction_summaries = []

        with st.spinner("5ãƒ¬ãƒ¼ã‚¹åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­..."):
            history_df_cache = load_history_csv(mode_val) 
            
            for i, race in enumerate(selected_races_indices):
                with results_container:
                    st.markdown(f"#### {i+1}æˆ¦ç›®: {race['venue']}{race['number']}R {race['name']}")
                    
                    df_race = auto_scraper.scrape_shutuba_data(race['id'], mode=mode_val, history_df=history_df_cache)
                    if df_race is None or df_race.empty:
                        st.error(f"ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—: {race['id']}")
                        return

                    processed_df = predict_race_logic(df_race, model, model_meta, stats=stats, mode=mode_val)
                    
                    if processed_df is not None:
                        # 1. Restore AI Score
                        processed_df['AIã‚¹ã‚³ã‚¢(%)'] = processed_df['AI_Prob'] * 100

                        # 2. Prepare D-Index
                        if 'D_Index' in processed_df.columns:
                            processed_df['DæŒ‡æ•°'] = processed_df['D_Index']
                        else:
                            processed_df['DæŒ‡æ•°'] = processed_df['AIã‚¹ã‚³ã‚¢(%)']
                            
                         # 3. Add Info Columns (Compatibility & History)
                        # Map internal names to display names AND convert to 0-10 score (Higher is Better)
                        # Logic matches individual analysis: 10 - (avg_rank / 2)
                        def convert_compat_score(x):
                            if pd.isna(x): return 5.0
                            return max(0, min(10, 10 - (x / 2)))

                        if 'jockey_compatibility' in processed_df.columns:
                            processed_df['é¨æ‰‹é©æ€§åº¦'] = processed_df['jockey_compatibility'].apply(convert_compat_score).round(1)
                        if 'distance_compatibility' in processed_df.columns:
                            processed_df['è·é›¢é©æ€§åº¦'] = processed_df['distance_compatibility'].apply(convert_compat_score).round(1)
                        if 'course_compatibility' in processed_df.columns:
                            processed_df['ã‚³ãƒ¼ã‚¹é©æ€§åº¦'] = processed_df['course_compatibility'].apply(convert_compat_score).round(1)
                            
                        if 'weighted_avg_speed' in processed_df.columns:
                             processed_df['å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'] = processed_df['weighted_avg_speed'].round(1)

                        if 'past_1_rank' in processed_df.columns:
                            processed_df['å‰èµ°ç€é †'] = processed_df['past_1_rank'].fillna('-')
                            
                        # Odds
                        if 'å˜å‹' in processed_df.columns:
                            processed_df['ç¾åœ¨ã‚ªãƒƒã‚º'] = pd.to_numeric(processed_df['å˜å‹'], errors='coerce').fillna(0.0)
                        
                        # Confidence
                        processed_df['ä¿¡é ¼åº¦'] = processed_df.apply(
                            lambda row: calculate_confidence_score(row, row['AI_Prob'], model_meta), axis=1
                        )
                        
                        # Sort
                        processed_df = processed_df.sort_values("DæŒ‡æ•°", ascending=False)
                        
                        # Mark & Adj EV
                        processed_df['äºˆæƒ³å°'] = ""
                        if 'ç¾åœ¨ã‚ªãƒƒã‚º' in processed_df.columns:
                             processed_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = (processed_df['AI_Prob'] * processed_df['ç¾åœ¨ã‚ªãƒƒã‚º']) - 1.0
                        else:
                             processed_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = 0.0

                        # Gap
                        gap = 0.0
                        if len(processed_df) >= 2:
                            gap = processed_df.iloc[0]['DæŒ‡æ•°'] - processed_df.iloc[1]['DæŒ‡æ•°']
                        
                        # Display
                        st.write(f"**GAPå€¤:** {gap:.1f}")
                        
                        # Create Pedigree Column
                        if 'father' in processed_df.columns and 'mother' in processed_df.columns:
                             processed_df['è¡€çµ±'] = processed_df.apply(
                                 lambda r: f"{r['father']} / {r['mother']}" + (f" ({r['bms']})" if pd.notna(r.get('bms')) else ""), 
                                 axis=1
                             )
                        else:
                             processed_df['è¡€çµ±'] = "-"
                        
                        cols_show = ['æ ', 'é¦¬ ç•ª', 'é¦¬å', 'äºˆæƒ³å°', 'DæŒ‡æ•°', 'AIã‚¹ã‚³ã‚¢(%)', 'ä¿¡é ¼åº¦', 'ç¾åœ¨ã‚ªãƒƒã‚º', 'èª¿æ•´å¾ŒæœŸå¾…å€¤']
                        for col in ['é¨æ‰‹é©æ€§åº¦', 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 'è·é›¢é©æ€§åº¦', 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å‰èµ°ç€é †']:
                            if col in processed_df.columns:
                                cols_show.append(col)
                        cols_show.append('è¡€çµ±')
                                
                        st.data_editor(
                            processed_df[cols_show],
                            height=300,
                            hide_index=True,
                            column_config={
                                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn("AIå‹ç‡", format="%d%%", min_value=0, max_value=100),
                                "DæŒ‡æ•°": st.column_config.ProgressColumn("DæŒ‡æ•°", format="%.1f", min_value=0, max_value=100),
                                "ä¿¡é ¼åº¦": st.column_config.NumberColumn("ä¿¡é ¼åº¦", format="%d%%"),
                                "äºˆæƒ³å°": st.column_config.SelectboxColumn("äºˆæƒ³å°", options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"], required=False, width="small"),
                                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn("èª¿æ•´å¾ŒæœŸå¾…å€¤", format="%.2f"),
                                "å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰": st.column_config.NumberColumn("å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰", format="%.1f m/s"),
                                "é¨æ‰‹é©æ€§åº¦": st.column_config.ProgressColumn("é¨æ‰‹é©æ€§", format="%.1f", min_value=0, max_value=10),
                                "ã‚³ãƒ¼ã‚¹é©æ€§åº¦": st.column_config.ProgressColumn("ã‚³ãƒ¼ã‚¹é©æ€§", format="%.1f", min_value=0, max_value=10),
                                "è·é›¢é©æ€§åº¦": st.column_config.ProgressColumn("è·é›¢é©æ€§", format="%.1f", min_value=0, max_value=10),
                            },
                             key=f"win5_editor_{race['id']}_{i}"
                        )
                        
                        # === Data Missing Alerts (WIN5) ===
                        edited_df = processed_df # Use processed_df as source
                        
                        def to_circled(n):
                            try:
                                n_int = int(n)
                                if 1 <= n_int <= 20: return chr(9311 + n_int)
                                return str(n)
                            except: return str(n)

                        unknown_history = []
                        if 'å‰èµ°ç€é †' in edited_df.columns:
                            unknown_history = [f"{to_circled(row['é¦¬ ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[edited_df['å‰èµ°ç€é †'] == 0].iterrows()]
                            
                        unknown_jockey = []
                        hidden_gems = []
                        if 'é¨æ‰‹é©æ€§åº¦' in edited_df.columns:
                            # 5.0 is the fallback score for missing data
                            jockey_missing_mask = (edited_df['é¨æ‰‹é©æ€§åº¦'] == 5.0)
                            unknown_jockey = [f"{to_circled(row['é¦¬ ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[jockey_missing_mask].iterrows()]
                            
                            if 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦' in edited_df.columns and 'è·é›¢é©æ€§åº¦' in edited_df.columns:
                                 potential_mask = (edited_df['ã‚³ãƒ¼ã‚¹é©æ€§åº¦'] >= 7.0) | (edited_df['è·é›¢é©æ€§åº¦'] >= 7.0)
                                 hidden_gems = [f"{to_circled(row['é¦¬ ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[jockey_missing_mask & potential_mask].iterrows()]
                
                        if unknown_history or unknown_jockey:
                             st.warning("âš ï¸ ä¸€éƒ¨ã®é¦¬ã«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãŒã‚ã‚Šã¾ã™")
                             cols_alert = st.columns(2)
                             with cols_alert[0]:
                                 if unknown_history:
                                     st.info(f"**åˆå‡ºèµ°ãƒ»å±¥æ­´ãªã—**: {', '.join(unknown_history)}")
                             with cols_alert[1]:
                                 if unknown_jockey:
                                     st.info(f"**é¨æ‰‹ãƒ‡ãƒ¼ã‚¿ä¸è¶³**: {', '.join(unknown_jockey)}")
                                 if hidden_gems:
                                      st.success(f"âœ¨ **é¨æ‰‹ã¯æœªçŸ¥æ•°ã§ã™ãŒã€é¦¬ã®é©æ€§ã¯é«˜ã„**: {', '.join(hidden_gems)}")
                        
                        # WIN5 Formation Logic (Win Only)
                        st.caption("ğŸ‘‡ 1ç€å€™è£œã‚’é¸æŠ (WIN5)")
                        
                        if gap >= 15.0: 
                             st.info(f"ğŸ¦¾ **é‰„æ¿** (Gap {gap:.1f}): 1é ­æŠœãæ¨å¥¨")
                        elif gap < 10.0:
                             st.warning(f"ğŸŒªï¸ **æ··æˆ¦** (Gap {gap:.1f}): è¤‡æ•°é ­æ¨å¥¨")
                        else: 
                             st.success(f"âš–ï¸ **æ¨™æº–** (Gap {gap:.1f}): ä¸Šä½æ‹®æŠ—")
                        
                        # Defaults
                        if gap >= 15.0:
                            default_win = processed_df['é¦¬ ç•ª'].iloc[:1].tolist()
                        elif gap < 10.0:
                             default_win = processed_df['é¦¬ ç•ª'].iloc[:3].tolist()
                        else:
                             default_win = processed_df['é¦¬ ç•ª'].iloc[:2].tolist()

                        all_nums = processed_df['é¦¬ ç•ª'].tolist()
                        sel_win = st.multiselect(f"{i+1}æˆ¦ç›®: 1ç€å€™è£œ", all_nums, default=default_win, key=f"win5_sel_{i}")
                        
                        count = len(sel_win)
                        st.markdown(f"**ç‚¹æ•°:** {count}ç‚¹")
                        total_combinations *= count
                        
                        summary_txt = f"**{i+1}æˆ¦ç›®**: [{','.join(sel_win)}]"
                        prediction_summaries.append(summary_txt)
                        
                        st.markdown("---")

        # Final Calculation
        st.subheader("ğŸ“Š WIN5 è²·ã„ç›®é›†è¨ˆ")
        st.write(f"**ç·çµ„ã¿åˆã‚ã›æ•°**: {total_combinations} é€šã‚Š")
        est_cost = total_combinations * 100
        st.write(f"**æ¨å®šé‡‘é¡ (100å††/ç‚¹)**: {est_cost:,} å††")
        
        with st.expander("è©³ç´°ã‚’ç¢ºèª", expanded=True):
            for s in prediction_summaries:
                st.markdown(s)



# --- Admin Menu ---
st.markdown("### è¨­å®š")
mode = st.radio("é–‹å‚¬ãƒ¢ãƒ¼ãƒ‰ (Mode)", ["JRA (ä¸­å¤®ç«¶é¦¬)", "NAR (åœ°æ–¹ç«¶é¦¬)"], horizontal=True)
mode_val = "JRA" if "JRA" in mode else "NAR"

with st.expander("ğŸ› ï¸ ç®¡ç†ãƒ„ãƒ¼ãƒ« (ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°ãªã©)"):
    col_admin_1, col_admin_2 = st.columns([1, 1])
    with col_admin_1:
         if st.button("ğŸ“… ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’æ›´æ–° (ä»Šå¾Œ1é€±é–“)"):
            with st.spinner(f"{mode_val}ã®æœ€æ–°ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ä¸­..."):
                success, msg = auto_scraper.scrape_todays_schedule(mode=mode_val)
                if success:
                    st.success(msg)
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {msg}")
    
    with col_admin_2:
         if st.button("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿"):
             st.cache_resource.clear()
             st.success("ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ¬¡å›äºˆæ¸¬æ™‚ã«å†ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# --- Analysis Mode Selection ---
st.markdown("### åˆ†æãƒ¢ãƒ¼ãƒ‰")
    
    # ------------------------------------------------------------------
    # Analysis Mode Selector
    # ------------------------------------------------------------------
options = ["ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ", "ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹ã‚’æ¢ã™ (ä¸€æ‹¬åˆ†æ)"]
if mode_val == "NAR":
    options.append("ğŸ¯ SP: ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ (NAR)")
if mode_val == "JRA":
     options.append("ğŸ‘‘ WIN5 (JRA)")

options.append("ğŸ“Š éå»ã®ãƒ¬ãƒ¼ã‚¹åˆ†æ (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹)")

analysis_mode = st.radio("æ©Ÿèƒ½ã‚’é¸æŠ", options, horizontal=True)

st.markdown("---")

# --- Race Selection ---
st.subheader("ğŸ“ ãƒ¬ãƒ¼ã‚¹é¸æŠ")

schedule_data = load_schedule_data(mode=mode_val)
race_id = None

if schedule_data and "races" in schedule_data:
    races = schedule_data['races']
    
    # 1. Filter by Date
    dates = sorted(list(set([r.get('date', 'Unknown') for r in races])))
    
    if analysis_mode == "ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ":
        # Layout columns for selection
        col_date, col_venue, col_race = st.columns(3)
        
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        # Filter races by date
        todays_races = [r for r in races if r.get('date') == selected_date]
        
        if todays_races:
            # 2. Filter by Venue
            venues = sorted(list(set([r['venue'] for r in todays_races])))
            
            with col_venue:
                selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ", venues)
                
            # Filter races by venue
            venue_races = [r for r in todays_races if r['venue'] == selected_venue]
            
            # 3. Select Race
            # Sort by race number
            venue_races.sort(key=lambda x: int(x['number']) if str(x['number']).isdigit() else 0)
            
            race_options = {f"{r['number']}R: {r['name']}": r['id'] for r in venue_races}
            
            with col_race:
                selected_label = st.selectbox("3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list(race_options.keys()))
                if selected_label:
                    race_id = race_options[selected_label]
        else:
            st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    elif analysis_mode == "ğŸ¯ SP: ãƒˆãƒªãƒ—ãƒ«é¦¬å˜ (NAR)":
        col_date, col_venue_tu = st.columns([1, 2])
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        todays_races = [r for r in races if r.get('date') == selected_date]
        
        if todays_races:
             # SPAT4 Lotoå¯¾è±¡å ´ã®ã¿æŠ½å‡º
             valid_tu_venues = ['é–€åˆ¥', 'æµ¦å’Œ', 'èˆ¹æ©‹', 'å¤§äº•', 'å·å´']
             venues = sorted(list(set([r.get('venue', 'Unknown') for r in todays_races if r.get('venue') in valid_tu_venues])))
             
             if not venues:
                 with col_venue_tu:
                     st.warning("å¯¾è±¡é–‹å‚¬ãªã— (å—é–¢ãƒ»é–€åˆ¥ã®ã¿)")
             else:
                 with col_venue_tu:
                     selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ (å¯¾è±¡å ´)", venues)
                 
                 venue_races = [r for r in todays_races if r['venue'] == selected_venue]
                 if venue_races:
                     render_triple_umatan_section(venue_races, mode_val)
                 else:
                     st.warning("ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
             st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    elif analysis_mode == "ğŸ‘‘ WIN5 (JRA)":
        st.info("ğŸ’¡ **WIN5**: JRAã®æŒ‡å®š5ãƒ¬ãƒ¼ã‚¹ã‚’äºˆæƒ³ã—ã¾ã™ã€‚")
        col_date, col_venue_multi = st.columns([1, 2])
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        # JRA Venues
        jra_venues = ['æ±äº¬', 'ä¸­å±±', 'äº¬éƒ½', 'é˜ªç¥', 'æ–°æ½Ÿ', 'ç¦å³¶', 'ä¸­äº¬', 'å°å€‰', 'æœ­å¹Œ', 'å‡½é¤¨']
        
        todays_races = [r for r in races if r.get('date') == selected_date]
        
        # Filter for JRA main venues if possible, or just all races for that day
        # WIN5 usually involves 5 races, potentially across venues.
        jra_day_races = [r for r in todays_races if r['venue'] in jra_venues]
        
        if not jra_day_races:
             st.warning(f"{selected_date} ã®JRAé–‹å‚¬ãƒ¬ãƒ¼ã‚¹ï¼ˆä¸»è¦å ´ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
             # Just pass all JRA races for that day to the renderer
             # User can select any 5 from them.
             
             # Show venues available
             avail_venues = list(set([r['venue'] for r in jra_day_races]))
             st.write(f"é–‹å‚¬å ´: {', '.join(avail_venues)}")
             
             # Sort logic for default selection inside renderer is 'Last 5'.
             # Pass all races sorted by time/number?
             # Auto-scraper data might not have time sorted, but 'number' is there.
             
             render_win5_section(jra_day_races, mode_val)

    elif analysis_mode == "ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹ã‚’æ¢ã™ (ä¸€æ‹¬åˆ†æ)":
        st.info("ğŸ’¡ **æ©Ÿèƒ½èª¬æ˜**: æŒ‡å®šã—ãŸæ—¥ã®å…¨ãƒ¬ãƒ¼ã‚¹ã‚’AIãŒåˆ†æã—ã€ä¿¡é ¼åº¦ãŒé«˜ã„ã€Œå …ã„ãƒ¬ãƒ¼ã‚¹ã€ã®ã¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚")
        
        col_date, col_venue_multi = st.columns([1, 2])
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        todays_races = [r for r in races if r.get('date') == selected_date]
        if todays_races:
            venues = sorted(list(set([r.get('venue', 'Unknown') for r in todays_races])))
            
            with col_venue_multi:
                 selected_venues = st.multiselect("2. é–‹å‚¬åœ°ã‚’é¸æŠ (ç©ºæ¬„ã§å…¨ä¼šå ´)", venues, default=venues)
            
            target_races = [r for r in todays_races if not selected_venues or r.get('venue') in selected_venues]
            st.write(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°: {len(target_races)} ãƒ¬ãƒ¼ã‚¹")
            
            confidence_threshold = st.slider("ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (ã“ã‚Œä»¥ä¸Šã®ä¿¡é ¼åº¦ã®ãƒ¬ãƒ¼ã‚¹ã‚’è¡¨ç¤º)", 0, 100, 70)
            use_odds_bias_batch = st.checkbox("ç¾åœ¨ã‚ªãƒƒã‚ºã‚’åŠ å‘³ã™ã‚‹ (æ¨å¥¨)", value=True, help="äººæ°—é¦¬ã®ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã€ä¸äººæ°—é¦¬ã‚’ä¸‹ã’ã¾ã™")

            if st.button("ğŸš€ ä¸€æ‹¬åˆ†æã‚’é–‹å§‹ã™ã‚‹", type="primary"):
                 if not target_races:
                     st.warning("å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                 else:
                     with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                         # from app.public_app import load_model, load_model_metadata
                         # from app.public_app import load_model, load_model_metadata
                         # from app.public_app import load_model, load_model_metadata
                         model = load_model(mode_val)
                         model_meta = load_model_metadata(mode_val)
                         stats = load_stats(mode_val)

                     
                     if not model:
                         st.error("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                     else:
                         results_container = st.container()
                         progress_bar = st.progress(0)
                         status_text = st.empty()
                         
                         solid_races_data = []
                         
                         for i, race in enumerate(target_races):
                             r_name = f"{race['venue']}{race['number']}R: {race['name']}"
                             status_text.text(f"åˆ†æä¸­ ({i+1}/{len(target_races)}): {r_name}...")
                             
                             try:
                                 # 1. Scrape with cached history
                                 if i > 0: time.sleep(1) 
                                 history_df_cache = load_history_csv(mode_val)
                                 df_race = auto_scraper.scrape_shutuba_data(race['id'], mode=mode_val, history_df=history_df_cache)
                                 
                                 if df_race is not None and not df_race.empty:
                                     # 2. Predict

                                     processed_df = predict_race_logic(df_race, model, model_meta, stats=stats, mode=mode_val)
                                    
                                     # Odds Bias (Batch Mode)
                                     if use_odds_bias_batch and processed_df is not None and 'å˜å‹' in processed_df.columns:
                                         try:
                                             # Local helper or lambda
                                             calc_prob = lambda x: 0.8 / float(x) if (str(x).replace('.','',1).isdigit() and float(x) > 0) else 0
                                             
                                             processed_df['Implied_Prob'] = processed_df['å˜å‹'].apply(calc_prob)
                                             # Blend: AI 70%, Market 30%
                                             alpha = 0.7
                                             processed_df['AI_Prob_Blended'] = (processed_df['AI_Prob'] * alpha) + (processed_df['Implied_Prob'] * (1 - alpha))
                                             processed_df['AI_Score'] = (processed_df['AI_Prob_Blended'] * 100).astype(int)
                                             
                                             # Recalculate D_Index using New AI Score
                                             # D_Index = AI(30%) + Compat(60%) + Blood(10%)
                                             # We need to ensure Compat_Index and Bloodline_Index exist
                                             if 'Compat_Index' in processed_df.columns and 'Bloodline_Index' in processed_df.columns:
                                                 processed_df['D_Index'] = (processed_df['AI_Score'] * 0.3) + (processed_df['Compat_Index'] * 0.6) + (processed_df['Bloodline_Index'] * 0.1)
                                                 processed_df['D_Index'] = processed_df['D_Index'].clip(1, 99)
                                             
                                         except Exception as e:
                                             # If error (e.g. odds not numeric), skip bias
                                             print(f"Odds bias error in batch: {e}")
                                     
                                     if processed_df is not None:
                                         # 3. Find Top Horses (Top 3) based on D-Index
                                         # User requested D-Index compliance
                                         processed_df = processed_df.sort_values('D_Index', ascending=False)
                                         
                                         # Save
                                         # Initialize basic metrics properly
                                         if processed_df.empty: continue
                                         
                                         top_horse = processed_df.iloc[0]
                                         conf = top_horse.get('D_Index', 0)
                                         
                                         # Calculate Gap (1st - 2nd)
                                         gap = 0.0
                                         gap_2_3 = 0.0
                                         gap_3_4 = 0.0
                                         
                                         if len(processed_df) >= 2:
                                             gap = conf - processed_df.iloc[1].get('D_Index', 0)
                                         
                                         if len(processed_df) >= 3:
                                             gap_2_3 = processed_df.iloc[1].get('D_Index', 0) - processed_df.iloc[2].get('D_Index', 0)
                                             
                                         if len(processed_df) >= 4:
                                             gap_3_4 = processed_df.iloc[2].get('D_Index', 0) - processed_df.iloc[3].get('D_Index', 0)
                                         
                                         # Calculate Top 5 Dispersion (Standard Deviation)
                                         top5_df = processed_df.head(5)
                                         top5_std = top5_df['D_Index'].std() if len(top5_df) > 1 else 0.0

                                         # Construct Multi-Horse String (Picks)
                                         picks_str = []
                                         marks = ["â—", "â—¯", "â–²", "â–³", "â˜†", "æ³¨"]
                                         
                                         for rank in range(min(6, len(processed_df))):
                                             h = processed_df.iloc[rank]
                                             m = marks[rank]
                                             h_num = h.get('é¦¬ ç•ª')
                                             if pd.isna(h_num): h_num = h.get('é¦¬ç•ª', '')
                                             
                                             c_num = str(h_num) 
                                             # Try circles if simple int
                                             try:
                                                 val = int(float(h_num))
                                                 if 1 <= val <= 20: c_num = chr(9311 + val)
                                                 else: c_num = f"({val})"
                                             except: pass
                                             
                                             d_val = f"{h.get('D_Index',0):.1f}"
                                             picks_str.append(f"{m} {c_num} {h['é¦¬å']} (D:{d_val})")
                                         
                                         picks_display = " / ".join(picks_str)

                                         # Odds Metrics
                                         odds_metrics = {}
                                         if 'å˜å‹' in processed_df.columns:
                                            try:
                                                valid_odds = pd.to_numeric(processed_df['å˜å‹'], errors='coerce').dropna().sort_values().tolist()
                                                if len(valid_odds) >= 2: 
                                                    odds_metrics['Gap 1-2'] = valid_odds[1] - valid_odds[0]
                                                else: odds_metrics['Gap 1-2'] = 0.0
                                                
                                                if len(valid_odds) >= 3:
                                                    odds_metrics['Gap 2-3'] = valid_odds[2] - valid_odds[1]
                                                    odds_metrics['Std 1-2-3'] = np.std(valid_odds[:3], ddof=1)
                                                else:
                                                    odds_metrics['Gap 2-3'] = 0.0
                                                    odds_metrics['Std 1-2-3'] = 0.0
                                                    
                                                if len(valid_odds) >= 6:
                                                     odds_metrics['Std 1-6'] = np.std(valid_odds[:6], ddof=1)
                                                else:
                                                     odds_metrics['Std 1-6'] = 0.0
                                            except: pass

                                         if conf >= confidence_threshold:
                                             # Consolidate Data
                                             r_dict = {
                                                 "race_name": race['name'],
                                                 "venue": race['venue'],
                                                 "R": f"{race['number']}R",
                                                 "picks": picks_display,
                                                 "top_horse": top_horse['é¦¬å'],
                                                 "confidence": conf,
                                                 "gap": gap,
                                                 "gap_2_3": gap_2_3,
                                                 "gap_3_4": gap_3_4,
                                                 "top_score": top_horse.get('AI_Score', 0),
                                                 "odds_1": top_horse.get('å˜å‹', 0),
                                                 "_gap_val": gap
                                             }
                                             r_dict.update(odds_metrics)
                                             solid_races_data.append(r_dict)
                             
                             except Exception as e:
                                 print(f"Error analyzing {race['id']}: {e}")
                                 
                             progress_bar.progress((i + 1) / len(target_races))
                         
                         status_text.success(f"å®Œäº†ï¼ {len(target_races)}ãƒ¬ãƒ¼ã‚¹ä¸­ã€æ¡ä»¶ã‚’æº€ãŸã™ãƒ¬ãƒ¼ã‚¹ã¯ {len(solid_races_data)} ä»¶ã§ã—ãŸã€‚")
                         
                         if solid_races_data:
                             st.markdown("### ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹å€™è£œ (2ä½ã¨ã®å·®ãŒå¤§ãã„é †)")
                             res_df = pd.DataFrame(solid_races_data)
                             res_df = res_df.sort_values('_gap_val', ascending=False)
                             
                             # Rename and Reorder for Display/Export
                             rename_map = {
                                 "venue": "é–‹å‚¬åœ°", 
                                 "R": "R", 
                                 "race_name": "ãƒ¬ãƒ¼ã‚¹å", 
                                 "picks": "äºˆæƒ³ (DæŒ‡æ•°)", 
                                 "top_horse": "æœ¬å‘½é¦¬", 
                                 "confidence": "TOP DæŒ‡æ•°", 
                                 "gap": "2ä½å·® (DæŒ‡æ•°)", 
                                 "odds_1": "å˜å‹", 
                                 "Gap 1-2": "ã‚ªãƒƒã‚ºå·® 1-2", 
                                 "Gap 2-3": "ã‚ªãƒƒã‚ºå·® 2-3",
                                 "Std 1-2-3": "ã‚ªãƒƒã‚ºåå·® (1-3)", 
                                 "Std 1-6": "ã‚ªãƒƒã‚ºåå·® (1-6)", 
                                 "top_score": "AIã‚¹ã‚³ã‚¢"
                             }
                             
                             res_df = res_df.rename(columns=rename_map)
                             
                             # Define Order
                             display_cols = [
                                 "é–‹å‚¬åœ°", "R", "ãƒ¬ãƒ¼ã‚¹å", "äºˆæƒ³ (DæŒ‡æ•°)", "æœ¬å‘½é¦¬", 
                                 "TOP DæŒ‡æ•°", "2ä½å·® (DæŒ‡æ•°)", "å˜å‹", 
                                 "ã‚ªãƒƒã‚ºå·® 1-2", "ã‚ªãƒƒã‚ºå·® 2-3", "ã‚ªãƒƒã‚ºåå·® (1-3)", "ã‚ªãƒƒã‚ºåå·® (1-6)", "AIã‚¹ã‚³ã‚¢"
                             ]
                             # Filter to available columns
                             final_cols = [c for c in display_cols if c in res_df.columns]
                             res_df = res_df[final_cols]
                             
                             if not res_df.empty:
                                  st.dataframe(
                                      res_df,
                                      column_config={
                                          "TOP DæŒ‡æ•°": st.column_config.ProgressColumn("TOP DæŒ‡æ•°", format="%.1f", min_value=0, max_value=100),
                                          "2ä½å·® (DæŒ‡æ•°)": st.column_config.NumberColumn("2ä½å·® (DæŒ‡æ•°)", format="%.1f"),
                                          "ã‚ªãƒƒã‚ºå·® 1-2": st.column_config.NumberColumn("ã‚ªãƒƒã‚ºå·® 1-2", format="%.1f"),
                                          "ã‚ªãƒƒã‚ºå·® 2-3": st.column_config.NumberColumn("ã‚ªãƒƒã‚ºå·® 2-3", format="%.1f"),
                                          "ã‚ªãƒƒã‚ºåå·® (1-3)": st.column_config.NumberColumn("ã‚ªãƒƒã‚ºåå·® (1-3)", format="%.2f"),
                                          "ã‚ªãƒƒã‚ºåå·® (1-6)": st.column_config.NumberColumn("ã‚ªãƒƒã‚ºåå·® (1-6)", format="%.2f"),
                                          "AIã‚¹ã‚³ã‚¢": st.column_config.NumberColumn("AIã‚¹ã‚³ã‚¢", format="%d"),
                                          "å˜å‹": st.column_config.NumberColumn("å˜å‹", format="%.1f")
                                      },
                                      hide_index=True
                                  )

                                  # --- Betting Recommendations ---
                                  st.markdown("---")
                                  st.markdown("### ğŸ¯ ãŠã™ã™ã‚ã®è³­ã‘æ–¹ (Beta)")
                                  
                                  c_gap = '2ä½å·® (DæŒ‡æ•°)'
                                  c_std3 = 'ã‚ªãƒƒã‚ºåå·® (1-3)'
                                  c_std6 = 'ã‚ªãƒƒã‚ºåå·® (1-6)'
                                  
                                  # Filter logic
                                  df_rec = res_df.copy()
                                  
                                  mask_priority = (df_rec[c_gap] > 5.0) & (df_rec[c_std3] < 1.5)
                                  df_priority = df_rec[mask_priority]

                                  mask_dividend = (df_rec[c_std6] < 4.0)
                                  df_dividend = df_rec[mask_dividend]

                                  mask_iron = (df_rec[c_gap] > 10.0)
                                  df_iron = df_rec[mask_iron]
                                  
                                  cols_show_rec = ['é–‹å‚¬åœ°', 'R', 'ãƒ¬ãƒ¼ã‚¹å', 'æœ¬å‘½é¦¬', 'äºˆæƒ³ (DæŒ‡æ•°)']

                                  st.markdown("#### ğŸ”¥ ã€æœ€å„ªå…ˆã€‘çš„ä¸­ç‡ãƒ»åˆ©ç›Šã®æŸ±")
                                  st.caption("æ¨å¥¨: ãƒ¯ã‚¤ãƒ‰4é ­BOX ï¼‹ ä¸‰é€£è¤‡4é ­BOX")
                                  st.info("DæŒ‡æ•°ä¸Šä½4é ­ã®æ±ºç€ã‚’å®Œå…¨ã«æ‰ãˆã¾ã™ã€‚æœ€ã‚‚å®‰å®šæ„ŸãŒã‚ã‚Šã€å¤šé‡çš„ä¸­ï¼ˆãƒˆãƒªãƒ—ãƒ«çš„ä¸­ï¼‰ãŒç™ºç”Ÿã—ã‚„ã™ã„æœ€å¼·ã®å¸ƒé™£ã§ã™ã€‚")
                                  if not df_priority.empty:
                                      st.success(f"ğŸ‘‰ **ãƒ¯ã‚¤ãƒ‰4é ­BOX ï¼‹ ä¸‰é€£è¤‡4é ­BOX**")
                                      st.dataframe(df_priority.head(4)[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  st.markdown("#### ğŸ’° ã€é«˜é…å½“ã€‘ç©´é¦¬ã‚’å«ã‚ãŸçˆ†ç™ºåŠ›")
                                  st.caption("æ¨å¥¨: ä¸‰é€£è¤‡6é ­BOX (20ç‚¹)")
                                  st.info("ãƒ¯ã‚¤ãƒ‰ã‚ˆã‚Šã‚‚ä¸‰é€£è¤‡ã«çµã‚‹ã“ã¨ã§ã€ä¸€æ’ƒ10ä¸‡é¦¬åˆ¸ã‚¯ãƒ©ã‚¹ã‚’é€ƒã•ãšåˆ©ç›ŠåŠ¹ç‡ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚ï¼ˆæ¡ä»¶: DæŒ‡æ•°5ä½ãƒ»6ä½ã«äººæ°—è–„ãŒå«ã¾ã‚Œã‚‹å ´åˆæ¨å¥¨ï¼‰")
                                  if not df_dividend.empty:
                                      st.success(f"ğŸ‘‰ **3é€£è¤‡ 6é ­BOX (20ç‚¹)**")
                                      st.dataframe(df_dividend.head(6)[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  st.markdown("#### ğŸ° ã€é‰„æ¿è»¸ã€‘è»¸é¦¬ã®çµ¶å¯¾çš„ä¿¡é ¼")
                                  st.caption("æ¨å¥¨: ãƒ¯ã‚¤ãƒ‰æµã— ï¼‹ ä¸‰é€£è¤‡è»¸1é ­æµã—")
                                  st.info("è»¸é¦¬ï¼ˆâ—ï¼‰ã‹ã‚‰ç›¸æ‰‹5é ­ã¸ã€‚è»¸é¦¬ãŒ3ç€ä»¥å†…ã«å…¥ã‚‹ç¢ºç‡ãŒæ¥µã‚ã¦é«˜ã„ãŸã‚ã€ç›¸æ‰‹ã«äººæ°—è–„ãŒé£›ã³è¾¼ã‚“ã éš›ã®ã€Œãƒ’ãƒ¢è’ã‚Œã€ã‚’ä¸‰é€£è¤‡ã§é«˜é…å½“ã«å¤‰ãˆã¾ã™ã€‚")
                                  if not df_iron.empty:
                                      st.success(f"ğŸ‘‰ **ãƒ¯ã‚¤ãƒ‰æµã— ï¼‹ ä¸‰é€£è¤‡è»¸1é ­æµã— (ç›¸æ‰‹5é ­)**")
                                      st.dataframe(df_iron.head(1)[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  # New Pattern 8: High Value Win (Gap > 10.0 & Odds >= 3.0)
                                  # New Pattern 8: High Value Win (Gap > 10.0 & Odds >= 3.0)
                                  if 'å˜å‹' in df_rec.columns:
                                      # Fix: Ensure odds is numeric for comparison
                                      df_rec['å˜å‹'] = pd.to_numeric(df_rec['å˜å‹'], errors='coerce')
                                      
                                      mask_value_win = (df_rec[c_gap] > 10.0) & (df_rec['å˜å‹'] >= 3.0)
                                      df_value_win = df_rec[mask_value_win]

                                      st.markdown("#### ğŸŒŸ ã€ç©´å‹è² ã€‘ä½æŠ•è³‡ãƒ»é«˜é…å½“")
                                      st.caption("æ¨å¥¨: å˜å‹ ï¼‹ è¤‡å‹ (æ¯”ç‡1:2)")
                                      st.info("æŒ‡æ•°1ä½ã®ç©´é¦¬ãŒ2ãƒ»3ç€ã«é£Ÿã„è¾¼ã‚€ã‚±ãƒ¼ã‚¹ãŒå¤šã„ãŸã‚ã€è¤‡å‹ã‚’åšã‚ã«è²·ã†ã“ã¨ã§ã€Œçš„ä¸­ã—ãŸã®ã«å¤–ã‚ŒãŸã€ã¨ã„ã†äº‹æ…‹ã‚’é˜²ãã€ç¢ºå®Ÿã«ãƒ—ãƒ©ã‚¹ã‚’æ‹¾ã„ã¾ã™ã€‚")
                                      if not df_value_win.empty:
                                          st.success(f"ğŸ‘‰ **å˜å‹ ï¼‹ è¤‡å‹ (æ¯”ç‡1:2)**")
                                          st.dataframe(df_value_win[cols_show_rec], hide_index=True)
                                      else:
                                          st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  # New Pattern 1: High Confidence
                                  c_conf = 'TOP DæŒ‡æ•°'
                                  mask_confident = (df_rec[c_conf] >= 80.0)
                                  df_confident = df_rec[mask_confident]

                                  st.markdown("#### ğŸ’ ã€ç¢ºå‹ç´šã€‘åœ§å€’çš„æŒ‡æ•°å·®")
                                  st.caption("æ¨å¥¨: å˜å‹ä¸€ç‚¹ ï¼‹ ä¸‰é€£è¤‡è»¸1é ­æµã—")
                                  st.info("DæŒ‡æ•°ãŒ2ä½ä»¥ä¸‹ã‚’å¤§ããå¼•ãé›¢ã—ã¦ã„ã‚‹å ´åˆï¼ˆå·®ãŒ10ä»¥ä¸Šæ¨å¥¨ï¼‰ã€å˜å‹ã§ç¢ºå®Ÿã«è³‡é‡‘ã‚’å›åã—ã¤ã¤ã€ä¸‰é€£è¤‡ã§ãƒœãƒ¼ãƒŠã‚¹ã‚’ç‹™ã†æˆ¦ç•¥ã§ã™ã€‚")
                                  if not df_confident.empty:
                                      st.success(f"ğŸ‘‰ **å˜å‹ä¸€ç‚¹ ï¼‹ ä¸‰é€£è¤‡è»¸1é ­æµã—**")
                                      st.dataframe(df_confident[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  # New Pattern 2: Chaos
                                  mask_chaos = (df_rec[c_gap] < 3.0) & (df_rec[c_conf] < 70.0)
                                  df_chaos = df_rec[mask_chaos]

                                  st.markdown("#### ğŸŒ€ ã€æ³¢ä¹±å«ã¿ãƒ»BOXæ¨å¥¨ã€‘")
                                  st.caption("æ¡ä»¶: 2ä½å·® < 3.0 ã‹ã¤ TOP DæŒ‡æ•° < 70.0 ï¼ˆæ··æˆ¦ã§è»¸ãŒæ±ºã¾ã‚‰ãªã„ï¼‰")
                                  if not df_chaos.empty:
                                      st.warning(f"ğŸ‘‰ **é¦¬é€£ãƒ»3é€£è¤‡ã®BOXï¼ˆä¸Šä½4ã€œ5é ­ï¼‰ã§é«˜é…å½“ç‹™ã„**")
                                      st.dataframe(df_chaos[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  # New Pattern 6: Duel (2 Strong Horses)
                                  c_gap_2_3 = 'gap_2_3'
                                  # Add columns if not exist
                                  if c_gap_2_3 not in df_rec.columns: df_rec[c_gap_2_3] = 0.0
                                  
                                  mask_duel = (df_rec[c_gap_2_3] > 10.0)
                                  df_duel = df_rec[mask_duel]

                                  st.markdown("#### âš”ï¸ ã€ä¸€é¨æ‰“ã¡ãƒ ãƒ¼ãƒ‰ã€‘")
                                  st.caption("æ¡ä»¶: 2ä½ã¨3ä½ã®DæŒ‡æ•°å·® > 10.0 ï¼ˆ2å¼·ãŒçªå‡ºã—ã¦ã„ã‚‹ï¼‰")
                                  if not df_duel.empty:
                                      st.info(f"ğŸ‘‰ **é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ 1-2 ä¸€ç‚¹å‹è² **")
                                      st.dataframe(df_duel[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

                                  # New Pattern 7: Top 3 (3 Strong Horses)
                                  c_gap_3_4 = 'gap_3_4'
                                  if c_gap_3_4 not in df_rec.columns: df_rec[c_gap_3_4] = 0.0
                                  
                                  mask_top3 = (df_rec[c_gap_3_4] > 10.0)
                                  df_top3 = df_rec[mask_top3]

                                  st.markdown("#### ğŸ”º ã€3å¼·å¯¾æ±ºã€‘")
                                  st.caption("æ¡ä»¶: 3ä½ã¨4ä½ã®DæŒ‡æ•°å·® > 10.0 ï¼ˆä¸Šä½3é ­ãŒçªå‡ºï¼‰")
                                  if not df_top3.empty:
                                      st.info(f"ğŸ‘‰ **3é€£è¤‡ 3é ­BOX (1ç‚¹è²·ã„)**")
                                      st.dataframe(df_top3[cols_show_rec], hide_index=True)
                                  else:
                                      st.write("è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")
                                  
                                  st.markdown("---")
                             else:
                                  st.warning("æ¡ä»¶ã‚’æº€ãŸã™å …ã„ãƒ¬ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                         else:
                             st.warning("æ¡ä»¶ã‚’æº€ãŸã™å …ã„ãƒ¬ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    elif analysis_mode == "ğŸ“Š éå»ã®ãƒ¬ãƒ¼ã‚¹åˆ†æ (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹)":
        st.markdown("### ğŸ“Š éå»ã®ãƒ¬ãƒ¼ã‚¹åˆ†æ: å …ã„ãƒ¬ãƒ¼ã‚¹ã®æŠ½å‡º")
        st.info("éå»ã®å…¨ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ã‚ªãƒƒã‚ºã®ã°ã‚‰ã¤ãã‚„äººæ°—å·®ã‚’è¨ˆç®—ã—ã€ç‰¹ã«ã€Œå …ã„ã€ï¼ˆäºˆæ¸¬ã—ã‚„ã™ã„ï¼‰ãƒ¬ãƒ¼ã‚¹ã‚’æŠ½å‡ºã—ã¾ã™ã€‚")

        # Helper: Load Data Cached
        @st.cache_data(ttl=3600)
        def load_analysis_data(path):
            return pd.read_parquet(path)

        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if mode_val == "NAR":
             db_path = os.path.join(project_root, "data", "raw", "database_nar.parquet")
        else:
             db_path = os.path.join(project_root, "data", "raw", "database.parquet")

        if not os.path.exists(db_path):
             st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        else:
             # Filters UI
             try:
                 # Load just to get metadata for filters (Cached)
                 df_raw = load_analysis_data(db_path)
                 
                 # Prepare Filter Options
                 if 'æ—¥ä»˜' in df_raw.columns:
                     df_raw['æ—¥ä»˜'] = pd.to_datetime(df_raw['æ—¥ä»˜'], errors='coerce')
                     valid_dates = df_raw['æ—¥ä»˜'].dropna()
                     if not valid_dates.empty:
                         min_date = valid_dates.min().date()
                         max_date = valid_dates.max().date()
                     else:
                         min_date = datetime.now().date()
                         max_date = datetime.now().date()
                 else:
                     min_date = datetime.now().date()
                     max_date = datetime.now().date()

                 all_venues = sorted(df_raw['é–‹å‚¬åœ°'].unique().astype(str)) if 'é–‹å‚¬åœ°' in df_raw.columns else []

                 # Layout
                 col_f1, col_f2 = st.columns(2)
                 with col_f1:
                     date_range = st.date_input(
                         "æ—¥ä»˜ç¯„å›² (Date Range)",
                         value=(min_date, max_date),
                         min_value=min_date,
                         max_value=max_date
                     )
                 with col_f2:
                     sel_venues = st.multiselect("é–‹å‚¬åœ° (Venue)", all_venues, default=[])

                 if st.button("ğŸ” æ¡ä»¶ã§åˆ†æé–‹å§‹"):
                     with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»åˆ†æä¸­..."):
                         df_target = df_raw.copy()
                         
                         # Apply Filters
                         if isinstance(date_range, tuple) and len(date_range) == 2:
                             start, end = date_range
                             msk = (df_target['æ—¥ä»˜'].dt.date >= start) & (df_target['æ—¥ä»˜'].dt.date <= end)
                             df_target = df_target[msk]
                         
                         if sel_venues:
                             df_target = df_target[df_target['é–‹å‚¬åœ°'].isin(sel_venues)]
                             
                         if df_target.empty:
                             st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                         else:
                             # Import Analysis Module
                             import ml.analysis_hard_race as analysis_hard_race
                             importlib.reload(analysis_hard_race)
                             
                             # Calculate Metrics
                             metrics_df = analysis_hard_race.calculate_hard_race_metrics(df_target)
                             
                             if metrics_df.empty:
                                 st.warning("åˆ†æå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆã‚ªãƒƒã‚ºæƒ…å ±ãªã©ï¼‰ã€‚")
                             else:
                                 # Merge Metadata
                                 meta_cols = ['race_id', 'æ—¥ä»˜', 'é–‹å‚¬åœ°', 'ãƒ¬ãƒ¼ã‚¹å']
                                 avail_meta = [c for c in meta_cols if c in df_target.columns]
                                 meta_df = df_target[avail_meta].drop_duplicates(subset=['race_id'])
                                 
                                 result_df = pd.merge(metrics_df, meta_df, on='race_id', how='left')
                                 # Format Date back to string for display if needed, but dataframe handles it.
                                 result_df = result_df.sort_values('odds_gap_1_2', ascending=False)
                                 
                                 st.session_state['hist_analysis_result'] = result_df
                                 st.success(f"åˆ†æå®Œäº†: {len(result_df)} ãƒ¬ãƒ¼ã‚¹")

             except Exception as e:
                 st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        if 'hist_analysis_result' in st.session_state:
             res_df = st.session_state['hist_analysis_result']
             st.markdown("#### åˆ†æçµæœ")
             st.caption("1ç•ªäººæ°—ã¨2ç•ªäººæ°—ã®ã‚ªãƒƒã‚ºå·®ãŒå¤§ãã„é †ã«è¡¨ç¤º")
             st.dataframe(
                 res_df,
                 column_config={
                     "odds_gap_1_2": st.column_config.NumberColumn("Gap 1-2", format="%.1f"),
                     "odds_gap_2_3": st.column_config.NumberColumn("Gap 2-3", format="%.1f"),
                     "odds_std_1_2_3": st.column_config.NumberColumn("Std 1-2-3", format="%.2f"),
                     "odds_std_1_6": st.column_config.NumberColumn("Std 1-6", format="%.2f"),
                 },
                 use_container_width=True
             )
             csv = res_df.to_csv(index=False).encode('utf-8')
             st.download_button("ğŸ“¥ CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, "hard_race.csv", "text/csv", key='dl-hist')
        
else:
    st.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    # No fallback text input for now to keep it clean, or keep it inside Individual mode if needed.
    # But existing code had it. Let's omitting it for Batch mode safety.
    if analysis_mode == "ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ":
         race_id = st.text_input("ãƒ¬ãƒ¼ã‚¹IDç›´æ¥å…¥åŠ› (12æ¡)", value="202305021211")


# Main Analysis
if race_id:
    st.header(f"ãƒ¬ãƒ¼ã‚¹åˆ†æ: {race_id}")

    # Load Model and Metadata
    model = load_model(mode=mode_val)
    model_meta = load_model_metadata(mode=mode_val)
    stats = load_stats(mode=mode_val)
    last_updated, days_ago = get_data_freshness(mode=mode_val)

    # Display Model Information and Data Freshness
    with st.expander("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ª", expanded=False):
        if model_meta:
            col_info1, col_info2, col_info3 = st.columns(3)

            with col_info1:
                st.metric(
                    "ãƒ¢ãƒ‡ãƒ«AUCï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰",
                    f"{model_meta.get('performance', {}).get('auc', 0):.3f}",
                    help="0.5=ãƒ©ãƒ³ãƒ€ãƒ ã€1.0=å®Œå…¨äºˆæ¸¬ã€‚0.75ä»¥ä¸ŠãŒç›®å®‰"
                )
                st.caption(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é‡: {model_meta.get('data_stats', {}).get('total_records', 0):,}ä»¶")

            with col_info2:
                if last_updated:
                    freshness_color = "ğŸŸ¢" if days_ago <= 3 else "ğŸŸ¡" if days_ago <= 7 else "ğŸ”´"
                    st.metric(
                        "ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°",
                        f"{days_ago}æ—¥å‰",
                        delta=f"{freshness_color} {last_updated}"
                    )
                else:
                    st.metric("ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°", "ä¸æ˜")

            with col_info3:
                data_size = model_meta.get('data_stats', {}).get('total_records', 0)
                if data_size < 1000:
                    quality = "âš ï¸ å°è¦æ¨¡"
                    quality_help = "ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ãŸã‚ã€äºˆæ¸¬ç²¾åº¦ã¯é™å®šçš„ã§ã™"
                elif data_size < 3000:
                    quality = "ğŸŸ¡ ä¸­è¦æ¨¡"
                    quality_help = "ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™"
                else:
                    quality = "ğŸŸ¢ ååˆ†"
                    quality_help = "ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã§å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™"

                st.metric("ãƒ‡ãƒ¼ã‚¿å“è³ª", quality, help=quality_help)

            # Warnings
            if model_meta.get('warnings'):
                st.warning("**âš ï¸ æ³¨æ„äº‹é …:**\n" + "\n".join([f"- {w}" for w in model_meta['warnings']]))
        else:
            st.info("ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    st.markdown("### ğŸ”® AIäºˆæ¸¬è¨­å®š")
    use_odds_bias = st.checkbox("ç¾åœ¨ã‚ªãƒƒã‚ºï¼ˆäººæ°—ï¼‰ã‚’åŠ å‘³ã—ã¦AIè©•ä¾¡ã‚’è£œæ­£ã™ã‚‹", value=True, help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ã€AIã®ç´”ç²‹ãªèƒ½åŠ›è©•ä¾¡ã«ã€Œç¾åœ¨ã®ã‚ªãƒƒã‚ºï¼ˆå¸‚å ´ã®æ”¯æŒï¼‰ã€ã‚’30%ç¨‹åº¦ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã¾ã™ã€‚äººæ°—é¦¬ã®ã‚¹ã‚³ã‚¢ãŒä¸ŠãŒã‚Šã€ä¸äººæ°—é¦¬ã®ã‚¹ã‚³ã‚¢ãŒä¸‹ãŒã‚Šã¾ã™ã€‚")

    button_analyze = st.button("ğŸš€ ã“ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã™ã‚‹ (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»AIäºˆæ¸¬)", type="primary", use_container_width=True)

    if button_analyze:
        if not race_id:
             st.error("ãƒ¬ãƒ¼ã‚¹IDãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        elif not model:
             st.error(f"ãƒ¢ãƒ‡ãƒ« ({mode_val}) ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ç®¡ç†ç”»é¢ã§å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            # === å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ– ===
            st.markdown("---")
            st.subheader("ğŸ”„ AIäºˆæ¸¬å‡¦ç†ãƒ•ãƒ­ãƒ¼")

            # ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()

            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å–å¾—
            status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 1/4:** å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            progress_bar.progress(25)
            history_df_cache = load_history_csv(mode_val)
            df = auto_scraper.scrape_shutuba_data(race_id, mode=mode_val, history_df=history_df_cache)

            if df is not None and not df.empty:
                status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 1/4: å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—2-4: AIäºˆæ¸¬ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆå…±é€šé–¢æ•°åŒ–ï¼‰
                status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 2-4:** ç‰¹å¾´é‡è¨ˆç®—ãƒ»AIäºˆæ¸¬ãƒ»ä¿¡é ¼åº¦ç®—å‡ºã‚’å®Ÿè¡Œä¸­...")
                progress_bar.progress(60)
                
                if model:

                    processed_df = predict_race_logic(df, model, model_meta, stats=stats, mode=mode_val)
                    
                    if processed_df is not None:
                         df = processed_df
                         status_text.success("âœ… AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                         progress_bar.progress(100)
                    else:
                         status_text.error("âŒ äºˆæ¸¬å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                         df['AI_Prob'] = 0.0
                         df['AI_Score'] = 0.0
                else:
                     status_text.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                     df['AI_Prob'] = 0.0
                     df['AI_Score'] = 0.0

                # 4. Display
                # Store in session state to persist edits
                st.session_state[f'data_{race_id}'] = df

                # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                st.markdown("---")
                st.success("ğŸ‰ **AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼** ä¸‹è¨˜ã®çµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # Show Data if available
    if f'data_{race_id}' in st.session_state:
        df_display = st.session_state[f'data_{race_id}'].copy()

        # === ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã®è¡¨ç¤º ===
        st.markdown("---")
        st.subheader("ğŸ‡ ãƒ¬ãƒ¼ã‚¹æ¦‚è¦")

        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±
        col_r1, col_r2, col_r3, col_r4 = st.columns(4)
        with col_r1:
            # Try multiple possible column names for venue
            venue = "ä¸æ˜"
            for col in ['ä¼šå ´', 'venue', 'ç«¶é¦¬å ´', 'å ´æ‰€']:
                if col in df_display.columns and len(df_display) > 0:
                    venue = df_display[col].iloc[0]
                    if pd.notna(venue) and venue != "":
                        break

            # If still unknown, try to extract from race_id (first 4 digits indicate place code)
            if venue == "ä¸æ˜" and race_id and len(race_id) >= 6:
                try:
                    place_code = int(race_id[4:6])
                    place_map = {
                        1: "æœ­å¹Œ", 2: "å‡½é¤¨", 3: "ç¦å³¶", 4: "æ–°æ½Ÿ", 5: "æ±äº¬",
                        6: "ä¸­å±±", 7: "ä¸­äº¬", 8: "äº¬éƒ½", 9: "é˜ªç¥", 10: "å°å€‰",
                        30: "é–€åˆ¥", 35: "ç››å²¡", 36: "æ°´æ²¢", 42: "æµ¦å’Œ", 43: "èˆ¹æ©‹",
                        44: "å¤§äº•", 45: "å·å´", 46: "é‡‘æ²¢", 47: "ç¬ æ¾", 48: "åå¤å±‹",
                        50: "åœ’ç”°", 51: "å§«è·¯", 54: "é«˜çŸ¥", 55: "ä½è³€", 3: "å¸¯åºƒ"
                    }
                    venue = place_map.get(place_code, "ä¸æ˜")
                except:
                    pass

            st.metric("é–‹å‚¬å ´", venue)
        with col_r2:
            race_name = df_display['ãƒ¬ãƒ¼ã‚¹å'].iloc[0] if 'ãƒ¬ãƒ¼ã‚¹å' in df_display.columns else "ä¸æ˜"
            st.metric("ãƒ¬ãƒ¼ã‚¹å", race_name if len(str(race_name)) < 20 else str(race_name)[:17] + "...")
        with col_r3:
            course_type = df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0] if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns else "ä¸æ˜"
            distance = df_display['è·é›¢'].iloc[0] if 'è·é›¢' in df_display.columns else "ä¸æ˜"
            st.metric("ã‚³ãƒ¼ã‚¹", f"{course_type} {distance}m")
        with col_r4:
            num_horses = len(df_display)
            st.metric("å‡ºèµ°é ­æ•°", f"{num_horses}é ­")

        # --- ã‚ªãƒƒã‚ºåŠ å‘³ãƒ­ã‚¸ãƒƒã‚¯ (Blended Score) ---
        if use_odds_bias and 'å˜å‹' in df_display.columns:
            # å˜å‹ã‚ªãƒƒã‚ºã‹ã‚‰å¸‚å ´ã®äºˆæ¸¬ç¢ºç‡ï¼ˆImplied Probabilityï¼‰ã‚’ç®—å‡º
            # æ§é™¤ç‡ã‚’è€ƒæ…®ã—ã¦ 0.8 / ã‚ªãƒƒã‚º ã¨ã™ã‚‹ï¼ˆæ¨™æº–çš„ï¼‰
            def calc_implied_prob(x):
                try:
                    odds = float(x)
                    return 0.8 / odds if odds > 0 else 0
                except:
                    return 0

            df_display['Implied_Prob'] = df_display['å˜å‹'].apply(calc_implied_prob)
            
            # ãƒ–ãƒ¬ãƒ³ãƒ‰ (AI: 70%, Market: 30%)
            alpha = 0.7
            df_display['AI_Prob_Blended'] = (df_display['AI_Prob'] * alpha) + (df_display['Implied_Prob'] * (1 - alpha))
            
            # Update AI Score & Confidence
            # ã‚¹ã‚³ã‚¢ã¯å˜ç´”ã«ç¢ºç«‹*100
            df_display['AI_Score_Raw'] = df_display['AI_Score'] # Keep raw for reference
            df_display['AI_Score'] = (df_display['AI_Prob_Blended'] * 100).astype(int)
            
            # Update Confidence (Simple scaling for now, or keep original? 
            # Updating confidence makes sense as market agreement increases certainty)
            # But let's keep Confidence tied to "Model's Confidence" to avoid confusion?
            # Actually, if we change AI Score, we should probably align Confidence or leave it.
            # User wants "Prediction" to include odds. 
            # Let's update Confidence slightly if Market agrees.
            
            # But for simplicity and safety, let's just update the Score which drives the Ranking.
            # Confidence is "How much we trust this evaluation". If Market agrees, trust goes up?
            # Let's just update AI_Score for ranking.
            
            st.warning("âš ï¸ **ç¾åœ¨ã‚ªãƒƒã‚ºåŠ å‘³ãƒ¢ãƒ¼ãƒ‰**: AIè©•ä¾¡ã‚¹ã‚³ã‚¢ãŒå¸‚å ´äººæ°—ï¼ˆã‚ªãƒƒã‚ºï¼‰ã®å½±éŸ¿ã‚’å—ã‘ã¦è£œæ­£ã•ã‚Œã¦ã„ã¾ã™ã€‚")

        # AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼
        if 'AI_Score' in df_display.columns and 'Confidence' in df_display.columns:
            avg_confidence = df_display['Confidence'].mean()
            max_ai_score = df_display['AI_Score'].max()
            st.info(f"ğŸ“Š **AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼**: æœ€é«˜AIå‹ç‡ {max_ai_score}% | å¹³å‡ä¿¡é ¼åº¦ {avg_confidence:.0f}%")

        # ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã®è©³ç´°è¡¨ç¤º
        venue = df_display['ä¼šå ´'].iloc[0] if 'ä¼šå ´' in df_display.columns else None
        if venue:
            try:
                from ml.venue_characteristics import get_venue_characteristics
                venue_char = get_venue_characteristics(venue)

                if venue_char:
                    st.markdown("#### ğŸŸï¸ ã‚³ãƒ¼ã‚¹ç‰¹æ€§")

                    col_c1, col_c2, col_c3, col_c4 = st.columns(4)

                    # ç›´ç·šè·é›¢
                    with col_c1:
                        # Determine Turf or Dirt
                        is_dirt = False
                        if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
                            course_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
                            if 'ãƒ€' in course_type:
                                is_dirt = True
                        
                        straight = venue_char.get('dirt_straight', 0) if is_dirt else venue_char.get('turf_straight', 0)
                        
                        if straight:
                            straight_label = "é•·ã„" if straight > 500 else "çŸ­ã„" if straight < 300 else "æ¨™æº–"
                            surface_label = "ãƒ€ãƒ¼ãƒˆ" if is_dirt else "èŠ"
                            st.metric(f"ç›´ç·šè·é›¢ ({surface_label})", f"{straight}m", delta=straight_label)
                        else:
                            st.metric("ç›´ç·šè·é›¢", "ä¸æ˜")

                    # å‹¾é…ï¼ˆå‚¾æ–œï¼‰
                    with col_c2:
                        slope = venue_char.get('slope', 'normal')
                        slope_map = {
                            'steep': 'æ€¥å‚ã‚ã‚Š',
                            'moderate': 'ç·©ã‚„ã‹ãªå‚',
                            'flat': 'å¹³å¦',
                            'normal': 'æ¨™æº–'
                        }
                        slope_label = slope_map.get(slope, slope)
                        slope_icon = "â›°ï¸" if slope == 'steep' else "ğŸ”ï¸" if slope == 'moderate' else "â”"
                        st.metric("å‹¾é…ï¼ˆå‚¾æ–œï¼‰", slope_label, delta=slope_icon)

                    # ã‚³ãƒ¼ã‚¹å¹…
                    with col_c3:
                        track_width = venue_char.get('track_width', 'standard')
                        width_map = {
                            'narrow': 'å°å›ã‚Š',
                            'standard': 'æ¨™æº–',
                            'wide': 'åºƒã„ã‚³ãƒ¼ã‚¹'
                        }
                        width_label = width_map.get(track_width, track_width)
                        st.metric("ã‚³ãƒ¼ã‚¹å¹…", width_label)

                    # å¤–æ æœ‰åˆ©åº¦
                    with col_c4:
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        if outer_advantage > 1.05:
                            outer_label = "å¤–æ æœ‰åˆ©"
                            outer_delta = "â†‘"
                        elif outer_advantage < 0.95:
                            outer_label = "å†…æ æœ‰åˆ©"
                            outer_delta = "â†“"
                        else:
                            outer_label = "å…¬å¹³"
                            outer_delta = "="
                        st.metric("æ ç•ªå‚¾å‘", outer_label, delta=outer_delta)

                    # ç‰¹æ€§ã®å½±éŸ¿èª¬æ˜
                    with st.expander("ğŸ’¡ ã“ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ãŒEVè¨ˆç®—ã«ä¸ãˆã‚‹å½±éŸ¿", expanded=False):
                        st.markdown(f"""
                        #### ğŸŸï¸ {venue}ã®ç‰¹æ€§

                        **1. ç›´ç·šè·é›¢: {straight}m ({straight_label})**
                        - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: äººæ°—é¦¬ã‚„ã‚„ä¸åˆ© (-5%)ã€ç©´é¦¬ã‚„ã‚„æœ‰åˆ© (+5%)
                        - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: äººæ°—é¦¬æœ‰åˆ© (+5%)ã€ç©´é¦¬ä¸åˆ© (-5%)
                        - ç†ç”±: é•·ã„ç›´ç·šã¯å·®ã—é¦¬ã«æœ‰åˆ©ã€çŸ­ã„ç›´ç·šã¯é€ƒã’ãƒ»å…ˆè¡Œé¦¬ã«æœ‰åˆ©

                        **2. å‹¾é…ï¼ˆå‚¾æ–œï¼‰: {slope_label}**
                        - æ€¥å‚ã‚ã‚Š: äººæ°—é¦¬ï¼ˆãƒ‘ãƒ¯ãƒ¼ãŒã‚ã‚‹é¦¬ï¼‰ãŒæœ‰åˆ© (+2%)
                        - ç†ç”±: å‚ã‚’ç™»ã‚‹éš›ã«é¦¬åŠ›ãŒå¿…è¦ã§ã€å®Ÿç¸¾é¦¬ãŒå„ªä½
                        - è©²å½“ç«¶é¦¬å ´: ä¸­å±±ã€é˜ªç¥ãªã©

                        **3. ã‚³ãƒ¼ã‚¹å¹…: {width_label}**
                        - å°å›ã‚Š: äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ© (+3%)
                        - ç†ç”±: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãã€å™¨ç”¨ã•ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹

                        **4. æ ç•ªå‚¾å‘: {outer_label}**
                        - å¤–æ æœ‰åˆ©ãªå ´åˆ: 6-8æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´ (Ã—{outer_advantage:.2f})
                        - å†…æ æœ‰åˆ©ãªå ´åˆ: 1-3æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´

                        âš ï¸ ã“ã‚Œã‚‰ã®èª¿æ•´ã¯æœŸå¾…å€¤(EV)è¨ˆç®—æ™‚ã«è‡ªå‹•çš„ã«é©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
                        """)
            except Exception as e:
                pass  # venue_characteristics ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        # Prepare Editor DF
        # Columns: Horse, Prob, Odds, Mark
        if 'Odds' not in df_display.columns:
             # Try to get scraped odds if available
             if 'å˜å‹' in df_display.columns:
                 df_display['Odds'] = pd.to_numeric(df_display['å˜å‹'], errors='coerce').fillna(0.0)
             else:
                 df_display['Odds'] = 0.0
        
        # course_compatibilityãŒpredict_race_logicã§æ—¢ã«ç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ç”Ÿæˆ
        if 'course_compatibility' not in df_display.columns:
            # Select appropriate course compatibility
            # If 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' contains 'èŠ', use turf, else dirt
            # Default to turf if unknown
            is_turf_race = True
            if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
                 # Check first row (all same race)
                 c_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
                 if 'ãƒ€' in c_type:
                     is_turf_race = False

            if is_turf_race:
                 df_display['course_compatibility'] = df_display.get('turf_compatibility', 5.0)
            else:
                 df_display['course_compatibility'] = df_display.get('dirt_compatibility', 5.0)

        # === Migration: Ensure D_Index exists (for cached data from old session) ===
        if 'D_Index' not in df_display.columns:
            if 'AI_Score' in df_display.columns:
                # Recalculate using Pure Compatibility (Rank 1-18 -> Score 100-0)
                def _calc_migration_compat(row):
                     scores = []
                     if pd.notna(row.get('jockey_compatibility')): scores.append(float(row['jockey_compatibility']))
                     if pd.notna(row.get('distance_compatibility')): scores.append(float(row['distance_compatibility']))
                     if pd.notna(row.get('course_compatibility')): scores.append(float(row['course_compatibility']))
                     if not scores: return 50.0 
                     avg_rank = sum(scores) / len(scores)
                     score = (18.0 - avg_rank) / 17.0 * 100
                     return max(0, min(100, score))
                
                compat_idx = df_display.apply(_calc_migration_compat, axis=1)
                df_display['D_Index'] = (df_display['AI_Score'] * 0.1) + (compat_idx * 0.9)
                df_display['D_Index'] = df_display['D_Index'].clip(1, 99)
            else:
                 df_display['D_Index'] = 0.0

        # === é©æ€§ã‚¹ã‚³ã‚¢ã‚’é©æ€§åº¦ã«å¤‰æ›ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„æ–¹ãŒè‰¯ã„ï¼‰ ===
        # å…ƒã®å€¤ã¯ã€Œå¹³å‡ç€é †ã€ï¼ˆå°ã•ã„æ–¹ãŒè‰¯ã„ï¼‰
        # é©æ€§åº¦ = 10 - å¹³å‡ç€é †ï¼ˆ0-10ç‚¹ã€é«˜ã„æ–¹ãŒè‰¯ã„ï¼‰

        for compat_col in ['jockey_compatibility', 'distance_compatibility', 'course_compatibility']:
            if compat_col in df_display.columns:
                # 10 - (å€¤ / 2) ã§ã‚¹ã‚³ã‚¢åŒ– (å¹³å‡ç€é †10.0 -> 5.0ç‚¹)
                # 1ä½ -> 9.5ç‚¹, 18ä½ -> 1.0ç‚¹
                df_display[compat_col] = df_display[compat_col].apply(
                    lambda x: max(0, min(10, 10 - (x / 2))) if pd.notna(x) else 5.0
                )

        rename_map = {
            'AI_Score': 'AIã‚¹ã‚³ã‚¢(%)',
            'D_Index': 'DæŒ‡æ•°',
            'Confidence': 'ä¿¡é ¼åº¦',
            'Odds': 'ç¾åœ¨ã‚ªãƒƒã‚º',
            'æ€§é½¢': 'å¹´é½¢',
            'é¦¬ ç•ª': 'é¦¬ç•ª',
            'jockey_compatibility': 'é¨æ‰‹é©æ€§åº¦',
            'distance_compatibility': 'è·é›¢é©æ€§åº¦',
            'course_compatibility': 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦',
            'turf_compatibility': 'èŠé©æ€§åº¦',
            'dirt_compatibility': 'ãƒ€ãƒ¼ãƒˆé©æ€§åº¦',
            'weighted_avg_speed': 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰',
            'weighted_avg_rank': 'å¹³å‡ç€é †',
            'jockey_win_rate': 'é¨æ‰‹å‹ç‡',
            'stable_win_rate': 'å©èˆå‹ç‡',
            'good_condition_avg': 'è‰¯é¦¬å ´é©æ€§',
            'heavy_condition_avg': 'é‡é¦¬å ´é©æ€§',
            'trend_rank': 'ç€é †ãƒˆãƒ¬ãƒ³ãƒ‰',
            'growth_factor': 'æˆé•·ä¿‚æ•°',
            'past_1_rank': 'å‰èµ°ç€é †',
            'past_2_rank': 'å‰ã€…èµ°ç€é †',
            'past_3_rank': '3èµ°å‰ç€é †'
        }

        # Ensure all display columns exist
        defaults = {
            'jockey_compatibility': 10.0,
            'distance_compatibility': 10.0,
            'course_compatibility': 10.0,
            'turf_compatibility': 10.0,
            'dirt_compatibility': 10.0,
            'weighted_avg_speed': 16.0,
            'weighted_avg_rank': 7.0,
            'jockey_win_rate': 0.1,
            'stable_win_rate': 0.1,
            'good_condition_avg': 10.0,
            'heavy_condition_avg': 10.0,
            'trend_rank': 0.0,
            'growth_factor': 1.0,
            'Confidence': 50,
            'past_1_rank': 0,
            'past_2_rank': 0,
            'past_3_rank': 0,
            'Bloodline_Index': 50.0
        }
        for c, v in defaults.items():
            if c not in df_display.columns:
                df_display[c] = v

        # Add Mark column BEFORE selecting display columns
        if 'äºˆæƒ³å°' not in df_display.columns:
            df_display['äºˆæƒ³å°'] = ""
            
        # Create Pedigree Column
        if 'father' in df_display.columns and 'mother' in df_display.columns:
             df_display['è¡€çµ±'] = df_display.apply(
                 lambda r: f"{r['father']} / {r['mother']}" + (f" ({r['bms']})" if pd.notna(r.get('bms')) else ""), 
                 axis=1
             )
        else:
             df_display['è¡€çµ±'] = "-"

        # Display columns with äºˆæƒ³å° next to é¦¬åï¼ˆåŸºæœ¬æƒ…å ±+ä¸»è¦é©æ€§åº¦ï¼‰
        display_cols = [
            'æ ', 'é¦¬ ç•ª', 'é¦¬å', 'äºˆæƒ³å°', 'æ€§é½¢',
            'D_Index', 'AI_Score', 'Confidence', 'Odds',
            'jockey_compatibility', 'course_compatibility', 'distance_compatibility',
            'Bloodline_Index',
            'weighted_avg_rank', 'weighted_avg_speed', 'past_1_rank', 'past_2_rank', 'è¡€çµ±'
        ]


        edited_df = df_display[display_cols].copy()
        edited_df.rename(columns=rename_map, inplace=True)
        
        # === Data Missing Alerts ===
        unknown_history = []
        
        def to_circled(n):
            try:
                n_int = int(n)
                if 1 <= n_int <= 20: 
                    return chr(9311 + n_int)
                return str(n)
            except:
                return str(n)

        if 'å‰èµ°ç€é †' in edited_df.columns:
            # Format: "â‘  Name"
            unknown_history = [f"{to_circled(row['é¦¬ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[edited_df['å‰èµ°ç€é †'] == 0].iterrows()]
            
        unknown_jockey = []
        hidden_gems = []
        if 'é¨æ‰‹é©æ€§åº¦' in edited_df.columns:
            # 5.0 is the fallback score for missing data
            jockey_missing_mask = (edited_df['é¨æ‰‹é©æ€§åº¦'] == 5.0)
            unknown_jockey = [f"{to_circled(row['é¦¬ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[jockey_missing_mask].iterrows()]
            
            # Check if Horse has high potential despite unknown jockey
            # High potential = Course OR Distance > 7.0
            if 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦' in edited_df.columns and 'è·é›¢é©æ€§åº¦' in edited_df.columns:
                 potential_mask = (edited_df['ã‚³ãƒ¼ã‚¹é©æ€§åº¦'] >= 7.0) | (edited_df['è·é›¢é©æ€§åº¦'] >= 7.0)
                 hidden_gems = [f"{to_circled(row['é¦¬ç•ª'])} {row['é¦¬å']}" for _, row in edited_df[jockey_missing_mask & potential_mask].iterrows()]

        if unknown_history or unknown_jockey:
             st.warning("âš ï¸ ä¸€éƒ¨ã®é¦¬ã«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãŒã‚ã‚Šã¾ã™")
             cols_alert = st.columns(2)
             with cols_alert[0]:
                 if unknown_history:
                     st.info(f"**åˆå‡ºèµ°ãƒ»å±¥æ­´ãªã—**: {', '.join(unknown_history)}")
             with cols_alert[1]:
                 if unknown_jockey:
                     st.info(f"**é¨æ‰‹ãƒ‡ãƒ¼ã‚¿ä¸è¶³**: {', '.join(unknown_jockey)}")
                 if hidden_gems:
                     st.success(f"âœ¨ **é¨æ‰‹ã¯æœªçŸ¥æ•°ã§ã™ãŒã€é¦¬ã®é©æ€§ã¯é«˜ã„**: {', '.join(hidden_gems)}")
        
        st.subheader("ğŸ“ äºˆæƒ³ãƒ»ã‚ªãƒƒã‚ºå…¥åŠ›")
        
        col_input_1, col_input_2 = st.columns([3, 1])
        with col_input_1:
             st.info("ã€Œäºˆæƒ³å°ã€ã‚„ã€Œç¾åœ¨ã‚ªãƒƒã‚ºã€ã‚’ç·¨é›†ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœŸå¾…å€¤(EV)ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
        with col_input_2:
             fetch_trigger = False
             if st.button("ğŸ”„ æœ€æ–°ã‚ªãƒƒã‚º (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ )"):
                 fetch_trigger = True

             if fetch_trigger:
                  with st.spinner("ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
                      try:
                          current_odds = auto_scraper.scrape_odds_for_race(race_id, mode=mode_val)
                          # Update session state df
                          if current_odds:
                              odds_map = {x['number']: x['odds'] for x in current_odds}
                              
                              target_df = st.session_state[f'data_{race_id}']
                              
                              # Update 'å˜å‹' and 'Odds'
                              def update_odds(row):
                                  try:
                                      num = int(row['é¦¬ ç•ª'])
                                      new_odds = odds_map.get(num)
                                      d = {
                                          'Odds': new_odds if new_odds is not None else row.get('Odds', 0.0)
                                      }
                                      return d
                                  except:
                                      return {'Odds': row.get('Odds', 0.0)}
                                  
                              # Apply updates
                              updated_data = target_df.apply(update_odds, axis=1, result_type='expand')
                              target_df['Odds'] = updated_data['Odds']
                              target_df['å˜å‹'] = updated_data['Odds']
                              
                              st.session_state[f'data_{race_id}'] = target_df
                              st.success("ã‚ªãƒƒã‚ºï¼ˆå˜å‹ï¼‰ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                              st.rerun()
                          else:
                              st.warning("ã‚ªãƒƒã‚ºã®å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                      except Exception as e:
                          st.error(f"ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        # Ensure Pedigree exists (Safety)
        if 'è¡€çµ±' not in edited_df.columns:
            edited_df['è¡€çµ±'] = "-"
        
        edited_df = st.data_editor(
            edited_df,
            column_config={
                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                    "AIå‹ç‡(%)",
                    help="1ç€ã«ãªã‚‹ AIäºˆæ¸¬ç¢ºç‡",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "DæŒ‡æ•°": st.column_config.ProgressColumn(
                    "DæŒ‡æ•°",
                    help="é©æ€§ã¨ä¿¡é ¼åº¦ã§å‚¾æ–œã‚’ã‹ã‘ãŸæœ€çµ‚ã‚¹ã‚³ã‚¢",
                    format="%.1f",
                    min_value=0,
                    max_value=100,
                ),
                "ä¿¡é ¼åº¦": st.column_config.ProgressColumn(
                    "äºˆæ¸¬ä¿¡é ¼åº¦",
                    help="ã“ã®äºˆæ¸¬ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç¾åœ¨ã‚ªãƒƒã‚º": st.column_config.NumberColumn(
                    "å˜å‹ã‚ªãƒƒã‚º",
                    help="å˜å‹ã‚ªãƒƒã‚ºï¼ˆå‚è€ƒï¼‰",
                    step=0.1,
                    format="%.1f"
                ),
                "è¡€çµ±": st.column_config.TextColumn(
                    "è¡€çµ±",
                    help="çˆ¶ / æ¯ (æ¯çˆ¶)",
                    width="medium"
                ),
                "Bloodline_Index": st.column_config.ProgressColumn(
                    "è¡€çµ±ã‚¹ã‚³ã‚¢",
                    help="è¡€çµ±çµ±è¨ˆã«åŸºã¥ãã‚¹ã‚³ã‚¢ (0-100)",
                    format="%.1f",
                    min_value=0,
                    max_value=100
                ),
                "å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰": st.column_config.NumberColumn(
                    "å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰",
                    help="éå»èµ°ã®å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰ (m/s)",
                    format="%.1f m/s"
                ),
                "å˜å‹æœŸå¾…å€¤": st.column_config.NumberColumn(
                    "å˜å‹æœŸå¾…å€¤",
                    help="ç´”ç²‹ãªå˜å‹æœŸå¾…å€¤ = (AIå‹ç‡ Ã— å˜å‹ã‚ªãƒƒã‚º) - 1.0",
                    format="%.2f"
                ),
                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(
                    "èª¿æ•´å¾ŒæœŸå¾…å€¤",
                    help="å°ãƒ»é©æ€§ã‚’åŠ å‘³ã—ãŸæœ€çµ‚çš„ãªå˜å‹æœŸå¾…å€¤",
                    format="%.2f"
                ),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(
                    "æ¨å¥¨åº¦(Kelly)",
                    help="ã‚±ãƒªãƒ¼åŸºæº–ã«ã‚ˆã‚‹æ¨å¥¨è³­ã‘ç‡",
                    format="%.1f%%",
                    min_value=0,
                    max_value=30, 
                ),
                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                    "äºˆæƒ³å°",
                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                    required=False,
                    help="äºˆæƒ³å°ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€èª¿æ•´å¾ŒæœŸå¾…å€¤ã«åæ˜ ã•ã‚Œã¾ã™"
                ),
                "é¨æ‰‹é©æ€§åº¦": st.column_config.ProgressColumn(
                    "é¨æ‰‹é©æ€§åº¦",
                    help="ã“ã®é¨æ‰‹ã¨ã®ç›¸æ€§",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                ),
                "ã‚³ãƒ¼ã‚¹é©æ€§åº¦": st.column_config.ProgressColumn(
                    "ã‚³ãƒ¼ã‚¹é©æ€§åº¦",
                    help="èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ ç›¸æ€§",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                ),
                "è·é›¢é©æ€§åº¦": st.column_config.ProgressColumn(
                    "è·é›¢é©æ€§åº¦",
                    help="ã“ã®è·é›¢ã§ã®ç›¸æ€§",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                )
            },
            hide_index=True,
            num_rows="fixed"  
        )
        
        # Calculate EV with JRA/NAR distinction
        # Determine race type from user's mode selection (as primary source)
        race_type = mode_val  # Use user's selected mode (JRA or NAR) as primary source of truth
        venue = ''  # Initialize venue

        # Get venue information if available
        if 'ä¼šå ´' in df_display.columns and len(df_display) > 0:
            venue = df_display['ä¼šå ´'].iloc[0]

            # If venue is available, use it to verify/override race_type for accuracy
            if venue:
                try:
                    import sys
                    import os
                    sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(__file__)), 'ml'))
                    from race_classifier import classify_race_type
                    venue_based_type = classify_race_type(venue)
                    # Use venue-based classification (more accurate than mode selection)
                    race_type = venue_based_type
                except:
                    # Fallback: manual classification
                    jra_venues = ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']
                    race_type = 'JRA' if venue in jra_venues else 'NAR'

        # EV calculation with race type AND venue specific parameters
        # Import venue characteristics
        venue_char = None
        try:
            from ml.venue_characteristics import get_venue_characteristics, get_distance_category
            if venue:
                venue_char = get_venue_characteristics(venue)
        except Exception as e:
            # Silently fail if venue characteristics not available
            pass

        # === Betting Recommendations for Individual Analysis ===
        st.markdown("---")
        st.markdown("### ğŸ¯ ãŠã™ã™ã‚ã®è²·ã„æ–¹ (Beta)")
        
        # Calculate Metrics manually from edited_df
        # We need: Gap (D-Index), Gap 1-2 (Odds), Std 1-3 (Odds), Std 1-6 (Odds), Top D-Index
        
        try:
            # 1. Sort by D-Index for Gap (D-Index) & Top D-Index
            # Note: edited_df might not be sorted by D-Index if user sorted differently in UI, but we need calculation based on values
            df_calc = edited_df.copy()
            
            # Ensure numeric with correct column names from Japanese UI
            df_calc['D_Index'] = pd.to_numeric(df_calc['DæŒ‡æ•°'], errors='coerce').fillna(0)
            df_calc['Odds'] = pd.to_numeric(df_calc['ç¾åœ¨ã‚ªãƒƒã‚º'], errors='coerce').fillna(0)
            
            # D-Index Metrics
            df_d_sorted = df_calc.sort_values('D_Index', ascending=False).reset_index(drop=True)
            top_d_index = df_d_sorted.iloc[0]['D_Index'] if len(df_d_sorted) > 0 else 0
            gap_d_index = (df_d_sorted.iloc[0]['D_Index'] - df_d_sorted.iloc[1]['D_Index']) if len(df_d_sorted) >= 2 else 0
            gap_d_2_3 = (df_d_sorted.iloc[1]['D_Index'] - df_d_sorted.iloc[2]['D_Index']) if len(df_d_sorted) >= 3 else 0
            gap_d_3_4 = (df_d_sorted.iloc[2]['D_Index'] - df_d_sorted.iloc[3]['D_Index']) if len(df_d_sorted) >= 4 else 0
            
            # Odds Metrics
            # Filter valid odds > 0
            valid_odds = df_calc[df_calc['Odds'] > 0]['Odds'].sort_values().tolist()
            
            gap_odds_1_2 = (valid_odds[1] - valid_odds[0]) if len(valid_odds) >= 2 else 0
            std_odds_1_3 = np.std(valid_odds[:3], ddof=1) if len(valid_odds) >= 3 else 0
            std_odds_1_6 = np.std(valid_odds[:6], ddof=1) if len(valid_odds) >= 6 else 0
            
            # Display Metrics for transparency (Optional, but helpful)
            # st.caption(f"Metrics: Top D={top_d_index:.1f}, Gap D={gap_d_index:.1f}, Gap Odds={gap_odds_1_2:.1f}, Std(1-3)={std_odds_1_3:.2f}, Std(1-6)={std_odds_1_6:.2f}")

            # Define columns to show in recommendation tables
            cols_show = [c for c in ['æ ', 'é¦¬ç•ª', 'é¦¬å', 'äºˆæƒ³å°', 'DæŒ‡æ•°', 'ç¾åœ¨ã‚ªãƒƒã‚º', 'ä¿¡é ¼åº¦', 'èª¿æ•´å¾ŒæœŸå¾…å€¤'] if c in df_d_sorted.columns]

            # Recommender Logic
            rec_found = False
            
            # 1. Sure Win
            if top_d_index >= 80.0:
                 st.success("ğŸ’ **ã€ç¢ºå‹ç´šã€‘åœ§å€’çš„æŒ‡æ•°å·®**")
                 st.write("DæŒ‡æ•°ãŒ2ä½ä»¥ä¸‹ã‚’å¤§ããå¼•ãé›¢ã—ã¦ã„ã‚‹å ´åˆã€å˜å‹ã§ç¢ºå®Ÿã«è³‡é‡‘ã‚’å›åã—ã¤ã¤ã€ä¸‰é€£è¤‡ã§ãƒœãƒ¼ãƒŠã‚¹ã‚’ç‹™ã†æˆ¦ç•¥ã§ã™ã€‚")
                 st.write(f"æ¨å¥¨: **å˜å‹ä¸€ç‚¹ ï¼‹ ä¸‰é€£è¤‡è»¸1é ­æµã—** (æœ¬å‘½: {df_d_sorted.iloc[0]['é¦¬å']})")
                 st.dataframe(df_d_sorted.head(1)[cols_show], hide_index=True)
                 rec_found = True
                 
            # 2. Top Priority
            # Logic Update: Also prioritize New Horse/Maiden races for BOX
            is_new_maiden = False
            if 'ãƒ¬ãƒ¼ã‚¹å' in df_display.columns:
                 r_name = str(df_display['ãƒ¬ãƒ¼ã‚¹å'].iloc[0])
                 if 'æ–°é¦¬' in r_name or 'æœªå‹åˆ©' in r_name:
                     is_new_maiden = True
            
            if (gap_d_index > 5.0 and std_odds_1_3 < 1.5) or (is_new_maiden):
                 title_suffix = " (æ–°é¦¬ãƒ»æœªå‹åˆ©ã¯BOXæ¨å¥¨)" if is_new_maiden else ""
                 st.success(f"ğŸ”¥ **ã€æœ€å„ªå…ˆã€‘çš„ä¸­ç‡ãƒ»åˆ©ç›Šã®æŸ±{title_suffix}**")
                 st.write("DæŒ‡æ•°ä¸Šä½4é ­ã®æ±ºç€ã‚’å®Œå…¨ã«æ‰ãˆã¾ã™ã€‚2æ—¥é–“ã§æœ€ã‚‚å®‰å®šæ„ŸãŒã‚ã‚Šã€å¤šé‡çš„ä¸­ï¼ˆãƒˆãƒªãƒ—ãƒ«çš„ä¸­ï¼‰ãŒç™ºç”Ÿã—ã‚„ã™ã„æœ€å¼·ã®å¸ƒé™£ã§ã™ã€‚")
                 st.write("æ¨å¥¨: **ãƒ¯ã‚¤ãƒ‰4é ­BOX ï¼‹ ä¸‰é€£è¤‡4é ­BOX**")
                 st.dataframe(df_d_sorted.head(4)[cols_show], hide_index=True)
                 rec_found = True

            # 3. High Dividend
            if std_odds_1_6 < 4.0:
                 st.info("ğŸ’° **ã€é«˜é…å½“ã€‘ç©´é¦¬ã‚’å«ã‚ãŸçˆ†ç™ºåŠ›**")
                 st.write("ãƒ¯ã‚¤ãƒ‰ã‚ˆã‚Šã‚‚ä¸‰é€£è¤‡ã«çµã‚‹ã“ã¨ã§ã€ä¸€æ’ƒ10ä¸‡é¦¬åˆ¸ã‚¯ãƒ©ã‚¹ã‚’é€ƒã•ãšåˆ©ç›ŠåŠ¹ç‡ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚")
                 st.write("æ¨å¥¨: **ä¸‰é€£è¤‡ 6é ­BOX (20ç‚¹)**")
                 st.dataframe(df_d_sorted.head(6)[cols_show], hide_index=True)
                 rec_found = True
                 
            # 4. Ironclad
            if gap_d_index > 10.0:
                 st.error("ğŸ° **ã€é‰„æ¿è»¸ã€‘è»¸é¦¬ã®çµ¶å¯¾çš„ä¿¡é ¼**")
                 st.write("è»¸é¦¬ï¼ˆâ—ï¼‰ã‹ã‚‰ç›¸æ‰‹5é ­ã¸ã€‚è»¸é¦¬ãŒ3ç€ä»¥å†…ã«å…¥ã‚‹ç¢ºç‡ãŒæ¥µã‚ã¦é«˜ã„ãŸã‚ã€ç›¸æ‰‹ã«äººæ°—è–„ãŒé£›ã³è¾¼ã‚“ã éš›ã®ã€Œãƒ’ãƒ¢è’ã‚Œã€ã‚’ä¸‰é€£è¤‡ã§é«˜é…å½“ã«å¤‰ãˆã¾ã™ã€‚")
                 st.write(f"æ¨å¥¨: **ãƒ¯ã‚¤ãƒ‰æµã— ï¼‹ ä¸‰é€£è¤‡è»¸1é ­æµã—** (è»¸: {df_d_sorted.iloc[0]['é¦¬å']})")
                 st.dataframe(df_d_sorted.head(1)[cols_show], hide_index=True)
                 rec_found = True

            # 4-2. High Value Win -> Hole Shot
            # Check odds of top horse
            top_odds = df_d_sorted.iloc[0].get('Odds', 0.0)
            if gap_d_index > 10.0 and top_odds >= 3.0:
                 st.success("ğŸŒŸ **ã€ç©´å‹è² ã€‘ä½æŠ•è³‡ãƒ»é«˜é…å½“**")
                 st.write("æŒ‡æ•°1ä½ã®ç©´é¦¬ãŒ2ãƒ»3ç€ã«é£Ÿã„è¾¼ã‚€ã‚±ãƒ¼ã‚¹ãŒå¤šã„ãŸã‚ã€è¤‡å‹ã‚’åšã‚ã«è²·ã†ã“ã¨ã§ã€Œçš„ä¸­ã—ãŸã®ã«å¤–ã‚ŒãŸã€ã¨ã„ã†äº‹æ…‹ã‚’é˜²ãã€ç¢ºå®Ÿã«ãƒ—ãƒ©ã‚¹ã‚’æ‹¾ã„ã¾ã™ã€‚")
                 st.write(f"æ¨å¥¨: **å˜å‹ ï¼‹ è¤‡å‹ (æ¯”ç‡1:2)** (æœ¬å‘½: {df_d_sorted.iloc[0]['é¦¬å']})")
                 st.dataframe(df_d_sorted.head(1)[cols_show], hide_index=True)
                 rec_found = True

            # 6. Duel (2 Strong)
            if gap_d_2_3 > 10.0:
                 st.info("âš”ï¸ **ã€ä¸€é¨æ‰“ã¡ãƒ ãƒ¼ãƒ‰ã€‘** (2ä½ã¨3ä½ã®DæŒ‡æ•°å·® > 10.0)")
                 st.write(f"æ¨å¥¨: **é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ 1-2 ä¸€ç‚¹å‹è² ** ({df_d_sorted.iloc[0]['é¦¬å']} - {df_d_sorted.iloc[1]['é¦¬å']})")
                 st.dataframe(df_d_sorted.head(2)[cols_show], hide_index=True)
                 rec_found = True

            # 7. Top 3 (3 Strong)
            if gap_d_3_4 > 10.0:
                 st.info("ğŸ”º **ã€3å¼·å¯¾æ±ºã€‘** (3ä½ã¨4ä½ã®DæŒ‡æ•°å·® > 10.0)")
                 st.write(f"æ¨å¥¨: **3é€£è¤‡ 3é ­BOX (1ç‚¹è²·ã„)** ({df_d_sorted.iloc[0]['é¦¬å']} - {df_d_sorted.iloc[1]['é¦¬å']} - {df_d_sorted.iloc[2]['é¦¬å']})")
                 st.dataframe(df_d_sorted.head(3)[cols_show], hide_index=True)
                 rec_found = True

            # 5. Chaos (Last check)
            if gap_d_index < 3.0 and top_d_index < 70.0 and not rec_found:
                 st.warning("ğŸŒ€ **ã€æ³¢ä¹±å«ã¿ãƒ»BOXæ¨å¥¨ã€‘** (2ä½å·® < 3.0 ã‹ã¤ TOP DæŒ‡æ•° < 70.0)")
                 st.write("æ¨å¥¨: **é¦¬é€£ãƒ»3é€£è¤‡ã®BOXï¼ˆä¸Šä½4ã€œ5é ­ï¼‰** ã§é«˜é…å½“ç‹™ã„")
                 st.dataframe(df_d_sorted.head(5)[cols_show], hide_index=True)
                 rec_found = True

            if not rec_found:
                 st.write("ğŸ’¡ ç‰¹ã«ãŠã™ã™ã‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¯è©²å½“ã—ã¾ã›ã‚“ã§ã—ãŸã€‚åŸºæœ¬ã®æœŸå¾…å€¤è²·ã„ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")

        except Exception as e:
            st.error(f"æ¨å¥¨åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")

        st.markdown("---")

        # === UI: ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–ã®é¸æŠ ===
        st.markdown("#### ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–")
        ranking_criteria = st.radio(
            "è©•ä¾¡æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:", 
            ["çš„ä¸­ç‡é‡è¦– (AIã‚¹ã‚³ã‚¢)", "å›åç‡é‡è¦– (æœŸå¾…å€¤)"], 
            horizontal=True,
            help="ã€Œçš„ä¸­ç‡ã€ã¯ã‚ªãƒƒã‚ºã‚’ç„¡è¦–ã—ã¦ç´”ç²‹ã«å‹ã¤ç¢ºç‡ãŒé«˜ã„é¦¬ã‚’æ¢ã—ã¾ã™ã€‚ã€Œå›åç‡ã€ã¯ã‚ªãƒƒã‚ºã‚’è€ƒæ…®ã—ã¦å„²ã‹ã‚‹é¦¬ã‚’æ¢ã—ã¾ã™ã€‚"
        )


        # Base parameters by race type
        if race_type == 'JRA':
            # === ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰è¨­å®š ===
            # ç‰¹å¾´: å®ŸåŠ›ãŒæ‹®æŠ—ã—ã¦ãŠã‚Šã€æ··æˆ¦ã«ãªã‚Šã‚„ã™ã„ã€‚ã‚ªãƒƒã‚ºã‚‚å‰²ã‚ŒãŒã¡ã€‚
            # å¯¾ç­–: çªå‡ºã—ãŸè£œæ­£ã¯é¿ã‘ã€ãƒ•ãƒ©ãƒƒãƒˆã«è¿‘ã„è©•ä¾¡ã‚’è¡Œã†ã€‚
            mark_weights = {
                "â—": 1.15,  # æœ¬å‘½: ä¿¡é ¼ã—ã™ããªã„ (1.15å€)
                "â—¯": 1.10,  # å¯¾æŠ—: 1.10å€
                "â–²": 1.05,  # å˜ç©´: 1.05å€
                "â–³": 1.02,  # é€£ä¸‹: 1.02å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.04  # 1ç€ç¢ºç‡4%æœªæº€ã¯é™¤å¤–
            venue_info = f"ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰" + (f" - {venue}" if venue else "")
        else:
            # === åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰è¨­å®š ===
            # ç‰¹å¾´: èƒ½åŠ›å·®ãŒå¤§ããã€å¼·ã„é¦¬ãŒé †å½“ã«å‹ã¤ã“ã¨ãŒå¤šã„ï¼ˆå …ã„æ±ºç€ï¼‰ã€‚
            # å¯¾ç­–: AIãŒé¸ã‚“ã æœ¬å‘½é¦¬ã¯ä¿¡é ¼ã§ãã‚‹ãŸã‚ã€è©•ä¾¡ã‚’å°‘ã—é«˜ã‚ã‚‹ã€‚
            mark_weights = {
                "â—": 1.30,  # æœ¬å‘½: æ¯”è¼ƒçš„ä¿¡é ¼ã§ãã‚‹ (1.3å€)
                "â—¯": 1.15,  # å¯¾æŠ—: 1.15å€
                "â–²": 1.10,  # å˜ç©´: 1.10å€
                "â–³": 1.05,  # é€£ä¸‹: 1.05å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.03  # 1ç€ç¢ºç‡3%æœªæº€ã¯é™¤å¤–
            venue_info = f"ğŸŒ™ åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰" + (f" - {venue}" if venue else "")

        # Venue-specific adjustments
        venue_features = []
        if venue_char:
            # ç›´ç·šè·é›¢ã«ã‚ˆã‚‹èª¿æ•´
            straight = venue_char.get('turf_straight', 300)
            if straight and straight > 500:  # é•·ã„ç›´ç·šï¼ˆæ–°æ½Ÿãªã©ï¼‰
                mark_weights["â—"] *= 0.95  # äººæ°—é¦¬ã‚„ã‚„ä¸åˆ©
                mark_weights["â–³"] *= 1.05  # ç©´é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("é•·ç›´ç·š")
            # ä¸­å±±(310m)ã‚‚å«ã‚ã‚‹ãŸã‚ã€é–¾å€¤ã‚’330mã«ç·©å’Œ
            elif straight and straight < 330:  # çŸ­ã„ç›´ç·šï¼ˆä¸­å±±ã€å‡½é¤¨ã€ç¦å³¶ã€å°å€‰ãªã©ï¼‰
                mark_weights["â—"] *= 1.05  # å…ˆè¡Œæ®‹ã‚Šã‚„ã™ãã€äººæ°—é¦¬æœ‰åˆ©
                mark_weights["â–³"] *= 0.95  # ç©´é¦¬ä¸åˆ©ï¼ˆå·®ã—å±Šã‹ãšï¼‰
                venue_features.append("çŸ­ç›´ç·š")

            # ã‚³ãƒ¼ã‚¹å¹…ã«ã‚ˆã‚‹èª¿æ•´
            track_width = venue_char.get('track_width')
            if track_width == 'narrow':  # ç‹­ã„ã‚³ãƒ¼ã‚¹
                mark_weights["â—"] *= 1.03  # å…ˆè¡Œæœ‰åˆ©ã€äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("å°å›ã‚Š")
            elif track_width == 'wide':  # åºƒã„ã‚³ãƒ¼ã‚¹
                # é¦¬ç¾¤ãŒåºƒãŒã‚Šã‚„ã™ãã€å±•é–‹æ¬¡ç¬¬
                pass

            # å‹¾é…ã«ã‚ˆã‚‹èª¿æ•´
            slope = venue_char.get('slope')
            if slope == 'steep':  # æ€¥å‚ã‚ã‚Šï¼ˆä¸­å±±ã€é˜ªç¥ã€ä¸­äº¬ãªã©ï¼‰
                mark_weights["â—"] *= 1.02  # ãƒ‘ãƒ¯ãƒ¼ã‚ã‚‹äººæ°—é¦¬æœ‰åˆ©
                mark_weights["â–³"] *= 0.98  # ãƒ‘ãƒ¯ãƒ¼ä¸è¶³ã®ç©´é¦¬ã¯å‰²å¼•
                venue_features.append("å‚ã‚ã‚Š(ãƒ‘ãƒ¯ãƒ¼è¦)")

        if venue_features:
            venue_info += f" ({', '.join(venue_features)})"

        st.info(venue_info)

        # === ç¢ºç‡è¼ƒæ­£ã®ãƒã‚§ãƒƒã‚¯ ===
        is_calibrated = False
        if model_meta and 'training_config' in model_meta:
             is_calibrated = model_meta['training_config'].get('calibrated', False)

        # Uncalibrated NAR Correction (Global application for consistency)
        if race_type == 'NAR' and not is_calibrated:
             # åœ°æ–¹ç«¶é¦¬ã‹ã¤æœªè¼ƒæ­£ã®å ´åˆã®ã¿ã€ä¿å®ˆçš„ãªèª¿æ•´ã‚’è¡Œã†
             # ã“ã‚Œã«ã‚ˆã‚Šã€è¡¨ç¤ºã•ã‚Œã‚‹AIã‚¹ã‚³ã‚¢ã¨EVè¨ˆç®—ã«ä½¿ã‚ã‚Œã‚‹ç¢ºç‡ãŒä¸€è‡´ã™ã‚‹
             def adjust_nar_prob_row(row):
                 p = row['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
                 new_p = p * 0.9 + 0.05
                 return int(new_p * 100)
             
             edited_df['AIã‚¹ã‚³ã‚¢(%)'] = edited_df.apply(adjust_nar_prob_row, axis=1)
             st.caption("â„¹ï¸ NARèª¿æ•´: AIã‚¹ã‚³ã‚¢ã¨æœŸå¾…å€¤ã‚’ä¿å®ˆçš„ã«è£œæ­£ã—ã¾ã—ãŸï¼ˆæœªè¼ƒæ­£ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ï¼‰")

        probs = edited_df['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
        odds = edited_df['ç¾åœ¨ã‚ªãƒƒã‚º']
        place_min_odds = edited_df.get('è¤‡å‹ä¸‹é™', pd.Series([0.0] * len(edited_df), index=edited_df.index)) 
        marks = edited_df['äºˆæƒ³å°']
        confidences = edited_df['ä¿¡é ¼åº¦']

        # Get run style compatibility if available
        run_style_compatibility = None
        if 'venue_run_style_compatibility' in edited_df.columns:
            run_style_compatibility = edited_df['venue_run_style_compatibility']

        # Get frame (æ ) for venue-specific frame advantage
        frames = None
        if 'æ ' in edited_df.columns:
            frames = edited_df['æ ']

        evs_pure = []      # ç´”ç²‹EVï¼ˆå°è£œæ­£ãªã—ï¼‰
        evs_adjusted = []  # èª¿æ•´å¾ŒEVï¼ˆå°è£œæ­£ã‚ã‚Šï¼‰
        kellys = []
        bias_reasons_list = [] # è£œæ­£ç†ç”±ãƒªã‚¹ãƒˆ

        for idx, (p, o_win, o_place, m, c) in enumerate(zip(probs, odds, place_min_odds, marks, confidences)):
            reasons = [] # ã“ã®é¦¬ã®è£œæ­£ç†ç”±
            
            # Use Win Odds for EV Calculation (since we are predicting target_win)
            calc_odds = 0.0
            if o_win > 1.0:
                 calc_odds = o_win
            elif o_place > 1.0:
                 # Fallback if Win Odds missing but Place Odds exist (rare)
                 calc_odds = o_place * 3.0
                 reasons.append("å˜å‹æ¨å®š")
            
            # Safety filter (race type specific)
            if p < safety_threshold:
                ev_pure = -1.0
                ev_adj = -1.0
                kelly = 0.0
                reasons.append("ç¢ºç‡ä¸è¶³(é™¤å¤–)")
            else:
                w = mark_weights.get(m, 1.0)
                if w != 1.0:
                     reasons.append(f"å°{m} (x{w:.2f})")
                
                # Already adjusted in Dataframe if needed
                adjusted_p = p

                # Apply run style compatibility if available
                if run_style_compatibility is not None:
                    run_compat = run_style_compatibility.iloc[idx]
                    if not pd.isna(run_compat) and run_compat != 1.0:
                        # è„šè³ªç›¸æ€§ãŒè‰¯ã„é¦¬ã¯æœŸå¾…å€¤ã‚’ä¸Šã’ã‚‹
                        adjusted_p *= run_compat
                        reasons.append(f"è„šè³ªé©æ€§ (x{run_compat:.2f})")

                # Apply frame advantage if available
                if frames is not None and venue_char:
                    frame = frames.iloc[idx]
                    if not pd.isna(frame):
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        try:
                            frame_num = int(frame)
                            if frame_num >= 6 and outer_advantage > 1.0:  # å¤–æ æœ‰åˆ©
                                adjusted_p *= outer_advantage
                                reasons.append(f"å¤–æ æœ‰åˆ© (x{outer_advantage:.2f})")
                            elif frame_num <= 3 and outer_advantage > 1.0:  # å†…æ ä¸åˆ©
                                penalty = 2.0 - outer_advantage
                                adjusted_p *= penalty
                                reasons.append(f"å†…æ ä¸åˆ© (x{penalty:.2f})")
                            
                            # å†…æ æœ‰åˆ©ãªå ´åˆ(outer_advantage < 1.0)
                            elif frame_num <= 3 and outer_advantage < 1.0:
                                bonus = 2.0 - outer_advantage
                                adjusted_p *= bonus
                                reasons.append(f"å†…æ æœ‰åˆ© (x{bonus:.2f})")
                            elif frame_num >= 6 and outer_advantage < 1.0:
                                adjusted_p *= outer_advantage
                                reasons.append(f"å¤–æ ä¸åˆ© (x{outer_advantage:.2f})")
                                
                        except: pass

                # ç´”ç²‹EV: å°è£œæ­£ãªã—ï¼ˆçµ±è¨ˆçš„ã«æ­£ã—ã„ï¼‰
                # Uses Place Odds
                ev_pure = (adjusted_p * calc_odds) - 1.0

                # èª¿æ•´å¾ŒEV: å°ãƒ»ä¿¡é ¼åº¦è£œæ­£ã‚ã‚Šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»è¦³ï¼‹ãƒªã‚¹ã‚¯æ›ç®—ï¼‰
                # ä¿¡é ¼åº¦(c)ã‚’ä¹—ç®—ã™ã‚‹ã“ã¨ã§ã€ã€ŒAIãŒè‡ªä¿¡ã®ãªã„ç©´é¦¬ã€ã®EVéå¤§è©•ä¾¡ã‚’é˜²ã
                trust_factor = c / 100.0
                ev_adj = (adjusted_p * w * calc_odds * trust_factor) - 1.0
                
                if trust_factor < 0.6:
                     reasons.append(f"ä¿¡é ¼åº¦ä½ (x{trust_factor:.2f})")

                # Kelly criterion: æœ€é©è³­ã‘é‡‘æ¯”ç‡ã®è¨ˆç®—
                # Formula: f* = (p * odds - 1) / (odds - 1)
                # ã“ã“ã§pã¯èª¿æ•´å¾Œã®ç¢ºç‡ã€oddsã¯ã‚ªãƒƒã‚º
                if calc_odds > 1.0:
                    kelly_raw = (adjusted_p * w * calc_odds - 1.0) / (calc_odds - 1.0)
                    # è² ã®å€¤ã¯0ã«ã€ä¸Šé™ã¯10%ã«åˆ¶é™ï¼ˆãƒªã‚¹ã‚¯ç®¡ç†ï¼‰
                    kelly = max(0.0, min(0.10, kelly_raw)) * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
                else:
                    kelly = 0.0
            
            evs_pure.append(ev_pure)
            evs_adjusted.append(ev_adj)
            kellys.append(kelly)
            bias_reasons_list.append(", ".join(reasons) if reasons else "-")

        edited_df['å˜å‹æœŸå¾…å€¤'] = evs_pure
        edited_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = evs_adjusted
        edited_df['æ¨å¥¨åº¦(Kelly)'] = kellys
        edited_df['è£œæ­£å†…å®¹'] = bias_reasons_list

        # === AIæœŸå¾…åº¦TOP5ã®ã‚°ãƒ©ãƒ•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡¨ç¤ºï¼‰ ===
        st.markdown("---")
        st.subheader("ğŸ“Š AIè©•ä¾¡ TOP5 åˆ†æ")

        # TOP5ã‚’AIã‚¹ã‚³ã‚¢ï¼ˆå‹ç‡ï¼‰ã§ã‚½ãƒ¼ãƒˆï¼ˆçš„ä¸­ç‡é‡è¦–ï¼‰

        

        # Apply sorting based on ranking criteria
        if ranking_criteria == "å›åç‡é‡è¦– (æœŸå¾…å€¤)":
            edited_df.sort_values(by='èª¿æ•´å¾ŒæœŸå¾…å€¤', ascending=False, inplace=True)
            y_col = 'èª¿æ•´å¾ŒæœŸå¾…å€¤'
            y_label = 'æœŸå¾…å€¤(EV)'
            bar_color = '#28a745'
        else: # "çš„ä¸­ç‡é‡è¦– (AIã‚¹ã‚³ã‚¢)"
            edited_df.sort_values(by='DæŒ‡æ•°', ascending=False, inplace=True)
            y_col = 'DæŒ‡æ•°'
            y_label = 'DæŒ‡æ•°'
            bar_color = '#1f77b4'

        top5_df = edited_df.head(5)
        
        # Plot Top 5
        st.subheader(f"ğŸ“ˆ {ranking_criteria} TOP 5")
        
        fig_top5 = go.Figure(go.Bar(
            x=top5_df['é¦¬å'],
            y=top5_df[y_col],
            text=top5_df[y_col].apply(lambda x: f"{x:.2f}" if y_col == 'èª¿æ•´å¾ŒæœŸå¾…å€¤' else f"{x:.1f}"),
            textposition='auto',
            marker_color=bar_color
        ))
        fig_top5.update_layout(
            yaxis_title=y_label,
            xaxis_title="é¦¬å",
            height=400,
            showlegend=False
        )

        st.plotly_chart(fig_top5, width="stretch")

        # è£œæ­£å†…å®¹ã®è¡¨ç¤º
        st.markdown("##### â„¹ï¸ æœŸå¾…å€¤èª¿æ•´ã®è©³ç´° (TOP5)")
        st.dataframe(
            top5_df[['äºˆæƒ³å°', 'é¦¬å', 'ç¾åœ¨ã‚ªãƒƒã‚º', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'è£œæ­£å†…å®¹']],
            column_config={
                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(format="%.2f"),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(format="%.1f%%", max_value=30),
            },
            hide_index=True,
            width='stretch'
        )

        # 2. é©æ€§ã‚¹ã‚³ã‚¢æ¯”è¼ƒï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰
        st.markdown("#### ğŸ¯ TOP5 é©æ€§åº¦æ¯”è¼ƒ")

        compatibility_cols = ['é¨æ‰‹é©æ€§åº¦', 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 'è·é›¢é©æ€§åº¦']
        compat_data = []
        for idx, row in top5_df.iterrows():
            compat_data.append({
                'é¦¬å': row['é¦¬å'],
                'é¨æ‰‹é©æ€§åº¦': row.get('é¨æ‰‹é©æ€§åº¦', 5.0),
                'ã‚³ãƒ¼ã‚¹é©æ€§åº¦': row.get('ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 5.0),
                'è·é›¢é©æ€§åº¦': row.get('è·é›¢é©æ€§åº¦', 5.0)
            })

        compat_df = pd.DataFrame(compat_data)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢ã«10ç‚¹æº€ç‚¹ã«å¤‰æ›æ¸ˆã¿ï¼‰
        heatmap_data = []
        for col in compatibility_cols:
            heatmap_data.append([val for val in compat_df[col]])

        fig_heatmap = go.Figure(data=go.Heatmap(
            z=heatmap_data,
            x=compat_df['é¦¬å'],
            y=compatibility_cols,
            colorscale='RdYlGn',
            text=[[f'{val:.1f}' for val in compat_df[col]] for col in compatibility_cols],
            texttemplate='%{text}',
            textfont={"size": 12},
            colorbar=dict(title="é©æ€§åº¦<br>(10ç‚¹æº€ç‚¹)")
        ))

        fig_heatmap.update_layout(
            title="é©æ€§åº¦ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰",
            xaxis_title="é¦¬å",
            height=300
        )

        st.plotly_chart(fig_heatmap, width="stretch")

        # 3. äºˆæ¸¬çµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰
        with st.expander("â„¹ï¸ AIåˆ†ææŒ‡æ¨™ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯", expanded=False):
            st.markdown("""
            ### ğŸ§  AIæŒ‡æ¨™ã®èª­ã¿æ–¹ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
            
            **1. ğŸ“ˆ AIã‚¹ã‚³ã‚¢ (AIå‹ç‡äºˆæ¸¬)**
            *   **æ„å‘³**: éå»ã®è†¨å¤§ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€AIãŒç®—å‡ºã—ãŸã€Œç´”ç²‹ãªå‹åˆ©ç¢ºç‡ã€ã§ã™ã€‚
            *   **ç‰¹å¾´**: ã‚ªãƒƒã‚ºã‚„äººæ°—ï¼ˆéå‰°è©•ä¾¡ï¼‰ã«å·¦å³ã•ã‚Œãšã€é¦¬ã®æœ¬æ¥ã®å®ŸåŠ›ã¨é©æ€§ã ã‘ã§è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚
            *   **ä¿¡é ¼æ€§**: æœªæ¥ã®æƒ…å ±ï¼ˆãƒ¬ãƒ¼ã‚¹çµæœï¼‰ã‚’å«ã¾ãªã„å³å¯†ãªå­¦ç¿’ã‚’è¡Œã£ã¦ã„ã‚‹ãŸã‚ã€æ¥µã‚ã¦å®¢è¦³çš„ã§ã™ã€‚

            **2. ğŸ›¡ï¸ ä¿¡é ¼åº¦ (Confidence)**
            *   **æ„å‘³**: ã€Œã“ã®äºˆæ¸¬ã«ä¹—ã£ã‹ã£ã¦ã‚‚å¤§ä¸ˆå¤«ã‹ã€ã¨ã„ã†å®‰å¿ƒæ„Ÿã‚’ç¤ºã™ç‹¬è‡ªã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰ã§ã™ã€‚
            *   **ç®—å‡ºãƒ­ã‚¸ãƒƒã‚¯**: 
                *   AIã®ç¢ºä¿¡åº¦ï¼ˆç¢ºç‡ã®å¼·ã•ï¼‰
                *   ãƒ‡ãƒ¼ã‚¿é‡ï¼ˆéå»ã®ãƒ¬ãƒ¼ã‚¹æ•°ï¼‰
                *   é©æ€§ã®ä¸€è‡´åº¦ï¼ˆå¾—æ„ãªé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ã‹ï¼‰
                *   ãƒªã‚¹ã‚¯è¦å› ï¼ˆé•·æœŸä¼‘é¤Šæ˜ã‘ãªã©ã¯æ¸›ç‚¹ï¼‰
            *   **æ´»ç”¨æ³•**: AIã‚¹ã‚³ã‚¢ãŒé«˜ãã¦ã‚‚ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯ã€ä¸ç¢ºå®šè¦ç´ ï¼ˆåˆå‡ºèµ°ãªã©ï¼‰ãŒå¤šã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚

            **3. ğŸ’° èª¿æ•´å¾ŒæœŸå¾…å€¤ (Adjusted EV)**
            *   **æ„å‘³**: ã€ŒæŠ•è³‡å¯¾è±¡ã¨ã—ã¦ã®ãŠã„ã—ã•ã€ã‚’ç¤ºã™æœ€é‡è¦æŒ‡æ¨™ã§ã™ã€‚
            *   **è¨ˆç®—å¼**: `(è£œæ­£å¾ŒAIç¢ºç‡ Ã— å°ã®é‡ã¿ Ã— ã‚ªãƒƒã‚º) - 1.0`
            *   **è£œæ­£å†…å®¹ã«ã¤ã„ã¦**:
                *   **ã‚³ãƒ¼ã‚¹ç‰¹æ€§**: ä¼šå ´ã”ã¨ã®æœ‰åˆ©ä¸åˆ©ï¼ˆå¤–æ æœ‰åˆ©ã€é€ƒã’æœ‰åˆ©ãªã©ï¼‰ã‚’è‡ªå‹•è£œæ­£ã—ã¦ã„ã¾ã™ï¼ˆã‚°ãƒ©ãƒ•ä¸‹ã®è¡¨ã§ç¢ºèªå¯èƒ½ï¼‰ã€‚
                *   **å°ã®é‡ã¿**: ã‚ãªãŸã®å…¥åŠ›ã—ãŸäºˆæƒ³å°ï¼ˆâ—=1.3å€ãªã©ï¼‰ã‚‚åæ˜ ã•ã‚Œã¾ã™ã€‚
            *   **ç‹™ã„ç›®**: ã“ã®æ•°å€¤ãŒãƒ—ãƒ©ã‚¹ï¼ˆç·‘è‰²ï¼‰ã®é¦¬ã¯ã€çµ±è¨ˆçš„ã«ã‚‚ä¸»è¦³çš„ã«ã‚‚ã€Œè²·ã†ä¾¡å€¤ã‚ã‚Šã€ã¨åˆ¤æ–­ã•ã‚ŒãŸé¦¬ã§ã™ã€‚

            **4. é©æ€§åº¦ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ãƒ»è·é›¢ï¼‰**
            - **å…¨æœŸé–“ï¼ˆ3å¹´é–“ï¼‰ã®Global History**ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—
            - å¹³å‡ç€é †ã‚’10ç‚¹æº€ç‚¹ã‚¹ã‚³ã‚¢ã«å¤‰æ›: `10 - (å¹³å‡ç€é † / 2)`
            - **æ•°å€¤ãŒé«˜ã„ã»ã©è‰¯ã„** (10ç‚¹=å¹³å‡1ç€, 5ç‚¹=å¹³å‡10ç€)
            - **7.0ç‚¹ä»¥ä¸Š**: å„ªç§€ (å¹³å‡ç€é † 6ç€ä»¥å†…)
            - **5.0ç‚¹**: æ¨™æº– (ãƒ‡ãƒ¼ã‚¿ãªã—ã€ã¾ãŸã¯å¹³å‡10ç€)
            - **3.0ç‚¹ä»¥ä¸‹**: ä¸å®‰ (å¹³å‡14ç€ä»¥ä¸‹)

            **5. ã‚³ãƒ¼ã‚¹ç‰¹æ€§ï¼ˆå‚¾æ–œãƒ»ç›´ç·šè·é›¢ãƒ»ã‚³ãƒ¼ã‚¹å¹…ãƒ»æ ç•ªï¼‰**
            - **å‹¾é…ï¼ˆå‚¾æ–œï¼‰**: æ€¥å‚ã‚ã‚Šã®ç«¶é¦¬å ´ã§ã¯äººæ°—é¦¬ãŒæœ‰åˆ©ï¼ˆ+2%ï¼‰
              - ä¸­å±±ã€é˜ªç¥ãªã©: å‚ã§ãƒ‘ãƒ¯ãƒ¼ãŒå¿…è¦ãªãŸã‚å®Ÿç¸¾é¦¬ãŒå„ªä½
            - **ç›´ç·šè·é›¢**:
              - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: å·®ã—é¦¬æœ‰åˆ©ã€ç©´é¦¬ãƒãƒ£ãƒ³ã‚¹ï¼ˆäººæ°—é¦¬-5%ã€ç©´é¦¬+5%ï¼‰
              - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: é€ƒã’ãƒ»å…ˆè¡Œé¦¬æœ‰åˆ©ã€äººæ°—é¦¬å …ã„ï¼ˆäººæ°—é¦¬+5%ï¼‰
            - **ã‚³ãƒ¼ã‚¹å¹…**:
              - å°å›ã‚Šã‚³ãƒ¼ã‚¹: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãå™¨ç”¨ãªé¦¬ãŒæœ‰åˆ©ï¼ˆäººæ°—é¦¬+3%ï¼‰
            - **æ ç•ªå‚¾å‘**:
              - å¤–æ æœ‰åˆ©ãªç«¶é¦¬å ´: 6-8æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´
              - å†…æ æœ‰åˆ©ãªç«¶é¦¬å ´: 1-3æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´

            âš ï¸ **ã“ã‚Œã‚‰ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã¯ã€ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™**

            ### ğŸ¯ æ¨å¥¨ã•ã‚Œã‚‹ä½¿ã„æ–¹

            1. **TOP5ã‚°ãƒ©ãƒ•**ã§AIè©•ä¾¡ã®é«˜ã„é¦¬ã‚’ç¢ºèª
            2. **æœŸå¾…å€¤(EV)ãŒãƒ—ãƒ©ã‚¹**ã®é¦¬ã«æ³¨ç›®
            3. **ä¿¡é ¼åº¦ãŒ70%ä»¥ä¸Š**ã®äºˆæ¸¬ã‚’å„ªå…ˆ
            4. **é©æ€§åº¦**ã§ç›¸æ€§ã‚’ç¢ºèªï¼ˆç‰¹ã«é¨æ‰‹é©æ€§åº¦ã¯é‡è¦ï¼‰
            5. **ç¾åœ¨ã‚ªãƒƒã‚º**ã¨**äºˆæƒ³å°**ã‚’å…¥åŠ›ã—ã¦EVã‚’æœ€çµ‚èª¿æ•´

            ### âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

            - **ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå¿…è¦**: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€Œ3ç€ä»¥å†…ã€ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
            - ç®¡ç†ãƒšãƒ¼ã‚¸ã§ä¸¡ãƒ¢ãƒ‡ãƒ«ï¼ˆJRA/NARï¼‰ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„
            - å†å­¦ç¿’å¾Œã€AIç¢ºç‡ã¯5-15%ã®ç¯„å›²ï¼ˆ1ç€ç¢ºç‡ã¨ã—ã¦å¦¥å½“ï¼‰ã«ãªã‚Šã¾ã™
            """)

        st.markdown("---")
        st.markdown("---")
        st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")

        # Rename for clarity if exists
        if 'AIæœŸå¾…å€¤' in edited_df.columns:
            edited_df.rename(columns={'AIæœŸå¾…å€¤': 'å˜å‹æœŸå¾…å€¤'}, inplace=True)


        # Highlight high EV and Kelly
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]

        # Select and Order Columns for Hit Rate Focus
        display_cols = [
            'äºˆæƒ³å°', 'æ ', 'é¦¬ ç•ª', 'é¦¬å', 
            'AIã‚¹ã‚³ã‚¢(%)', 'ä¿¡é ¼åº¦', 
            'jockey_compatibility', 'time_stats', 
            'ç¾åœ¨ã‚ªãƒƒã‚º', 'å˜å‹æœŸå¾…å€¤', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'æ¨å¥¨åº¦(Kelly)'
        ]
        # Filter existing columns
        display_cols = [c for c in display_cols if c in edited_df.columns]
        
        st.dataframe(
            edited_df[display_cols].style
            .format({
                'æ¨å¥¨åº¦(Kelly)': lambda x: '-' if x <= 0 else f'{x:.1f}%',
                'å˜å‹æœŸå¾…å€¤': '{:.2f}',
                'èª¿æ•´å¾ŒæœŸå¾…å€¤': '{:.2f}',
                'AIã‚¹ã‚³ã‚¢(%)': '{:.1f}',
                'ä¿¡é ¼åº¦': '{:.0f}'
            })
            .map(lambda x: 'background-color: #d4edda' if x > 0 else '', subset=['å˜å‹æœŸå¾…å€¤', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'æ¨å¥¨åº¦(Kelly)'])
        )



        # Visualization
        st.markdown("---")
        st.subheader("ğŸ” å€‹åˆ¥é¦¬ã®è©³ç´°åˆ†æ")

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼šé¦¬ã®è©³ç´°åˆ†æã‚’ç”Ÿæˆ
        def create_horse_analysis(horse_name, df_display, edited_df):
            """å€‹åˆ¥é¦¬ã®èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆã¨éå»5èµ°ã®æ¨ç§»ã‚’ç”Ÿæˆ"""
            # Find row
            row = df_display[df_display['é¦¬å'] == horse_name].iloc[0]

            # --- Scoring Logic (Lower rank is better, so Invert) ---
            # --- Scoring Logic (Lower rank is better, so Invert) ---
            def rank_to_score(r):
                if pd.isna(r) or r > 18: return 0
                # Use same logic as table: 10 - (Rank / 2)
                # Rank 1 -> 9.5
                # Rank 10 -> 5.0
                return max(0, min(10, 10 - (r / 2)))

            # Calculate scores
            sp_val = row.get('weighted_avg_speed', 16.0)
            score_speed = max(0, min(10, (sp_val - 15.0) * 5))
            j_val = row.get('jockey_compatibility', 10.0) # Raw Rank
            score_jockey = rank_to_score(j_val)
            c_val = row.get('course_compatibility', 10.0) # Raw Rank
            score_course = rank_to_score(c_val)
            d_val = row.get('distance_compatibility', 10.0) # Raw Rank
            score_dist = rank_to_score(d_val)
            rank_val = row.get('weighted_avg_rank', 10.0) # Raw Rank
            score_form = rank_to_score(rank_val)

            # Radar Chart
            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=[score_speed, score_form, score_jockey, score_course, score_dist, score_speed],
                theta=['ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å®Ÿç¸¾(ç€é †)', 'é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§'],
                fill='toself',
                name=horse_name,
                line=dict(color='#1f77b4')
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 10])),
                height=300,
                margin=dict(l=40, r=40, t=40, b=40)
            )

            # Past 5 Runs Line Chart
            history_data = []
            for i in range(5, 0, -1):
                if f"past_{i}_rank" in row and pd.notna(row[f"past_{i}_rank"]):
                    history_data.append({
                        "Run": f"{i}èµ°å‰",
                        "ç€é †": row[f"past_{i}_rank"],
                        "3Fã‚¿ã‚¤ãƒ ": row[f"past_{i}_last_3f"]
                    })

            if history_data:
                hist_df = pd.DataFrame(history_data)
                from plotly.subplots import make_subplots
                fig_line = make_subplots(specs=[[{"secondary_y": True}]])
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['ç€é †'], name="ç€é †", mode='lines+markers', line=dict(color='#ff7f0e')), secondary_y=False)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['3Fã‚¿ã‚¤ãƒ '], name="ä¸Šã‚Š3F", mode='lines+markers', line=dict(dash='dot', color='#2ca02c')), secondary_y=True)
                fig_line.update_layout(height=300, margin=dict(l=40, r=40, t=40, b=40))
                fig_line.update_yaxes(title_text="ç€é †", autorange="reversed", secondary_y=False)
                fig_line.update_yaxes(title_text="ä¸Šã‚Š3F (ç§’)", secondary_y=True)
            else:
                fig_line = go.Figure()
                fig_line.add_annotation(text="éå»ãƒ‡ãƒ¼ã‚¿ãªã—")
                fig_line.update_layout(height=300)

            # Get prediction summary
            pred_row = edited_df[edited_df['é¦¬å'] == horse_name].iloc[0]

            return fig_radar, fig_line, pred_row

        try:
            # === åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠ ===
            st.info("ğŸ’¡ åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è©•ä¾¡ä¸Šä½5é ­ï¼‰")

            # Get all horses sorted by AI Score
            all_horses = edited_df.sort_values('DæŒ‡æ•°', ascending=False)['é¦¬å'].tolist()
            default_horses = top5_df['é¦¬å'].tolist()
            
            # Ensure default horses are in the options (sanity check)
            default_horses = [h for h in default_horses if h in all_horses]

            selected_horses = st.multiselect(
                "åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠ",
                options=all_horses,
                default=default_horses
            )

            for idx, horse_name in enumerate(selected_horses):
                with st.expander(f"**{idx+1}ä½: {horse_name}**", expanded=(idx < 2)):  # 1-2ä½ã¯å±•é–‹è¡¨ç¤º
                    fig_radar, fig_line, pred_row = create_horse_analysis(horse_name, df_display, edited_df)

                    # Prediction Summary
                    col_s1, col_s2, col_s3, col_s4, col_s5 = st.columns(5)
                    with col_s1:
                         # Use D-Index
                        st.metric("DæŒ‡æ•°", f"{pred_row['DæŒ‡æ•°']:.1f}", help="é©æ€§ã¨ä¿¡é ¼åº¦ã§å‚¾æ–œã‚’ã‹ã‘ãŸã‚¹ã‚³ã‚¢")
                    with col_s2:
                        st.metric("ä¿¡é ¼åº¦", f"{pred_row['ä¿¡é ¼åº¦']}%")
                    with col_s3:
                        ai_ev_val = pred_row.get('å˜å‹æœŸå¾…å€¤', 0.0)
                        st.metric("å˜å‹æœŸå¾…å€¤", f"{ai_ev_val:.2f}")
                    with col_s4:
                        adj_ev_val = pred_row['èª¿æ•´å¾ŒæœŸå¾…å€¤']
                        ev_delta = "è²·ã„æ¨å¥¨" if adj_ev_val > 0 else "è¦‹é€ã‚Š"
                        st.metric("èª¿æ•´å¾ŒEV", f"{adj_ev_val:.2f}", delta=ev_delta)
                    with col_s5:
                        odds_val = pred_row.get('ç¾åœ¨ã‚ªãƒƒã‚º', 0.0)
                        st.metric("ã‚ªãƒƒã‚º", f"{odds_val:.1f}å€")

                    # Charts
                    col_c1, col_c2 = st.columns(2)
                    with col_c1:
                        st.markdown("**èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ**")
                        st.plotly_chart(fig_radar, width="stretch", key=f"radar_{idx}_{horse_name}")
                    with col_c2:
                        st.markdown("**éå»5èµ°ã®æ¨ç§»**")
                        st.plotly_chart(fig_line, width="stretch", key=f"line_{idx}_{horse_name}")

            # === ã‚«ãƒ¼ãƒ‰è¡¨ç¤º: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—é¢¨åˆ†æ ===
            st.markdown("---")
            st.subheader("ğŸ“Š èƒ½åŠ›ãƒãƒ©ãƒ³ã‚¹åˆ†æ")
            
            # Helper for circled numbers
            def to_circled_num(n):
                try:
                    val = int(float(n)) 
                    if 1 <= val <= 20: return chr(9311 + val)
                    return f"({val})"
                except: return ""

            # Helper to format horse name
            def fmt_horse(row):
                num = row.get('é¦¬ ç•ª')
                if pd.isna(num): num = row.get('é¦¬ç•ª', '')
                name = row['é¦¬å']
                c_num = to_circled_num(num)
                if c_num: return f"{c_num} {name}".strip()
                elif pd.notna(num) and str(num).strip(): return f"({num}) {name}".strip()
                else: return name

            # 3 Columns for 3 Types of Analysis
            col_a1, col_a2, col_a3 = st.columns(3)
            
            with col_a1:
                 st.markdown("#### ğŸš€ ã‚¹ãƒ”ãƒ¼ãƒ‰é‡è¦–")
                 st.caption("å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰ä¸Šä½")
                 speed_top = edited_df.sort_values('å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰', ascending=False).head(3)
                 for _, row in speed_top.iterrows():
                     st.write(f"{fmt_horse(row)}: {row['å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰']:.1f}")

            with col_a2:
                 st.markdown("#### ğŸ’ª å®‰å®šæ„Ÿé‡è¦–")
                 st.caption("å¹³å‡ç€é †ä¸Šä½")
                 stab_top = edited_df.sort_values('å¹³å‡ç€é †', ascending=True).head(3)
                 for _, row in stab_top.iterrows():
                     st.write(f"{fmt_horse(row)}: {row['å¹³å‡ç€é †']:.1f}")

            with col_a3:
                 st.markdown("#### ğŸ§¬ è¡€çµ±ãƒ»é©æ€§é‡è¦–")
                 st.caption("Bloodline_Indexä¸Šä½")
                 blood_top = edited_df.sort_values('Bloodline_Index', ascending=False).head(3)
                 for _, row in blood_top.iterrows():
                     st.write(f"{fmt_horse(row)}: {row['Bloodline_Index']:.1f}")
                    
        except Exception as e:
            st.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.text(traceback.format_exc())




