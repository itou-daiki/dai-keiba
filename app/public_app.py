import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import pickle
import json
import plotly.express as px
import plotly.graph_objects as go
import time
import logging

# Setup logger
logger = logging.getLogger(__name__)

# Add paths
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(PROJECT_ROOT, 'scraper'))
sys.path.append(os.path.join(PROJECT_ROOT, 'ml'))

try:
    import importlib
    import auto_scraper
    importlib.reload(auto_scraper) # Force reload to apply fixes
    from feature_engineering import process_data
    from db_helper import KeibaDatabase
except ImportError as e:
    st.error(f"Import Error: {e}")

st.set_page_config(page_title="AI Keiba Predictor", layout="wide")

# --- Utils ---
@st.cache_resource
def load_model(mode="JRA"):
    model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/lgbm_model_nar.pkl" if mode == "NAR" else "ml/models/lgbm_model.pkl")
    if os.path.exists(model_path):
        with open(model_path, 'rb') as f:
            return pickle.load(f)
    return None

@st.cache_resource
def load_model_metadata(mode="JRA"):
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ãªã©ï¼‰ã‚’èª­ã¿è¾¼ã‚€"""
    meta_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/lgbm_model_nar_meta.json" if mode == "NAR" else "ml/models/lgbm_model_meta.json")
    if os.path.exists(meta_path):
        with open(meta_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

@st.cache_resource
def load_history_csv(mode):
    """éå»ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ (é«˜é€ŸåŒ–)"""
    csv_path = os.path.join(PROJECT_ROOT, "data", "raw", "database_nar.csv" if mode == "NAR" else "database.csv")
    if os.path.exists(csv_path):
        try:
            # Cloud optimization: Load only necessary columns
            usecols = [
                'horse_id', 'race_id', 'æ—¥ä»˜', 'ç€ é †', 'ã‚¿ã‚¤ãƒ ', 'ãƒ¬ãƒ¼ã‚¹å', 
                'å¾Œ3F', 'é¦¬ä½“é‡(å¢—æ¸›)', 'é¨æ‰‹', 'é¦¬å ´çŠ¶æ…‹', 'å˜å‹ ã‚ªãƒƒã‚º', 
                'å¤©å€™', 'è·é›¢', 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'
            ]
            # Ensure columns exist (handling potential mismatches if file is old)
            # But read_csv usecols must match exactly.
            # We assume standard database.csv structure.
            # If strictly needed, we could read header first, but that's slow.
            # We'll just try loading.
            
            return pd.read_csv(
                csv_path, 
                usecols=lambda c: c in usecols, # Lambda handles missing cols gracefully? No, filtering.
                dtype={'horse_id': str, 'race_id': str, 'ç€ é †': str} 
            )
        except Exception as e:
            st.warning(f"History load failed: {e}")
            pass
    return None

@st.cache_resource
def load_stats(mode="JRA"):
    """çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹æˆç¸¾ãªã©ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰"""
    stats_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), f"ml/models/feature_stats_nar.pkl" if mode == "NAR" else "ml/models/feature_stats.pkl")
    if os.path.exists(stats_path):
        try:
            with open(stats_path, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            st.warning(f"Stats load error: {e}")
    return None

def get_data_freshness(mode="JRA"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’å–å¾—ï¼ˆSQLå¯¾å¿œï¼‰"""
    db_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "keiba_data.db")
    if os.path.exists(db_path):
        try:
            db = KeibaDatabase(db_path)
            freshness = db.get_data_freshness(mode)
            return freshness, 0  # é®®åº¦æƒ…å ±ã‚’æ–‡å­—åˆ—ã§è¿”ã™
        except Exception as e:
            st.warning(f"ãƒ‡ãƒ¼ã‚¿é®®åº¦ã®å–å¾—ã«å¤±æ•—: {e}")
            return "ä¸æ˜", -1
    return "DBãªã—", -1
    return None, None

def calculate_confidence_score(ai_prob, model_meta, jockey_compat=None, course_compat=None, distance_compat=None, is_rest_comeback=0, has_history=True):
    """
    äºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰

    Args:
        ai_prob: AIäºˆæ¸¬ç¢ºç‡ï¼ˆ0-1ï¼‰
        model_meta: ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        jockey_compat: é¨æ‰‹ç›¸æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        course_compat: ã‚³ãƒ¼ã‚¹é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        distance_compat: è·é›¢é©æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ã€Noneã®å ´åˆã¯è€ƒæ…®ã—ãªã„ï¼‰
        is_rest_comeback: ä¼‘é¤Šæ˜ã‘ãƒ•ãƒ©ã‚°ï¼ˆ1=True, 0=Falseï¼‰
        has_history: éå»èµ°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ã©ã†ã‹ (True/False)

    Returns:
        int: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
    """
    if not model_meta:
        return 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # ===== 1. ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦: ãƒ¢ãƒ‡ãƒ«ã®AUCã‹ã‚‰ç®—å‡º =====
    base_confidence = model_meta.get('performance', {}).get('auc', 0.75) * 100

    # ===== 2. ãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚‹èª¿æ•´ =====
    data_size = model_meta.get('data_stats', {}).get('total_records', 0)
    if data_size < 1000:
        data_penalty = -20  # ãƒ‡ãƒ¼ã‚¿é‡å°‘ãªã„
    elif data_size < 3000:
        data_penalty = -8
    elif data_size < 5000:
        data_penalty = -3
    else:
        data_penalty = 0

    # ===== 3. äºˆæ¸¬ç¢ºç‡ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé€£ç¶šçš„ãªèª¿æ•´ï¼‰ =====
    # 0.5ã‹ã‚‰é›¢ã‚Œã‚‹ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒç¢ºä¿¡ã‚’æŒã£ã¦ã„ã‚‹ï¼‰
    # 0.5ã«è¿‘ã„ã»ã©ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒè¿·ã£ã¦ã„ã‚‹ï¼‰
    distance_from_uncertain = abs(ai_prob - 0.5)

    # è·é›¢ã«åŸºã¥ãä¿¡é ¼åº¦ãƒœãƒ¼ãƒŠã‚¹: 0.5é›¢ã‚Œã¦ã„ã‚‹ã¨æœ€å¤§+20ã€0.0ã ã¨-20
    # å¼ã‚’èª¿æ•´ã—ã¦ç¯„å›²ã‚’æ‹¡å¤§
    prob_bonus = (distance_from_uncertain * 2 - 0.25) * 40

    # ã•ã‚‰ã«æ¥µç«¯ãªäºˆæ¸¬ï¼ˆ<0.10 or >0.90ï¼‰ã«ã¯è¿½åŠ ãƒœãƒ¼ãƒŠã‚¹ (Top 3ç”¨ã«èª¿æ•´)
    if ai_prob < 0.10 or ai_prob > 0.90:
        prob_bonus += 12

    # AIç¢ºç‡ãŒæ¥µç«¯ã«ä½ã„å ´åˆã¯ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§ï¼‰
    if ai_prob < 0.15:
        prob_bonus -= 10

    # ===== 4. é©æ€§ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆæ–°è¦è¿½åŠ ï¼‰ =====
    compat_bonus = 0

    # åˆ©ç”¨å¯èƒ½ãªé©æ€§ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ
    compat_scores = []
    if jockey_compat is not None and not pd.isna(jockey_compat):
        compat_scores.append(jockey_compat)
    if course_compat is not None and not pd.isna(course_compat):
        compat_scores.append(course_compat)
    if distance_compat is not None and not pd.isna(distance_compat):
        compat_scores.append(distance_compat)

    if compat_scores:
        avg_compat = sum(compat_scores) / len(compat_scores)
        min_compat = min(compat_scores)

        # å¹³å‡é©æ€§ã«ã‚ˆã‚‹èª¿æ•´ (Lower is Better, since these are Ranks 1-18)
        # 1.0 - 4.0: Excellent
        # 4.1 - 8.0: Good
        # 8.1 - 12.0: Average
        # 12.1+: Poor
        
        if avg_compat <= 3.5:
            compat_bonus = +15  # å…¨ã¦é«˜é©æ€§ (Rank 1-3)
        elif avg_compat <= 7.0:
            compat_bonus = +8   # è‰¯é©æ€§ (Rank 4-7)
        elif avg_compat <= 11.0:
            compat_bonus = 0    # å¹³å‡çš„
        elif avg_compat <= 14.0:
            compat_bonus = -12  # ä¸é©æ€§
        else:
            compat_bonus = -25  # è‡´å‘½çš„ (Rank 15-18)

        # æœ€ä½ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹è¿½åŠ ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆã„ãšã‚Œã‹ã®é©æ€§ãŒæ¥µç«¯ã«ä½ã„å ´åˆ = RankãŒå¤§ãã„ï¼‰
        if max(compat_scores) > 13.0:
            compat_bonus -= 15  # è‡´å‘½çš„ãªä¸é©æ€§ã‚’æŠ±ãˆã¦ã„ã‚‹
        elif max(compat_scores) > 10.0:
            compat_bonus -= 5


    # ===== 5. ä¼‘é¤Šæ˜ã‘ãƒ»é–“éš”ã«ã‚ˆã‚‹èª¿æ•´ (æ–°è¦è¿½åŠ ) =====
    interval_penalty = 0
    if is_rest_comeback == 1:
        interval_penalty = -10 # é•·æœŸä¼‘é¤Šæ˜ã‘ã¯ä¸ç¢ºå®šè¦ç´ ãŒå¤šã„
        
    # ===== 6. åˆå‡ºèµ°ãƒ»å±¥æ­´ãªã—ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£ (æ–°è¦è¿½åŠ ) =====
    history_penalty = 0
    if not has_history:
        history_penalty = -40 # ãƒ‡ãƒ¼ã‚¿ãŒå…¨ããªã„é¦¬ã¯ä¿¡é ¼ã§ããªã„

    # ===== æœ€çµ‚è¨ˆç®— =====
    confidence = base_confidence + data_penalty + prob_bonus + compat_bonus + interval_penalty + history_penalty

    # ç¯„å›²ã‚’æ‹¡å¤§: 20-95ï¼ˆã‚ˆã‚Šå·®åˆ¥åŒ–ï¼‰
    return int(max(20, min(95, confidence)))

def predict_race_logic(df, model, model_meta, stats=None):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦AIäºˆæ¸¬ã¨ä¿¡é ¼åº¦è¨ˆç®—ã‚’è¡Œã†
    stats: çµ±è¨ˆæƒ…å ±ã®è¾æ›¸ï¼ˆinferenceç”¨ï¼‰
    """
    try:
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆä¼šå ´ç‰¹æ€§ã‚ã‚Šï¼‰
        # inference mode: pass stats
        X_df = process_data(df, use_venue_features=True, input_stats=stats)

        # Align features with model
        if hasattr(model, 'feature_name'):
             model_features = model.feature_name()
             # Ensure all features exist and log missing ones
             missing_features = []
             for f in model_features:
                 if f not in X_df.columns:
                     missing_features.append(f)
                     X_df[f] = 0

             if missing_features:
                 logger.warning(f"âš ï¸  Missing features defaulted to 0 (first 10): {missing_features[:10]}")
                 if len(missing_features) > 10:
                     logger.warning(f"... and {len(missing_features)-10} more missing features")

             X_pred = X_df[model_features].fillna(0)
        else:
             # Fallback for older sklearn models or if feature_name not available
             meta_cols = ['é¦¬å', 'horse_id', 'æ ', 'é¦¬ ç•ª', 'race_id', 'date', 'rank', 'ç€ é †']
             features = [c for c in X_df.columns if c not in meta_cols and c != 'target_win']
             X_pred = X_df[features].select_dtypes(include=['number']).fillna(0)

        # Predict
        probs = model.predict(X_pred)

        df['AI_Prob'] = probs
        df['AI_Score'] = (probs * 100).astype(int)

        # Calculate Confidence
        confidences = []
        for idx, p in enumerate(probs):
            jockey_c = X_df['jockey_compatibility'].iloc[idx] if 'jockey_compatibility' in X_df.columns else None
            distance_c = X_df['distance_compatibility'].iloc[idx] if 'distance_compatibility' in X_df.columns else None
            
            # Course compatibility
            course_c = None
            if 'turf_compatibility' in X_df.columns and 'dirt_compatibility' in X_df.columns:
                if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df.columns:
                    course_type = df['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[idx]
                    if 'èŠ' in str(course_type):
                        course_c = X_df['turf_compatibility'].iloc[idx]
                    elif 'ãƒ€' in str(course_type):
                        course_c = X_df['dirt_compatibility'].iloc[idx]
                else:
                    course_c = X_df['turf_compatibility'].iloc[idx] # Default

            is_rest = X_df['is_rest_comeback'].iloc[idx] if 'is_rest_comeback' in X_df.columns else 0
            
            # Check for history (using raw df columns if available, or heuristic on X_df)
            has_history = True
            if 'past_1_rank' in df.columns:
                 val = df['past_1_rank'].iloc[idx]
                 if pd.isna(val) or val == 0 or val == "":
                     has_history = False
            
            conf = calculate_confidence_score(p, model_meta, jockey_c, course_c, distance_c, is_rest, has_history)
            confidences.append(conf)

        df['Confidence'] = confidences

        # Merge relevant features back to df
        cols_to_merge = [
            'turf_compatibility', 'dirt_compatibility',
            'jockey_compatibility', 'distance_compatibility',
            'weighted_avg_speed', 'weighted_avg_rank',
            'dd_frame_bias', 'dd_run_style_bias',
            'jockey_win_rate', 'course_distance_record',
            'good_condition_avg', 'heavy_condition_avg',
            'stable_win_rate', 'jockey_top3_rate',
            'trend_rank', 'growth_factor',
            # éå»æˆç¸¾ãƒ‡ãƒ¼ã‚¿ã‚‚è¿½åŠ 
            'past_1_rank', 'past_2_rank', 'past_3_rank', 'past_4_rank', 'past_5_rank',
            'past_1_last_3f', 'past_2_last_3f', 'past_3_last_3f'
        ]
        for c in cols_to_merge:
            if c in X_df.columns:
                df[c] = X_df[c]

        # course_compatibilityã‚’å‹•çš„ã«ç”Ÿæˆï¼ˆã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦èŠ/ãƒ€ãƒ¼ãƒˆã‚’é¸æŠï¼‰
        if 'turf_compatibility' in df.columns and 'dirt_compatibility' in df.columns:
            if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df.columns:
                df['course_compatibility'] = df.apply(
                    lambda row: row['turf_compatibility'] if 'èŠ' in str(row.get('ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', ''))
                               else row['dirt_compatibility'] if 'ãƒ€' in str(row.get('ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—', ''))
                               else row['turf_compatibility'],  # Default to turf
                    axis=1
                )
            else:
                # ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ä¸æ˜ã®å ´åˆã¯èŠã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
                df['course_compatibility'] = df['turf_compatibility']
        elif 'turf_compatibility' in df.columns:
            df['course_compatibility'] = df['turf_compatibility']
        elif 'dirt_compatibility' in df.columns:
            df['course_compatibility'] = df['dirt_compatibility']
        else:
            df['course_compatibility'] = 5.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        return df
    except Exception as e:
        import traceback
        st.error(f"Prediction Error: {e}")
        st.code(traceback.format_exc())
        return None

def load_schedule_data(mode="JRA"):
    json_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "temp", "todays_data_nar.json" if mode == "NAR" else "todays_data.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# --- UI ---
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Logic Explanation
with st.expander("â„¹ï¸ ã“ã®AIäºˆæƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ã¤ã„ã¦ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)"):
    st.markdown("""
    ### ğŸ§  AIäºˆæƒ³ã®ä»•çµ„ã¿
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**LightGBM**ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€éå»ã®è†¨å¤§ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ1ç€ï¼ˆå‹åˆ©ï¼‰ã®ç¢ºç‡ã€ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
    
    #### ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
    - **åŸºæœ¬æƒ…å ±**: æ ç•ªã€é¦¬ç•ªã€é¦¬é½¢ã€æ–¤é‡ã€é¨æ‰‹
    - **éå»5èµ°ã®æˆç¸¾**: ç€é †ã€èµ°ç ´ã‚¿ã‚¤ãƒ ã€ä¸Šã‚Š3Fã€é€šéé †ï¼ˆè„šè³ªï¼‰ã€é¦¬ä½“é‡ã€é¦¬å ´çŠ¶æ…‹ã€**å¤©æ°—**ã€**æœ€çµ‚ã‚ªãƒƒã‚º**
    - **ç›´è¿‘é‡è¦–**: éå»ã®ãƒ¬ãƒ¼ã‚¹ã¯ç›´è¿‘ã®ã‚‚ã®ã»ã©é‡è¦è¦–ã™ã‚‹ã€Œæ™‚é–“æ¸›è¡°ã€å‡¦ç†ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
    
    #### ğŸ¯ æœŸå¾…å€¤ (EV) ã¨ã¯ï¼Ÿ
    ã€Œãã®é¦¬åˆ¸ã‚’è²·ã„ç¶šã‘ãŸã¨ãã«ã€æœ€çµ‚çš„ã«ã„ãã‚‰å„²ã‹ã‚‹ã‹ã€ã®æŒ‡æ¨™ã§ã™ã€‚
    
    $$
    \text{èª¿æ•´å¾ŒæœŸå¾…å€¤} = (\text{AIã®å‹ç‡} \times \text{ã‚ãªãŸã®å°} \times \text{ã‚ªãƒƒã‚º}) - 1.0
    $$
    
    - **ãƒ—ãƒ©ã‚¹ (0ä»¥ä¸Š)**: è²·ãˆã°è²·ã†ã»ã©å„²ã‹ã‚‹ãƒãƒ£ãƒ³ã‚¹ãŒã‚ã‚‹é¦¬ï¼ˆæ¨å¥¨ï¼ï¼‰
    - **ãƒã‚¤ãƒŠã‚¹**: å‹ã¤ç¢ºç‡ã«æ¯”ã¹ã¦ã‚ªãƒƒã‚ºãŒä½ã™ãã‚‹ï¼ˆå‰²ã«åˆã‚ãªã„ï¼‰é¦¬
    - **ã‚ãªãŸã®å°**: AIã®äºˆæ¸¬ã«ã€ã‚ãªãŸã®ç›´æ„Ÿï¼ˆâ—ã‚„â—¯ï¼‰ã‚’ãƒŸãƒƒã‚¯ã‚¹ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚AIã ã‘ã§ãªãã€ã‚ãªãŸã®ç›¸é¦¬çœ¼ã‚‚åæ˜ ã•ã‚Œã¾ã™ã€‚

    #### ğŸ‡ ä¸­å¤®ç«¶é¦¬ vs ğŸŒ™ åœ°æ–¹ç«¶é¦¬
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¼šå ´ã‹ã‚‰è‡ªå‹•çš„ã«ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰ã¨åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰ã‚’åˆ¤å®šã—ã€ãã‚Œãã‚Œã«æœ€é©åŒ–ã•ã‚ŒãŸæœŸå¾…å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    **ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.3å€, â—¯=1.15å€ï¼ˆæ§ãˆã‚ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡8%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: ãƒ¬ãƒ™ãƒ«ãŒé«˜ãã€äºˆæƒ³ãŒå …ã‚

    **åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰:**
    - å°ã®è£œæ­£ä¿‚æ•°: â—=1.8å€, â—¯=1.4å€ï¼ˆç©æ¥µçš„ï¼‰
    - å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿: AIç¢ºç‡5%æœªæº€ã¯é™¤å¤–
    - ç‰¹å¾´: æ³¢ä¹±ãŒå¤šãã€äººæ°—è–„ãŒå‹ã¡ã‚„ã™ã„

    #### ğŸ“Š ä¿¡é ¼æ€§å‘ä¸Šã®å–ã‚Šçµ„ã¿
    - **ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: è¨“ç·´æ—¥æ™‚ã€æ€§èƒ½æŒ‡æ¨™ï¼ˆAUCï¼‰ã€ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¸¸æ™‚è¡¨ç¤º
    - **äºˆæ¸¬ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: å„äºˆæ¸¬ã«ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’0-100%ã§æ•°å€¤åŒ–
    - **ãƒ‡ãƒ¼ã‚¿æ–°é®®åº¦**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’è¡¨ç¤ºï¼ˆ3æ—¥ä»¥å†…ãŒç†æƒ³ï¼‰
    - **æ³¨æ„å–šèµ·**: ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³ã‚„äºˆæ¸¬ã®é™ç•Œã‚’æ˜ç¤º
    - **é€æ˜æ€§**: ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ»é™ç•Œã‚’éš ã•ãšé–‹ç¤º
    """)

# --- Admin Menu ---
st.markdown("### è¨­å®š")
mode = st.radio("é–‹å‚¬ãƒ¢ãƒ¼ãƒ‰ (Mode)", ["JRA (ä¸­å¤®ç«¶é¦¬)", "NAR (åœ°æ–¹ç«¶é¦¬)"], horizontal=True)
mode_val = "JRA" if "JRA" in mode else "NAR"

# --- Debug Info ---
with st.expander("ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ± (Cloud Status)"):
    st.write(f"Mode: {mode_val}")
    csv_path = os.path.join(PROJECT_ROOT, "data", "raw", "database_nar.csv" if mode_val == "NAR" else "database.csv")
    if os.path.exists(csv_path):
        size_mb = os.path.getsize(csv_path) / (1024 * 1024)
        st.write(f"âœ… CSV Found: {size_mb:.1f} MB")
    else:
        st.error(f"âŒ CSV Not Found: {csv_path}")

    # History Load Check
    try:
        hist = load_history_csv(mode_val)
        if hist is not None:
             st.write(f"âœ… History Loaded: {hist.shape}")
             st.write(f"Columns ({len(hist.columns)}): {list(hist.columns)[:5]}...")
             if 'horse_id' in hist.columns:
                 st.write(f"First ID: {hist['horse_id'].iloc[0]}")
        else:
             st.error("âŒ History Load Returned None")
    except Exception as e:
        st.error(f"âŒ History Check Failed: {e}")

with st.expander("ğŸ› ï¸ ç®¡ç†ãƒ„ãƒ¼ãƒ« (ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°ãªã©)"):
    col_admin_1, col_admin_2 = st.columns([1, 1])
    with col_admin_1:
         if st.button("ğŸ“… ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’æ›´æ–° (ä»Šå¾Œ1é€±é–“)"):
            with st.spinner(f"{mode_val}ã®æœ€æ–°ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ä¸­..."):
                success, msg = auto_scraper.scrape_todays_schedule(mode=mode_val)
                if success:
                    st.success(msg)
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {msg}")
    
    with col_admin_2:
         if st.button("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿"):
             st.cache_resource.clear()
             st.success("ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ¬¡å›äºˆæ¸¬æ™‚ã«å†ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# --- Analysis Mode Selection ---
st.markdown("### åˆ†æãƒ¢ãƒ¼ãƒ‰")
analysis_mode = st.radio("æ©Ÿèƒ½ã‚’é¸æŠ", ["ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ", "ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹ã‚’æ¢ã™ (ä¸€æ‹¬åˆ†æ)"], horizontal=True)

st.markdown("---")

# --- Race Selection ---
st.subheader("ğŸ“ ãƒ¬ãƒ¼ã‚¹é¸æŠ")

schedule_data = load_schedule_data(mode=mode_val)
race_id = None

if schedule_data and "races" in schedule_data:
    races = schedule_data['races']
    
    # 1. Filter by Date
    dates = sorted(list(set([r.get('date', 'Unknown') for r in races])))
    
    if analysis_mode == "ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ":
        # Layout columns for selection
        col_date, col_venue, col_race = st.columns(3)
        
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        # Filter races by date
        todays_races = [r for r in races if r.get('date') == selected_date]
        
        if todays_races:
            # 2. Filter by Venue
            venues = sorted(list(set([r['venue'] for r in todays_races])))
            
            with col_venue:
                selected_venue = st.selectbox("2. é–‹å‚¬åœ°ã‚’é¸æŠ", venues)
                
            # Filter races by venue
            venue_races = [r for r in todays_races if r['venue'] == selected_venue]
            
            # 3. Select Race
            # Sort by race number
            venue_races.sort(key=lambda x: int(x['number']) if str(x['number']).isdigit() else 0)
            
            race_options = {f"{r['number']}R: {r['name']}": r['id'] for r in venue_races}
            
            with col_race:
                selected_label = st.selectbox("3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list(race_options.keys()))
                if selected_label:
                    race_id = race_options[selected_label]
        else:
            st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    elif analysis_mode == "ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹ã‚’æ¢ã™ (ä¸€æ‹¬åˆ†æ)":
        st.info("ğŸ’¡ **æ©Ÿèƒ½èª¬æ˜**: æŒ‡å®šã—ãŸæ—¥ã®å…¨ãƒ¬ãƒ¼ã‚¹ã‚’AIãŒåˆ†æã—ã€ä¿¡é ¼åº¦ãŒé«˜ã„ã€Œå …ã„ãƒ¬ãƒ¼ã‚¹ã€ã®ã¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚")
        
        col_date, col_venue_multi = st.columns([1, 2])
        with col_date:
             selected_date = st.selectbox("1. æ—¥ä»˜ã‚’é¸æŠ", dates)
        
        todays_races = [r for r in races if r.get('date') == selected_date]
        if todays_races:
            venues = sorted(list(set([r.get('venue', 'Unknown') for r in todays_races])))
            
            with col_venue_multi:
                 selected_venues = st.multiselect("2. é–‹å‚¬åœ°ã‚’é¸æŠ (ç©ºæ¬„ã§å…¨ä¼šå ´)", venues, default=venues)
            
            target_races = [r for r in todays_races if not selected_venues or r.get('venue') in selected_venues]
            st.write(f"å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°: {len(target_races)} ãƒ¬ãƒ¼ã‚¹")
            
            confidence_threshold = st.slider("ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (ã“ã‚Œä»¥ä¸Šã®ä¿¡é ¼åº¦ã®ãƒ¬ãƒ¼ã‚¹ã‚’è¡¨ç¤º)", 0, 100, 70)
            use_odds_bias_batch = st.checkbox("ç¾åœ¨ã‚ªãƒƒã‚ºã‚’åŠ å‘³ã™ã‚‹ (æ¨å¥¨)", value=True, help="äººæ°—é¦¬ã®ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã€ä¸äººæ°—é¦¬ã‚’ä¸‹ã’ã¾ã™")

            if st.button("ğŸš€ ä¸€æ‹¬åˆ†æã‚’é–‹å§‹ã™ã‚‹", type="primary"):
                 if not target_races:
                     st.warning("å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                 else:
                     with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                         # from app.public_app import load_model, load_model_metadata
                         # from app.public_app import load_model, load_model_metadata
                         # from app.public_app import load_model, load_model_metadata
                         model = load_model(mode_val)
                         model_meta = load_model_metadata(mode_val)
                         stats = load_stats(mode_val)

                     
                     if not model:
                         st.error("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                     else:
                         results_container = st.container()
                         progress_bar = st.progress(0)
                         status_text = st.empty()
                         
                         solid_races_data = []
                         
                         for i, race in enumerate(target_races):
                             r_name = f"{race['venue']}{race['number']}R: {race['name']}"
                             status_text.text(f"åˆ†æä¸­ ({i+1}/{len(target_races)}): {r_name}...")
                             
                             try:
                                 # 1. Scrape with cached history
                                 if i > 0: time.sleep(1) 
                                 history_df_cache = load_history_csv(mode_val)
                                 df_race = auto_scraper.scrape_shutuba_data(race['id'], mode=mode_val, history_df=history_df_cache)
                                 
                                 if df_race is not None and not df_race.empty:
                                     # 2. Predict

                                     processed_df = predict_race_logic(df_race, model, model_meta, stats=stats)
                                    
                                     # Odds Bias (Batch Mode)
                                     if use_odds_bias_batch and processed_df is not None and 'å˜å‹' in processed_df.columns:
                                         try:
                                             # Local helper or lambda
                                             calc_prob = lambda x: 0.8 / float(x) if (str(x).replace('.','',1).isdigit() and float(x) > 0) else 0
                                             
                                             processed_df['Implied_Prob'] = processed_df['å˜å‹'].apply(calc_prob)
                                             # Blend: AI 70%, Market 30%
                                             alpha = 0.7
                                             processed_df['AI_Prob_Blended'] = (processed_df['AI_Prob'] * alpha) + (processed_df['Implied_Prob'] * (1 - alpha))
                                             processed_df['AI_Score'] = (processed_df['AI_Prob_Blended'] * 100).astype(int)
                                         except Exception as e:
                                             # If error (e.g. odds not numeric), skip bias
                                             print(f"Odds bias error in batch: {e}")

                                     
                                     if processed_df is not None:
                                         # 3. Find Top Horses (Top 3)
                                         processed_df = processed_df.sort_values('AI_Score', ascending=False)
                                         
                                         top_horse = processed_df.iloc[0]
                                         conf = top_horse['Confidence']
                                         
                                         # Construct Multi-Horse String
                                         picks_str = []
                                         marks = ["â—", "â—¯", "â–²", "â–³", "â˜†"]
                                         
                                         # Helper for circled numbers (local scope)
                                         def to_circled_num_local(n):
                                             try:
                                                 val = int(float(n))
                                                 if 1 <= val <= 20:
                                                     return chr(9311 + val)
                                                 return f"({val})"
                                             except:
                                                 return ""

                                         for rank in range(min(5, len(processed_df))):
                                             h = processed_df.iloc[rank]
                                             m = marks[rank]
                                             h_num = h.get('é¦¬ ç•ª')
                                             if pd.isna(h_num): h_num = h.get('é¦¬ç•ª', '')
                                             
                                             c_num = to_circled_num_local(h_num)
                                             
                                             # Format: "â— â‘¦ ã‚¦ãƒãƒ¡ã‚¤" or "â— (7) ã‚¦ãƒãƒ¡ã‚¤" or "â— ã‚¦ãƒãƒ¡ã‚¤"
                                             if c_num:
                                                 picks_str.append(f"{m} {c_num} {h['é¦¬å']} ({h['AI_Score']}%)")
                                             elif pd.notna(h_num) and str(h_num).strip():
                                                  picks_str.append(f"{m} ({h_num}) {h['é¦¬å']} ({h['AI_Score']}%)")
                                             else:
                                                 picks_str.append(f"{m} {h['é¦¬å']} ({h['AI_Score']}%)")
                                         
                                         picks_display = " / ".join(picks_str)

                                         if conf >= confidence_threshold:
                                             solid_races_data.append({
                                                 "ä¼šå ´": race['venue'],
                                                 "R": f"{race['number']}R",
                                                 "ãƒ¬ãƒ¼ã‚¹å": race['name'],
                                                 "AIäºˆæƒ³ (â—/â—¯/â–²/â–³/â˜†)": picks_display,
                                                  # "æœ¬å‘½é¦¬": top_horse['é¦¬å'], # Removed in favor of multi-display
                                                 "ä¿¡é ¼åº¦": f"{conf}%",
                                                 # "AIæŒ‡æ•°": f"{score}%", # Included in string
                                                 "race_id": race['id']
                                             })
                             
                             except Exception as e:
                                 print(f"Error analyzing {race['id']}: {e}")
                                 
                             progress_bar.progress((i + 1) / len(target_races))
                         
                         status_text.success(f"å®Œäº†ï¼ {len(target_races)}ãƒ¬ãƒ¼ã‚¹ä¸­ã€æ¡ä»¶ã‚’æº€ãŸã™ãƒ¬ãƒ¼ã‚¹ã¯ {len(solid_races_data)} ä»¶ã§ã—ãŸã€‚")
                         
                         if solid_races_data:
                             st.markdown("### ğŸ’ å …ã„ãƒ¬ãƒ¼ã‚¹å€™è£œ")
                             res_df = pd.DataFrame(solid_races_data)
                             st.dataframe(res_df, width='stretch')
                             st.info("è©³ç´°ã‚’è¦‹ãŸã„å ´åˆã¯ã€ä¸Šã®ã€Œå€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æã€ãƒ¢ãƒ¼ãƒ‰ã§è©²å½“ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                         else:
                             st.warning("æ¡ä»¶ã‚’æº€ãŸã™å …ã„ãƒ¬ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä¿¡é ¼åº¦åŸºæº–ã‚’ä¸‹ã’ã¦ã¿ã¦ãã ã•ã„ã€‚")
        else:
             st.warning(f"{selected_date} ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
else:
    st.warning("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    # No fallback text input for now to keep it clean, or keep it inside Individual mode if needed.
    # But existing code had it. Let's omitting it for Batch mode safety.
    if analysis_mode == "ğŸ” å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹åˆ†æ":
         race_id = st.text_input("ãƒ¬ãƒ¼ã‚¹IDç›´æ¥å…¥åŠ› (12æ¡)", value="202305021211")


# Main Analysis
if race_id:
    st.header(f"ãƒ¬ãƒ¼ã‚¹åˆ†æ: {race_id}")

    # Load Model and Metadata
    model = load_model(mode=mode_val)
    model_meta = load_model_metadata(mode=mode_val)
    stats = load_stats(mode=mode_val)
    last_updated, days_ago = get_data_freshness(mode=mode_val)

    # Display Model Information and Data Freshness
    with st.expander("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ª", expanded=False):
        if model_meta:
            col_info1, col_info2, col_info3 = st.columns(3)

            with col_info1:
                st.metric(
                    "ãƒ¢ãƒ‡ãƒ«AUCï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰",
                    f"{model_meta.get('performance', {}).get('auc', 0):.3f}",
                    help="0.5=ãƒ©ãƒ³ãƒ€ãƒ ã€1.0=å®Œå…¨äºˆæ¸¬ã€‚0.75ä»¥ä¸ŠãŒç›®å®‰"
                )
                st.caption(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é‡: {model_meta.get('data_stats', {}).get('total_records', 0):,}ä»¶")

            with col_info2:
                if last_updated:
                    freshness_color = "ğŸŸ¢" if days_ago <= 3 else "ğŸŸ¡" if days_ago <= 7 else "ğŸ”´"
                    st.metric(
                        "ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°",
                        f"{days_ago}æ—¥å‰",
                        delta=f"{freshness_color} {last_updated}"
                    )
                else:
                    st.metric("ãƒ‡ãƒ¼ã‚¿æœ€çµ‚æ›´æ–°", "ä¸æ˜")

            with col_info3:
                data_size = model_meta.get('data_stats', {}).get('total_records', 0)
                if data_size < 1000:
                    quality = "âš ï¸ å°è¦æ¨¡"
                    quality_help = "ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„ãŸã‚ã€äºˆæ¸¬ç²¾åº¦ã¯é™å®šçš„ã§ã™"
                elif data_size < 3000:
                    quality = "ğŸŸ¡ ä¸­è¦æ¨¡"
                    quality_help = "ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™"
                else:
                    quality = "ğŸŸ¢ ååˆ†"
                    quality_help = "ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã§å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™"

                st.metric("ãƒ‡ãƒ¼ã‚¿å“è³ª", quality, help=quality_help)

            # Warnings
            if model_meta.get('warnings'):
                st.warning("**âš ï¸ æ³¨æ„äº‹é …:**\n" + "\n".join([f"- {w}" for w in model_meta['warnings']]))
        else:
            st.info("ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    st.markdown("### ğŸ”® AIäºˆæ¸¬è¨­å®š")
    use_odds_bias = st.checkbox("ç¾åœ¨ã‚ªãƒƒã‚ºï¼ˆäººæ°—ï¼‰ã‚’åŠ å‘³ã—ã¦AIè©•ä¾¡ã‚’è£œæ­£ã™ã‚‹", value=True, help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ã€AIã®ç´”ç²‹ãªèƒ½åŠ›è©•ä¾¡ã«ã€Œç¾åœ¨ã®ã‚ªãƒƒã‚ºï¼ˆå¸‚å ´ã®æ”¯æŒï¼‰ã€ã‚’30%ç¨‹åº¦ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã¾ã™ã€‚äººæ°—é¦¬ã®ã‚¹ã‚³ã‚¢ãŒä¸ŠãŒã‚Šã€ä¸äººæ°—é¦¬ã®ã‚¹ã‚³ã‚¢ãŒä¸‹ãŒã‚Šã¾ã™ã€‚")

    button_analyze = st.button("ğŸš€ ã“ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã™ã‚‹ (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»AIäºˆæ¸¬)", type="primary", use_container_width=True)

    if button_analyze:
        if not race_id:
             st.error("ãƒ¬ãƒ¼ã‚¹IDãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        elif not model:
             st.error(f"ãƒ¢ãƒ‡ãƒ« ({mode_val}) ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ç®¡ç†ç”»é¢ã§å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            # === å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®å¯è¦–åŒ– ===
            st.markdown("---")
            st.subheader("ğŸ”„ AIäºˆæ¸¬å‡¦ç†ãƒ•ãƒ­ãƒ¼")

            # ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()

            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å–å¾—
            status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 1/4:** å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            progress_bar.progress(25)
            history_df_cache = load_history_csv(mode_val)
            df = auto_scraper.scrape_shutuba_data(race_id, mode=mode_val, history_df=history_df_cache)

            if df is not None and not df.empty:
                status_text.success("âœ… ã‚¹ãƒ†ãƒƒãƒ— 1/4: å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—2-4: AIäºˆæ¸¬ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆå…±é€šé–¢æ•°åŒ–ï¼‰
                status_text.info("**ã‚¹ãƒ†ãƒƒãƒ— 2-4:** ç‰¹å¾´é‡è¨ˆç®—ãƒ»AIäºˆæ¸¬ãƒ»ä¿¡é ¼åº¦ç®—å‡ºã‚’å®Ÿè¡Œä¸­...")
                progress_bar.progress(60)
                
                if model:

                    processed_df = predict_race_logic(df, model, model_meta, stats=stats)
                    
                    if processed_df is not None:
                         df = processed_df
                         status_text.success("âœ… AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                         progress_bar.progress(100)
                    else:
                         status_text.error("âŒ äºˆæ¸¬å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                         df['AI_Prob'] = 0.0
                         df['AI_Score'] = 0.0
                else:
                     status_text.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                     df['AI_Prob'] = 0.0
                     df['AI_Score'] = 0.0

                # 4. Display
                # Store in session state to persist edits
                st.session_state[f'data_{race_id}'] = df

                # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                st.markdown("---")
                st.success("ğŸ‰ **AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼** ä¸‹è¨˜ã®çµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # Show Data if available
    if f'data_{race_id}' in st.session_state:
        df_display = st.session_state[f'data_{race_id}'].copy()

        # === ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã®è¡¨ç¤º ===
        st.markdown("---")
        st.subheader("ğŸ‡ ãƒ¬ãƒ¼ã‚¹æ¦‚è¦")

        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±
        col_r1, col_r2, col_r3, col_r4 = st.columns(4)
        with col_r1:
            # Try multiple possible column names for venue
            venue = "ä¸æ˜"
            for col in ['ä¼šå ´', 'venue', 'ç«¶é¦¬å ´', 'å ´æ‰€']:
                if col in df_display.columns and len(df_display) > 0:
                    venue = df_display[col].iloc[0]
                    if pd.notna(venue) and venue != "":
                        break

            # If still unknown, try to extract from race_id (first 4 digits indicate place code)
            if venue == "ä¸æ˜" and race_id and len(race_id) >= 6:
                try:
                    place_code = int(race_id[4:6])
                    place_map = {
                        1: "æœ­å¹Œ", 2: "å‡½é¤¨", 3: "ç¦å³¶", 4: "æ–°æ½Ÿ", 5: "æ±äº¬",
                        6: "ä¸­å±±", 7: "ä¸­äº¬", 8: "äº¬éƒ½", 9: "é˜ªç¥", 10: "å°å€‰",
                        30: "é–€åˆ¥", 35: "ç››å²¡", 36: "æ°´æ²¢", 42: "æµ¦å’Œ", 43: "èˆ¹æ©‹",
                        44: "å¤§äº•", 45: "å·å´", 46: "é‡‘æ²¢", 47: "ç¬ æ¾", 48: "åå¤å±‹",
                        50: "åœ’ç”°", 51: "å§«è·¯", 54: "é«˜çŸ¥", 55: "ä½è³€", 3: "å¸¯åºƒ"
                    }
                    venue = place_map.get(place_code, "ä¸æ˜")
                except:
                    pass

            st.metric("é–‹å‚¬å ´", venue)
        with col_r2:
            race_name = df_display['ãƒ¬ãƒ¼ã‚¹å'].iloc[0] if 'ãƒ¬ãƒ¼ã‚¹å' in df_display.columns else "ä¸æ˜"
            st.metric("ãƒ¬ãƒ¼ã‚¹å", race_name if len(str(race_name)) < 20 else str(race_name)[:17] + "...")
        with col_r3:
            course_type = df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0] if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns else "ä¸æ˜"
            distance = df_display['è·é›¢'].iloc[0] if 'è·é›¢' in df_display.columns else "ä¸æ˜"
            st.metric("ã‚³ãƒ¼ã‚¹", f"{course_type} {distance}m")
        with col_r4:
            num_horses = len(df_display)
            st.metric("å‡ºèµ°é ­æ•°", f"{num_horses}é ­")

        # --- ã‚ªãƒƒã‚ºåŠ å‘³ãƒ­ã‚¸ãƒƒã‚¯ (Blended Score) ---
        if use_odds_bias and 'å˜å‹' in df_display.columns:
            # å˜å‹ã‚ªãƒƒã‚ºã‹ã‚‰å¸‚å ´ã®äºˆæ¸¬ç¢ºç‡ï¼ˆImplied Probabilityï¼‰ã‚’ç®—å‡º
            # æ§é™¤ç‡ã‚’è€ƒæ…®ã—ã¦ 0.8 / ã‚ªãƒƒã‚º ã¨ã™ã‚‹ï¼ˆæ¨™æº–çš„ï¼‰
            def calc_implied_prob(x):
                try:
                    odds = float(x)
                    return 0.8 / odds if odds > 0 else 0
                except:
                    return 0

            df_display['Implied_Prob'] = df_display['å˜å‹'].apply(calc_implied_prob)
            
            # ãƒ–ãƒ¬ãƒ³ãƒ‰ (AI: 70%, Market: 30%)
            alpha = 0.7
            df_display['AI_Prob_Blended'] = (df_display['AI_Prob'] * alpha) + (df_display['Implied_Prob'] * (1 - alpha))
            
            # Update AI Score & Confidence
            # ã‚¹ã‚³ã‚¢ã¯å˜ç´”ã«ç¢ºç«‹*100
            df_display['AI_Score_Raw'] = df_display['AI_Score'] # Keep raw for reference
            df_display['AI_Score'] = (df_display['AI_Prob_Blended'] * 100).astype(int)
            
            # Update Confidence (Simple scaling for now, or keep original? 
            # Updating confidence makes sense as market agreement increases certainty)
            # But let's keep Confidence tied to "Model's Confidence" to avoid confusion?
            # Actually, if we change AI Score, we should probably align Confidence or leave it.
            # User wants "Prediction" to include odds. 
            # Let's update Confidence slightly if Market agrees.
            
            # But for simplicity and safety, let's just update the Score which drives the Ranking.
            # Confidence is "How much we trust this evaluation". If Market agrees, trust goes up?
            # Let's just update AI_Score for ranking.
            
            st.warning("âš ï¸ **ç¾åœ¨ã‚ªãƒƒã‚ºåŠ å‘³ãƒ¢ãƒ¼ãƒ‰**: AIè©•ä¾¡ã‚¹ã‚³ã‚¢ãŒå¸‚å ´äººæ°—ï¼ˆã‚ªãƒƒã‚ºï¼‰ã®å½±éŸ¿ã‚’å—ã‘ã¦è£œæ­£ã•ã‚Œã¦ã„ã¾ã™ã€‚")

        # AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼
        if 'AI_Score' in df_display.columns and 'Confidence' in df_display.columns:
            avg_confidence = df_display['Confidence'].mean()
            max_ai_score = df_display['AI_Score'].max()
            st.info(f"ğŸ“Š **AIäºˆæ¸¬ã‚µãƒãƒªãƒ¼**: æœ€é«˜AIå‹ç‡ {max_ai_score}% | å¹³å‡ä¿¡é ¼åº¦ {avg_confidence:.0f}%")

        # ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã®è©³ç´°è¡¨ç¤º
        venue = df_display['ä¼šå ´'].iloc[0] if 'ä¼šå ´' in df_display.columns else None
        if venue:
            try:
                from ml.venue_characteristics import get_venue_characteristics
                venue_char = get_venue_characteristics(venue)

                if venue_char:
                    st.markdown("#### ğŸŸï¸ ã‚³ãƒ¼ã‚¹ç‰¹æ€§")

                    col_c1, col_c2, col_c3, col_c4 = st.columns(4)

                    # ç›´ç·šè·é›¢
                    with col_c1:
                        straight = venue_char.get('turf_straight', 0)
                        if straight:
                            straight_label = "é•·ã„" if straight > 500 else "çŸ­ã„" if straight < 300 else "æ¨™æº–"
                            st.metric("ç›´ç·šè·é›¢", f"{straight}m", delta=straight_label)
                        else:
                            st.metric("ç›´ç·šè·é›¢", "ä¸æ˜")

                    # å‹¾é…ï¼ˆå‚¾æ–œï¼‰
                    with col_c2:
                        slope = venue_char.get('slope', 'normal')
                        slope_map = {
                            'steep': 'æ€¥å‚ã‚ã‚Š',
                            'moderate': 'ç·©ã‚„ã‹ãªå‚',
                            'flat': 'å¹³å¦',
                            'normal': 'æ¨™æº–'
                        }
                        slope_label = slope_map.get(slope, slope)
                        slope_icon = "â›°ï¸" if slope == 'steep' else "ğŸ”ï¸" if slope == 'moderate' else "â”"
                        st.metric("å‹¾é…ï¼ˆå‚¾æ–œï¼‰", slope_label, delta=slope_icon)

                    # ã‚³ãƒ¼ã‚¹å¹…
                    with col_c3:
                        track_width = venue_char.get('track_width', 'standard')
                        width_map = {
                            'narrow': 'å°å›ã‚Š',
                            'standard': 'æ¨™æº–',
                            'wide': 'åºƒã„ã‚³ãƒ¼ã‚¹'
                        }
                        width_label = width_map.get(track_width, track_width)
                        st.metric("ã‚³ãƒ¼ã‚¹å¹…", width_label)

                    # å¤–æ æœ‰åˆ©åº¦
                    with col_c4:
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        if outer_advantage > 1.05:
                            outer_label = "å¤–æ æœ‰åˆ©"
                            outer_delta = "â†‘"
                        elif outer_advantage < 0.95:
                            outer_label = "å†…æ æœ‰åˆ©"
                            outer_delta = "â†“"
                        else:
                            outer_label = "å…¬å¹³"
                            outer_delta = "="
                        st.metric("æ ç•ªå‚¾å‘", outer_label, delta=outer_delta)

                    # ç‰¹æ€§ã®å½±éŸ¿èª¬æ˜
                    with st.expander("ğŸ’¡ ã“ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ãŒEVè¨ˆç®—ã«ä¸ãˆã‚‹å½±éŸ¿", expanded=False):
                        st.markdown(f"""
                        #### ğŸŸï¸ {venue}ã®ç‰¹æ€§

                        **1. ç›´ç·šè·é›¢: {straight}m ({straight_label})**
                        - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: äººæ°—é¦¬ã‚„ã‚„ä¸åˆ© (-5%)ã€ç©´é¦¬ã‚„ã‚„æœ‰åˆ© (+5%)
                        - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: äººæ°—é¦¬æœ‰åˆ© (+5%)ã€ç©´é¦¬ä¸åˆ© (-5%)
                        - ç†ç”±: é•·ã„ç›´ç·šã¯å·®ã—é¦¬ã«æœ‰åˆ©ã€çŸ­ã„ç›´ç·šã¯é€ƒã’ãƒ»å…ˆè¡Œé¦¬ã«æœ‰åˆ©

                        **2. å‹¾é…ï¼ˆå‚¾æ–œï¼‰: {slope_label}**
                        - æ€¥å‚ã‚ã‚Š: äººæ°—é¦¬ï¼ˆãƒ‘ãƒ¯ãƒ¼ãŒã‚ã‚‹é¦¬ï¼‰ãŒæœ‰åˆ© (+2%)
                        - ç†ç”±: å‚ã‚’ç™»ã‚‹éš›ã«é¦¬åŠ›ãŒå¿…è¦ã§ã€å®Ÿç¸¾é¦¬ãŒå„ªä½
                        - è©²å½“ç«¶é¦¬å ´: ä¸­å±±ã€é˜ªç¥ãªã©

                        **3. ã‚³ãƒ¼ã‚¹å¹…: {width_label}**
                        - å°å›ã‚Š: äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ© (+3%)
                        - ç†ç”±: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãã€å™¨ç”¨ã•ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹

                        **4. æ ç•ªå‚¾å‘: {outer_label}**
                        - å¤–æ æœ‰åˆ©ãªå ´åˆ: 6-8æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´ (Ã—{outer_advantage:.2f})
                        - å†…æ æœ‰åˆ©ãªå ´åˆ: 1-3æ ã®é¦¬ã®ç¢ºç‡ã‚’èª¿æ•´

                        âš ï¸ ã“ã‚Œã‚‰ã®èª¿æ•´ã¯æœŸå¾…å€¤(EV)è¨ˆç®—æ™‚ã«è‡ªå‹•çš„ã«é©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
                        """)
            except Exception as e:
                pass  # venue_characteristics ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        # Prepare Editor DF
        # Columns: Horse, Prob, Odds, Mark
        if 'Odds' not in df_display.columns:
             # Try to get scraped odds if available
             if 'å˜å‹' in df_display.columns:
                 df_display['Odds'] = pd.to_numeric(df_display['å˜å‹'], errors='coerce').fillna(0.0)
             else:
                 df_display['Odds'] = 0.0
        
        # course_compatibilityãŒpredict_race_logicã§æ—¢ã«ç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ç”Ÿæˆ
        if 'course_compatibility' not in df_display.columns:
            # Select appropriate course compatibility
            # If 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' contains 'èŠ', use turf, else dirt
            # Default to turf if unknown
            is_turf_race = True
            if 'ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—' in df_display.columns:
                 # Check first row (all same race)
                 c_type = str(df_display['ã‚³ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—'].iloc[0])
                 if 'ãƒ€' in c_type:
                     is_turf_race = False

            if is_turf_race:
                 df_display['course_compatibility'] = df_display.get('turf_compatibility', 5.0)
            else:
                 df_display['course_compatibility'] = df_display.get('dirt_compatibility', 5.0)

        # === é©æ€§ã‚¹ã‚³ã‚¢ã‚’é©æ€§åº¦ã«å¤‰æ›ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„æ–¹ãŒè‰¯ã„ï¼‰ ===
        # å…ƒã®å€¤ã¯ã€Œå¹³å‡ç€é †ã€ï¼ˆå°ã•ã„æ–¹ãŒè‰¯ã„ï¼‰
        # é©æ€§åº¦ = 10 - å¹³å‡ç€é †ï¼ˆ0-10ç‚¹ã€é«˜ã„æ–¹ãŒè‰¯ã„ï¼‰

        for compat_col in ['jockey_compatibility', 'distance_compatibility', 'course_compatibility']:
            if compat_col in df_display.columns:
                # 10 - (å€¤ / 2) ã§ã‚¹ã‚³ã‚¢åŒ– (å¹³å‡ç€é †10.0 -> 5.0ç‚¹)
                # 1ä½ -> 9.5ç‚¹, 18ä½ -> 1.0ç‚¹
                df_display[compat_col] = df_display[compat_col].apply(
                    lambda x: max(0, min(10, 10 - (x / 2))) if pd.notna(x) else 5.0
                )

        rename_map = {
            'AI_Score': 'AIã‚¹ã‚³ã‚¢(%)',
            'Confidence': 'ä¿¡é ¼åº¦',
            'Odds': 'ç¾åœ¨ã‚ªãƒƒã‚º',
            'æ€§é½¢': 'å¹´é½¢',
            'é¦¬ ç•ª': 'é¦¬ç•ª',
            'jockey_compatibility': 'é¨æ‰‹é©æ€§åº¦',
            'distance_compatibility': 'è·é›¢é©æ€§åº¦',
            'course_compatibility': 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦',
            'turf_compatibility': 'èŠé©æ€§åº¦',
            'dirt_compatibility': 'ãƒ€ãƒ¼ãƒˆé©æ€§åº¦',
            'weighted_avg_speed': 'å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰',
            'weighted_avg_rank': 'å¹³å‡ç€é †',
            'jockey_win_rate': 'é¨æ‰‹å‹ç‡',
            'stable_win_rate': 'å©èˆå‹ç‡',
            'good_condition_avg': 'è‰¯é¦¬å ´é©æ€§',
            'heavy_condition_avg': 'é‡é¦¬å ´é©æ€§',
            'trend_rank': 'ç€é †ãƒˆãƒ¬ãƒ³ãƒ‰',
            'growth_factor': 'æˆé•·ä¿‚æ•°',
            'past_1_rank': 'å‰èµ°ç€é †',
            'past_2_rank': 'å‰ã€…èµ°ç€é †',
            'past_3_rank': '3èµ°å‰ç€é †'
        }

        # Ensure all display columns exist
        defaults = {
            'jockey_compatibility': 10.0,
            'distance_compatibility': 10.0,
            'course_compatibility': 10.0,
            'turf_compatibility': 10.0,
            'dirt_compatibility': 10.0,
            'weighted_avg_speed': 16.0,
            'weighted_avg_rank': 7.0,
            'jockey_win_rate': 0.1,
            'stable_win_rate': 0.1,
            'good_condition_avg': 10.0,
            'heavy_condition_avg': 10.0,
            'trend_rank': 0.0,
            'growth_factor': 1.0,
            'Confidence': 50,
            'past_1_rank': 0,
            'past_2_rank': 0,
            'past_3_rank': 0
        }
        for c, v in defaults.items():
            if c not in df_display.columns:
                df_display[c] = v

        # Add Mark column BEFORE selecting display columns
        if 'äºˆæƒ³å°' not in df_display.columns:
            df_display['äºˆæƒ³å°'] = ""

        # Display columns with äºˆæƒ³å° next to é¦¬åï¼ˆåŸºæœ¬æƒ…å ±+ä¸»è¦é©æ€§åº¦ï¼‰
        display_cols = [
            'æ ', 'é¦¬ ç•ª', 'é¦¬å', 'äºˆæƒ³å°', 'æ€§é½¢',
            'AI_Score', 'Confidence', 'Odds',
            'jockey_compatibility', 'course_compatibility', 'distance_compatibility',
            'weighted_avg_rank', 'past_1_rank', 'past_2_rank'
        ]


        edited_df = df_display[display_cols].copy()
        edited_df.rename(columns=rename_map, inplace=True)
        
        st.subheader("ğŸ“ äºˆæƒ³ãƒ»ã‚ªãƒƒã‚ºå…¥åŠ›")
        
        col_input_1, col_input_2 = st.columns([3, 1])
        with col_input_1:
             st.info("ã€Œäºˆæƒ³å°ã€ã‚„ã€Œç¾åœ¨ã‚ªãƒƒã‚ºã€ã‚’ç·¨é›†ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœŸå¾…å€¤(EV)ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
        with col_input_2:
             if st.button("ğŸ”„ æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—"):
                 with st.spinner("æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­..."):
                     try:
                         current_odds = auto_scraper.scrape_odds_for_race(race_id, mode=mode_val)
                         # Update session state df
                         if current_odds:
                             odds_map = {x['number']: x['odds'] for x in current_odds}
                             
                             target_df = st.session_state[f'data_{race_id}']
                             
                             # Update 'å˜å‹' and 'Odds', and 'è¤‡å‹ä¸‹é™'
                             def update_odds(row):
                                 try:
                                     num = int(row['é¦¬ ç•ª'])
                                     d = {
                                         'Odds': odds_map.get(num, {}).get('odds', row.get('Odds', 0.0)),
                                         'PlaceMin': odds_map.get(num, {}).get('place_odds_min', row.get('PlaceMin', 0.0))
                                     }
                                     return d
                                 except:
                                     return {'Odds': row.get('Odds', 0.0), 'PlaceMin': row.get('PlaceMin', 0.0)}
                                 
                             # Apply updates
                             updated_data = target_df.apply(update_odds, axis=1, result_type='expand')
                             target_df['Odds'] = updated_data['Odds']
                             target_df['å˜å‹'] = updated_data['Odds']
                             target_df['PlaceMin'] = updated_data['PlaceMin']
                             target_df['è¤‡å‹ä¸‹é™'] = updated_data['PlaceMin']
                             
                             st.session_state[f'data_{race_id}'] = target_df
                             st.success("ã‚ªãƒƒã‚ºï¼ˆå˜å‹ãƒ»è¤‡å‹ï¼‰ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")
                             st.rerun()
                         else:
                             st.warning("ã‚ªãƒƒã‚ºã®å–å¾—ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                     except Exception as e:
                         st.error(f"ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        # Ensure PlaceMin exists
        if 'è¤‡å‹ä¸‹é™' not in edited_df.columns:
            edited_df['è¤‡å‹ä¸‹é™'] = 0.0
        
        edited_df = st.data_editor(
            edited_df,
            column_config={
                "AIã‚¹ã‚³ã‚¢(%)": st.column_config.ProgressColumn(
                    "AIå‹ç‡(%)",
                    help="1ç€ã«ãªã‚‹ AIäºˆæ¸¬ç¢ºç‡",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ä¿¡é ¼åº¦": st.column_config.ProgressColumn(
                    "äºˆæ¸¬ä¿¡é ¼åº¦",
                    help="ã“ã®äºˆæ¸¬ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢",
                    format="%d%%",
                    min_value=0,
                    max_value=100,
                ),
                "ç¾åœ¨ã‚ªãƒƒã‚º": st.column_config.NumberColumn(
                    "å˜å‹ã‚ªãƒƒã‚º",
                    help="å˜å‹ã‚ªãƒƒã‚ºï¼ˆå‚è€ƒï¼‰",
                    step=0.1,
                    format="%.1f"
                ),
                "è¤‡å‹ä¸‹é™": st.column_config.NumberColumn(
                    "è¤‡å‹ä¸‹é™",
                    help="è¤‡å‹ã‚ªãƒƒã‚ºã®ä¸‹é™å€¤ã€‚å‚è€ƒæƒ…å ±",
                    step=0.1,
                    format="%.1f"
                ),
                "å˜å‹æœŸå¾…å€¤": st.column_config.NumberColumn(
                    "å˜å‹æœŸå¾…å€¤",
                    help="ç´”ç²‹ãªå˜å‹æœŸå¾…å€¤ = (AIå‹ç‡ Ã— å˜å‹ã‚ªãƒƒã‚º) - 1.0",
                    format="%.2f"
                ),
                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(
                    "èª¿æ•´å¾ŒæœŸå¾…å€¤",
                    help="å°ãƒ»é©æ€§ã‚’åŠ å‘³ã—ãŸæœ€çµ‚çš„ãªå˜å‹æœŸå¾…å€¤",
                    format="%.2f"
                ),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(
                    "æ¨å¥¨åº¦(Kelly)",
                    help="ã‚±ãƒªãƒ¼åŸºæº–ã«ã‚ˆã‚‹æ¨å¥¨è³­ã‘ç‡",
                    format="%.1f%%",
                    min_value=0,
                    max_value=30, 
                ),
                "äºˆæƒ³å°": st.column_config.SelectboxColumn(
                    "äºˆæƒ³å°",
                    options=["", "â—", "â—¯", "â–²", "â–³", "âœ•"],
                    required=False,
                    help="äºˆæƒ³å°ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€èª¿æ•´å¾ŒæœŸå¾…å€¤ã«åæ˜ ã•ã‚Œã¾ã™"
                ),
                "é¨æ‰‹é©æ€§åº¦": st.column_config.ProgressColumn(
                    "é¨æ‰‹é©æ€§åº¦",
                    help="ã“ã®é¨æ‰‹ã¨ã®ç›¸æ€§",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                ),
                "ã‚³ãƒ¼ã‚¹é©æ€§åº¦": st.column_config.ProgressColumn(
                    "ã‚³ãƒ¼ã‚¹é©æ€§åº¦",
                    help="èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ ç›¸æ€§",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                ),
                "è·é›¢é©æ€§åº¦": st.column_config.ProgressColumn(
                    "è·é›¢é©æ€§åº¦",
                    help="ã“ã®è·é›¢ã§ã®ç›¸æ€§",
                    format="%.1f",
                    min_value=0,
                    max_value=10
                )
            },
            hide_index=True,
            num_rows="fixed"  
        )
        
        # Calculate EV with JRA/NAR distinction
        # Determine race type from user's mode selection (as primary source)
        race_type = mode_val  # Use user's selected mode (JRA or NAR) as primary source of truth
        venue = ''  # Initialize venue

        # Get venue information if available
        if 'ä¼šå ´' in df_display.columns and len(df_display) > 0:
            venue = df_display['ä¼šå ´'].iloc[0]

            # If venue is available, use it to verify/override race_type for accuracy
            if venue:
                try:
                    import sys
                    import os
                    sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(__file__)), 'ml'))
                    from race_classifier import classify_race_type
                    venue_based_type = classify_race_type(venue)
                    # Use venue-based classification (more accurate than mode selection)
                    race_type = venue_based_type
                except:
                    # Fallback: manual classification
                    jra_venues = ['æœ­å¹Œ', 'å‡½é¤¨', 'ç¦å³¶', 'æ–°æ½Ÿ', 'æ±äº¬', 'ä¸­å±±', 'ä¸­äº¬', 'äº¬éƒ½', 'é˜ªç¥', 'å°å€‰']
                    race_type = 'JRA' if venue in jra_venues else 'NAR'

        # EV calculation with race type AND venue specific parameters
        # Import venue characteristics
        venue_char = None
        try:
            from ml.venue_characteristics import get_venue_characteristics, get_distance_category
            if venue:
                venue_char = get_venue_characteristics(venue)
        except Exception as e:
            # Silently fail if venue characteristics not available
            pass

        # === UI: ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–ã®é¸æŠ ===
        st.markdown("#### ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–")
        ranking_criteria = st.radio(
            "è©•ä¾¡æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:", 
            ["çš„ä¸­ç‡é‡è¦– (AIã‚¹ã‚³ã‚¢)", "å›åç‡é‡è¦– (æœŸå¾…å€¤)"], 
            horizontal=True,
            help="ã€Œçš„ä¸­ç‡ã€ã¯ã‚ªãƒƒã‚ºã‚’ç„¡è¦–ã—ã¦ç´”ç²‹ã«å‹ã¤ç¢ºç‡ãŒé«˜ã„é¦¬ã‚’æ¢ã—ã¾ã™ã€‚ã€Œå›åç‡ã€ã¯ã‚ªãƒƒã‚ºã‚’è€ƒæ…®ã—ã¦å„²ã‹ã‚‹é¦¬ã‚’æ¢ã—ã¾ã™ã€‚"
        )


        # Base parameters by race type
        if race_type == 'JRA':
            # === ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰è¨­å®š ===
            # ç‰¹å¾´: å®ŸåŠ›ãŒæ‹®æŠ—ã—ã¦ãŠã‚Šã€æ··æˆ¦ã«ãªã‚Šã‚„ã™ã„ã€‚ã‚ªãƒƒã‚ºã‚‚å‰²ã‚ŒãŒã¡ã€‚
            # å¯¾ç­–: çªå‡ºã—ãŸè£œæ­£ã¯é¿ã‘ã€ãƒ•ãƒ©ãƒƒãƒˆã«è¿‘ã„è©•ä¾¡ã‚’è¡Œã†ã€‚
            mark_weights = {
                "â—": 1.15,  # æœ¬å‘½: ä¿¡é ¼ã—ã™ããªã„ (1.15å€)
                "â—¯": 1.10,  # å¯¾æŠ—: 1.10å€
                "â–²": 1.05,  # å˜ç©´: 1.05å€
                "â–³": 1.02,  # é€£ä¸‹: 1.02å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.04  # 1ç€ç¢ºç‡4%æœªæº€ã¯é™¤å¤–
            venue_info = f"ğŸ‡ ä¸­å¤®ç«¶é¦¬ï¼ˆJRAï¼‰" + (f" - {venue}" if venue else "")
        else:
            # === åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰è¨­å®š ===
            # ç‰¹å¾´: èƒ½åŠ›å·®ãŒå¤§ããã€å¼·ã„é¦¬ãŒé †å½“ã«å‹ã¤ã“ã¨ãŒå¤šã„ï¼ˆå …ã„æ±ºç€ï¼‰ã€‚
            # å¯¾ç­–: AIãŒé¸ã‚“ã æœ¬å‘½é¦¬ã¯ä¿¡é ¼ã§ãã‚‹ãŸã‚ã€è©•ä¾¡ã‚’å°‘ã—é«˜ã‚ã‚‹ã€‚
            mark_weights = {
                "â—": 1.30,  # æœ¬å‘½: æ¯”è¼ƒçš„ä¿¡é ¼ã§ãã‚‹ (1.3å€)
                "â—¯": 1.15,  # å¯¾æŠ—: 1.15å€
                "â–²": 1.10,  # å˜ç©´: 1.10å€
                "â–³": 1.05,  # é€£ä¸‹: 1.05å€
                "âœ•": 0.0,   # æ¶ˆã—: 0å€
                "": 1.0     # å°ãªã—: 1.0å€
            }
            safety_threshold = 0.03  # 1ç€ç¢ºç‡3%æœªæº€ã¯é™¤å¤–
            venue_info = f"ğŸŒ™ åœ°æ–¹ç«¶é¦¬ï¼ˆNARï¼‰" + (f" - {venue}" if venue else "")

        # Venue-specific adjustments
        venue_features = []
        if venue_char:
            # ç›´ç·šè·é›¢ã«ã‚ˆã‚‹èª¿æ•´
            straight = venue_char.get('turf_straight', 300)
            if straight and straight > 500:  # é•·ã„ç›´ç·šï¼ˆæ–°æ½Ÿãªã©ï¼‰
                mark_weights["â—"] *= 0.95  # äººæ°—é¦¬ã‚„ã‚„ä¸åˆ©
                mark_weights["â–³"] *= 1.05  # ç©´é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("é•·ç›´ç·š")
            elif straight and straight < 300:  # çŸ­ã„ç›´ç·šï¼ˆä¸­å±±ã€å‡½é¤¨ãªã©ï¼‰
                mark_weights["â—"] *= 1.05  # äººæ°—é¦¬æœ‰åˆ©
                mark_weights["â–³"] *= 0.95  # ç©´é¦¬ä¸åˆ©
                venue_features.append("çŸ­ç›´ç·š")

            # ã‚³ãƒ¼ã‚¹å¹…ã«ã‚ˆã‚‹èª¿æ•´
            track_width = venue_char.get('track_width')
            if track_width == 'narrow':  # ç‹­ã„ã‚³ãƒ¼ã‚¹
                mark_weights["â—"] *= 1.03  # å…ˆè¡Œæœ‰åˆ©ã€äººæ°—é¦¬ã‚„ã‚„æœ‰åˆ©
                venue_features.append("å°å›ã‚Š")
            elif track_width == 'wide':  # åºƒã„ã‚³ãƒ¼ã‚¹
                # é¦¬ç¾¤ãŒåºƒãŒã‚Šã‚„ã™ãã€å±•é–‹æ¬¡ç¬¬
                pass

            # å‹¾é…ã«ã‚ˆã‚‹èª¿æ•´
            slope = venue_char.get('slope')
            if slope == 'steep':  # æ€¥å‚ã‚ã‚Šï¼ˆä¸­å±±ãªã©ï¼‰
                mark_weights["â—"] *= 1.02  # ãƒ‘ãƒ¯ãƒ¼ã‚ã‚‹äººæ°—é¦¬æœ‰åˆ©
                venue_features.append("å‚ã‚ã‚Š")

        if venue_features:
            venue_info += f" ({', '.join(venue_features)})"

        st.info(venue_info)

        # === ç¢ºç‡è¼ƒæ­£ã®ãƒã‚§ãƒƒã‚¯ ===
        is_calibrated = False
        if model_meta and 'training_config' in model_meta:
             is_calibrated = model_meta['training_config'].get('calibrated', False)

        # Uncalibrated NAR Correction (Global application for consistency)
        if race_type == 'NAR' and not is_calibrated:
             # åœ°æ–¹ç«¶é¦¬ã‹ã¤æœªè¼ƒæ­£ã®å ´åˆã®ã¿ã€ä¿å®ˆçš„ãªèª¿æ•´ã‚’è¡Œã†
             # ã“ã‚Œã«ã‚ˆã‚Šã€è¡¨ç¤ºã•ã‚Œã‚‹AIã‚¹ã‚³ã‚¢ã¨EVè¨ˆç®—ã«ä½¿ã‚ã‚Œã‚‹ç¢ºç‡ãŒä¸€è‡´ã™ã‚‹
             def adjust_nar_prob_row(row):
                 p = row['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
                 new_p = p * 0.9 + 0.05
                 return int(new_p * 100)
             
             edited_df['AIã‚¹ã‚³ã‚¢(%)'] = edited_df.apply(adjust_nar_prob_row, axis=1)
             st.caption("â„¹ï¸ NARèª¿æ•´: AIã‚¹ã‚³ã‚¢ã¨æœŸå¾…å€¤ã‚’ä¿å®ˆçš„ã«è£œæ­£ã—ã¾ã—ãŸï¼ˆæœªè¼ƒæ­£ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ï¼‰")

        probs = edited_df['AIã‚¹ã‚³ã‚¢(%)'] / 100.0
        odds = edited_df['ç¾åœ¨ã‚ªãƒƒã‚º']
        place_min_odds = edited_df['è¤‡å‹ä¸‹é™'] # Use Place Odds
        marks = edited_df['äºˆæƒ³å°']
        confidences = edited_df['ä¿¡é ¼åº¦']

        # Get run style compatibility if available
        run_style_compatibility = None
        if 'venue_run_style_compatibility' in edited_df.columns:
            run_style_compatibility = edited_df['venue_run_style_compatibility']

        # Get frame (æ ) for venue-specific frame advantage
        frames = None
        if 'æ ' in edited_df.columns:
            frames = edited_df['æ ']

        evs_pure = []      # ç´”ç²‹EVï¼ˆå°è£œæ­£ãªã—ï¼‰
        evs_adjusted = []  # èª¿æ•´å¾ŒEVï¼ˆå°è£œæ­£ã‚ã‚Šï¼‰
        kellys = []
        bias_reasons_list = [] # è£œæ­£ç†ç”±ãƒªã‚¹ãƒˆ

        for idx, (p, o_win, o_place, m, c) in enumerate(zip(probs, odds, place_min_odds, marks, confidences)):
            reasons = [] # ã“ã®é¦¬ã®è£œæ­£ç†ç”±
            
            # Use Win Odds for EV Calculation (since we are predicting target_win)
            calc_odds = 0.0
            if o_win > 1.0:
                 calc_odds = o_win
            elif o_place > 1.0:
                 # Fallback if Win Odds missing but Place Odds exist (rare)
                 calc_odds = o_place * 3.0
                 reasons.append("å˜å‹æ¨å®š")
            
            # Safety filter (race type specific)
            if p < safety_threshold:
                ev_pure = -1.0
                ev_adj = -1.0
                kelly = 0.0
                reasons.append("ç¢ºç‡ä¸è¶³(é™¤å¤–)")
            else:
                w = mark_weights.get(m, 1.0)
                if w != 1.0:
                     reasons.append(f"å°{m} (x{w:.2f})")
                
                # Already adjusted in Dataframe if needed
                adjusted_p = p

                # Apply run style compatibility if available
                if run_style_compatibility is not None:
                    run_compat = run_style_compatibility.iloc[idx]
                    if not pd.isna(run_compat) and run_compat != 1.0:
                        # è„šè³ªç›¸æ€§ãŒè‰¯ã„é¦¬ã¯æœŸå¾…å€¤ã‚’ä¸Šã’ã‚‹
                        adjusted_p *= run_compat
                        reasons.append(f"è„šè³ªé©æ€§ (x{run_compat:.2f})")

                # Apply frame advantage if available
                if frames is not None and venue_char:
                    frame = frames.iloc[idx]
                    if not pd.isna(frame):
                        outer_advantage = venue_char.get('outer_track_advantage', 1.0)
                        try:
                            frame_num = int(frame)
                            if frame_num >= 6 and outer_advantage > 1.0:  # å¤–æ æœ‰åˆ©
                                adjusted_p *= outer_advantage
                                reasons.append(f"å¤–æ æœ‰åˆ© (x{outer_advantage:.2f})")
                            elif frame_num <= 3 and outer_advantage > 1.0:  # å†…æ ä¸åˆ©
                                penalty = 2.0 - outer_advantage
                                adjusted_p *= penalty
                                reasons.append(f"å†…æ ä¸åˆ© (x{penalty:.2f})")
                            
                            # å†…æ æœ‰åˆ©ãªå ´åˆ(outer_advantage < 1.0)
                            elif frame_num <= 3 and outer_advantage < 1.0:
                                bonus = 2.0 - outer_advantage
                                adjusted_p *= bonus
                                reasons.append(f"å†…æ æœ‰åˆ© (x{bonus:.2f})")
                            elif frame_num >= 6 and outer_advantage < 1.0:
                                adjusted_p *= outer_advantage
                                reasons.append(f"å¤–æ ä¸åˆ© (x{outer_advantage:.2f})")
                                
                        except: pass

                # ç´”ç²‹EV: å°è£œæ­£ãªã—ï¼ˆçµ±è¨ˆçš„ã«æ­£ã—ã„ï¼‰
                # Uses Place Odds
                ev_pure = (adjusted_p * calc_odds) - 1.0

                # èª¿æ•´å¾ŒEV: å°ãƒ»ä¿¡é ¼åº¦è£œæ­£ã‚ã‚Šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»è¦³ï¼‹ãƒªã‚¹ã‚¯æ›ç®—ï¼‰
                # ä¿¡é ¼åº¦(c)ã‚’ä¹—ç®—ã™ã‚‹ã“ã¨ã§ã€ã€ŒAIãŒè‡ªä¿¡ã®ãªã„ç©´é¦¬ã€ã®EVéå¤§è©•ä¾¡ã‚’é˜²ã
                trust_factor = c / 100.0
                ev_adj = (adjusted_p * w * calc_odds * trust_factor) - 1.0
                
                if trust_factor < 0.6:
                     reasons.append(f"ä¿¡é ¼åº¦ä½ (x{trust_factor:.2f})")

                # Kelly criterion: æœ€é©è³­ã‘é‡‘æ¯”ç‡ã®è¨ˆç®—
                # Formula: f* = (p * odds - 1) / (odds - 1)
                # ã“ã“ã§pã¯èª¿æ•´å¾Œã®ç¢ºç‡ã€oddsã¯ã‚ªãƒƒã‚º
                if calc_odds > 1.0:
                    kelly_raw = (adjusted_p * w * calc_odds - 1.0) / (calc_odds - 1.0)
                    # è² ã®å€¤ã¯0ã«ã€ä¸Šé™ã¯10%ã«åˆ¶é™ï¼ˆãƒªã‚¹ã‚¯ç®¡ç†ï¼‰
                    kelly = max(0.0, min(0.10, kelly_raw)) * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
                else:
                    kelly = 0.0
            
            evs_pure.append(ev_pure)
            evs_adjusted.append(ev_adj)
            kellys.append(kelly)
            bias_reasons_list.append(", ".join(reasons) if reasons else "-")

        edited_df['å˜å‹æœŸå¾…å€¤'] = evs_pure
        edited_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] = evs_adjusted
        edited_df['æ¨å¥¨åº¦(Kelly)'] = kellys
        edited_df['è£œæ­£å†…å®¹'] = bias_reasons_list

        # === AIæœŸå¾…åº¦TOP5ã®ã‚°ãƒ©ãƒ•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡¨ç¤ºï¼‰ ===
        st.markdown("---")
        st.subheader("ğŸ“Š AIè©•ä¾¡ TOP5 åˆ†æ")

        # TOP5ã‚’AIã‚¹ã‚³ã‚¢ï¼ˆå‹ç‡ï¼‰ã§ã‚½ãƒ¼ãƒˆï¼ˆçš„ä¸­ç‡é‡è¦–ï¼‰

        

        # Apply sorting based on ranking criteria
        if ranking_criteria == "å›åç‡é‡è¦– (æœŸå¾…å€¤)":
            edited_df.sort_values(by='èª¿æ•´å¾ŒæœŸå¾…å€¤', ascending=False, inplace=True)
            y_col = 'èª¿æ•´å¾ŒæœŸå¾…å€¤'
            y_label = 'æœŸå¾…å€¤(EV)'
            bar_color = '#28a745'
        else: # "çš„ä¸­ç‡é‡è¦– (AIã‚¹ã‚³ã‚¢)"
            edited_df.sort_values(by='AIã‚¹ã‚³ã‚¢(%)', ascending=False, inplace=True)
            y_col = 'AIã‚¹ã‚³ã‚¢(%)'
            y_label = 'AIã‚¹ã‚³ã‚¢(%)'
            bar_color = '#1f77b4'

        top5_df = edited_df.head(5)
        
        # Plot Top 5
        st.subheader(f"ğŸ“ˆ {ranking_criteria} TOP 5")
        
        fig_top5 = go.Figure(go.Bar(
            x=top5_df['é¦¬å'],
            y=top5_df[y_col],
            text=top5_df[y_col].apply(lambda x: f"{x:.2f}" if y_col == 'èª¿æ•´å¾ŒæœŸå¾…å€¤' else f"{x}%"),
            textposition='auto',
            marker_color=bar_color
        ))
        fig_top5.update_layout(
            yaxis_title=y_label,
            xaxis_title="é¦¬å",
            height=400,
            showlegend=False
        )

        st.plotly_chart(fig_top5, width="stretch")

        # è£œæ­£å†…å®¹ã®è¡¨ç¤º
        st.markdown("##### â„¹ï¸ æœŸå¾…å€¤èª¿æ•´ã®è©³ç´° (TOP5)")
        st.dataframe(
            top5_df[['äºˆæƒ³å°', 'é¦¬å', 'ç¾åœ¨ã‚ªãƒƒã‚º', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'è£œæ­£å†…å®¹']],
            column_config={
                "èª¿æ•´å¾ŒæœŸå¾…å€¤": st.column_config.NumberColumn(format="%.2f"),
                "æ¨å¥¨åº¦(Kelly)": st.column_config.ProgressColumn(format="%.1f%%", max_value=30),
            },
            hide_index=True,
            width='stretch'
        )

        # 2. é©æ€§ã‚¹ã‚³ã‚¢æ¯”è¼ƒï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰
        st.markdown("#### ğŸ¯ TOP5 é©æ€§åº¦æ¯”è¼ƒ")

        compatibility_cols = ['é¨æ‰‹é©æ€§åº¦', 'ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 'è·é›¢é©æ€§åº¦']
        compat_data = []
        for idx, row in top5_df.iterrows():
            compat_data.append({
                'é¦¬å': row['é¦¬å'],
                'é¨æ‰‹é©æ€§åº¦': row.get('é¨æ‰‹é©æ€§åº¦', 5.0),
                'ã‚³ãƒ¼ã‚¹é©æ€§åº¦': row.get('ã‚³ãƒ¼ã‚¹é©æ€§åº¦', 5.0),
                'è·é›¢é©æ€§åº¦': row.get('è·é›¢é©æ€§åº¦', 5.0)
            })

        compat_df = pd.DataFrame(compat_data)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢ã«10ç‚¹æº€ç‚¹ã«å¤‰æ›æ¸ˆã¿ï¼‰
        heatmap_data = []
        for col in compatibility_cols:
            heatmap_data.append([val for val in compat_df[col]])

        fig_heatmap = go.Figure(data=go.Heatmap(
            z=heatmap_data,
            x=compat_df['é¦¬å'],
            y=compatibility_cols,
            colorscale='RdYlGn',
            text=[[f'{val:.1f}' for val in compat_df[col]] for col in compatibility_cols],
            texttemplate='%{text}',
            textfont={"size": 12},
            colorbar=dict(title="é©æ€§åº¦<br>(10ç‚¹æº€ç‚¹)")
        ))

        fig_heatmap.update_layout(
            title="é©æ€§åº¦ï¼ˆ10ç‚¹æº€ç‚¹ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰",
            xaxis_title="é¦¬å",
            height=300
        )

        st.plotly_chart(fig_heatmap, width="stretch")

        # 3. äºˆæ¸¬çµæœã®è§£é‡ˆã‚¬ã‚¤ãƒ‰
        with st.expander("â„¹ï¸ AIåˆ†ææŒ‡æ¨™ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯", expanded=False):
            st.markdown("""
            ### ğŸ§  AIæŒ‡æ¨™ã®èª­ã¿æ–¹ãƒ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
            
            **1. ğŸ“ˆ AIã‚¹ã‚³ã‚¢ (AIå‹ç‡äºˆæ¸¬)**
            *   **æ„å‘³**: éå»ã®è†¨å¤§ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€AIãŒç®—å‡ºã—ãŸã€Œç´”ç²‹ãªå‹åˆ©ç¢ºç‡ã€ã§ã™ã€‚
            *   **ç‰¹å¾´**: ã‚ªãƒƒã‚ºã‚„äººæ°—ï¼ˆéå‰°è©•ä¾¡ï¼‰ã«å·¦å³ã•ã‚Œãšã€é¦¬ã®æœ¬æ¥ã®å®ŸåŠ›ã¨é©æ€§ã ã‘ã§è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚
            *   **ä¿¡é ¼æ€§**: æœªæ¥ã®æƒ…å ±ï¼ˆãƒ¬ãƒ¼ã‚¹çµæœï¼‰ã‚’å«ã¾ãªã„å³å¯†ãªå­¦ç¿’ã‚’è¡Œã£ã¦ã„ã‚‹ãŸã‚ã€æ¥µã‚ã¦å®¢è¦³çš„ã§ã™ã€‚

            **2. ğŸ›¡ï¸ ä¿¡é ¼åº¦ (Confidence)**
            *   **æ„å‘³**: ã€Œã“ã®äºˆæ¸¬ã«ä¹—ã£ã‹ã£ã¦ã‚‚å¤§ä¸ˆå¤«ã‹ã€ã¨ã„ã†å®‰å¿ƒæ„Ÿã‚’ç¤ºã™ç‹¬è‡ªã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰ã§ã™ã€‚
            *   **ç®—å‡ºãƒ­ã‚¸ãƒƒã‚¯**: 
                *   AIã®ç¢ºä¿¡åº¦ï¼ˆç¢ºç‡ã®å¼·ã•ï¼‰
                *   ãƒ‡ãƒ¼ã‚¿é‡ï¼ˆéå»ã®ãƒ¬ãƒ¼ã‚¹æ•°ï¼‰
                *   é©æ€§ã®ä¸€è‡´åº¦ï¼ˆå¾—æ„ãªé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ã‹ï¼‰
                *   ãƒªã‚¹ã‚¯è¦å› ï¼ˆé•·æœŸä¼‘é¤Šæ˜ã‘ãªã©ã¯æ¸›ç‚¹ï¼‰
            *   **æ´»ç”¨æ³•**: AIã‚¹ã‚³ã‚¢ãŒé«˜ãã¦ã‚‚ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯ã€ä¸ç¢ºå®šè¦ç´ ï¼ˆåˆå‡ºèµ°ãªã©ï¼‰ãŒå¤šã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚

            **3. ğŸ’° èª¿æ•´å¾ŒæœŸå¾…å€¤ (Adjusted EV)**
            *   **æ„å‘³**: ã€ŒæŠ•è³‡å¯¾è±¡ã¨ã—ã¦ã®ãŠã„ã—ã•ã€ã‚’ç¤ºã™æœ€é‡è¦æŒ‡æ¨™ã§ã™ã€‚
            *   **è¨ˆç®—å¼**: `(è£œæ­£å¾ŒAIç¢ºç‡ Ã— å°ã®é‡ã¿ Ã— ã‚ªãƒƒã‚º) - 1.0`
            *   **è£œæ­£å†…å®¹ã«ã¤ã„ã¦**:
                *   **ã‚³ãƒ¼ã‚¹ç‰¹æ€§**: ä¼šå ´ã”ã¨ã®æœ‰åˆ©ä¸åˆ©ï¼ˆå¤–æ æœ‰åˆ©ã€é€ƒã’æœ‰åˆ©ãªã©ï¼‰ã‚’è‡ªå‹•è£œæ­£ã—ã¦ã„ã¾ã™ï¼ˆã‚°ãƒ©ãƒ•ä¸‹ã®è¡¨ã§ç¢ºèªå¯èƒ½ï¼‰ã€‚
                *   **å°ã®é‡ã¿**: ã‚ãªãŸã®å…¥åŠ›ã—ãŸäºˆæƒ³å°ï¼ˆâ—=1.3å€ãªã©ï¼‰ã‚‚åæ˜ ã•ã‚Œã¾ã™ã€‚
            *   **ç‹™ã„ç›®**: ã“ã®æ•°å€¤ãŒãƒ—ãƒ©ã‚¹ï¼ˆç·‘è‰²ï¼‰ã®é¦¬ã¯ã€çµ±è¨ˆçš„ã«ã‚‚ä¸»è¦³çš„ã«ã‚‚ã€Œè²·ã†ä¾¡å€¤ã‚ã‚Šã€ã¨åˆ¤æ–­ã•ã‚ŒãŸé¦¬ã§ã™ã€‚

            **4. é©æ€§åº¦ï¼ˆé¨æ‰‹ãƒ»ã‚³ãƒ¼ã‚¹ãƒ»è·é›¢ï¼‰**
            - **å…¨æœŸé–“ï¼ˆ3å¹´é–“ï¼‰ã®Global History**ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—
            - å¹³å‡ç€é †ã‚’10ç‚¹æº€ç‚¹ã‚¹ã‚³ã‚¢ã«å¤‰æ›: `10 - (å¹³å‡ç€é † / 2)`
            - **æ•°å€¤ãŒé«˜ã„ã»ã©è‰¯ã„** (10ç‚¹=å¹³å‡1ç€, 5ç‚¹=å¹³å‡10ç€)
            - **7.0ç‚¹ä»¥ä¸Š**: å„ªç§€ (å¹³å‡ç€é † 6ç€ä»¥å†…)
            - **5.0ç‚¹**: æ¨™æº– (ãƒ‡ãƒ¼ã‚¿ãªã—ã€ã¾ãŸã¯å¹³å‡10ç€)
            - **3.0ç‚¹ä»¥ä¸‹**: ä¸å®‰ (å¹³å‡14ç€ä»¥ä¸‹)

            **5. ã‚³ãƒ¼ã‚¹ç‰¹æ€§ï¼ˆå‚¾æ–œãƒ»ç›´ç·šè·é›¢ãƒ»ã‚³ãƒ¼ã‚¹å¹…ãƒ»æ ç•ªï¼‰**
            - **å‹¾é…ï¼ˆå‚¾æ–œï¼‰**: æ€¥å‚ã‚ã‚Šã®ç«¶é¦¬å ´ã§ã¯äººæ°—é¦¬ãŒæœ‰åˆ©ï¼ˆ+2%ï¼‰
              - ä¸­å±±ã€é˜ªç¥ãªã©: å‚ã§ãƒ‘ãƒ¯ãƒ¼ãŒå¿…è¦ãªãŸã‚å®Ÿç¸¾é¦¬ãŒå„ªä½
            - **ç›´ç·šè·é›¢**:
              - é•·ã„ç›´ç·šï¼ˆ500mä»¥ä¸Šï¼‰: å·®ã—é¦¬æœ‰åˆ©ã€ç©´é¦¬ãƒãƒ£ãƒ³ã‚¹ï¼ˆäººæ°—é¦¬-5%ã€ç©´é¦¬+5%ï¼‰
              - çŸ­ã„ç›´ç·šï¼ˆ300mæœªæº€ï¼‰: é€ƒã’ãƒ»å…ˆè¡Œé¦¬æœ‰åˆ©ã€äººæ°—é¦¬å …ã„ï¼ˆäººæ°—é¦¬+5%ï¼‰
            - **ã‚³ãƒ¼ã‚¹å¹…**:
              - å°å›ã‚Šã‚³ãƒ¼ã‚¹: ã‚³ãƒ¼ãƒŠãƒ¼ãŒå¤šãå™¨ç”¨ãªé¦¬ãŒæœ‰åˆ©ï¼ˆäººæ°—é¦¬+3%ï¼‰
            - **æ ç•ªå‚¾å‘**:
              - å¤–æ æœ‰åˆ©ãªç«¶é¦¬å ´: 6-8æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´
              - å†…æ æœ‰åˆ©ãªç«¶é¦¬å ´: 1-3æ ã®ç¢ºç‡ã‚’ä¸Šæ–¹èª¿æ•´

            âš ï¸ **ã“ã‚Œã‚‰ã®ã‚³ãƒ¼ã‚¹ç‰¹æ€§ã¯ã€ãƒ¬ãƒ¼ã‚¹æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™**

            ### ğŸ¯ æ¨å¥¨ã•ã‚Œã‚‹ä½¿ã„æ–¹

            1. **TOP5ã‚°ãƒ©ãƒ•**ã§AIè©•ä¾¡ã®é«˜ã„é¦¬ã‚’ç¢ºèª
            2. **æœŸå¾…å€¤(EV)ãŒãƒ—ãƒ©ã‚¹**ã®é¦¬ã«æ³¨ç›®
            3. **ä¿¡é ¼åº¦ãŒ70%ä»¥ä¸Š**ã®äºˆæ¸¬ã‚’å„ªå…ˆ
            4. **é©æ€§åº¦**ã§ç›¸æ€§ã‚’ç¢ºèªï¼ˆç‰¹ã«é¨æ‰‹é©æ€§åº¦ã¯é‡è¦ï¼‰
            5. **ç¾åœ¨ã‚ªãƒƒã‚º**ã¨**äºˆæƒ³å°**ã‚’å…¥åŠ›ã—ã¦EVã‚’æœ€çµ‚èª¿æ•´

            ### âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

            - **ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå¿…è¦**: ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€Œ3ç€ä»¥å†…ã€ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
            - ç®¡ç†ãƒšãƒ¼ã‚¸ã§ä¸¡ãƒ¢ãƒ‡ãƒ«ï¼ˆJRA/NARï¼‰ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„
            - å†å­¦ç¿’å¾Œã€AIç¢ºç‡ã¯5-15%ã®ç¯„å›²ï¼ˆ1ç€ç¢ºç‡ã¨ã—ã¦å¦¥å½“ï¼‰ã«ãªã‚Šã¾ã™
            """)

        st.markdown("---")
        st.markdown("---")
        st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")

        # Rename for clarity if exists
        if 'AIæœŸå¾…å€¤' in edited_df.columns:
            edited_df.rename(columns={'AIæœŸå¾…å€¤': 'å˜å‹æœŸå¾…å€¤'}, inplace=True)


        # Highlight high EV and Kelly
        def highlight_ev(s):
            is_high = s > 0
            return ['background-color: #d4edda' if v else '' for v in is_high]

        # Select and Order Columns for Hit Rate Focus
        display_cols = [
            'äºˆæƒ³å°', 'æ ', 'é¦¬ ç•ª', 'é¦¬å', 
            'AIã‚¹ã‚³ã‚¢(%)', 'ä¿¡é ¼åº¦', 
            'jockey_compatibility', 'time_stats', 
            'ç¾åœ¨ã‚ªãƒƒã‚º', 'å˜å‹æœŸå¾…å€¤', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'æ¨å¥¨åº¦(Kelly)'
        ]
        # Filter existing columns
        display_cols = [c for c in display_cols if c in edited_df.columns]
        
        st.dataframe(
            edited_df[display_cols].style
            .format({
                'æ¨å¥¨åº¦(Kelly)': lambda x: '-' if x <= 0 else f'{x:.1f}%',
                'å˜å‹æœŸå¾…å€¤': '{:.2f}',
                'èª¿æ•´å¾ŒæœŸå¾…å€¤': '{:.2f}',
                'AIã‚¹ã‚³ã‚¢(%)': '{:.1f}',
                'ä¿¡é ¼åº¦': '{:.0f}'
            })
            .map(lambda x: 'background-color: #d4edda' if x > 0 else '', subset=['å˜å‹æœŸå¾…å€¤', 'èª¿æ•´å¾ŒæœŸå¾…å€¤', 'æ¨å¥¨åº¦(Kelly)'])
        )



        # Visualization
        st.markdown("---")
        st.subheader("ğŸ” å€‹åˆ¥é¦¬ã®è©³ç´°åˆ†æ")

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼šé¦¬ã®è©³ç´°åˆ†æã‚’ç”Ÿæˆ
        def create_horse_analysis(horse_name, df_display, edited_df):
            """å€‹åˆ¥é¦¬ã®èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆã¨éå»5èµ°ã®æ¨ç§»ã‚’ç”Ÿæˆ"""
            # Find row
            row = df_display[df_display['é¦¬å'] == horse_name].iloc[0]

            # --- Scoring Logic (Lower rank is better, so Invert) ---
            # --- Scoring Logic (Lower rank is better, so Invert) ---
            def rank_to_score(r):
                if pd.isna(r) or r > 18: return 0
                # Use same logic as table: 10 - (Rank / 2)
                # Rank 1 -> 9.5
                # Rank 10 -> 5.0
                return max(0, min(10, 10 - (r / 2)))

            # Calculate scores
            sp_val = row.get('weighted_avg_speed', 16.0)
            score_speed = max(0, min(10, (sp_val - 15.0) * 5))
            j_val = row.get('jockey_compatibility', 10.0) # Raw Rank
            score_jockey = rank_to_score(j_val)
            c_val = row.get('course_compatibility', 10.0) # Raw Rank
            score_course = rank_to_score(c_val)
            d_val = row.get('distance_compatibility', 10.0) # Raw Rank
            score_dist = rank_to_score(d_val)
            rank_val = row.get('weighted_avg_rank', 10.0) # Raw Rank
            score_form = rank_to_score(rank_val)

            # Radar Chart
            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=[score_speed, score_form, score_jockey, score_course, score_dist, score_speed],
                theta=['ã‚¹ãƒ”ãƒ¼ãƒ‰', 'å®Ÿç¸¾(ç€é †)', 'é¨æ‰‹ç›¸æ€§', 'ã‚³ãƒ¼ã‚¹é©æ€§', 'è·é›¢é©æ€§'],
                fill='toself',
                name=horse_name,
                line=dict(color='#1f77b4')
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 10])),
                height=300,
                margin=dict(l=40, r=40, t=40, b=40)
            )

            # Past 5 Runs Line Chart
            history_data = []
            for i in range(5, 0, -1):
                if f"past_{i}_rank" in row and pd.notna(row[f"past_{i}_rank"]):
                    history_data.append({
                        "Run": f"{i}èµ°å‰",
                        "ç€é †": row[f"past_{i}_rank"],
                        "3Fã‚¿ã‚¤ãƒ ": row[f"past_{i}_last_3f"]
                    })

            if history_data:
                hist_df = pd.DataFrame(history_data)
                from plotly.subplots import make_subplots
                fig_line = make_subplots(specs=[[{"secondary_y": True}]])
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['ç€é †'], name="ç€é †", mode='lines+markers', line=dict(color='#ff7f0e')), secondary_y=False)
                fig_line.add_trace(go.Scatter(x=hist_df['Run'], y=hist_df['3Fã‚¿ã‚¤ãƒ '], name="ä¸Šã‚Š3F", mode='lines+markers', line=dict(dash='dot', color='#2ca02c')), secondary_y=True)
                fig_line.update_layout(height=300, margin=dict(l=40, r=40, t=40, b=40))
                fig_line.update_yaxes(title_text="ç€é †", autorange="reversed", secondary_y=False)
                fig_line.update_yaxes(title_text="ä¸Šã‚Š3F (ç§’)", secondary_y=True)
            else:
                fig_line = go.Figure()
                fig_line.add_annotation(text="éå»ãƒ‡ãƒ¼ã‚¿ãªã—")
                fig_line.update_layout(height=300)

            # Get prediction summary
            pred_row = edited_df[edited_df['é¦¬å'] == horse_name].iloc[0]

            return fig_radar, fig_line, pred_row

        try:
            # === åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠ ===
            st.info("ğŸ’¡ åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è©•ä¾¡ä¸Šä½5é ­ï¼‰")

            # Get all horses sorted by AI Score
            all_horses = edited_df.sort_values('AIã‚¹ã‚³ã‚¢(%)', ascending=False)['é¦¬å'].tolist()
            default_horses = top5_df['é¦¬å'].tolist()
            
            # Ensure default horses are in the options (sanity check)
            default_horses = [h for h in default_horses if h in all_horses]

            selected_horses = st.multiselect(
                "åˆ†æå¯¾è±¡ã®é¦¬ã‚’é¸æŠ",
                options=all_horses,
                default=default_horses
            )

            for idx, horse_name in enumerate(selected_horses):
                with st.expander(f"**{idx+1}ä½: {horse_name}**", expanded=(idx < 2)):  # 1-2ä½ã¯å±•é–‹è¡¨ç¤º
                    fig_radar, fig_line, pred_row = create_horse_analysis(horse_name, df_display, edited_df)

                    # Prediction Summary
                    col_s1, col_s2, col_s3, col_s4, col_s5 = st.columns(5)
                    with col_s1:
                        st.metric("AIå‹ç‡", f"{pred_row['AIã‚¹ã‚³ã‚¢(%)']}%")
                    with col_s2:
                        st.metric("ä¿¡é ¼åº¦", f"{pred_row['ä¿¡é ¼åº¦']}%")
                    with col_s3:
                        ai_ev_val = pred_row.get('å˜å‹æœŸå¾…å€¤', 0.0)
                        st.metric("å˜å‹æœŸå¾…å€¤", f"{ai_ev_val:.2f}")
                    with col_s4:
                        adj_ev_val = pred_row['èª¿æ•´å¾ŒæœŸå¾…å€¤']
                        ev_delta = "è²·ã„æ¨å¥¨" if adj_ev_val > 0 else "è¦‹é€ã‚Š"
                        st.metric("èª¿æ•´å¾ŒEV", f"{adj_ev_val:.2f}", delta=ev_delta)
                    with col_s5:
                        odds_val = pred_row.get('ç¾åœ¨ã‚ªãƒƒã‚º', 0.0)
                        st.metric("ã‚ªãƒƒã‚º", f"{odds_val:.1f}å€")

                    # Charts
                    col_c1, col_c2 = st.columns(2)
                    with col_c1:
                        st.markdown("**èƒ½åŠ›ãƒãƒ£ãƒ¼ãƒˆ**")
                        st.plotly_chart(fig_radar, width="stretch", key=f"radar_{idx}_{horse_name}")
                    with col_c2:
                        st.markdown("**éå»5èµ°ã®æ¨ç§»**")
                        st.plotly_chart(fig_line, width="stretch", key=f"line_{idx}_{horse_name}")

            # === ãŠã™ã™ã‚ã®è²·ã„æ–¹ææ¡ˆ ===
            st.markdown("---")
            st.subheader("ğŸ« AIãŠã™ã™ã‚ã®è²·ã„æ–¹")
            
            # Budget Input
            budget = st.number_input("ğŸ’° äºˆç®— (å††)", min_value=100, step=100, value=1000, help="ã“ã®äºˆç®—ã«åˆã‚ã›ã¦è³¼å…¥é‡‘é¡ã‚’é…åˆ†ã—ã¾ã™")

            # Logic for betting recommendations
            if ranking_criteria == "å›åç‡é‡è¦– (æœŸå¾…å€¤)":
                 sorted_df = edited_df.sort_values('èª¿æ•´å¾ŒæœŸå¾…å€¤', ascending=False)
                 allow_negative_ev = False
            else:
                 sorted_df = edited_df.sort_values('AIã‚¹ã‚³ã‚¢(%)', ascending=False)
                 allow_negative_ev = True

            top1 = sorted_df.iloc[0]
            top2 = sorted_df.iloc[1] if len(sorted_df) > 1 else None
            top3 = sorted_df.iloc[2] if len(sorted_df) > 2 else None
            
            # Helper for circled numbers
            def to_circled_num(n):
                try:
                    val = int(float(n)) # Handle float 1.0 -> 1
                    if 1 <= val <= 20:
                        return chr(9311 + val)
                    return f"({val})"
                except:
                    return ""

            # Helper to format horse name with circle num
            def fmt_horse(row):
                # Try both column names
                num = row.get('é¦¬ ç•ª')
                if pd.isna(num):
                    num = row.get('é¦¬ç•ª', '')
                
                name = row['é¦¬å']
                
                # Format: "â‘¦ ã‚¦ãƒãƒ¡ã‚¤" or "(7) ã‚¦ãƒãƒ¡ã‚¤" or just "ã‚¦ãƒãƒ¡ã‚¤" if no num
                c_num = to_circled_num(num)
                if c_num:
                    return f"{c_num} {name}".strip()
                elif pd.notna(num) and str(num).strip():
                     return f"({num}) {name}".strip()
                else:
                    return name

            # Cards Layout
            col_bet1, col_bet2, col_bet3 = st.columns(3)

            # 1. ğŸ¯ Tankei (Tansho/Fukusho)
            with col_bet1:
                st.markdown("#### ğŸ¯ å˜ç³» (WIN/PLACE)")
                # Relax EV constraint for Hit Rate focus
                if top1['AIã‚¹ã‚³ã‚¢(%)'] >= 10 and top1['ä¿¡é ¼åº¦'] >= 60 and (allow_negative_ev or top1['èª¿æ•´å¾ŒæœŸå¾…å€¤'] > 0):
                    bet_type = "å˜å‹ (WIN)" if top1['AIã‚¹ã‚³ã‚¢(%)'] >= 20 else "è¤‡å‹ (PLACE)"
                    
                    # Allocation: 50% of budget for Tankei focus
                    amount = int((budget * 0.5) / 100) * 100
                    if amount < 100: amount = 100
                    
                    st.success(f"**{bet_type}**")
                    st.metric(fmt_horse(top1), f"{amount}å††", delta=f"EV: {top1['èª¿æ•´å¾ŒæœŸå¾…å€¤']:.2f}")
                    st.caption(f"ä¿¡é ¼åº¦: {top1['ä¿¡é ¼åº¦']}%")
                else:
                    st.info("æ¡ä»¶ã«åˆã†è»¸é¦¬ãŒã„ã¾ã›ã‚“")
                    st.caption("è¦‹é€ã‚Š (No Bet)")

            # 2. ğŸ”„ Renkei (Umaren/Wide)
            with col_bet2:
                st.markdown("#### ğŸ”„ é€£ç³» (EXACTA/WIDE)")
                if top1['AIã‚¹ã‚³ã‚¢(%)'] >= 30:
                    # Solid Favorite -> Nagashi
                    st.success("**é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ æµã—**")
                    targets = []
                    if top2 is not None: targets.append(fmt_horse(top2))
                    if top3 is not None: targets.append(fmt_horse(top3))
                    
                    # Allocation: Budget / points
                    points = len(targets)
                    if points > 0:
                        amount_per_point = int((budget / points) / 100) * 100 
                        if amount_per_point < 100: amount_per_point = 100
                        st.write(f"è»¸: **{fmt_horse(top1)}**")
                        st.write(f"ç´: {', '.join(targets)}")
                        st.metric("1ç‚¹ã‚ãŸã‚Š", f"{amount_per_point}å††", help=f"åˆè¨ˆ {(amount_per_point * points)}å††")
                    else:
                        st.write("ç›¸æ‰‹é¦¬ä¸è¶³")
                elif top1['AIã‚¹ã‚³ã‚¢(%)'] < 20:
                     # Confused -> Box
                     st.warning("**é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ BOX**")
                     box_horses = [fmt_horse(row) for i, row in sorted_df.head(5).iterrows()][:4] # Top 4 box = 6 points
                     
                     points = 6 # 4C2
                     amount_per_point = int((budget / points) / 100) * 100
                     if amount_per_point < 100: amount_per_point = 100
                     
                     st.write(f"æ¨å¥¨: {', '.join(box_horses)}")
                     st.caption("æ··æˆ¦æ¨¡æ§˜ã§ã™")
                     st.metric("1ç‚¹ã‚ãŸã‚Š", f"{amount_per_point}å††", help=f"4é ­BOX (6ç‚¹): {amount_per_point * 6}å††")
                else:
                     st.info("**é¦¬é€£ ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**")
                     st.caption("é©å®œèª¿æ•´ã—ã¦ãã ã•ã„")
                     st.write(f"1åˆ—ç›®: {fmt_horse(top1)}")
                     targets = []
                     if top2 is not None: targets.append(fmt_horse(top2))
                     if top3 is not None: targets.append(fmt_horse(top3))
                     st.write(f"2åˆ—ç›®: {', '.join(targets)}")

            # 3. ğŸ§¨ Aname (Longshot)
            with col_bet3:
                st.markdown("#### ğŸ§¨ ç©´ç›® (LONGSHOT)")
                # Find high EV but low probability (Score < 15%)
                longshots = sorted_df[
                    (sorted_df['AIã‚¹ã‚³ã‚¢(%)'] < 15) & 
                    (sorted_df['èª¿æ•´å¾ŒæœŸå¾…å€¤'] > 0.3) &
                    (sorted_df['ä¿¡é ¼åº¦'] >= 40)
                ]
                
                if not longshots.empty:
                    ls_horse = longshots.iloc[0]
                    st.error(f"**ç‹™ã„ç›®: {fmt_horse(ls_horse)}**")
                    st.metric("æœŸå¾…å€¤", f"{ls_horse['èª¿æ•´å¾ŒæœŸå¾…å€¤']:.2f}", delta="High EV")
                    st.write(f"å˜ã‚ªãƒƒã‚º: {ls_horse.get('ç¾åœ¨ã‚ªãƒƒã‚º', 0)}å€")
                    st.caption("ãƒ¯ã‚¤ãƒ‰ãƒ»è¤‡å‹ã®ç´ã«æ¨å¥¨")
                else:
                    st.info("æ¨å¥¨ã§ãã‚‹ç©´é¦¬ãªã—")
                    st.caption("å …ã„æ±ºç€ã®å¯èƒ½æ€§å¤§")
                    
        except Exception as e:
            st.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.text(traceback.format_exc())
