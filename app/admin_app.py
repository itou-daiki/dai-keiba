import streamlit as st
import subprocess
import os
import sys
import pandas as pd
from datetime import date, datetime
import time
import plotly.graph_objects as go

# Add ml to path
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'ml'))
try:
    import train_model
    import feature_engineering
    import importlib
    importlib.reload(train_model)
    importlib.reload(feature_engineering)
except ImportError:
    st.error("Failed to import train_model. Make sure ml/train_model.py exists.")

# Set page config
st.set_page_config(page_title="JRA ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ‘ãƒãƒ«", layout="wide")

st.title("ğŸ‡ JRA ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç®¡ç†ãƒ‘ãƒãƒ«")

# --- UI Layout ---
st.markdown("### âš™ï¸ è¨­å®š")

mode_option = st.radio("é–‹å‚¬ãƒ¢ãƒ¼ãƒ‰ (Mode)", ["JRA (ä¸­å¤®ç«¶é¦¬)", "NAR (åœ°æ–¹ç«¶é¦¬)"], index=0)
mode_val = "JRA" if "JRA" in mode_option else "NAR"
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Target filenames based on mode
if mode_val == "NAR":
    csv_filename = "database_nar.parquet"
    target_parquet = os.path.join(project_root, "data", "raw", "database_nar.parquet")
    target_csv = os.path.join(project_root, "data", "raw", "database_nar.csv")
    model_name = "lgbm_model_nar.pkl"
    processed_data_path = os.path.join(project_root, "ml", "processed_data_nar.parquet")
else:
    csv_filename = "database.parquet"
    target_parquet = os.path.join(project_root, "data", "raw", "database.parquet")
    target_csv = os.path.join(project_root, "data", "raw", "database.csv")
    model_name = "lgbm_model.pkl"
    processed_data_path = os.path.join(project_root, "ml", "processed_data.parquet")

st.markdown("---")

# --- 1. Data Management Section (Top Priority) ---
st.markdown("## ğŸ› ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç† (Data Management)")

# 1.1 Upload
st.markdown("### ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (CSV)")
uploaded_file = st.file_uploader("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹CSV (database.csvãªã©) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"], key="uploader")

if uploaded_file is not None:
    if st.button("å¤‰æ›ã—ã¦ä¿å­˜ (CSV -> Parquet)", type="primary"):
        with st.spinner("CSVã‚’èª­ã¿è¾¼ã¿ã€Parquetã«å¤‰æ›ä¸­..."):
            try:
                df_upload = pd.read_csv(uploaded_file, low_memory=False, dtype={'horse_id': str, 'race_id': str})
                
                # Save as CSV (Raw)
                df_upload.to_csv(target_csv, index=False)
                st.success(f"âœ… CSVä¿å­˜å®Œäº†: {os.path.basename(target_csv)}")
                
                # Save as Parquet
                df_upload.to_parquet(target_parquet, compression='snappy', index=False)
                st.success(f"âœ… Parquetå¤‰æ›ãƒ»ä¿å­˜å®Œäº†: {os.path.basename(target_parquet)}")
            except Exception as e:
                st.error(f"å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")

st.markdown("---")

# 1.2 Preview
st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
if os.path.exists(target_parquet):
    try:
        df = pd.read_parquet(target_parquet)
        st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•° (è¡Œ)", len(df))
        st.caption("â€»ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã„ãŸã‚ã€æœ€æ–°ã®1000ä»¶ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
        st.dataframe(df.tail(1000), width='stretch')
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.warning(f"{csv_filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

st.caption("ä½¿ã„æ–¹: Colabã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—å¾Œã€ã“ã“ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€GitçµŒç”±ã§åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚")

st.markdown("---")

st.markdown("---")

# --- 2. D-Index Optimization Section ---
st.markdown("## âš–ï¸ DæŒ‡æ•° é‡ã¿æœ€é©åŒ– (D-Index Optimization)")
st.info("ğŸ’¡ éå»ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€DæŒ‡æ•°ã®æ§‹æˆè¦ç´ ï¼ˆAIæŒ‡æ•°ã€é©æ€§æŒ‡æ•°ã€è¡€çµ±æŒ‡æ•°ï¼‰ã®æœ€é©ãªé‡ã¿é…åˆ†ã‚’ç®—å‡ºã—ã¾ã™ã€‚")

# 2.1 Settings
st.markdown("### æœŸé–“è¨­å®š")
period_opt = st.selectbox("æ¤œè¨¼æœŸé–“ (Verification Period)", ["ç›´è¿‘1å¹´é–“ (Recommended)", "ç›´è¿‘3å¹´é–“", "å…¨æœŸé–“"], index=0)

# Load current weights
current_weights = {'ai': 0.4, 'compat': 0.5, 'blood': 0.1}
d_index_conf_path = os.path.join(project_root, "config", "d_index_config.json")
if os.path.exists(d_index_conf_path):
    try:
        with open(d_index_conf_path, 'r') as f:
            current_weights = json.load(f)
    except:
        pass
        
st.markdown("### ç¾åœ¨ã®é‡ã¿")
st.write(current_weights)

st.markdown("---")

# 2.2 Action
st.markdown("### ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
if st.button("âš–ï¸ é‡ã¿ã‚’æœ€é©åŒ–ã™ã‚‹ (Optimize Weights)", type="primary"):
    with st.spinner("æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­... (ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
        try:
            # 1. Load Data
            if not os.path.exists(processed_data_path):
                st.error("å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€ŒMLOpsã€ã§å‰å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            df_proc = pd.read_parquet(processed_data_path)
            
            # 2. Filter Period
            df_proc['date'] = pd.to_datetime(df_proc['date'])
            max_date = df_proc['date'].max()
            
            if "1å¹´é–“" in period_opt:
                start_date = max_date - pd.Timedelta(days=365)
                df_proc = df_proc[df_proc['date'] >= start_date]
            elif "3å¹´é–“" in period_opt:
                start_date = max_date - pd.Timedelta(days=365*3)
                df_proc = df_proc[df_proc['date'] >= start_date]
            
            st.write(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_proc)} rows (æœŸé–“: {df_proc['date'].min().date()} ~ {df_proc['date'].max().date()})")

            # 3. Optimize (Inline logic for now, using scoring.py)
            import scoring
            importlib.reload(scoring)
            import optuna
            from sklearn.metrics import roc_auc_score
            
            def objective(trial):
                # 1. Top Level Weights
                w_ai = trial.suggest_float('ai', 0.0, 1.0)
                w_compat = trial.suggest_float('compat', 0.0, 1.0)
                w_blood = trial.suggest_float('blood', 0.0, 1.0)
                
                # 2. Sub Weights for Compatibility
                w_jockey = trial.suggest_float('jockey', 0.0, 1.0)
                w_dist = trial.suggest_float('distance', 0.0, 1.0)
                w_course = trial.suggest_float('course', 0.0, 1.0)

                # Normalize constraints
                top_sum = w_ai + w_compat + w_blood
                if top_sum == 0: return 0.0
                
                sub_sum = w_jockey + w_dist + w_course
                if sub_sum == 0: return 0.0

                # Create config dict
                config = {
                    'top_level': {
                        'ai': w_ai / top_sum,
                        'compat': w_compat / top_sum,
                        'blood': w_blood / top_sum
                    },
                    'compat_sub_weights': {
                        'jockey': w_jockey / sub_sum,
                        'distance': w_dist / sub_sum,
                        'course': w_course / sub_sum
                    }
                }
                
                # Calculate D-Scores for all rows
                # We need to compute Compat_Index DYNAMICALLY based on sub-weights
                
                # Vectorized Calc for Speed
                # Extract columns
                j_compat = df_proc.get('jockey_compatibility', 0).fillna(0)
                d_compat = df_proc.get('distance_compatibility', 0).fillna(0)
                c_compat = df_proc.get('course_compatibility', 0).fillna(0)
                
                # Calculate Dynamic Compat Index
                # Weighted Sum
                compat_scores = (j_compat * config['compat_sub_weights']['jockey']) + \
                                (d_compat * config['compat_sub_weights']['distance']) + \
                                (c_compat * config['compat_sub_weights']['course'])
                
                # Note: Original logic was specialized (ranking average). 
                # For optimization speed, we approximate: 
                # If the inputs are already 0-100 or ranks, we must handle carefully.
                # Looking at public_app logic: compatibility is RANK based (1-18).
                # So we need to average the Ranks, then Normalize.
                
                avg_rank = compat_scores # Since weights sum to 1.0
                
                # Convert Rank to Score (0-100)
                # score = (18.0 - avg_rank) / 17.0 * 100
                compat_index_vec = (18.0 - avg_rank) / 17.0 * 100
                compat_index_vec = compat_index_vec.clip(0, 100)
                
                # Bloodline Index (Fixed logic usually, but can re-calc if needed)
                if 'Bloodline_Index' not in df_proc.columns:
                    df_proc['Bloodline_Index'] = df_proc.apply(scoring.calculate_bloodline_index, axis=1)
                
                # Final D-Index
                d_scores = (df_proc['AI_Score'] * config['top_level']['ai']) + \
                           (compat_index_vec * config['top_level']['compat']) + \
                           (df_proc['Bloodline_Index'] * config['top_level']['blood'])
                
                try:
                    auc = roc_auc_score(df_proc['target_win'], d_scores)
                    return auc
                except:
                    return 0.0

            study = optuna.create_study(direction='maximize')
            study.optimize(objective, n_trials=50) 
            
            # Extract Best Parameters
            best_p = study.best_params
            
            # Normalize Best Params to final config
            top_total = best_p['ai'] + best_p['compat'] + best_p['blood']
            sub_total = best_p['jockey'] + best_p['distance'] + best_p['course']
            
            final_config = {
                "top_level": {
                    "ai": round(best_p['ai'] / top_total, 3),
                    "compat": round(best_p['compat'] / top_total, 3),
                    "blood": round(best_p['blood'] / top_total, 3)
                },
                "compat_sub_weights": {
                    "jockey": round(best_p['jockey'] / sub_total, 3),
                    "distance": round(best_p['distance'] / sub_total, 3),
                    "course": round(best_p['course'] / sub_total, 3)
                }
            }
            
            st.success(f"âœ… è©³ç´°æœ€é©åŒ–å®Œäº†! Best AUC: {study.best_value:.4f}")
            
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("#### å¤§æ ã®é‡ã¿ (Top Level)")
                st.write(final_config['top_level'])
            with c2:
                st.markdown("#### é©æ€§æŒ‡æ•°ã®å†…è¨³ (Sub Weights)")
                st.write(final_config['compat_sub_weights'])
            
            # 4. Save
            if st.button("ğŸ’¾ ã“ã®è¨­å®šã‚’ä¿å­˜ã—ã¦é©ç”¨ã™ã‚‹"):
               with open(d_index_conf_path, 'w') as f:
                   json.dump(final_config, f, indent=4)
               st.success("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
               st.session_state['current_weights'] = final_config

        except Exception as e:
            st.error(f"æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.code(traceback.format_exc())

st.markdown("---")

# --- 3. MLOps Section (Training & Deploy) ---
st.markdown("## ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç† (MLOps)")

st.info("ğŸ’¡ **å…¨è‡ªå‹•ãƒ—ãƒ­ã‚»ã‚¹**: ãƒœã‚¿ãƒ³ä¸€ã¤ã§ã€Œå‰å‡¦ç† â†’ æœ€é©åŒ–(100å›) â†’ å­¦ç¿’ â†’ è¼ƒæ­£(Calibration) â†’ Git Pushã€ã¾ã§å®Ÿè¡Œã—ã¾ã™ã€‚")

# 2.1 Settings
st.markdown("### å­¦ç¿’è¨­å®š")
# All settings are fixed/default now
st.markdown("""
- **æœ€é©åŒ– (Optuna)**: âœ… ON (100 trials)
- **ç¢ºç‡è¼ƒæ­£ (Calibration)**: âœ… ON
- **å‰å‡¦ç†**: âœ… è‡ªå‹•å®Ÿè¡Œ
""")

auto_push = st.checkbox("å­¦ç¿’å®Œäº†å¾Œã€ãƒªãƒã‚¸ãƒˆãƒªã‚’è‡ªå‹•æ›´æ–° (Git Push)", value=True, help="å­¦ç¿’æˆåŠŸæ™‚ã«å¤‰æ›´ã‚’è‡ªå‹•çš„ã«ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã™")

st.markdown("---")

# 2.2 Action
st.markdown("### ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
if st.button("ğŸš€ ãƒ•ãƒ«å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ (æœ€é©åŒ–+è¼ƒæ­£+ãƒ‡ãƒ—ãƒ­ã‚¤)", type="primary", use_container_width=True):
    
    # Paths
    db_path = target_parquet
    data_path = processed_data_path
    
    model_dir = os.path.join(project_root, "ml", "models")
    os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, model_name)

    # 1. Preprocess
    with st.spinner("1/4 ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç† & çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­..."):
        if os.path.exists(db_path):
            # Calculate Features
            try:
                feature_engineering.calculate_features(db_path, data_path)
                
                # Export Stats
                import export_stats
                importlib.reload(export_stats)
                if export_stats.export_stats(mode=mode_val):
                    st.success("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿(Inferenceç”¨)ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
                else:
                    st.warning("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•— (å­¦ç¿’ã¯ç¶šè¡Œ)")
                    
                # Save to SQL DB (Optional but good for inspection)
                try:
                    import db_helper
                    importlib.reload(db_helper)
                    df_proc = pd.read_parquet(data_path)
                    db_path_sql = os.path.join(project_root, "keiba_data.db")
                    # Ensure file creation
                    conn_check = importlib.import_module("sqlite3").connect(db_path_sql)
                    conn_check.close()
                    db = db_helper.KeibaDatabase(db_path_sql)
                    db.save_processed_data(df_proc, mode=mode_val)
                except Exception as e:
                    print(f"SQL Save skipped: {e}")

            except Exception as e:
                st.error(f"å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                st.stop()
        else:
                st.error(f"{csv_filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                st.stop()

    # 2. Optimization
    n_trials = 100
    with st.spinner(f"2/4 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ä¸­ (Optuna {n_trials} trials)..."):
        try:
            opt_res = train_model.optimize_hyperparameters(data_path, n_trials=n_trials)
            if opt_res:
                st.success(f"æœ€é©åŒ–å®Œäº†: Best AUC {opt_res['best_auc']:.4f}")
                st.session_state['best_params'] = opt_res['best_params']
            else:
                st.warning("æœ€é©åŒ–ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ï¼‰")
        except Exception as e:
            st.error(f"æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()
    
    # 3. Training & Calibration
    with st.spinner("3/4 ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ & ç¢ºç‡è¼ƒæ­£ä¸­..."):
        params = st.session_state.get('best_params', None)
        try:
            # Force calibrate=True
            results = train_model.train_and_save_model(data_path, model_path, params=params, calibrate=True)
            if results:
                st.success("å­¦ç¿’å®Œäº†ï¼")
                st.session_state['ml_results'] = results
            else:
                st.error("å­¦ç¿’å¤±æ•—")
                st.stop()
        except Exception as e:
            st.error(f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()

    # 4. Auto Push
    if auto_push:
        with st.spinner("4/4 ãƒªãƒã‚¸ãƒˆãƒªæ›´æ–°ä¸­ (Git Push)..."):
            try:
                # Relative paths for git
                if mode_val == "NAR":
                    model_path_rel = "ml/models/lgbm_model_nar.pkl"
                else:
                    model_path_rel = "ml/models/lgbm_model.pkl"
                
                meta_path_rel = model_path_rel.replace('.pkl', '_meta.json')
                stats_path_rel = f"ml/models/feature_stats{'_nar' if mode_val == 'NAR' else ''}.pkl" # Stats file

                commit_msg = f"Auto-update model ({mode_val}): {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                
                cmds = [
                    ["git", "add", model_path_rel, meta_path_rel, stats_path_rel],
                    ["git", "commit", "-m", commit_msg],
                    ["git", "push", "origin", "main"]
                ]
                
                for cmd in cmds:
                    res = subprocess.run(cmd, cwd=project_root, capture_output=True, text=True)
                    if res.returncode != 0:
                        if "nothing to commit" not in (res.stdout + res.stderr).lower():
                            st.warning(f"Git Warning: {res.stderr}")
                
                st.success("âœ… å…¨ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ï¼ãƒªãƒã‚¸ãƒˆãƒªæ›´æ–°æ¸ˆã¿")
            except Exception as e:
                st.error(f"Git Push Error: {e}")


# --- Display Training Results ---
if 'ml_results' in st.session_state:
    st.markdown("---")
    res = st.session_state['ml_results']
    
    st.markdown("#### ğŸ“Š å­¦ç¿’çµæœãƒ¬ãƒãƒ¼ãƒˆ")
    m_col1, m_col2, m_col3 = st.columns(3)
    m_col1.metric("Accuracy", f"{res['accuracy']:.4f}")
    m_col2.metric("AUC", f"{res['auc']:.4f}")
    m_col3.metric("Positive Rate", f"{res.get('win_rate', 0.0):.2%}")
    
    # Feature Importance only (Learning Curve requires evals_result which might be bulky or different format now)
    if 'feature_importance' in res:
        fi = pd.DataFrame(res['feature_importance'])
        if not fi.empty:
            fig_fi = go.Figure(go.Bar(
                x=fi['Value'], y=fi['Feature'], orientation='h'
            ))
            fig_fi.update_layout(
                title="ç‰¹å¾´é‡é‡è¦åº¦ (Top 20)",
                yaxis=dict(autorange="reversed"),
                xaxis_title="Importance (Gain)",
                 height=600
            )
            st.plotly_chart(fig_fi, width="stretch")


